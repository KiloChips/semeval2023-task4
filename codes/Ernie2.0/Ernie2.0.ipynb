{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca3164b-c1b8-4284-88c7-a27fbb26403e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:00:38.793641Z",
     "iopub.status.busy": "2022-12-29T06:00:38.792945Z",
     "iopub.status.idle": "2022-12-29T06:00:41.850601Z",
     "shell.execute_reply": "2022-12-29T06:00:41.849543Z",
     "shell.execute_reply.started": "2022-12-29T06:00:38.793596Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.4.8)\r\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\r\n",
      "Requirement already satisfied: dill<0.3.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.3.3)\r\n",
      "Requirement already satisfied: fastapi in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.88.0)\r\n",
      "Requirement already satisfied: typer in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.7.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (12.6.0)\r\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (3.20.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.11.1)\r\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\r\n",
      "Requirement already satisfied: paddle2onnx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.7.0)\r\n",
      "Requirement already satisfied: paddlefsl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\r\n",
      "Requirement already satisfied: uvicorn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.20.0)\r\n",
      "Requirement already satisfied: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.4.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.1.96)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.64.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.19.5)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (4.2.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.1.5)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.1.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.8.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (10.0.0)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2022.11.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (5.1.2)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2.24.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (4.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (3.0.12)\r\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from fastapi->paddlenlp) (1.10.2)\r\n",
      "Requirement already satisfied: starlette==0.22.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from fastapi->paddlenlp) (0.22.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from starlette==0.22.0->fastapi->paddlenlp) (3.6.1)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (2.13.0)\r\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (0.9.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from typer->paddlenlp) (8.0.4)\r\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from uvicorn->paddlenlp) (0.14.0)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.16.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\r\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\r\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (8.2.0)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (3.0.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.1.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.7.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (6.0.2)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (0.13.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (22.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.9)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2019.9.11)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.25.11)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.0.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp) (3.8.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (2.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a1e9fa-ffa3-4b95-a409-79c6fc9b301d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:05:00.244071Z",
     "iopub.status.busy": "2022-12-29T06:05:00.243368Z",
     "iopub.status.idle": "2022-12-29T06:05:03.379817Z",
     "shell.execute_reply": "2022-12-29T06:05:03.378713Z",
     "shell.execute_reply.started": "2022-12-29T06:05:00.244020Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import paddle\n",
    "import paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b12a32a-0270-4a6c-8ae5-96807a5ec43d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:06:58.835237Z",
     "iopub.status.busy": "2022-12-29T06:06:58.834631Z",
     "iopub.status.idle": "2022-12-29T06:06:58.843078Z",
     "shell.execute_reply": "2022-12-29T06:06:58.842335Z",
     "shell.execute_reply.started": "2022-12-29T06:06:58.835196Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 自定义数据集\n",
    "import re\n",
    "\n",
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "# 清洗无效字符\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\r\", \"\").replace(\"\\n\", \"\")\n",
    "    text = re.sub(r\"\\\\n\\n\", \".\", text)\n",
    "    return text\n",
    "\n",
    "# 定义读取数据集函数\n",
    "def read_custom_data(filepath):\n",
    "    f = open(filepath)\n",
    "    next(f)\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        data = line.strip().split('\\t')\n",
    "        labels = [float(d) for d in data[2:]]\n",
    "        yield {\"Argument ID\": data[0], \"sentence\":clean_text(data[1]),\"labels\": labels}\n",
    "    f.close()\n",
    "\n",
    "def read_custom_data_test(filepath):\n",
    "    f = open(filepath)\n",
    "    next(f)\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        data = line.strip().split('\\t')\n",
    "        yield {\"Argument ID\": data[0], \"sentence\":clean_text(data[1]),\"labels\":[]}\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6f05f6-7c04-4e86-ab9e-2b6def788879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:03.473117Z",
     "iopub.status.busy": "2022-12-29T06:07:03.472474Z",
     "iopub.status.idle": "2022-12-29T06:07:03.479868Z",
     "shell.execute_reply": "2022-12-29T06:07:03.479185Z",
     "shell.execute_reply.started": "2022-12-29T06:07:03.473075Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data\r\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ccc796-42d7-447e-bd45-9d693005ec60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:05.010925Z",
     "iopub.status.busy": "2022-12-29T06:07:05.009847Z",
     "iopub.status.idle": "2022-12-29T06:07:05.084277Z",
     "shell.execute_reply": "2022-12-29T06:07:05.083171Z",
     "shell.execute_reply.started": "2022-12-29T06:07:05.010886Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load_dataset()创建数据集\n",
    "# lazy=False，数据集返回为MapDataset类型\n",
    "# 对训练集和验证集进行预处理\n",
    "train_ds = load_dataset(read_custom_data, filepath='train.tsv', lazy=False) \n",
    "valid_ds = load_dataset(read_custom_data, filepath='validation.tsv', lazy=False)\n",
    "validZhihu_ds = load_dataset(read_custom_data, filepath='zhihu_validation.tsv', lazy=False)\n",
    "test_ds = load_dataset(read_custom_data_test, filepath='test.tsv', lazy=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a446c21-91be-422d-a6c5-421d8f34f9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:11.960195Z",
     "iopub.status.busy": "2022-12-29T06:07:11.959529Z",
     "iopub.status.idle": "2022-12-29T06:07:18.378387Z",
     "shell.execute_reply": "2022-12-29T06:07:18.377070Z",
     "shell.execute_reply.started": "2022-12-29T06:07:11.960153Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 14:07:11,962] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'ernie-2.0-large-en'.\r\n",
      "[2022-12-29 14:07:11,966] [    INFO] - Model config ErnieConfig {\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"enable_recompute\": false,\r\n",
      "  \"fuse\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\",\r\n",
      "    \"3\": \"LABEL_3\",\r\n",
      "    \"4\": \"LABEL_4\",\r\n",
      "    \"5\": \"LABEL_5\",\r\n",
      "    \"6\": \"LABEL_6\",\r\n",
      "    \"7\": \"LABEL_7\",\r\n",
      "    \"8\": \"LABEL_8\",\r\n",
      "    \"9\": \"LABEL_9\",\r\n",
      "    \"10\": \"LABEL_10\",\r\n",
      "    \"11\": \"LABEL_11\",\r\n",
      "    \"12\": \"LABEL_12\",\r\n",
      "    \"13\": \"LABEL_13\",\r\n",
      "    \"14\": \"LABEL_14\",\r\n",
      "    \"15\": \"LABEL_15\",\r\n",
      "    \"16\": \"LABEL_16\",\r\n",
      "    \"17\": \"LABEL_17\",\r\n",
      "    \"18\": \"LABEL_18\",\r\n",
      "    \"19\": \"LABEL_19\"\r\n",
      "  },\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 4096,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_10\": 10,\r\n",
      "    \"LABEL_11\": 11,\r\n",
      "    \"LABEL_12\": 12,\r\n",
      "    \"LABEL_13\": 13,\r\n",
      "    \"LABEL_14\": 14,\r\n",
      "    \"LABEL_15\": 15,\r\n",
      "    \"LABEL_16\": 16,\r\n",
      "    \"LABEL_17\": 17,\r\n",
      "    \"LABEL_18\": 18,\r\n",
      "    \"LABEL_19\": 19,\r\n",
      "    \"LABEL_2\": 2,\r\n",
      "    \"LABEL_3\": 3,\r\n",
      "    \"LABEL_4\": 4,\r\n",
      "    \"LABEL_5\": 5,\r\n",
      "    \"LABEL_6\": 6,\r\n",
      "    \"LABEL_7\": 7,\r\n",
      "    \"LABEL_8\": 8,\r\n",
      "    \"LABEL_9\": 9\r\n",
      "  },\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 512,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 24,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"pool_act\": \"tanh\",\r\n",
      "  \"task_id\": 0,\r\n",
      "  \"task_type_vocab_size\": 3,\r\n",
      "  \"type_vocab_size\": 4,\r\n",
      "  \"use_task_id\": true,\r\n",
      "  \"vocab_size\": 30522\r\n",
      "}\r\n",
      "\r\n",
      "[2022-12-29 14:07:11,970] [    INFO] - Configuration saved in /home/aistudio/.paddlenlp/models/ernie-2.0-large-en/config.json\r\n",
      "W1229 14:07:11.975570 25547 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W1229 14:07:11.980445 25547 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2022-12-29 14:07:14,318] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,321] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,418] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,421] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,425] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,428] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,430] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,432] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,434] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,436] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,440] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,443] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,447] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,449] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,453] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,455] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,459] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,461] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,470] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,472] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,480] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,482] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,488] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,491] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,496] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,498] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,503] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,505] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,510] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,512] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,521] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,524] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,534] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,536] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,541] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,543] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,548] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,550] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,555] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,557] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,562] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,564] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,574] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,576] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,586] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,589] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,594] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,596] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,601] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,604] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,608] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,611] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,615] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,617] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,627] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,629] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,639] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,642] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,646] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,649] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,653] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,656] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,660] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,662] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,667] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,669] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,678] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,680] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,690] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,692] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,696] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,699] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,703] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,706] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,710] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,712] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,717] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,719] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,728] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,731] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,740] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,743] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,747] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,750] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,754] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,757] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,761] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,764] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,769] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,771] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,779] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,782] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,790] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,792] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,796] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,798] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,803] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,805] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,810] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,813] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,817] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,819] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,829] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,831] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,841] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,843] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,848] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,850] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,855] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,857] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,862] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,864] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,868] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,870] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,878] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,881] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,889] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,891] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,895] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,897] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,901] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,903] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,907] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,909] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,913] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,915] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,923] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,925] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,934] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,936] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,940] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,942] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,946] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,948] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,951] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,953] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,957] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,960] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,970] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,973] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,982] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,985] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,990] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,992] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,996] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:14,998] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,002] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,004] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,008] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,010] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,019] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,021] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,029] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,031] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,035] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,038] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,041] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,043] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,047] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,049] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,053] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,056] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,067] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,069] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,079] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,082] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,087] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,090] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,094] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,097] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,101] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,104] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,108] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,111] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,120] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,122] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,131] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,134] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,139] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,141] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,146] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,148] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,152] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,155] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,159] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,162] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,171] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,173] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,183] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,186] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,191] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,194] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,200] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,202] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,207] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,209] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,213] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,216] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,225] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,227] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,237] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,239] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,244] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,246] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,251] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,253] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,257] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,260] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,264] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,266] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,275] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,278] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,286] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,289] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,293] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,295] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,300] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,302] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,307] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,309] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,313] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,316] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,324] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,327] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,335] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,338] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,342] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,344] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,349] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,351] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,355] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,358] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,362] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,364] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,373] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,375] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,384] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,387] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,391] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,393] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,398] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,400] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,404] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,407] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,411] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,414] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,422] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,425] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,433] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,436] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,440] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,442] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,447] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,449] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,453] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,456] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,460] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,462] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,471] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,473] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,482] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,484] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,488] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,491] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,495] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,497] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,502] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,504] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,508] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,511] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,519] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,522] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,530] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,533] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,537] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,539] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,544] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,546] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,550] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,553] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,557] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,560] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,568] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,571] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,579] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,582] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,586] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,589] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,593] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,595] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,599] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,602] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,606] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,608] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,617] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,620] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,628] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,631] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,635] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:15,637] [ WARNING] - Do not access config from `model.initializer_range` which will be deprecated after v2.6.0, Instead, do `model.config.initializer_range`\r\n",
      "[2022-12-29 14:07:18,337] [    INFO] - All model checkpoint weights were used when initializing ErnieForSequenceClassification.\r\n",
      "\r\n",
      "[2022-12-29 14:07:18,340] [ WARNING] - Some weights of ErnieForSequenceClassification were not initialized from the model checkpoint at ernie-2.0-large-en and are newly initialized: ['classifier.weight', 'ernie.embeddings.task_type_embeddings.weight', 'classifier.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "[2022-12-29 14:07:18,344] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-2.0-large-en'.\r\n",
      "[2022-12-29 14:07:18,348] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-2.0-large-en/vocab.txt\r\n",
      "[2022-12-29 14:07:18,369] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-2.0-large-en/tokenizer_config.json\r\n",
      "[2022-12-29 14:07:18,373] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-2.0-large-en/special_tokens_map.json\r\n"
     ]
    }
   ],
   "source": [
    "# 加载中文ERNIE 3.0预训练模型和分词器\n",
    "from paddlenlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"ernie-2.0-large-en\"   # ERNIE2.0 模型\n",
    "num_classes = 20  # 20分类任务\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=num_classes)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55b3ef1-0b4a-4636-95a6-f6e3f375b638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:29.164185Z",
     "iopub.status.busy": "2022-12-29T06:07:29.163506Z",
     "iopub.status.idle": "2022-12-29T06:07:29.173271Z",
     "shell.execute_reply": "2022-12-29T06:07:29.172533Z",
     "shell.execute_reply.started": "2022-12-29T06:07:29.164142Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "from paddle.io import DataLoader, BatchSampler\n",
    "from paddlenlp.data import DataCollatorWithPadding\n",
    "\n",
    "# 数据预处理函数，利用分词器将文本转化为整数序列\n",
    "def preprocess_function(examples, tokenizer, max_seq_length):\n",
    "    result = tokenizer(text=examples[\"sentence\"], max_seq_len=max_seq_length)\n",
    "    result[\"labels\"] = examples[\"labels\"]\n",
    "    return result\n",
    "\n",
    "trans_func = functools.partial(preprocess_function, tokenizer=tokenizer, max_seq_length=128)\n",
    "train_ds = train_ds.map(trans_func)\n",
    "valid_ds = valid_ds.map(trans_func)\n",
    "validZhihu_ds = validZhihu_ds.map(trans_func)\n",
    "test_ds = test_ds.map(trans_func)\n",
    "\n",
    "# collate_fn函数构造，将不同长度序列充到批中数据的最大长度，再将数据堆叠\n",
    "collate_fn = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 定义BatchSampler，选择批大小和是否随机乱序，进行DataLoader\n",
    "train_batch_sampler = BatchSampler(train_ds, batch_size=32, shuffle=True)\n",
    "valid_batch_sampler = BatchSampler(valid_ds, batch_size=16, shuffle=False)\n",
    "validZhihu_batch_sampler = BatchSampler(validZhihu_ds, batch_size=16, shuffle=False)\n",
    "test_batch_sampler = BatchSampler(test_ds, batch_size=16, shuffle=False)\n",
    "\n",
    "train_data_loader = DataLoader(dataset=train_ds, batch_sampler=train_batch_sampler, collate_fn=collate_fn)\n",
    "valid_data_loader = DataLoader(dataset=valid_ds, batch_sampler=valid_batch_sampler, collate_fn=collate_fn)\n",
    "validZhihu_data_loader = DataLoader(dataset=validZhihu_ds, batch_sampler=validZhihu_batch_sampler, collate_fn=collate_fn)\n",
    "test_data_loader = DataLoader(dataset=test_ds, batch_sampler=test_batch_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd1d4b5-f854-43f5-9ecd-be26c5463b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:30.608652Z",
     "iopub.status.busy": "2022-12-29T06:07:30.607752Z",
     "iopub.status.idle": "2022-12-29T06:07:30.638127Z",
     "shell.execute_reply": "2022-12-29T06:07:30.637313Z",
     "shell.execute_reply.started": "2022-12-29T06:07:30.608611Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from paddle.metric import Metric\n",
    "\n",
    "# 自定义MultiLabelReport评价指标\n",
    "class MultiLabelReport(Metric):\n",
    "    \"\"\"\n",
    "    AUC and F1 Score for multi-label text classification task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name='MultiLabelReport', average='macro'):\n",
    "        super(MultiLabelReport, self).__init__()\n",
    "        self.average = average\n",
    "        self._name = name\n",
    "        self.reset()\n",
    "\n",
    "    # def f1_score(self, y_prob):\n",
    "    #     '''\n",
    "    #     Returns the f1 score by searching the best threshhold\n",
    "    #     '''\n",
    "    #     best_score = 0\n",
    "    #     for threshold in [i * 0.01 for i in range(100)]:\n",
    "    #         self.y_pred = y_prob > threshold\n",
    "    #         score = sklearn.metrics.f1_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "    #         if score > best_score:\n",
    "    #             best_score = score\n",
    "    #             precison = precision_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "    #             recall = recall_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "    #     return best_score, precison, recall\n",
    "\n",
    "    def f1_score(self, y_prob):\n",
    "        '''\n",
    "        Returns the f1 score by searching the best threshhold\n",
    "        '''\n",
    "        thresholds =0\n",
    "        self.y_pred = y_prob > thresholds\n",
    "        score = sklearn.metrics.f1_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "        precison = precision_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "        recall = recall_score(y_pred=self.y_pred, y_true=self.y_true, average=self.average)\n",
    "        return score, precison, recall\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets all of the metric state.\n",
    "        \"\"\"\n",
    "        self.y_prob = None\n",
    "        self.y_true = None\n",
    "\n",
    "    def update(self, probs, labels):\n",
    "        if self.y_prob is not None:\n",
    "            self.y_prob = np.append(self.y_prob, probs.numpy(), axis=0)\n",
    "        else:\n",
    "            self.y_prob = probs.numpy()\n",
    "        if self.y_true is not None:\n",
    "            self.y_true = np.append(self.y_true, labels.numpy(), axis=0)\n",
    "        else:\n",
    "            self.y_true = labels.numpy()\n",
    "\n",
    "    def accumulate(self):\n",
    "        # auc = roc_auc_score(\n",
    "        #     y_score=self.y_prob, y_true=self.y_true, average=self.average)\n",
    "        f1_score, precison, recall = self.f1_score(y_prob=self.y_prob)\n",
    "        # return auc, f1_score, precison, recall\n",
    "        return f1_score, precison, recall\n",
    "    \n",
    "\n",
    "    def name(self):\n",
    "        \"\"\"\n",
    "        Returns metric name\n",
    "        \"\"\"\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "316a6b24-81b3-4f81-aa98-59ef6a55fc04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:32.046504Z",
     "iopub.status.busy": "2022-12-29T06:07:32.045429Z",
     "iopub.status.idle": "2022-12-29T06:07:32.052886Z",
     "shell.execute_reply": "2022-12-29T06:07:32.052163Z",
     "shell.execute_reply.started": "2022-12-29T06:07:32.046466Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def multilabel_categorical_crossentropy(y_true, y_pred):\n",
    "    \"\"\"多标签分类的交叉熵\n",
    "    说明：y_true和y_pred的shape一致，y_true的元素非0即1，\n",
    "         1表示对应的类为目标类，0表示对应的类为非目标类。\n",
    "    警告：请保证y_pred的值域是全体实数，换言之一般情况下y_pred\n",
    "         不用加激活函数，尤其是不能加sigmoid或者softmax！预测\n",
    "         阶段则输出y_pred大于0的类。如有疑问，请仔细阅读并理解\n",
    "         本文。\n",
    "    假如类别总数为10\n",
    "    label ：[0,1,0,0,0,0,0,0,0,1]  代表条数据被标注为 2,10 属于 2类也属于10类\n",
    "    输出也为10类别 输出维度也为10。\n",
    "    类别从1位置开始0位置代表阈值s就是输出的维度第一个位置是阈值预测\n",
    "    目标类的分数都大于s，非目标类的分数都小于s\n",
    "    这里阈值s默认为0故而可忽略只要类从1开始就可\n",
    "    \"\"\"\n",
    "    y_pred = (1 - 2 * y_true) * y_pred\n",
    "    y_pred_neg = y_pred - y_true * 1e12\n",
    "    y_pred_pos = y_pred - (1 - y_true) * 1e12\n",
    "\n",
    "\n",
    "    zeros = paddle.zeros_like(y_pred[..., :1])\n",
    "\n",
    "    y_pred_neg = paddle.concat((y_pred_neg, zeros), axis=-1)\n",
    "    y_pred_pos = paddle.concat((y_pred_pos, zeros), axis=-1)\n",
    "\n",
    "\n",
    "    neg_loss = paddle.logsumexp(y_pred_neg, axis=-1)\n",
    "    pos_loss = paddle.logsumexp(y_pred_pos, axis=-1)\n",
    "    return neg_loss + pos_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc77ffe-be40-448f-845e-3c0a80fb8939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:33.162075Z",
     "iopub.status.busy": "2022-12-29T06:07:33.161429Z",
     "iopub.status.idle": "2022-12-29T06:07:33.168163Z",
     "shell.execute_reply": "2022-12-29T06:07:33.167432Z",
     "shell.execute_reply.started": "2022-12-29T06:07:33.162035Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# AdamW优化器、交叉熵损失函数、自定义MultiLabelReport评价指标\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=4e-5, parameters=model.parameters(), weight_decay=0.01)\n",
    "criterion = multilabel_categorical_crossentropy\n",
    "metric = MultiLabelReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "affc6cf5-a92d-482b-8b84-83631604ca1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:36.200527Z",
     "iopub.status.busy": "2022-12-29T06:07:36.199914Z",
     "iopub.status.idle": "2022-12-29T06:07:36.205739Z",
     "shell.execute_reply": "2022-12-29T06:07:36.204796Z",
     "shell.execute_reply.started": "2022-12-29T06:07:36.200488Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_vocab = [\"Self-direction: thought\",\"Self-direction: action\",\"Stimulation\",\"Hedonism\",\"Achievement\",\"Power: dominance\",\"Power: resources\",\"Face\",\"Security: personal\",\"Security: societal\",\"Tradition\",\"Conformity: rules\",\"Conformity: interpersonal\",\"Humility\",\"Benevolence: caring\",\"Benevolence: dependability\",\"Universalism: concern\",\"Universalism: nature\",\"Universalism: tolerance\",\"Universalism: objectivity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b59875d-ef50-4102-abe4-2209ad89ae88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:37.250395Z",
     "iopub.status.busy": "2022-12-29T06:07:37.249764Z",
     "iopub.status.idle": "2022-12-29T06:07:37.259948Z",
     "shell.execute_reply": "2022-12-29T06:07:37.259049Z",
     "shell.execute_reply.started": "2022-12-29T06:07:37.250358Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# 构建验证集evaluate函数\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader, label_vocab, if_return_results=True):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    results = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(labels,logits)\n",
    "        # probs = F.sigmoid(logits)\n",
    "        probs = logits\n",
    "        loss = loss.mean()\n",
    "        losses.append(loss.numpy())\n",
    "        metric.update(probs, labels)\n",
    "        if if_return_results:\n",
    "            probs = probs.tolist()\n",
    "            for prob in probs:\n",
    "                result = []\n",
    "                for c, pred in enumerate(prob):\n",
    "                    if pred > 0:\n",
    "                        result.append(label_vocab[c])\n",
    "                        # result.append(str(c))\n",
    "                results.append(','.join(result))\n",
    "\n",
    "    # auc, f1_score, precison, recall = metric.accumulate()\n",
    "    f1_score, precison, recall = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, f1 score: %.5f, precison: %.5f, recall: %.5f\" %\n",
    "          (np.mean(losses), f1_score, precison, recall))\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    if if_return_results:\n",
    "        return results\n",
    "    else:\n",
    "        return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39db008f-092c-468a-b652-2b985b25ddbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:38.973581Z",
     "iopub.status.busy": "2022-12-29T06:07:38.972919Z",
     "iopub.status.idle": "2022-12-29T06:07:38.981210Z",
     "shell.execute_reply": "2022-12-29T06:07:38.980063Z",
     "shell.execute_reply.started": "2022-12-29T06:07:38.973538Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/model\r\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e9deec-50c5-416e-be72-c0ceeef8ba9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T03:15:59.617967Z",
     "iopub.status.busy": "2022-12-29T03:15:59.616505Z",
     "iopub.status.idle": "2022-12-29T04:14:14.396880Z",
     "shell.execute_reply": "2022-12-29T04:14:14.395771Z",
     "shell.execute_reply.started": "2022-12-29T03:15:59.617891Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 4.10663, f1 score: 0.21181, speed: 1.63 step/s\r\n",
      "global step 20, epoch: 1, batch: 20, loss: 4.07766, f1 score: 0.19203, speed: 1.72 step/s\r\n",
      "global step 30, epoch: 1, batch: 30, loss: 4.06239, f1 score: 0.17248, speed: 1.53 step/s\r\n",
      "global step 40, epoch: 1, batch: 40, loss: 3.94547, f1 score: 0.16890, speed: 1.61 step/s\r\n",
      "eval loss: 3.91192, f1 score: 0.10681, precison: 0.23412, recall: 0.11292\r\n",
      "eval loss: 3.69470, f1 score: 0.06602, precison: 0.07659, recall: 0.07246\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:16:36,317] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:16:39,506] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:16:39,509] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:16:39,515] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:16:42,619] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:16:42,623] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 50, epoch: 1, batch: 50, loss: 3.82056, f1 score: 0.22150, speed: 0.42 step/s\r\n",
      "global step 60, epoch: 1, batch: 60, loss: 3.73289, f1 score: 0.23713, speed: 1.67 step/s\r\n",
      "global step 70, epoch: 1, batch: 70, loss: 3.80777, f1 score: 0.26480, speed: 1.54 step/s\r\n",
      "global step 80, epoch: 1, batch: 80, loss: 3.58494, f1 score: 0.27662, speed: 1.81 step/s\r\n",
      "eval loss: 3.68114, f1 score: 0.26435, precison: 0.42329, recall: 0.22789\r\n",
      "eval loss: 3.47785, f1 score: 0.18896, precison: 0.24290, recall: 0.19614\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:17:18,011] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:17:34,000] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:17:34,004] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:17:34,009] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:17:46,169] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:17:46,173] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 90, epoch: 1, batch: 90, loss: 3.74324, f1 score: 0.29425, speed: 0.22 step/s\r\n",
      "global step 100, epoch: 1, batch: 100, loss: 3.58679, f1 score: 0.30519, speed: 1.65 step/s\r\n",
      "global step 110, epoch: 1, batch: 110, loss: 3.37050, f1 score: 0.31331, speed: 1.62 step/s\r\n",
      "global step 120, epoch: 1, batch: 120, loss: 3.63459, f1 score: 0.31910, speed: 1.72 step/s\r\n",
      "eval loss: 3.61151, f1 score: 0.31005, precison: 0.54439, recall: 0.26087\r\n",
      "eval loss: 3.40661, f1 score: 0.23042, precison: 0.30289, recall: 0.24682\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:18:21,655] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:18:34,808] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:18:34,890] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:18:35,039] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:18:49,928] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:18:49,932] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 130, epoch: 1, batch: 130, loss: 3.74028, f1 score: 0.36366, speed: 0.22 step/s\r\n",
      "global step 140, epoch: 1, batch: 140, loss: 3.46223, f1 score: 0.36220, speed: 1.64 step/s\r\n",
      "global step 150, epoch: 1, batch: 150, loss: 3.43084, f1 score: 0.37515, speed: 1.53 step/s\r\n",
      "global step 160, epoch: 1, batch: 160, loss: 3.59865, f1 score: 0.37822, speed: 1.66 step/s\r\n",
      "eval loss: 3.58387, f1 score: 0.34142, precison: 0.57111, recall: 0.28338\r\n",
      "eval loss: 3.44472, f1 score: 0.22652, precison: 0.29378, recall: 0.22960\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:19:26,160] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:19:38,059] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:19:38,062] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 170, epoch: 2, batch: 1, loss: 3.39209, f1 score: 0.38175, speed: 0.34 step/s\r\n",
      "global step 180, epoch: 2, batch: 11, loss: 3.42437, f1 score: 0.40102, speed: 1.58 step/s\r\n",
      "global step 190, epoch: 2, batch: 21, loss: 3.32769, f1 score: 0.42292, speed: 1.74 step/s\r\n",
      "global step 200, epoch: 2, batch: 31, loss: 3.31444, f1 score: 0.42379, speed: 1.61 step/s\r\n",
      "eval loss: 3.53636, f1 score: 0.35086, precison: 0.59108, recall: 0.29830\r\n",
      "eval loss: 3.32879, f1 score: 0.21791, precison: 0.25955, recall: 0.21178\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:20:13,969] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:20:28,571] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:20:28,655] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 210, epoch: 2, batch: 41, loss: 3.30145, f1 score: 0.45610, speed: 0.31 step/s\r\n",
      "global step 220, epoch: 2, batch: 51, loss: 3.26393, f1 score: 0.45691, speed: 1.64 step/s\r\n",
      "global step 230, epoch: 2, batch: 61, loss: 3.26927, f1 score: 0.47441, speed: 1.72 step/s\r\n",
      "global step 240, epoch: 2, batch: 71, loss: 3.24475, f1 score: 0.47133, speed: 1.65 step/s\r\n",
      "eval loss: 3.55279, f1 score: 0.34391, precison: 0.63858, recall: 0.28220\r\n",
      "eval loss: 3.32988, f1 score: 0.22984, precison: 0.25984, recall: 0.22239\r\n",
      "global step 250, epoch: 2, batch: 81, loss: 3.28239, f1 score: 0.46843, speed: 0.56 step/s\r\n",
      "global step 260, epoch: 2, batch: 91, loss: 3.38605, f1 score: 0.46053, speed: 1.64 step/s\r\n",
      "global step 270, epoch: 2, batch: 101, loss: 3.25487, f1 score: 0.46809, speed: 1.63 step/s\r\n",
      "global step 280, epoch: 2, batch: 111, loss: 3.41354, f1 score: 0.46623, speed: 1.52 step/s\r\n",
      "eval loss: 3.52249, f1 score: 0.35630, precison: 0.57311, recall: 0.29760\r\n",
      "eval loss: 3.27932, f1 score: 0.24117, precison: 0.26136, recall: 0.24590\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:21:41,040] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:21:52,960] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:21:52,964] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:21:52,969] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:22:05,728] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:22:05,731] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 290, epoch: 2, batch: 121, loss: 3.25182, f1 score: 0.44148, speed: 0.24 step/s\r\n",
      "global step 300, epoch: 2, batch: 131, loss: 3.34432, f1 score: 0.47066, speed: 1.69 step/s\r\n",
      "global step 310, epoch: 2, batch: 141, loss: 3.14139, f1 score: 0.46936, speed: 1.63 step/s\r\n",
      "global step 320, epoch: 2, batch: 151, loss: 3.41236, f1 score: 0.46819, speed: 1.66 step/s\r\n",
      "eval loss: 3.50289, f1 score: 0.37304, precison: 0.55918, recall: 0.31240\r\n",
      "eval loss: 3.29145, f1 score: 0.24562, precison: 0.26543, recall: 0.25643\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:22:41,218] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:22:53,315] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:22:53,319] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:22:53,324] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:23:05,357] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:23:05,361] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 330, epoch: 2, batch: 161, loss: 3.32557, f1 score: 0.48373, speed: 0.24 step/s\r\n",
      "global step 340, epoch: 3, batch: 2, loss: 3.07756, f1 score: 0.50958, speed: 1.58 step/s\r\n",
      "global step 350, epoch: 3, batch: 12, loss: 2.88560, f1 score: 0.52097, speed: 1.78 step/s\r\n",
      "global step 360, epoch: 3, batch: 22, loss: 3.35589, f1 score: 0.52934, speed: 1.70 step/s\r\n",
      "eval loss: 3.49279, f1 score: 0.38646, precison: 0.57101, recall: 0.33731\r\n",
      "eval loss: 3.36636, f1 score: 0.27316, precison: 0.26696, recall: 0.29261\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:23:41,227] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:23:53,258] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:23:53,261] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:23:53,267] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:24:05,343] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:24:05,346] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 370, epoch: 3, batch: 32, loss: 3.06634, f1 score: 0.57185, speed: 0.24 step/s\r\n",
      "global step 380, epoch: 3, batch: 42, loss: 2.92001, f1 score: 0.55952, speed: 1.65 step/s\r\n",
      "global step 390, epoch: 3, batch: 52, loss: 3.09460, f1 score: 0.56114, speed: 1.69 step/s\r\n",
      "global step 400, epoch: 3, batch: 62, loss: 3.19478, f1 score: 0.56589, speed: 1.62 step/s\r\n",
      "eval loss: 3.53920, f1 score: 0.38484, precison: 0.59443, recall: 0.33223\r\n",
      "eval loss: 3.28543, f1 score: 0.27413, precison: 0.28424, recall: 0.30275\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:24:41,216] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:24:53,225] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:24:53,228] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 410, epoch: 3, batch: 72, loss: 2.86062, f1 score: 0.55426, speed: 0.33 step/s\r\n",
      "global step 420, epoch: 3, batch: 82, loss: 2.94631, f1 score: 0.56009, speed: 1.67 step/s\r\n",
      "global step 430, epoch: 3, batch: 92, loss: 2.91413, f1 score: 0.55659, speed: 1.55 step/s\r\n",
      "global step 440, epoch: 3, batch: 102, loss: 3.28858, f1 score: 0.55620, speed: 1.76 step/s\r\n",
      "eval loss: 3.53899, f1 score: 0.40394, precison: 0.61883, recall: 0.33932\r\n",
      "eval loss: 3.41231, f1 score: 0.27738, precison: 0.28513, recall: 0.30259\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:25:29,612] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:25:41,747] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:25:41,750] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:25:41,755] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:25:53,808] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:25:53,811] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 450, epoch: 3, batch: 112, loss: 2.85530, f1 score: 0.53837, speed: 0.24 step/s\r\n",
      "global step 460, epoch: 3, batch: 122, loss: 2.95775, f1 score: 0.54486, speed: 1.62 step/s\r\n",
      "global step 470, epoch: 3, batch: 132, loss: 2.84000, f1 score: 0.55160, speed: 1.65 step/s\r\n",
      "global step 480, epoch: 3, batch: 142, loss: 2.91449, f1 score: 0.55662, speed: 1.56 step/s\r\n",
      "eval loss: 3.53916, f1 score: 0.40542, precison: 0.59738, recall: 0.34766\r\n",
      "eval loss: 3.36845, f1 score: 0.27820, precison: 0.30936, recall: 0.29785\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:26:29,463] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:26:41,478] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:26:41,481] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:26:41,487] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:26:53,711] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:26:53,714] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 490, epoch: 3, batch: 152, loss: 2.96441, f1 score: 0.53566, speed: 0.24 step/s\r\n",
      "global step 500, epoch: 3, batch: 162, loss: 3.12547, f1 score: 0.54230, speed: 1.64 step/s\r\n",
      "global step 510, epoch: 4, batch: 3, loss: 2.94903, f1 score: 0.54588, speed: 1.87 step/s\r\n",
      "global step 520, epoch: 4, batch: 13, loss: 2.83676, f1 score: 0.58563, speed: 1.53 step/s\r\n",
      "eval loss: 3.57097, f1 score: 0.45381, precison: 0.55110, recall: 0.41208\r\n",
      "eval loss: 3.28349, f1 score: 0.33727, precison: 0.36510, recall: 0.36480\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:27:29,641] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:27:43,025] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:27:43,095] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n",
      "[2022-12-29 11:27:43,233] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:27:55,173] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:27:55,177] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 530, epoch: 4, batch: 23, loss: 2.97219, f1 score: 0.65159, speed: 0.23 step/s\r\n",
      "global step 540, epoch: 4, batch: 33, loss: 2.52479, f1 score: 0.65269, speed: 1.69 step/s\r\n",
      "global step 550, epoch: 4, batch: 43, loss: 2.91261, f1 score: 0.64124, speed: 1.72 step/s\r\n",
      "global step 560, epoch: 4, batch: 53, loss: 2.61222, f1 score: 0.63546, speed: 1.58 step/s\r\n",
      "eval loss: 3.57695, f1 score: 0.44555, precison: 0.57609, recall: 0.39516\r\n",
      "eval loss: 3.28545, f1 score: 0.34214, precison: 0.33663, recall: 0.36806\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:28:30,481] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:28:44,548] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:28:44,629] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 570, epoch: 4, batch: 63, loss: 2.74849, f1 score: 0.64587, speed: 0.31 step/s\r\n",
      "global step 580, epoch: 4, batch: 73, loss: 2.91046, f1 score: 0.63517, speed: 1.71 step/s\r\n",
      "global step 590, epoch: 4, batch: 83, loss: 2.51367, f1 score: 0.64195, speed: 1.63 step/s\r\n",
      "global step 600, epoch: 4, batch: 93, loss: 2.63432, f1 score: 0.64232, speed: 1.66 step/s\r\n",
      "eval loss: 3.64839, f1 score: 0.42212, precison: 0.59919, recall: 0.36252\r\n",
      "eval loss: 3.44445, f1 score: 0.30499, precison: 0.31580, recall: 0.33516\r\n",
      "global step 610, epoch: 4, batch: 103, loss: 2.95672, f1 score: 0.61929, speed: 0.55 step/s\r\n",
      "global step 620, epoch: 4, batch: 113, loss: 2.71923, f1 score: 0.63795, speed: 1.76 step/s\r\n",
      "global step 630, epoch: 4, batch: 123, loss: 3.11496, f1 score: 0.63265, speed: 1.78 step/s\r\n",
      "global step 640, epoch: 4, batch: 133, loss: 2.54275, f1 score: 0.62257, speed: 1.72 step/s\r\n",
      "eval loss: 3.65717, f1 score: 0.42960, precison: 0.56714, recall: 0.38490\r\n",
      "eval loss: 3.42747, f1 score: 0.36682, precison: 0.37675, recall: 0.41024\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:29:55,973] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:30:07,910] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:30:07,913] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 650, epoch: 4, batch: 143, loss: 2.74396, f1 score: 0.59712, speed: 0.33 step/s\r\n",
      "global step 660, epoch: 4, batch: 153, loss: 2.81148, f1 score: 0.63334, speed: 1.67 step/s\r\n",
      "global step 670, epoch: 4, batch: 163, loss: 2.40235, f1 score: 0.62504, speed: 1.74 step/s\r\n",
      "global step 680, epoch: 5, batch: 4, loss: 2.36740, f1 score: 0.63585, speed: 1.80 step/s\r\n",
      "eval loss: 3.70600, f1 score: 0.44188, precison: 0.59140, recall: 0.38229\r\n",
      "eval loss: 3.40700, f1 score: 0.35074, precison: 0.40971, recall: 0.36437\r\n",
      "global step 690, epoch: 5, batch: 14, loss: 2.56684, f1 score: 0.69799, speed: 0.57 step/s\r\n",
      "global step 700, epoch: 5, batch: 24, loss: 2.60512, f1 score: 0.69892, speed: 1.53 step/s\r\n",
      "global step 710, epoch: 5, batch: 34, loss: 2.28034, f1 score: 0.70241, speed: 1.67 step/s\r\n",
      "global step 720, epoch: 5, batch: 44, loss: 2.42489, f1 score: 0.70359, speed: 1.59 step/s\r\n",
      "eval loss: 3.72019, f1 score: 0.44775, precison: 0.58497, recall: 0.40264\r\n",
      "eval loss: 3.52435, f1 score: 0.34283, precison: 0.31025, recall: 0.41388\r\n",
      "global step 730, epoch: 5, batch: 54, loss: 2.37855, f1 score: 0.70984, speed: 0.56 step/s\r\n",
      "global step 740, epoch: 5, batch: 64, loss: 2.51395, f1 score: 0.70177, speed: 1.78 step/s\r\n",
      "global step 750, epoch: 5, batch: 74, loss: 2.16384, f1 score: 0.71399, speed: 1.62 step/s\r\n",
      "global step 760, epoch: 5, batch: 84, loss: 2.43818, f1 score: 0.71014, speed: 1.60 step/s\r\n",
      "eval loss: 3.79639, f1 score: 0.42241, precison: 0.60034, recall: 0.37006\r\n",
      "eval loss: 3.58348, f1 score: 0.30284, precison: 0.29180, recall: 0.33728\r\n",
      "global step 770, epoch: 5, batch: 94, loss: 2.65597, f1 score: 0.69634, speed: 0.55 step/s\r\n",
      "global step 780, epoch: 5, batch: 104, loss: 2.48121, f1 score: 0.71920, speed: 1.69 step/s\r\n",
      "global step 790, epoch: 5, batch: 114, loss: 2.81592, f1 score: 0.70405, speed: 1.70 step/s\r\n",
      "global step 800, epoch: 5, batch: 124, loss: 2.82143, f1 score: 0.70646, speed: 1.54 step/s\r\n",
      "eval loss: 3.86138, f1 score: 0.43826, precison: 0.58054, recall: 0.39230\r\n",
      "eval loss: 3.70123, f1 score: 0.32713, precison: 0.30740, recall: 0.37546\r\n",
      "global step 810, epoch: 5, batch: 134, loss: 2.66031, f1 score: 0.69269, speed: 0.57 step/s\r\n",
      "global step 820, epoch: 5, batch: 144, loss: 2.72096, f1 score: 0.69667, speed: 1.65 step/s\r\n",
      "global step 830, epoch: 5, batch: 154, loss: 2.65118, f1 score: 0.69345, speed: 1.64 step/s\r\n",
      "global step 840, epoch: 5, batch: 164, loss: 2.72403, f1 score: 0.70093, speed: 1.57 step/s\r\n",
      "eval loss: 3.86562, f1 score: 0.43599, precison: 0.55204, recall: 0.38746\r\n",
      "eval loss: 3.60713, f1 score: 0.39081, precison: 0.39011, recall: 0.42911\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:33:08,018] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 11:33:19,888] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 11:33:19,892] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 850, epoch: 6, batch: 5, loss: 2.09816, f1 score: 0.72687, speed: 0.34 step/s\r\n",
      "global step 860, epoch: 6, batch: 15, loss: 2.01062, f1 score: 0.73261, speed: 1.67 step/s\r\n",
      "global step 870, epoch: 6, batch: 25, loss: 2.11164, f1 score: 0.74504, speed: 1.63 step/s\r\n",
      "global step 880, epoch: 6, batch: 35, loss: 2.13907, f1 score: 0.74744, speed: 1.54 step/s\r\n",
      "eval loss: 3.94304, f1 score: 0.45414, precison: 0.54619, recall: 0.41846\r\n",
      "eval loss: 3.76684, f1 score: 0.37933, precison: 0.35281, recall: 0.43824\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:33:55,814] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:34:07,690] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:34:07,694] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 890, epoch: 6, batch: 45, loss: 2.37319, f1 score: 0.75855, speed: 0.34 step/s\r\n",
      "global step 900, epoch: 6, batch: 55, loss: 2.15354, f1 score: 0.76278, speed: 1.64 step/s\r\n",
      "global step 910, epoch: 6, batch: 65, loss: 1.94582, f1 score: 0.75853, speed: 1.53 step/s\r\n",
      "global step 920, epoch: 6, batch: 75, loss: 2.08132, f1 score: 0.75755, speed: 1.66 step/s\r\n",
      "eval loss: 3.98186, f1 score: 0.43696, precison: 0.55007, recall: 0.39378\r\n",
      "eval loss: 3.67943, f1 score: 0.35867, precison: 0.34253, recall: 0.41830\r\n",
      "global step 930, epoch: 6, batch: 85, loss: 2.34456, f1 score: 0.75767, speed: 0.56 step/s\r\n",
      "global step 940, epoch: 6, batch: 95, loss: 2.20435, f1 score: 0.75558, speed: 1.53 step/s\r\n",
      "global step 950, epoch: 6, batch: 105, loss: 1.70536, f1 score: 0.76145, speed: 1.54 step/s\r\n",
      "global step 960, epoch: 6, batch: 115, loss: 2.10169, f1 score: 0.75604, speed: 1.68 step/s\r\n",
      "eval loss: 4.07300, f1 score: 0.44969, precison: 0.55665, recall: 0.40540\r\n",
      "eval loss: 3.93687, f1 score: 0.37695, precison: 0.37814, recall: 0.45087\r\n",
      "global step 970, epoch: 6, batch: 125, loss: 2.23922, f1 score: 0.76061, speed: 0.56 step/s\r\n",
      "global step 980, epoch: 6, batch: 135, loss: 1.77457, f1 score: 0.76303, speed: 1.68 step/s\r\n",
      "global step 990, epoch: 6, batch: 145, loss: 2.15329, f1 score: 0.76612, speed: 1.59 step/s\r\n",
      "global step 1000, epoch: 6, batch: 155, loss: 2.19116, f1 score: 0.76858, speed: 1.53 step/s\r\n",
      "eval loss: 4.10867, f1 score: 0.45025, precison: 0.55345, recall: 0.41567\r\n",
      "eval loss: 3.99909, f1 score: 0.36114, precison: 0.32245, recall: 0.45642\r\n",
      "global step 1010, epoch: 6, batch: 165, loss: 2.39485, f1 score: 0.77079, speed: 0.57 step/s\r\n",
      "global step 1020, epoch: 7, batch: 6, loss: 1.74876, f1 score: 0.77765, speed: 1.72 step/s\r\n",
      "global step 1030, epoch: 7, batch: 16, loss: 1.54677, f1 score: 0.79282, speed: 1.56 step/s\r\n",
      "global step 1040, epoch: 7, batch: 26, loss: 2.01516, f1 score: 0.79917, speed: 1.60 step/s\r\n",
      "eval loss: 4.20350, f1 score: 0.45608, precison: 0.54396, recall: 0.42651\r\n",
      "eval loss: 4.11137, f1 score: 0.34979, precison: 0.30210, recall: 0.47215\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:36:33,703] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:36:45,587] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:36:45,591] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1050, epoch: 7, batch: 36, loss: 1.93574, f1 score: 0.81284, speed: 0.33 step/s\r\n",
      "global step 1060, epoch: 7, batch: 46, loss: 1.72673, f1 score: 0.82815, speed: 1.69 step/s\r\n",
      "global step 1070, epoch: 7, batch: 56, loss: 1.96732, f1 score: 0.82687, speed: 1.67 step/s\r\n",
      "global step 1080, epoch: 7, batch: 66, loss: 1.88227, f1 score: 0.82175, speed: 1.65 step/s\r\n",
      "eval loss: 4.30330, f1 score: 0.46673, precison: 0.55485, recall: 0.43791\r\n",
      "eval loss: 4.12265, f1 score: 0.36877, precison: 0.32435, recall: 0.49042\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:37:21,683] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:37:33,544] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:37:33,548] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1090, epoch: 7, batch: 76, loss: 1.81379, f1 score: 0.80404, speed: 0.35 step/s\r\n",
      "global step 1100, epoch: 7, batch: 86, loss: 1.79007, f1 score: 0.81880, speed: 1.59 step/s\r\n",
      "global step 1110, epoch: 7, batch: 96, loss: 1.78335, f1 score: 0.82127, speed: 1.72 step/s\r\n",
      "global step 1120, epoch: 7, batch: 106, loss: 1.74477, f1 score: 0.81748, speed: 1.72 step/s\r\n",
      "eval loss: 4.35737, f1 score: 0.46576, precison: 0.55348, recall: 0.43966\r\n",
      "eval loss: 4.25647, f1 score: 0.38368, precison: 0.35104, recall: 0.45909\r\n",
      "global step 1130, epoch: 7, batch: 116, loss: 1.92818, f1 score: 0.83927, speed: 0.57 step/s\r\n",
      "global step 1140, epoch: 7, batch: 126, loss: 1.94844, f1 score: 0.82442, speed: 1.71 step/s\r\n",
      "global step 1150, epoch: 7, batch: 136, loss: 1.82009, f1 score: 0.82484, speed: 1.63 step/s\r\n",
      "global step 1160, epoch: 7, batch: 146, loss: 1.76436, f1 score: 0.81649, speed: 1.62 step/s\r\n",
      "eval loss: 4.44882, f1 score: 0.44971, precison: 0.54753, recall: 0.42220\r\n",
      "eval loss: 4.13499, f1 score: 0.36572, precison: 0.34966, recall: 0.44392\r\n",
      "global step 1170, epoch: 7, batch: 156, loss: 2.08955, f1 score: 0.78501, speed: 0.57 step/s\r\n",
      "global step 1180, epoch: 7, batch: 166, loss: 1.72058, f1 score: 0.79613, speed: 1.50 step/s\r\n",
      "global step 1190, epoch: 8, batch: 7, loss: 1.42315, f1 score: 0.80871, speed: 1.67 step/s\r\n",
      "global step 1200, epoch: 8, batch: 17, loss: 1.39798, f1 score: 0.82093, speed: 1.58 step/s\r\n",
      "eval loss: 4.44515, f1 score: 0.45033, precison: 0.55631, recall: 0.40946\r\n",
      "eval loss: 4.28150, f1 score: 0.35111, precison: 0.31516, recall: 0.43677\r\n",
      "global step 1210, epoch: 8, batch: 27, loss: 1.65335, f1 score: 0.87490, speed: 0.56 step/s\r\n",
      "global step 1220, epoch: 8, batch: 37, loss: 1.59105, f1 score: 0.85597, speed: 1.60 step/s\r\n",
      "global step 1230, epoch: 8, batch: 47, loss: 1.53976, f1 score: 0.86378, speed: 1.61 step/s\r\n",
      "global step 1240, epoch: 8, batch: 57, loss: 1.47537, f1 score: 0.86306, speed: 1.65 step/s\r\n",
      "eval loss: 4.49669, f1 score: 0.45889, precison: 0.56093, recall: 0.41696\r\n",
      "eval loss: 4.18430, f1 score: 0.31783, precison: 0.29864, recall: 0.35783\r\n",
      "global step 1250, epoch: 8, batch: 67, loss: 1.58980, f1 score: 0.85836, speed: 0.56 step/s\r\n",
      "global step 1260, epoch: 8, batch: 77, loss: 1.49189, f1 score: 0.85933, speed: 1.66 step/s\r\n",
      "global step 1270, epoch: 8, batch: 87, loss: 1.34890, f1 score: 0.86381, speed: 1.57 step/s\r\n",
      "global step 1280, epoch: 8, batch: 97, loss: 1.51453, f1 score: 0.85922, speed: 1.62 step/s\r\n",
      "eval loss: 4.65633, f1 score: 0.45306, precison: 0.56555, recall: 0.41711\r\n",
      "eval loss: 4.29066, f1 score: 0.32449, precison: 0.28465, recall: 0.39910\r\n",
      "global step 1290, epoch: 8, batch: 107, loss: 1.14953, f1 score: 0.86487, speed: 0.55 step/s\r\n",
      "global step 1300, epoch: 8, batch: 117, loss: 1.83134, f1 score: 0.86836, speed: 1.60 step/s\r\n",
      "global step 1310, epoch: 8, batch: 127, loss: 1.28409, f1 score: 0.86684, speed: 1.66 step/s\r\n",
      "global step 1320, epoch: 8, batch: 137, loss: 1.41459, f1 score: 0.86866, speed: 1.60 step/s\r\n",
      "eval loss: 4.70449, f1 score: 0.46187, precison: 0.50905, recall: 0.44477\r\n",
      "eval loss: 4.49030, f1 score: 0.36246, precison: 0.31014, recall: 0.49521\r\n",
      "global step 1330, epoch: 8, batch: 147, loss: 1.50153, f1 score: 0.83696, speed: 0.56 step/s\r\n",
      "global step 1340, epoch: 8, batch: 157, loss: 1.35852, f1 score: 0.85320, speed: 1.57 step/s\r\n",
      "global step 1350, epoch: 8, batch: 167, loss: 1.59357, f1 score: 0.84537, speed: 1.67 step/s\r\n",
      "global step 1360, epoch: 9, batch: 8, loss: 1.30581, f1 score: 0.86358, speed: 1.70 step/s\r\n",
      "eval loss: 4.81243, f1 score: 0.45740, precison: 0.55661, recall: 0.42213\r\n",
      "eval loss: 4.54169, f1 score: 0.34305, precison: 0.30800, recall: 0.43227\r\n",
      "global step 1370, epoch: 9, batch: 18, loss: 1.34604, f1 score: 0.90336, speed: 0.56 step/s\r\n",
      "global step 1380, epoch: 9, batch: 28, loss: 1.13041, f1 score: 0.90423, speed: 1.77 step/s\r\n",
      "global step 1390, epoch: 9, batch: 38, loss: 1.21955, f1 score: 0.90676, speed: 1.72 step/s\r\n",
      "global step 1400, epoch: 9, batch: 48, loss: 1.00515, f1 score: 0.90770, speed: 1.62 step/s\r\n",
      "eval loss: 4.85876, f1 score: 0.46427, precison: 0.54024, recall: 0.44338\r\n",
      "eval loss: 4.75012, f1 score: 0.31549, precison: 0.27414, recall: 0.42111\r\n",
      "global step 1410, epoch: 9, batch: 58, loss: 1.43585, f1 score: 0.90357, speed: 0.55 step/s\r\n",
      "global step 1420, epoch: 9, batch: 68, loss: 1.34942, f1 score: 0.90599, speed: 1.54 step/s\r\n",
      "global step 1430, epoch: 9, batch: 78, loss: 1.13715, f1 score: 0.89457, speed: 1.53 step/s\r\n",
      "global step 1440, epoch: 9, batch: 88, loss: 1.20726, f1 score: 0.89303, speed: 1.63 step/s\r\n",
      "eval loss: 4.91168, f1 score: 0.45219, precison: 0.58216, recall: 0.41245\r\n",
      "eval loss: 4.54531, f1 score: 0.34396, precison: 0.31625, recall: 0.40892\r\n",
      "global step 1450, epoch: 9, batch: 98, loss: 1.34205, f1 score: 0.90212, speed: 0.57 step/s\r\n",
      "global step 1460, epoch: 9, batch: 108, loss: 0.96710, f1 score: 0.88870, speed: 1.82 step/s\r\n",
      "global step 1470, epoch: 9, batch: 118, loss: 1.34266, f1 score: 0.89386, speed: 1.65 step/s\r\n",
      "global step 1480, epoch: 9, batch: 128, loss: 1.40818, f1 score: 0.89467, speed: 1.66 step/s\r\n",
      "eval loss: 4.97492, f1 score: 0.45188, precison: 0.53507, recall: 0.42792\r\n",
      "eval loss: 4.91035, f1 score: 0.33734, precison: 0.28616, recall: 0.44305\r\n",
      "global step 1490, epoch: 9, batch: 138, loss: 1.19136, f1 score: 0.88512, speed: 0.55 step/s\r\n",
      "global step 1500, epoch: 9, batch: 148, loss: 1.40513, f1 score: 0.89479, speed: 1.80 step/s\r\n",
      "global step 1510, epoch: 9, batch: 158, loss: 1.35687, f1 score: 0.89201, speed: 1.61 step/s\r\n",
      "global step 1520, epoch: 9, batch: 168, loss: 1.02060, f1 score: 0.89302, speed: 1.47 step/s\r\n",
      "eval loss: 4.98479, f1 score: 0.46625, precison: 0.53825, recall: 0.43215\r\n",
      "eval loss: 4.83348, f1 score: 0.35324, precison: 0.32546, recall: 0.43965\r\n",
      "global step 1530, epoch: 10, batch: 9, loss: 1.10773, f1 score: 0.92006, speed: 0.55 step/s\r\n",
      "global step 1540, epoch: 10, batch: 19, loss: 1.08875, f1 score: 0.92218, speed: 1.52 step/s\r\n",
      "global step 1550, epoch: 10, batch: 29, loss: 0.87286, f1 score: 0.92397, speed: 1.65 step/s\r\n",
      "global step 1560, epoch: 10, batch: 39, loss: 0.86721, f1 score: 0.92508, speed: 1.70 step/s\r\n",
      "eval loss: 5.18824, f1 score: 0.45698, precison: 0.52040, recall: 0.43781\r\n",
      "eval loss: 4.99031, f1 score: 0.36408, precison: 0.33368, recall: 0.43912\r\n",
      "global step 1570, epoch: 10, batch: 49, loss: 0.90478, f1 score: 0.93717, speed: 0.56 step/s\r\n",
      "global step 1580, epoch: 10, batch: 59, loss: 0.89247, f1 score: 0.94141, speed: 1.60 step/s\r\n",
      "global step 1590, epoch: 10, batch: 69, loss: 0.99731, f1 score: 0.93576, speed: 1.69 step/s\r\n",
      "global step 1600, epoch: 10, batch: 79, loss: 1.01992, f1 score: 0.93115, speed: 1.59 step/s\r\n",
      "eval loss: 5.15281, f1 score: 0.47006, precison: 0.53538, recall: 0.44855\r\n",
      "eval loss: 5.05231, f1 score: 0.33646, precison: 0.28795, recall: 0.43846\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:45:24,100] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:45:36,013] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:45:36,016] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1610, epoch: 10, batch: 89, loss: 0.95544, f1 score: 0.93246, speed: 0.33 step/s\r\n",
      "global step 1620, epoch: 10, batch: 99, loss: 0.80955, f1 score: 0.92934, speed: 1.54 step/s\r\n",
      "global step 1630, epoch: 10, batch: 109, loss: 1.19103, f1 score: 0.92790, speed: 1.69 step/s\r\n",
      "global step 1640, epoch: 10, batch: 119, loss: 1.11744, f1 score: 0.92783, speed: 1.68 step/s\r\n",
      "eval loss: 5.18518, f1 score: 0.46724, precison: 0.54385, recall: 0.43090\r\n",
      "eval loss: 5.05233, f1 score: 0.33715, precison: 0.29596, recall: 0.41985\r\n",
      "global step 1650, epoch: 10, batch: 129, loss: 1.15165, f1 score: 0.92492, speed: 0.56 step/s\r\n",
      "global step 1660, epoch: 10, batch: 139, loss: 0.78620, f1 score: 0.93335, speed: 1.56 step/s\r\n",
      "global step 1670, epoch: 10, batch: 149, loss: 1.08533, f1 score: 0.93662, speed: 1.66 step/s\r\n",
      "global step 1680, epoch: 10, batch: 159, loss: 1.02232, f1 score: 0.93319, speed: 1.65 step/s\r\n",
      "eval loss: 5.31440, f1 score: 0.45747, precison: 0.52270, recall: 0.43690\r\n",
      "eval loss: 5.07678, f1 score: 0.32661, precison: 0.28214, recall: 0.42393\r\n",
      "global step 1690, epoch: 10, batch: 169, loss: 0.98249, f1 score: 0.91304, speed: 0.57 step/s\r\n",
      "global step 1700, epoch: 11, batch: 10, loss: 0.71157, f1 score: 0.94476, speed: 1.59 step/s\r\n",
      "global step 1710, epoch: 11, batch: 20, loss: 0.68352, f1 score: 0.94646, speed: 1.74 step/s\r\n",
      "global step 1720, epoch: 11, batch: 30, loss: 0.77741, f1 score: 0.94526, speed: 1.61 step/s\r\n",
      "eval loss: 5.41686, f1 score: 0.47521, precison: 0.52312, recall: 0.46005\r\n",
      "eval loss: 5.32375, f1 score: 0.35016, precison: 0.30294, recall: 0.47901\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:47:24,782] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:47:36,634] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:47:36,639] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1730, epoch: 11, batch: 40, loss: 0.93112, f1 score: 0.95230, speed: 0.33 step/s\r\n",
      "global step 1740, epoch: 11, batch: 50, loss: 1.06776, f1 score: 0.95014, speed: 1.51 step/s\r\n",
      "global step 1750, epoch: 11, batch: 60, loss: 0.95632, f1 score: 0.95348, speed: 1.57 step/s\r\n",
      "global step 1760, epoch: 11, batch: 70, loss: 0.75492, f1 score: 0.95209, speed: 1.58 step/s\r\n",
      "eval loss: 5.46707, f1 score: 0.47733, precison: 0.53434, recall: 0.45592\r\n",
      "eval loss: 5.29777, f1 score: 0.34214, precison: 0.28484, recall: 0.46253\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:48:14,158] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:48:26,202] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:48:26,205] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1770, epoch: 11, batch: 80, loss: 0.72860, f1 score: 0.96174, speed: 0.34 step/s\r\n",
      "global step 1780, epoch: 11, batch: 90, loss: 0.71436, f1 score: 0.95529, speed: 1.71 step/s\r\n",
      "global step 1790, epoch: 11, batch: 100, loss: 0.96701, f1 score: 0.95019, speed: 1.64 step/s\r\n",
      "global step 1800, epoch: 11, batch: 110, loss: 1.05396, f1 score: 0.94980, speed: 1.72 step/s\r\n",
      "eval loss: 5.53526, f1 score: 0.46358, precison: 0.52260, recall: 0.44914\r\n",
      "eval loss: 5.30072, f1 score: 0.35648, precison: 0.29662, recall: 0.46644\r\n",
      "global step 1810, epoch: 11, batch: 120, loss: 0.90577, f1 score: 0.93361, speed: 0.54 step/s\r\n",
      "global step 1820, epoch: 11, batch: 130, loss: 0.92675, f1 score: 0.93351, speed: 1.54 step/s\r\n",
      "global step 1830, epoch: 11, batch: 140, loss: 0.84533, f1 score: 0.94376, speed: 1.69 step/s\r\n",
      "global step 1840, epoch: 11, batch: 150, loss: 0.99986, f1 score: 0.94068, speed: 1.59 step/s\r\n",
      "eval loss: 5.67292, f1 score: 0.45862, precison: 0.52236, recall: 0.44063\r\n",
      "eval loss: 5.78966, f1 score: 0.33635, precison: 0.28843, recall: 0.44046\r\n",
      "global step 1850, epoch: 11, batch: 160, loss: 0.87708, f1 score: 0.93604, speed: 0.57 step/s\r\n",
      "global step 1860, epoch: 12, batch: 1, loss: 0.50625, f1 score: 0.94630, speed: 1.71 step/s\r\n",
      "global step 1870, epoch: 12, batch: 11, loss: 0.81623, f1 score: 0.95151, speed: 1.60 step/s\r\n",
      "global step 1880, epoch: 12, batch: 21, loss: 0.66253, f1 score: 0.95266, speed: 1.49 step/s\r\n",
      "eval loss: 5.66231, f1 score: 0.47012, precison: 0.52225, recall: 0.44834\r\n",
      "eval loss: 5.54421, f1 score: 0.34063, precison: 0.28243, recall: 0.46499\r\n",
      "global step 1890, epoch: 12, batch: 31, loss: 0.46219, f1 score: 0.95577, speed: 0.57 step/s\r\n",
      "global step 1900, epoch: 12, batch: 41, loss: 0.62792, f1 score: 0.96215, speed: 1.78 step/s\r\n",
      "global step 1910, epoch: 12, batch: 51, loss: 0.59864, f1 score: 0.96366, speed: 1.58 step/s\r\n",
      "global step 1920, epoch: 12, batch: 61, loss: 0.75968, f1 score: 0.96333, speed: 1.59 step/s\r\n",
      "eval loss: 5.65183, f1 score: 0.47059, precison: 0.52396, recall: 0.44759\r\n",
      "eval loss: 5.47700, f1 score: 0.32831, precison: 0.28569, recall: 0.42366\r\n",
      "global step 1930, epoch: 12, batch: 71, loss: 0.66243, f1 score: 0.95923, speed: 0.56 step/s\r\n",
      "global step 1940, epoch: 12, batch: 81, loss: 0.64707, f1 score: 0.95552, speed: 1.49 step/s\r\n",
      "global step 1950, epoch: 12, batch: 91, loss: 0.70770, f1 score: 0.95536, speed: 1.75 step/s\r\n",
      "global step 1960, epoch: 12, batch: 101, loss: 0.87688, f1 score: 0.95868, speed: 1.60 step/s\r\n",
      "eval loss: 5.79653, f1 score: 0.46418, precison: 0.52736, recall: 0.44324\r\n",
      "eval loss: 5.68716, f1 score: 0.33178, precison: 0.28166, recall: 0.44219\r\n",
      "global step 1970, epoch: 12, batch: 111, loss: 0.61230, f1 score: 0.95072, speed: 0.56 step/s\r\n",
      "global step 1980, epoch: 12, batch: 121, loss: 0.55275, f1 score: 0.96469, speed: 1.69 step/s\r\n",
      "global step 1990, epoch: 12, batch: 131, loss: 0.56712, f1 score: 0.96363, speed: 1.58 step/s\r\n",
      "global step 2000, epoch: 12, batch: 141, loss: 0.65060, f1 score: 0.96504, speed: 1.69 step/s\r\n",
      "eval loss: 5.84093, f1 score: 0.47817, precison: 0.53090, recall: 0.46360\r\n",
      "eval loss: 5.58552, f1 score: 0.36806, precison: 0.30318, recall: 0.49815\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:52:03,372] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:52:15,281] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:52:15,284] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2010, epoch: 12, batch: 151, loss: 0.68306, f1 score: 0.96516, speed: 0.33 step/s\r\n",
      "global step 2020, epoch: 12, batch: 161, loss: 0.66456, f1 score: 0.95941, speed: 1.64 step/s\r\n",
      "global step 2030, epoch: 13, batch: 2, loss: 0.56720, f1 score: 0.96128, speed: 1.70 step/s\r\n",
      "global step 2040, epoch: 13, batch: 12, loss: 0.67984, f1 score: 0.96397, speed: 1.74 step/s\r\n",
      "eval loss: 5.95194, f1 score: 0.47661, precison: 0.51294, recall: 0.46535\r\n",
      "eval loss: 5.71082, f1 score: 0.31050, precison: 0.26142, recall: 0.41428\r\n",
      "global step 2050, epoch: 13, batch: 22, loss: 0.65817, f1 score: 0.97747, speed: 0.55 step/s\r\n",
      "global step 2060, epoch: 13, batch: 32, loss: 0.61720, f1 score: 0.97286, speed: 1.60 step/s\r\n",
      "global step 2070, epoch: 13, batch: 42, loss: 0.54500, f1 score: 0.97631, speed: 1.57 step/s\r\n",
      "global step 2080, epoch: 13, batch: 52, loss: 0.35696, f1 score: 0.97668, speed: 1.63 step/s\r\n",
      "eval loss: 5.96524, f1 score: 0.48327, precison: 0.52876, recall: 0.46728\r\n",
      "eval loss: 5.78968, f1 score: 0.34595, precison: 0.32763, recall: 0.44918\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:53:27,997] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:53:40,098] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:53:40,102] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2090, epoch: 13, batch: 62, loss: 0.55511, f1 score: 0.97676, speed: 0.33 step/s\r\n",
      "global step 2100, epoch: 13, batch: 72, loss: 0.45450, f1 score: 0.97401, speed: 1.55 step/s\r\n",
      "global step 2110, epoch: 13, batch: 82, loss: 0.32420, f1 score: 0.97072, speed: 1.44 step/s\r\n",
      "global step 2120, epoch: 13, batch: 92, loss: 0.64047, f1 score: 0.97172, speed: 1.67 step/s\r\n",
      "eval loss: 5.98810, f1 score: 0.47577, precison: 0.51675, recall: 0.45952\r\n",
      "eval loss: 5.68259, f1 score: 0.35168, precison: 0.29640, recall: 0.47164\r\n",
      "global step 2130, epoch: 13, batch: 102, loss: 0.60634, f1 score: 0.97172, speed: 0.59 step/s\r\n",
      "global step 2140, epoch: 13, batch: 112, loss: 0.40812, f1 score: 0.96856, speed: 1.69 step/s\r\n",
      "global step 2150, epoch: 13, batch: 122, loss: 0.75256, f1 score: 0.96762, speed: 1.66 step/s\r\n",
      "global step 2160, epoch: 13, batch: 132, loss: 0.56520, f1 score: 0.96900, speed: 1.67 step/s\r\n",
      "eval loss: 6.20888, f1 score: 0.45975, precison: 0.52850, recall: 0.44908\r\n",
      "eval loss: 5.90526, f1 score: 0.34116, precison: 0.28422, recall: 0.44909\r\n",
      "global step 2170, epoch: 13, batch: 142, loss: 0.55600, f1 score: 0.96835, speed: 0.56 step/s\r\n",
      "global step 2180, epoch: 13, batch: 152, loss: 0.40605, f1 score: 0.97244, speed: 1.66 step/s\r\n",
      "global step 2190, epoch: 13, batch: 162, loss: 0.51158, f1 score: 0.97225, speed: 1.51 step/s\r\n",
      "global step 2200, epoch: 14, batch: 3, loss: 0.32317, f1 score: 0.97212, speed: 1.65 step/s\r\n",
      "eval loss: 6.16137, f1 score: 0.46125, precison: 0.53855, recall: 0.43868\r\n",
      "eval loss: 5.81744, f1 score: 0.34749, precison: 0.29065, recall: 0.46004\r\n",
      "global step 2210, epoch: 14, batch: 13, loss: 0.59644, f1 score: 0.98241, speed: 0.56 step/s\r\n",
      "global step 2220, epoch: 14, batch: 23, loss: 0.48005, f1 score: 0.98225, speed: 1.61 step/s\r\n",
      "global step 2230, epoch: 14, batch: 33, loss: 0.48901, f1 score: 0.98076, speed: 1.56 step/s\r\n",
      "global step 2240, epoch: 14, batch: 43, loss: 0.54559, f1 score: 0.97927, speed: 1.69 step/s\r\n",
      "eval loss: 6.14183, f1 score: 0.47222, precison: 0.53415, recall: 0.44383\r\n",
      "eval loss: 5.84547, f1 score: 0.35734, precison: 0.33455, recall: 0.44190\r\n",
      "global step 2250, epoch: 14, batch: 53, loss: 0.39233, f1 score: 0.97948, speed: 0.56 step/s\r\n",
      "global step 2260, epoch: 14, batch: 63, loss: 0.42431, f1 score: 0.98554, speed: 1.73 step/s\r\n",
      "global step 2270, epoch: 14, batch: 73, loss: 0.54630, f1 score: 0.97992, speed: 1.62 step/s\r\n",
      "global step 2280, epoch: 14, batch: 83, loss: 0.25258, f1 score: 0.97914, speed: 1.63 step/s\r\n",
      "eval loss: 6.18731, f1 score: 0.48515, precison: 0.52548, recall: 0.47039\r\n",
      "eval loss: 6.01195, f1 score: 0.33910, precison: 0.32629, recall: 0.42503\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:56:41,561] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 11:56:53,434] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 11:56:53,438] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2290, epoch: 14, batch: 93, loss: 0.31857, f1 score: 0.97364, speed: 0.33 step/s\r\n",
      "global step 2300, epoch: 14, batch: 103, loss: 0.75649, f1 score: 0.97637, speed: 1.70 step/s\r\n",
      "global step 2310, epoch: 14, batch: 113, loss: 0.21889, f1 score: 0.98061, speed: 1.59 step/s\r\n",
      "global step 2320, epoch: 14, batch: 123, loss: 0.63312, f1 score: 0.97709, speed: 1.60 step/s\r\n",
      "eval loss: 6.34990, f1 score: 0.48252, precison: 0.50874, recall: 0.47856\r\n",
      "eval loss: 6.15652, f1 score: 0.35332, precison: 0.32605, recall: 0.48284\r\n",
      "global step 2330, epoch: 14, batch: 133, loss: 0.34404, f1 score: 0.98643, speed: 0.56 step/s\r\n",
      "global step 2340, epoch: 14, batch: 143, loss: 0.40079, f1 score: 0.97711, speed: 1.74 step/s\r\n",
      "global step 2350, epoch: 14, batch: 153, loss: 0.37670, f1 score: 0.97682, speed: 1.65 step/s\r\n",
      "global step 2360, epoch: 14, batch: 163, loss: 0.59220, f1 score: 0.97439, speed: 1.69 step/s\r\n",
      "eval loss: 6.24704, f1 score: 0.46625, precison: 0.52541, recall: 0.43655\r\n",
      "eval loss: 5.72366, f1 score: 0.33862, precison: 0.32670, recall: 0.42567\r\n",
      "global step 2370, epoch: 15, batch: 4, loss: 0.36161, f1 score: 0.97353, speed: 0.55 step/s\r\n",
      "global step 2380, epoch: 15, batch: 14, loss: 0.37596, f1 score: 0.97865, speed: 1.56 step/s\r\n",
      "global step 2390, epoch: 15, batch: 24, loss: 0.51536, f1 score: 0.98019, speed: 1.64 step/s\r\n",
      "global step 2400, epoch: 15, batch: 34, loss: 0.24408, f1 score: 0.98098, speed: 1.70 step/s\r\n",
      "eval loss: 6.41923, f1 score: 0.47870, precison: 0.52383, recall: 0.46917\r\n",
      "eval loss: 6.15428, f1 score: 0.33777, precison: 0.28076, recall: 0.46219\r\n",
      "global step 2410, epoch: 15, batch: 44, loss: 0.59010, f1 score: 0.97673, speed: 0.56 step/s\r\n",
      "global step 2420, epoch: 15, batch: 54, loss: 0.34806, f1 score: 0.97717, speed: 1.76 step/s\r\n",
      "global step 2430, epoch: 15, batch: 64, loss: 0.45522, f1 score: 0.97521, speed: 1.61 step/s\r\n",
      "global step 2440, epoch: 15, batch: 74, loss: 0.36622, f1 score: 0.97560, speed: 1.63 step/s\r\n",
      "eval loss: 6.39101, f1 score: 0.47774, precison: 0.51821, recall: 0.46597\r\n",
      "eval loss: 6.36445, f1 score: 0.33578, precison: 0.27718, recall: 0.45444\r\n",
      "global step 2450, epoch: 15, batch: 84, loss: 0.32186, f1 score: 0.98677, speed: 0.54 step/s\r\n",
      "global step 2460, epoch: 15, batch: 94, loss: 0.61069, f1 score: 0.98169, speed: 1.69 step/s\r\n",
      "global step 2470, epoch: 15, batch: 104, loss: 0.47358, f1 score: 0.97732, speed: 1.64 step/s\r\n",
      "global step 2480, epoch: 15, batch: 114, loss: 0.45774, f1 score: 0.97804, speed: 1.73 step/s\r\n",
      "eval loss: 6.54163, f1 score: 0.47772, precison: 0.53585, recall: 0.46168\r\n",
      "eval loss: 6.26011, f1 score: 0.39430, precison: 0.34022, recall: 0.57230\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 11:59:54,559] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu/config.json\r\n",
      "[2022-12-29 12:00:19,202] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu/tokenizer_config.json\r\n",
      "[2022-12-29 12:00:19,221] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2490, epoch: 15, batch: 124, loss: 0.26813, f1 score: 0.99123, speed: 0.23 step/s\r\n",
      "global step 2500, epoch: 15, batch: 134, loss: 0.37820, f1 score: 0.98299, speed: 1.78 step/s\r\n",
      "global step 2510, epoch: 15, batch: 144, loss: 0.29995, f1 score: 0.98606, speed: 1.59 step/s\r\n",
      "global step 2520, epoch: 15, batch: 154, loss: 0.34441, f1 score: 0.98491, speed: 1.72 step/s\r\n",
      "eval loss: 6.50462, f1 score: 0.48911, precison: 0.53623, recall: 0.47334\r\n",
      "eval loss: 6.28880, f1 score: 0.34251, precison: 0.28111, recall: 0.47931\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 12:00:54,927] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 12:01:09,544] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 12:01:09,548] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2530, epoch: 15, batch: 164, loss: 0.47579, f1 score: 0.98157, speed: 0.31 step/s\r\n",
      "global step 2540, epoch: 16, batch: 5, loss: 0.43891, f1 score: 0.98233, speed: 1.66 step/s\r\n",
      "global step 2550, epoch: 16, batch: 15, loss: 0.34689, f1 score: 0.98204, speed: 1.66 step/s\r\n",
      "global step 2560, epoch: 16, batch: 25, loss: 0.42079, f1 score: 0.98301, speed: 1.64 step/s\r\n",
      "eval loss: 6.65712, f1 score: 0.48505, precison: 0.51982, recall: 0.48329\r\n",
      "eval loss: 6.39782, f1 score: 0.34724, precison: 0.28115, recall: 0.51078\r\n",
      "global step 2570, epoch: 16, batch: 35, loss: 0.25801, f1 score: 0.98461, speed: 0.55 step/s\r\n",
      "global step 2580, epoch: 16, batch: 45, loss: 0.24862, f1 score: 0.98766, speed: 1.62 step/s\r\n",
      "global step 2590, epoch: 16, batch: 55, loss: 0.21864, f1 score: 0.98727, speed: 1.64 step/s\r\n",
      "global step 2600, epoch: 16, batch: 65, loss: 0.50354, f1 score: 0.98738, speed: 1.53 step/s\r\n",
      "eval loss: 6.60937, f1 score: 0.48753, precison: 0.51832, recall: 0.48009\r\n",
      "eval loss: 6.32857, f1 score: 0.34336, precison: 0.28279, recall: 0.49010\r\n",
      "global step 2610, epoch: 16, batch: 75, loss: 0.29974, f1 score: 0.98549, speed: 0.55 step/s\r\n",
      "global step 2620, epoch: 16, batch: 85, loss: 0.25958, f1 score: 0.98211, speed: 1.81 step/s\r\n",
      "global step 2630, epoch: 16, batch: 95, loss: 0.42048, f1 score: 0.98114, speed: 1.83 step/s\r\n",
      "global step 2640, epoch: 16, batch: 105, loss: 0.41688, f1 score: 0.98103, speed: 1.65 step/s\r\n",
      "eval loss: 6.68208, f1 score: 0.48706, precison: 0.52555, recall: 0.48417\r\n",
      "eval loss: 6.35619, f1 score: 0.35076, precison: 0.28210, recall: 0.49431\r\n",
      "global step 2650, epoch: 16, batch: 115, loss: 0.49555, f1 score: 0.97679, speed: 0.55 step/s\r\n",
      "global step 2660, epoch: 16, batch: 125, loss: 0.17655, f1 score: 0.98075, speed: 1.62 step/s\r\n",
      "global step 2670, epoch: 16, batch: 135, loss: 0.57940, f1 score: 0.98016, speed: 1.74 step/s\r\n",
      "global step 2680, epoch: 16, batch: 145, loss: 0.53869, f1 score: 0.97957, speed: 1.60 step/s\r\n",
      "eval loss: 6.59849, f1 score: 0.48114, precison: 0.52762, recall: 0.45781\r\n",
      "eval loss: 6.72048, f1 score: 0.33946, precison: 0.27886, recall: 0.48661\r\n",
      "global step 2690, epoch: 16, batch: 155, loss: 0.20852, f1 score: 0.98088, speed: 0.55 step/s\r\n",
      "global step 2700, epoch: 16, batch: 165, loss: 0.36555, f1 score: 0.98301, speed: 1.71 step/s\r\n",
      "global step 2710, epoch: 17, batch: 6, loss: 0.41423, f1 score: 0.98150, speed: 1.74 step/s\r\n",
      "global step 2720, epoch: 17, batch: 16, loss: 0.24372, f1 score: 0.98367, speed: 1.62 step/s\r\n",
      "eval loss: 6.68408, f1 score: 0.47667, precison: 0.52913, recall: 0.45434\r\n",
      "eval loss: 6.52546, f1 score: 0.34258, precison: 0.33266, recall: 0.42057\r\n",
      "global step 2730, epoch: 17, batch: 26, loss: 0.35001, f1 score: 0.98462, speed: 0.56 step/s\r\n",
      "global step 2740, epoch: 17, batch: 36, loss: 0.61919, f1 score: 0.98317, speed: 1.66 step/s\r\n",
      "global step 2750, epoch: 17, batch: 46, loss: 0.35855, f1 score: 0.98488, speed: 1.64 step/s\r\n",
      "global step 2760, epoch: 17, batch: 56, loss: 0.24116, f1 score: 0.98533, speed: 1.63 step/s\r\n",
      "eval loss: 6.75072, f1 score: 0.47841, precison: 0.52195, recall: 0.46471\r\n",
      "eval loss: 6.65691, f1 score: 0.37211, precison: 0.34355, recall: 0.50777\r\n",
      "global step 2770, epoch: 17, batch: 66, loss: 0.17248, f1 score: 0.98414, speed: 0.57 step/s\r\n",
      "global step 2780, epoch: 17, batch: 76, loss: 0.31293, f1 score: 0.98071, speed: 1.64 step/s\r\n",
      "global step 2790, epoch: 17, batch: 86, loss: 0.42167, f1 score: 0.98178, speed: 1.47 step/s\r\n",
      "global step 2800, epoch: 17, batch: 96, loss: 0.25948, f1 score: 0.98278, speed: 1.61 step/s\r\n",
      "eval loss: 6.74443, f1 score: 0.47576, precison: 0.51451, recall: 0.46303\r\n",
      "eval loss: 6.66378, f1 score: 0.33078, precison: 0.28165, recall: 0.44861\r\n",
      "global step 2810, epoch: 17, batch: 106, loss: 0.25736, f1 score: 0.97981, speed: 0.54 step/s\r\n",
      "global step 2820, epoch: 17, batch: 116, loss: 0.17952, f1 score: 0.98183, speed: 1.61 step/s\r\n",
      "global step 2830, epoch: 17, batch: 126, loss: 0.29708, f1 score: 0.98196, speed: 1.79 step/s\r\n",
      "global step 2840, epoch: 17, batch: 136, loss: 0.17704, f1 score: 0.98403, speed: 1.58 step/s\r\n",
      "eval loss: 6.73937, f1 score: 0.48104, precison: 0.53370, recall: 0.45813\r\n",
      "eval loss: 6.45353, f1 score: 0.31291, precison: 0.26822, recall: 0.42724\r\n",
      "global step 2850, epoch: 17, batch: 146, loss: 0.37531, f1 score: 0.98345, speed: 0.55 step/s\r\n",
      "global step 2860, epoch: 17, batch: 156, loss: 0.26388, f1 score: 0.98096, speed: 1.66 step/s\r\n",
      "global step 2870, epoch: 17, batch: 166, loss: 0.29484, f1 score: 0.98234, speed: 1.59 step/s\r\n",
      "global step 2880, epoch: 18, batch: 7, loss: 0.22946, f1 score: 0.98252, speed: 1.59 step/s\r\n",
      "eval loss: 6.93278, f1 score: 0.48606, precison: 0.51280, recall: 0.48098\r\n",
      "eval loss: 6.81511, f1 score: 0.31172, precison: 0.26140, recall: 0.43029\r\n",
      "global step 2890, epoch: 18, batch: 17, loss: 0.18566, f1 score: 0.98577, speed: 0.55 step/s\r\n",
      "global step 2900, epoch: 18, batch: 27, loss: 0.40787, f1 score: 0.98696, speed: 1.57 step/s\r\n",
      "global step 2910, epoch: 18, batch: 37, loss: 0.26881, f1 score: 0.98540, speed: 1.74 step/s\r\n",
      "global step 2920, epoch: 18, batch: 47, loss: 0.22264, f1 score: 0.98706, speed: 1.67 step/s\r\n",
      "eval loss: 7.00030, f1 score: 0.48544, precison: 0.53338, recall: 0.47331\r\n",
      "eval loss: 6.89126, f1 score: 0.35742, precison: 0.32745, recall: 0.47509\r\n",
      "global step 2930, epoch: 18, batch: 57, loss: 0.45699, f1 score: 0.98742, speed: 0.55 step/s\r\n",
      "global step 2940, epoch: 18, batch: 67, loss: 0.12558, f1 score: 0.98802, speed: 1.71 step/s\r\n",
      "global step 2950, epoch: 18, batch: 77, loss: 0.21850, f1 score: 0.98520, speed: 1.55 step/s\r\n",
      "global step 2960, epoch: 18, batch: 87, loss: 0.21031, f1 score: 0.98633, speed: 1.55 step/s\r\n",
      "eval loss: 7.03431, f1 score: 0.48026, precison: 0.52880, recall: 0.46551\r\n",
      "eval loss: 6.89820, f1 score: 0.34500, precison: 0.31762, recall: 0.43899\r\n",
      "global step 2970, epoch: 18, batch: 97, loss: 0.19246, f1 score: 0.99021, speed: 0.56 step/s\r\n",
      "global step 2980, epoch: 18, batch: 107, loss: 0.25878, f1 score: 0.98558, speed: 1.70 step/s\r\n",
      "global step 2990, epoch: 18, batch: 117, loss: 0.17985, f1 score: 0.98468, speed: 1.83 step/s\r\n",
      "global step 3000, epoch: 18, batch: 127, loss: 0.33304, f1 score: 0.98435, speed: 1.65 step/s\r\n",
      "eval loss: 7.01792, f1 score: 0.49189, precison: 0.52654, recall: 0.48107\r\n",
      "eval loss: 6.95169, f1 score: 0.30715, precison: 0.26447, recall: 0.40759\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 12:08:24,610] [    INFO] - Configuration saved in ernie2.0_ckpt/config.json\r\n",
      "[2022-12-29 12:08:37,585] [    INFO] - tokenizer config file saved in ernie2.0_ckpt/tokenizer_config.json\r\n",
      "[2022-12-29 12:08:37,588] [    INFO] - Special tokens file saved in ernie2.0_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 3010, epoch: 18, batch: 137, loss: 0.32662, f1 score: 0.98742, speed: 0.33 step/s\r\n",
      "global step 3020, epoch: 18, batch: 147, loss: 0.40685, f1 score: 0.98560, speed: 1.63 step/s\r\n",
      "global step 3030, epoch: 18, batch: 157, loss: 0.26224, f1 score: 0.98320, speed: 1.70 step/s\r\n",
      "global step 3040, epoch: 18, batch: 167, loss: 0.26660, f1 score: 0.98207, speed: 1.59 step/s\r\n",
      "eval loss: 7.03179, f1 score: 0.48569, precison: 0.54195, recall: 0.46862\r\n",
      "eval loss: 6.81358, f1 score: 0.31031, precison: 0.25938, recall: 0.42364\r\n",
      "global step 3050, epoch: 19, batch: 8, loss: 0.18939, f1 score: 0.99327, speed: 0.57 step/s\r\n",
      "global step 3060, epoch: 19, batch: 18, loss: 0.23990, f1 score: 0.99162, speed: 1.80 step/s\r\n",
      "global step 3070, epoch: 19, batch: 28, loss: 0.24451, f1 score: 0.99055, speed: 1.65 step/s\r\n",
      "global step 3080, epoch: 19, batch: 38, loss: 0.23496, f1 score: 0.99075, speed: 1.60 step/s\r\n",
      "eval loss: 7.21831, f1 score: 0.48455, precison: 0.52628, recall: 0.48090\r\n",
      "eval loss: 6.91323, f1 score: 0.34343, precison: 0.28500, recall: 0.47346\r\n",
      "global step 3090, epoch: 19, batch: 48, loss: 0.13090, f1 score: 0.99052, speed: 0.56 step/s\r\n",
      "global step 3100, epoch: 19, batch: 58, loss: 0.11421, f1 score: 0.98292, speed: 1.60 step/s\r\n",
      "global step 3110, epoch: 19, batch: 68, loss: 0.34297, f1 score: 0.98153, speed: 1.60 step/s\r\n",
      "global step 3120, epoch: 19, batch: 78, loss: 0.44384, f1 score: 0.98368, speed: 1.77 step/s\r\n",
      "eval loss: 7.18196, f1 score: 0.47581, precison: 0.53019, recall: 0.46581\r\n",
      "eval loss: 7.12379, f1 score: 0.32251, precison: 0.26604, recall: 0.45907\r\n",
      "global step 3130, epoch: 19, batch: 88, loss: 0.27697, f1 score: 0.99089, speed: 0.55 step/s\r\n",
      "global step 3140, epoch: 19, batch: 98, loss: 0.48648, f1 score: 0.98912, speed: 1.64 step/s\r\n",
      "global step 3150, epoch: 19, batch: 108, loss: 0.18138, f1 score: 0.98986, speed: 1.65 step/s\r\n",
      "global step 3160, epoch: 19, batch: 118, loss: 0.15595, f1 score: 0.98987, speed: 1.61 step/s\r\n",
      "eval loss: 7.11190, f1 score: 0.46374, precison: 0.52393, recall: 0.44326\r\n",
      "eval loss: 6.81847, f1 score: 0.38293, precison: 0.35071, recall: 0.48684\r\n",
      "global step 3170, epoch: 19, batch: 128, loss: 0.15889, f1 score: 0.98771, speed: 0.57 step/s\r\n",
      "global step 3180, epoch: 19, batch: 138, loss: 0.25193, f1 score: 0.98568, speed: 1.64 step/s\r\n",
      "global step 3190, epoch: 19, batch: 148, loss: 0.11854, f1 score: 0.98425, speed: 1.63 step/s\r\n",
      "global step 3200, epoch: 19, batch: 158, loss: 0.14015, f1 score: 0.98423, speed: 1.54 step/s\r\n",
      "eval loss: 7.06164, f1 score: 0.47258, precison: 0.53850, recall: 0.45070\r\n",
      "eval loss: 6.89916, f1 score: 0.35349, precison: 0.32918, recall: 0.45407\r\n",
      "global step 3210, epoch: 19, batch: 168, loss: 0.53950, f1 score: 0.98978, speed: 0.56 step/s\r\n",
      "global step 3220, epoch: 20, batch: 9, loss: 0.17022, f1 score: 0.98664, speed: 1.77 step/s\r\n",
      "global step 3230, epoch: 20, batch: 19, loss: 0.32801, f1 score: 0.98778, speed: 1.66 step/s\r\n",
      "global step 3240, epoch: 20, batch: 29, loss: 0.19586, f1 score: 0.98873, speed: 1.59 step/s\r\n",
      "eval loss: 7.40214, f1 score: 0.47365, precison: 0.51337, recall: 0.46679\r\n",
      "eval loss: 7.02780, f1 score: 0.36942, precison: 0.32726, recall: 0.49908\r\n",
      "global step 3250, epoch: 20, batch: 39, loss: 0.20437, f1 score: 0.99349, speed: 0.55 step/s\r\n",
      "global step 3260, epoch: 20, batch: 49, loss: 0.23124, f1 score: 0.99253, speed: 1.82 step/s\r\n",
      "global step 3270, epoch: 20, batch: 59, loss: 0.27800, f1 score: 0.99149, speed: 1.53 step/s\r\n",
      "global step 3280, epoch: 20, batch: 69, loss: 0.13068, f1 score: 0.99006, speed: 1.55 step/s\r\n",
      "eval loss: 7.25298, f1 score: 0.47775, precison: 0.53339, recall: 0.45880\r\n",
      "eval loss: 6.96507, f1 score: 0.36007, precison: 0.34111, recall: 0.46490\r\n",
      "global step 3290, epoch: 20, batch: 79, loss: 0.19011, f1 score: 0.99139, speed: 0.56 step/s\r\n",
      "global step 3300, epoch: 20, batch: 89, loss: 0.22854, f1 score: 0.98928, speed: 1.65 step/s\r\n",
      "global step 3310, epoch: 20, batch: 99, loss: 0.19798, f1 score: 0.98885, speed: 1.50 step/s\r\n",
      "global step 3320, epoch: 20, batch: 109, loss: 0.12581, f1 score: 0.98909, speed: 1.60 step/s\r\n",
      "eval loss: 7.46039, f1 score: 0.48200, precison: 0.52115, recall: 0.46587\r\n",
      "eval loss: 7.03367, f1 score: 0.35870, precison: 0.31566, recall: 0.48246\r\n",
      "global step 3330, epoch: 20, batch: 119, loss: 0.11167, f1 score: 0.99169, speed: 0.58 step/s\r\n",
      "global step 3340, epoch: 20, batch: 129, loss: 0.11758, f1 score: 0.99003, speed: 1.65 step/s\r\n",
      "global step 3350, epoch: 20, batch: 139, loss: 0.27562, f1 score: 0.98774, speed: 1.74 step/s\r\n",
      "global step 3360, epoch: 20, batch: 149, loss: 0.26061, f1 score: 0.98670, speed: 1.64 step/s\r\n",
      "eval loss: 7.36594, f1 score: 0.48253, precison: 0.52881, recall: 0.46258\r\n",
      "eval loss: 7.02412, f1 score: 0.33691, precison: 0.31992, recall: 0.44388\r\n",
      "global step 3370, epoch: 20, batch: 159, loss: 0.20123, f1 score: 0.97836, speed: 0.55 step/s\r\n",
      "global step 3380, epoch: 20, batch: 169, loss: 0.54909, f1 score: 0.97541, speed: 1.78 step/s\r\n"
     ]
    }
   ],
   "source": [
    "epochs = 20 # 训练轮次\n",
    "ckpt_dir = \"ernie2.0_ckpt\" # 训练过程中保存模型参数的文件夹\n",
    "save_dir2 = \"ernie2.0_ckpt_zhihu\"\n",
    "\n",
    "global_step = 0  # 迭代次数\n",
    "tic_train = time.time()\n",
    "best_f1_score = 0\n",
    "best_f1_score2 = 0\n",
    "\n",
    "# 模型训练\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "\n",
    "        # 计算模型输出、损失函数值、分类概率值、准确率、f1分数\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        \n",
    "        loss = criterion(labels, logits)\n",
    "        loss = loss.mean()\n",
    "        probs = logits\n",
    "        #probs = F.sigmoid(logits)\n",
    "        metric.update(probs, labels)\n",
    "        \n",
    "        # auc, f1_score, _,  _= metric.accumulate()\n",
    "        f1_score, _,  _= metric.accumulate()\n",
    "\n",
    "\n",
    "        # 每迭代100次，打印损失函数值、准确率、f1分数、计算速度\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, f1 score: %.5f, speed: %.2f step/s\"\n",
    "                % (global_step, epoch, step, loss, f1_score,\n",
    "                    10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        \n",
    "        # 反向梯度回传，更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        \n",
    "        #每迭代40次，评估当前训练的模型、保存当前最佳模型参数和分词器的词表等\n",
    "        if global_step % 40 == 0:\n",
    "            save_dir = ckpt_dir\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            eval_f1_score = evaluate(model, criterion, metric, valid_data_loader, label_vocab, if_return_results=False)\n",
    "            eval_f1_score2 = evaluate(model, criterion, metric, validZhihu_data_loader, label_vocab, if_return_results=False)\n",
    "            if eval_f1_score > best_f1_score:\n",
    "                best_f1_score = eval_f1_score\n",
    "                model.save_pretrained(save_dir)\n",
    "                tokenizer.save_pretrained(save_dir)\n",
    "            if eval_f1_score2 > best_f1_score2:\n",
    "                best_f1_score2 = eval_f1_score2\n",
    "                model.save_pretrained(save_dir2)\n",
    "                tokenizer.save_pretrained(save_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8eba0db-6e4c-4242-a5e4-e57ff74ec8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T04:27:22.813476Z",
     "iopub.status.busy": "2022-12-29T04:27:22.812725Z",
     "iopub.status.idle": "2022-12-29T04:27:37.144889Z",
     "shell.execute_reply": "2022-12-29T04:27:37.144083Z",
     "shell.execute_reply.started": "2022-12-29T04:27:22.813430Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNIE 3.0 在20分类验证集的最佳表现： eval loss: 7.01792, f1 score: 0.49189, precison: 0.52654, recall: 0.48107\r\n",
      "ERNIE 2.0 在20分类知乎验证集的最佳表现： eval loss: 6.95169, f1 score: 0.30715, precison: 0.26447, recall: 0.40759\r\n"
     ]
    }
   ],
   "source": [
    "# 模型加载\n",
    "# 加载最后的模型参数\n",
    "model.set_dict(paddle.load('ernie2.0_ckpt/model_state.pdparams'))\n",
    "\n",
    "# 加载之前训练好的模型参数\n",
    "# model.set_dict(paddle.load('/home/aistudio/work/model_state.pdparams'))\n",
    "\n",
    "# 模型验证\n",
    "print(\"ERNIE 3.0 在20分类验证集的最佳表现：\", end= \" \")\n",
    "results1 = evaluate(model, criterion, metric, valid_data_loader, label_vocab)\n",
    "print(\"ERNIE 2.0 在20分类知乎验证集的最佳表现：\", end= \" \")\n",
    "results = evaluate(model, criterion, metric, validZhihu_data_loader, label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59432852-ee3a-4428-864e-898d7956f90e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#接下来调低学习率继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd16e98-4313-47e4-aac4-b3593c078a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T04:27:41.914678Z",
     "iopub.status.busy": "2022-12-29T04:27:41.913983Z",
     "iopub.status.idle": "2022-12-29T04:45:54.049720Z",
     "shell.execute_reply": "2022-12-29T04:45:54.048766Z",
     "shell.execute_reply.started": "2022-12-29T04:27:41.914631Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.21115, f1 score: 0.98385, speed: 1.66 step/s\r\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.16292, f1 score: 0.98723, speed: 1.73 step/s\r\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.21903, f1 score: 0.98882, speed: 1.63 step/s\r\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.31735, f1 score: 0.98897, speed: 1.77 step/s\r\n",
      "eval loss: 7.06932, f1 score: 0.48287, precison: 0.52517, recall: 0.46811\r\n",
      "eval loss: 6.89580, f1 score: 0.33898, precison: 0.28671, recall: 0.45758\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 12:28:17,567] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu_2/config.json\r\n",
      "[2022-12-29 12:28:21,176] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu_2/tokenizer_config.json\r\n",
      "[2022-12-29 12:28:21,180] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu_2/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 50, epoch: 1, batch: 50, loss: 0.26855, f1 score: 0.98274, speed: 0.47 step/s\r\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.36780, f1 score: 0.98395, speed: 1.62 step/s\r\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.14001, f1 score: 0.98685, speed: 1.58 step/s\r\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.42516, f1 score: 0.98601, speed: 1.70 step/s\r\n",
      "eval loss: 7.15546, f1 score: 0.47923, precison: 0.53627, recall: 0.45987\r\n",
      "eval loss: 7.08550, f1 score: 0.36831, precison: 0.31563, recall: 0.48252\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 12:28:57,495] [    INFO] - Configuration saved in ernie2.0_ckpt_zhihu_2/config.json\r\n",
      "[2022-12-29 12:29:10,478] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_zhihu_2/tokenizer_config.json\r\n",
      "[2022-12-29 12:29:10,481] [    INFO] - Special tokens file saved in ernie2.0_ckpt_zhihu_2/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 90, epoch: 1, batch: 90, loss: 0.24385, f1 score: 0.98606, speed: 0.33 step/s\r\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.15140, f1 score: 0.98754, speed: 1.85 step/s\r\n",
      "global step 110, epoch: 1, batch: 110, loss: 0.11361, f1 score: 0.98634, speed: 1.65 step/s\r\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.16482, f1 score: 0.98783, speed: 1.78 step/s\r\n",
      "eval loss: 7.11093, f1 score: 0.47989, precison: 0.52526, recall: 0.45943\r\n",
      "eval loss: 6.98985, f1 score: 0.34697, precison: 0.33055, recall: 0.44697\r\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.23779, f1 score: 0.98184, speed: 0.55 step/s\r\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.27784, f1 score: 0.98685, speed: 1.68 step/s\r\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.15618, f1 score: 0.98787, speed: 1.78 step/s\r\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.22180, f1 score: 0.98697, speed: 1.57 step/s\r\n",
      "eval loss: 7.04342, f1 score: 0.47451, precison: 0.53075, recall: 0.45275\r\n",
      "eval loss: 6.96310, f1 score: 0.35033, precison: 0.33452, recall: 0.45170\r\n",
      "global step 170, epoch: 2, batch: 1, loss: 0.27266, f1 score: 0.99015, speed: 0.58 step/s\r\n",
      "global step 180, epoch: 2, batch: 11, loss: 0.22515, f1 score: 0.99249, speed: 1.60 step/s\r\n",
      "global step 190, epoch: 2, batch: 21, loss: 0.21531, f1 score: 0.99201, speed: 1.74 step/s\r\n",
      "global step 200, epoch: 2, batch: 31, loss: 0.17179, f1 score: 0.99225, speed: 1.62 step/s\r\n",
      "eval loss: 7.26249, f1 score: 0.47157, precison: 0.53821, recall: 0.44825\r\n",
      "eval loss: 7.03328, f1 score: 0.34051, precison: 0.28510, recall: 0.45703\r\n",
      "global step 210, epoch: 2, batch: 41, loss: 0.10144, f1 score: 0.99147, speed: 0.56 step/s\r\n",
      "global step 220, epoch: 2, batch: 51, loss: 0.15404, f1 score: 0.98867, speed: 1.56 step/s\r\n",
      "global step 230, epoch: 2, batch: 61, loss: 0.30891, f1 score: 0.98768, speed: 1.56 step/s\r\n",
      "global step 240, epoch: 2, batch: 71, loss: 0.20802, f1 score: 0.98801, speed: 1.55 step/s\r\n",
      "eval loss: 7.15236, f1 score: 0.48008, precison: 0.51746, recall: 0.46484\r\n",
      "eval loss: 7.28858, f1 score: 0.31977, precison: 0.27054, recall: 0.43405\r\n",
      "global step 250, epoch: 2, batch: 81, loss: 0.20121, f1 score: 0.99427, speed: 0.56 step/s\r\n",
      "global step 260, epoch: 2, batch: 91, loss: 0.43443, f1 score: 0.98703, speed: 1.53 step/s\r\n",
      "global step 270, epoch: 2, batch: 101, loss: 0.43910, f1 score: 0.98915, speed: 1.61 step/s\r\n",
      "global step 280, epoch: 2, batch: 111, loss: 0.09234, f1 score: 0.98917, speed: 1.86 step/s\r\n",
      "eval loss: 7.15090, f1 score: 0.48415, precison: 0.53406, recall: 0.46386\r\n",
      "eval loss: 7.09826, f1 score: 0.33858, precison: 0.28543, recall: 0.45105\r\n",
      "global step 290, epoch: 2, batch: 121, loss: 0.11034, f1 score: 0.98351, speed: 0.57 step/s\r\n",
      "global step 300, epoch: 2, batch: 131, loss: 0.23806, f1 score: 0.98813, speed: 1.81 step/s\r\n",
      "global step 310, epoch: 2, batch: 141, loss: 0.26688, f1 score: 0.98889, speed: 1.72 step/s\r\n",
      "global step 320, epoch: 2, batch: 151, loss: 0.18163, f1 score: 0.98835, speed: 1.62 step/s\r\n",
      "eval loss: 7.18714, f1 score: 0.48793, precison: 0.52622, recall: 0.47309\r\n",
      "eval loss: 7.15659, f1 score: 0.35094, precison: 0.33118, recall: 0.47395\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 12:32:45,032] [    INFO] - Configuration saved in ernie2.0_ckpt_2/config.json\r\n",
      "[2022-12-29 12:32:48,565] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_2/tokenizer_config.json\r\n",
      "[2022-12-29 12:32:48,570] [    INFO] - Special tokens file saved in ernie2.0_ckpt_2/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 330, epoch: 2, batch: 161, loss: 0.42477, f1 score: 0.98692, speed: 0.47 step/s\r\n",
      "global step 340, epoch: 3, batch: 2, loss: 0.17821, f1 score: 0.98679, speed: 1.51 step/s\r\n",
      "global step 350, epoch: 3, batch: 12, loss: 0.27965, f1 score: 0.98829, speed: 1.68 step/s\r\n",
      "global step 360, epoch: 3, batch: 22, loss: 0.14351, f1 score: 0.98821, speed: 1.57 step/s\r\n",
      "eval loss: 7.27132, f1 score: 0.48481, precison: 0.53005, recall: 0.46868\r\n",
      "eval loss: 7.10334, f1 score: 0.33454, precison: 0.32406, recall: 0.42970\r\n",
      "global step 370, epoch: 3, batch: 32, loss: 0.23289, f1 score: 0.99221, speed: 0.56 step/s\r\n",
      "global step 380, epoch: 3, batch: 42, loss: 0.13566, f1 score: 0.99182, speed: 1.66 step/s\r\n",
      "global step 390, epoch: 3, batch: 52, loss: 0.31035, f1 score: 0.99115, speed: 1.66 step/s\r\n",
      "global step 400, epoch: 3, batch: 62, loss: 0.31810, f1 score: 0.98940, speed: 1.67 step/s\r\n",
      "eval loss: 7.33294, f1 score: 0.47639, precison: 0.53946, recall: 0.45930\r\n",
      "eval loss: 7.20191, f1 score: 0.33663, precison: 0.32280, recall: 0.43760\r\n",
      "global step 410, epoch: 3, batch: 72, loss: 0.09074, f1 score: 0.99526, speed: 0.56 step/s\r\n",
      "global step 420, epoch: 3, batch: 82, loss: 0.29250, f1 score: 0.99336, speed: 1.62 step/s\r\n",
      "global step 430, epoch: 3, batch: 92, loss: 0.09891, f1 score: 0.99229, speed: 1.60 step/s\r\n",
      "global step 440, epoch: 3, batch: 102, loss: 0.10675, f1 score: 0.99293, speed: 1.62 step/s\r\n",
      "eval loss: 7.31519, f1 score: 0.48561, precison: 0.52724, recall: 0.47063\r\n",
      "eval loss: 7.17413, f1 score: 0.32512, precison: 0.27562, recall: 0.43219\r\n",
      "global step 450, epoch: 3, batch: 112, loss: 0.09282, f1 score: 0.98495, speed: 0.55 step/s\r\n",
      "global step 460, epoch: 3, batch: 122, loss: 0.10239, f1 score: 0.98782, speed: 1.70 step/s\r\n",
      "global step 470, epoch: 3, batch: 132, loss: 0.16191, f1 score: 0.98673, speed: 1.76 step/s\r\n",
      "global step 480, epoch: 3, batch: 142, loss: 0.35747, f1 score: 0.98603, speed: 1.74 step/s\r\n",
      "eval loss: 7.33054, f1 score: 0.47949, precison: 0.53581, recall: 0.45938\r\n",
      "eval loss: 7.10674, f1 score: 0.32910, precison: 0.27764, recall: 0.42966\r\n",
      "global step 490, epoch: 3, batch: 152, loss: 0.16809, f1 score: 0.98669, speed: 0.55 step/s\r\n",
      "global step 500, epoch: 3, batch: 162, loss: 0.27387, f1 score: 0.98662, speed: 1.61 step/s\r\n",
      "global step 510, epoch: 4, batch: 3, loss: 0.19782, f1 score: 0.98747, speed: 1.80 step/s\r\n",
      "global step 520, epoch: 4, batch: 13, loss: 0.16685, f1 score: 0.98825, speed: 1.81 step/s\r\n",
      "eval loss: 7.35130, f1 score: 0.47956, precison: 0.53449, recall: 0.45944\r\n",
      "eval loss: 7.04480, f1 score: 0.32733, precison: 0.27588, recall: 0.43074\r\n",
      "global step 530, epoch: 4, batch: 23, loss: 0.07225, f1 score: 0.99332, speed: 0.56 step/s\r\n",
      "global step 540, epoch: 4, batch: 33, loss: 0.09042, f1 score: 0.99469, speed: 1.67 step/s\r\n",
      "global step 550, epoch: 4, batch: 43, loss: 0.12540, f1 score: 0.99430, speed: 1.55 step/s\r\n",
      "global step 560, epoch: 4, batch: 53, loss: 0.19895, f1 score: 0.99369, speed: 1.65 step/s\r\n",
      "eval loss: 7.46083, f1 score: 0.47834, precison: 0.52475, recall: 0.46481\r\n",
      "eval loss: 7.29920, f1 score: 0.32590, precison: 0.31036, recall: 0.42358\r\n",
      "global step 570, epoch: 4, batch: 63, loss: 0.27019, f1 score: 0.98008, speed: 0.55 step/s\r\n",
      "global step 580, epoch: 4, batch: 73, loss: 0.19000, f1 score: 0.98309, speed: 1.55 step/s\r\n",
      "global step 590, epoch: 4, batch: 83, loss: 0.37152, f1 score: 0.98468, speed: 1.62 step/s\r\n",
      "global step 600, epoch: 4, batch: 93, loss: 0.27705, f1 score: 0.98684, speed: 1.62 step/s\r\n",
      "eval loss: 7.40607, f1 score: 0.48678, precison: 0.51807, recall: 0.47776\r\n",
      "eval loss: 7.29930, f1 score: 0.33756, precison: 0.28784, recall: 0.44081\r\n",
      "global step 610, epoch: 4, batch: 103, loss: 0.09203, f1 score: 0.99299, speed: 0.55 step/s\r\n",
      "global step 620, epoch: 4, batch: 113, loss: 0.07397, f1 score: 0.99250, speed: 1.65 step/s\r\n",
      "global step 630, epoch: 4, batch: 123, loss: 0.10150, f1 score: 0.99235, speed: 1.67 step/s\r\n",
      "global step 640, epoch: 4, batch: 133, loss: 0.18909, f1 score: 0.99254, speed: 1.73 step/s\r\n",
      "eval loss: 7.45249, f1 score: 0.48186, precison: 0.52505, recall: 0.46930\r\n",
      "eval loss: 7.28102, f1 score: 0.33494, precison: 0.28005, recall: 0.45178\r\n",
      "global step 650, epoch: 4, batch: 143, loss: 0.15555, f1 score: 0.98637, speed: 0.57 step/s\r\n",
      "global step 660, epoch: 4, batch: 153, loss: 0.06903, f1 score: 0.98595, speed: 1.64 step/s\r\n",
      "global step 670, epoch: 4, batch: 163, loss: 0.37470, f1 score: 0.98357, speed: 1.65 step/s\r\n",
      "global step 680, epoch: 5, batch: 4, loss: 0.12985, f1 score: 0.98562, speed: 1.69 step/s\r\n",
      "eval loss: 7.44061, f1 score: 0.47768, precison: 0.53996, recall: 0.45826\r\n",
      "eval loss: 7.31774, f1 score: 0.33089, precison: 0.27680, recall: 0.44748\r\n",
      "global step 690, epoch: 5, batch: 14, loss: 0.08959, f1 score: 0.99374, speed: 0.58 step/s\r\n",
      "global step 700, epoch: 5, batch: 24, loss: 0.07351, f1 score: 0.99381, speed: 1.74 step/s\r\n",
      "global step 710, epoch: 5, batch: 34, loss: 0.14856, f1 score: 0.99405, speed: 1.67 step/s\r\n",
      "global step 720, epoch: 5, batch: 44, loss: 0.39305, f1 score: 0.99105, speed: 1.59 step/s\r\n",
      "eval loss: 7.49828, f1 score: 0.48033, precison: 0.52682, recall: 0.46429\r\n",
      "eval loss: 7.27793, f1 score: 0.32585, precison: 0.27513, recall: 0.42945\r\n",
      "global step 730, epoch: 5, batch: 54, loss: 0.16605, f1 score: 0.98914, speed: 0.55 step/s\r\n",
      "global step 740, epoch: 5, batch: 64, loss: 0.21908, f1 score: 0.98632, speed: 1.66 step/s\r\n",
      "global step 750, epoch: 5, batch: 74, loss: 0.08212, f1 score: 0.98801, speed: 1.59 step/s\r\n",
      "global step 760, epoch: 5, batch: 84, loss: 0.20318, f1 score: 0.99020, speed: 1.61 step/s\r\n",
      "eval loss: 7.60817, f1 score: 0.47884, precison: 0.52480, recall: 0.46811\r\n",
      "eval loss: 7.60003, f1 score: 0.33542, precison: 0.27445, recall: 0.46473\r\n",
      "global step 770, epoch: 5, batch: 94, loss: 0.18065, f1 score: 0.99464, speed: 0.55 step/s\r\n",
      "global step 780, epoch: 5, batch: 104, loss: 0.11880, f1 score: 0.99286, speed: 1.57 step/s\r\n",
      "global step 790, epoch: 5, batch: 114, loss: 0.06597, f1 score: 0.99344, speed: 1.67 step/s\r\n",
      "global step 800, epoch: 5, batch: 124, loss: 0.09602, f1 score: 0.99253, speed: 1.58 step/s\r\n",
      "eval loss: 7.60693, f1 score: 0.48589, precison: 0.52744, recall: 0.47432\r\n",
      "eval loss: 7.58941, f1 score: 0.33356, precison: 0.27463, recall: 0.47281\r\n",
      "global step 810, epoch: 5, batch: 134, loss: 0.08274, f1 score: 0.98822, speed: 0.55 step/s\r\n",
      "global step 820, epoch: 5, batch: 144, loss: 0.05618, f1 score: 0.99049, speed: 1.69 step/s\r\n",
      "global step 830, epoch: 5, batch: 154, loss: 0.19044, f1 score: 0.98833, speed: 1.76 step/s\r\n",
      "global step 840, epoch: 5, batch: 164, loss: 0.41968, f1 score: 0.98440, speed: 1.60 step/s\r\n",
      "eval loss: 7.55736, f1 score: 0.48644, precison: 0.53577, recall: 0.46703\r\n",
      "eval loss: 7.45916, f1 score: 0.32869, precison: 0.27094, recall: 0.45028\r\n",
      "global step 850, epoch: 6, batch: 5, loss: 0.31197, f1 score: 0.98895, speed: 0.57 step/s\r\n",
      "global step 860, epoch: 6, batch: 15, loss: 0.14221, f1 score: 0.99230, speed: 1.56 step/s\r\n",
      "global step 870, epoch: 6, batch: 25, loss: 0.24043, f1 score: 0.98949, speed: 1.47 step/s\r\n",
      "global step 880, epoch: 6, batch: 35, loss: 0.28294, f1 score: 0.98967, speed: 1.53 step/s\r\n",
      "eval loss: 7.66149, f1 score: 0.48474, precison: 0.53868, recall: 0.47012\r\n",
      "eval loss: 7.69301, f1 score: 0.32607, precison: 0.26798, recall: 0.46088\r\n",
      "global step 890, epoch: 6, batch: 45, loss: 0.05236, f1 score: 0.99114, speed: 0.56 step/s\r\n",
      "global step 900, epoch: 6, batch: 55, loss: 0.06839, f1 score: 0.99045, speed: 1.67 step/s\r\n",
      "global step 910, epoch: 6, batch: 65, loss: 0.20900, f1 score: 0.99098, speed: 1.67 step/s\r\n",
      "global step 920, epoch: 6, batch: 75, loss: 0.39764, f1 score: 0.99078, speed: 1.69 step/s\r\n",
      "eval loss: 7.64370, f1 score: 0.48414, precison: 0.52083, recall: 0.47056\r\n",
      "eval loss: 7.73733, f1 score: 0.34004, precison: 0.29424, recall: 0.46588\r\n",
      "global step 930, epoch: 6, batch: 85, loss: 0.05539, f1 score: 0.99494, speed: 0.58 step/s\r\n",
      "global step 940, epoch: 6, batch: 95, loss: 0.40108, f1 score: 0.99072, speed: 1.45 step/s\r\n",
      "global step 950, epoch: 6, batch: 105, loss: 0.14811, f1 score: 0.99212, speed: 1.58 step/s\r\n",
      "global step 960, epoch: 6, batch: 115, loss: 0.44745, f1 score: 0.98903, speed: 1.66 step/s\r\n",
      "eval loss: 7.59323, f1 score: 0.49040, precison: 0.53397, recall: 0.47277\r\n",
      "eval loss: 7.68647, f1 score: 0.35710, precison: 0.31020, recall: 0.47708\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-29 12:42:27,476] [    INFO] - Configuration saved in ernie2.0_ckpt_2/config.json\r\n",
      "[2022-12-29 12:42:40,149] [    INFO] - tokenizer config file saved in ernie2.0_ckpt_2/tokenizer_config.json\r\n",
      "[2022-12-29 12:42:40,153] [    INFO] - Special tokens file saved in ernie2.0_ckpt_2/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 970, epoch: 6, batch: 125, loss: 0.06501, f1 score: 0.99287, speed: 0.33 step/s\r\n",
      "global step 980, epoch: 6, batch: 135, loss: 0.19972, f1 score: 0.99013, speed: 1.66 step/s\r\n",
      "global step 990, epoch: 6, batch: 145, loss: 0.11650, f1 score: 0.99009, speed: 1.61 step/s\r\n",
      "global step 1000, epoch: 6, batch: 155, loss: 0.07342, f1 score: 0.99112, speed: 1.58 step/s\r\n",
      "eval loss: 7.70304, f1 score: 0.48682, precison: 0.53351, recall: 0.47065\r\n",
      "eval loss: 7.69689, f1 score: 0.35761, precison: 0.33537, recall: 0.46318\r\n",
      "global step 1010, epoch: 6, batch: 165, loss: 0.04741, f1 score: 0.98182, speed: 0.55 step/s\r\n",
      "global step 1020, epoch: 7, batch: 6, loss: 0.05366, f1 score: 0.98776, speed: 1.67 step/s\r\n",
      "global step 1030, epoch: 7, batch: 16, loss: 0.10682, f1 score: 0.99035, speed: 1.73 step/s\r\n",
      "global step 1040, epoch: 7, batch: 26, loss: 0.11000, f1 score: 0.99068, speed: 1.58 step/s\r\n",
      "eval loss: 7.67372, f1 score: 0.48071, precison: 0.53462, recall: 0.46123\r\n",
      "eval loss: 7.60245, f1 score: 0.32904, precison: 0.27477, recall: 0.44439\r\n",
      "global step 1050, epoch: 7, batch: 36, loss: 0.06303, f1 score: 0.99390, speed: 0.57 step/s\r\n",
      "global step 1060, epoch: 7, batch: 46, loss: 0.15844, f1 score: 0.99187, speed: 1.60 step/s\r\n",
      "global step 1070, epoch: 7, batch: 56, loss: 0.05196, f1 score: 0.99272, speed: 1.52 step/s\r\n",
      "global step 1080, epoch: 7, batch: 66, loss: 0.19211, f1 score: 0.99170, speed: 1.58 step/s\r\n",
      "eval loss: 7.70274, f1 score: 0.48556, precison: 0.52617, recall: 0.47201\r\n",
      "eval loss: 7.73861, f1 score: 0.34764, precison: 0.32625, recall: 0.46946\r\n",
      "global step 1090, epoch: 7, batch: 76, loss: 0.04801, f1 score: 0.99052, speed: 0.56 step/s\r\n",
      "global step 1100, epoch: 7, batch: 86, loss: 0.06323, f1 score: 0.99085, speed: 1.58 step/s\r\n",
      "global step 1110, epoch: 7, batch: 96, loss: 0.14240, f1 score: 0.99012, speed: 1.69 step/s\r\n",
      "global step 1120, epoch: 7, batch: 106, loss: 0.16619, f1 score: 0.98859, speed: 1.67 step/s\r\n",
      "eval loss: 7.84120, f1 score: 0.46583, precison: 0.53868, recall: 0.44620\r\n",
      "eval loss: 7.60728, f1 score: 0.34948, precison: 0.30470, recall: 0.45702\r\n",
      "global step 1130, epoch: 7, batch: 116, loss: 0.14152, f1 score: 0.98841, speed: 0.55 step/s\r\n",
      "global step 1140, epoch: 7, batch: 126, loss: 0.06854, f1 score: 0.99122, speed: 1.76 step/s\r\n",
      "global step 1150, epoch: 7, batch: 136, loss: 0.16713, f1 score: 0.99043, speed: 1.78 step/s\r\n",
      "global step 1160, epoch: 7, batch: 146, loss: 0.16969, f1 score: 0.98991, speed: 1.57 step/s\r\n",
      "eval loss: 7.78519, f1 score: 0.48668, precison: 0.53504, recall: 0.46992\r\n",
      "eval loss: 7.66328, f1 score: 0.34206, precison: 0.31815, recall: 0.45813\r\n",
      "global step 1170, epoch: 7, batch: 156, loss: 0.20953, f1 score: 0.98849, speed: 0.58 step/s\r\n",
      "global step 1180, epoch: 7, batch: 166, loss: 0.26417, f1 score: 0.98277, speed: 1.78 step/s\r\n"
     ]
    }
   ],
   "source": [
    "optimizer = paddle.optimizer.AdamW(learning_rate=2e-5, parameters=model.parameters(), weight_decay=0.01)\n",
    "epochs = 7 # 训练轮次\n",
    "ckpt_dir = \"ernie2.0_ckpt_2\" # 训练过程中保存模型参数的文件夹\n",
    "save_dir2 = \"ernie2.0_ckpt_zhihu_2\"\n",
    "\n",
    "global_step = 0  # 迭代次数\n",
    "tic_train = time.time()\n",
    "best_f1_score = 0.48538\n",
    "best_f1_score2 = 0.33237\n",
    "# 模型训练\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "\n",
    "        # 计算模型输出、损失函数值、分类概率值、准确率、f1分数\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        \n",
    "        loss = criterion(labels, logits)\n",
    "        loss = loss.mean()\n",
    "        probs = logits\n",
    "        #probs = F.sigmoid(logits)\n",
    "        metric.update(probs, labels)\n",
    "        \n",
    "        # auc, f1_score, _,  _= metric.accumulate()\n",
    "        f1_score, _,  _= metric.accumulate()\n",
    "\n",
    "\n",
    "        # 每迭代100次，打印损失函数值、准确率、f1分数、计算速度\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, f1 score: %.5f, speed: %.2f step/s\"\n",
    "                % (global_step, epoch, step, loss, f1_score,\n",
    "                    10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        \n",
    "        # 反向梯度回传，更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        \n",
    "        #每迭代40次，评估当前训练的模型、保存当前最佳模型参数和分词器的词表等\n",
    "        if global_step % 40 == 0:\n",
    "            save_dir = ckpt_dir\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            eval_f1_score = evaluate(model, criterion, metric, valid_data_loader, label_vocab, if_return_results=False)\n",
    "            eval_f1_score2 = evaluate(model, criterion, metric, validZhihu_data_loader, label_vocab, if_return_results=False)\n",
    "            if eval_f1_score > best_f1_score:\n",
    "                best_f1_score = eval_f1_score\n",
    "                model.save_pretrained(save_dir)\n",
    "                tokenizer.save_pretrained(save_dir)\n",
    "            if eval_f1_score2 > best_f1_score2:\n",
    "                best_f1_score2 = eval_f1_score2\n",
    "                model.save_pretrained(save_dir2)\n",
    "                tokenizer.save_pretrained(save_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16d9c6a-d3bd-4f38-8b57-b6af48d364fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:07:46.084215Z",
     "iopub.status.busy": "2022-12-29T06:07:46.083575Z",
     "iopub.status.idle": "2022-12-29T06:08:00.372329Z",
     "shell.execute_reply": "2022-12-29T06:08:00.371283Z",
     "shell.execute_reply.started": "2022-12-29T06:07:46.084176Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNIE 3.0 在20分类验证集的最佳表现： eval loss: 7.59323, f1 score: 0.49040, precison: 0.53397, recall: 0.47277\r\n",
      "ERNIE 2.0 在20分类知乎验证集的最佳表现： eval loss: 7.68647, f1 score: 0.35710, precison: 0.31020, recall: 0.47708\r\n"
     ]
    }
   ],
   "source": [
    "# 模型加载\n",
    "# 加载验证集上效果最好的模型参数\n",
    "model.set_dict(paddle.load('ernie2.0_ckpt_2/model_state.pdparams'))\n",
    "\n",
    "# 加载之前训练好的模型参数\n",
    "# model.set_dict(paddle.load('/home/aistudio/work/model_state.pdparams'))\n",
    "\n",
    "# 模型验证\n",
    "print(\"ERNIE 3.0 在20分类验证集的最佳表现：\", end= \" \")\n",
    "results1 = evaluate(model, criterion, metric, valid_data_loader, label_vocab)\n",
    "print(\"ERNIE 2.0 在20分类知乎验证集的最佳表现：\", end= \" \")\n",
    "results = evaluate(model, criterion, metric, validZhihu_data_loader, label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6705f15d-16e0-41ab-ac22-0dd43d05d6f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:08:07.051320Z",
     "iopub.status.busy": "2022-12-29T06:08:07.050556Z",
     "iopub.status.idle": "2022-12-29T06:08:07.059162Z",
     "shell.execute_reply": "2022-12-29T06:08:07.058239Z",
     "shell.execute_reply.started": "2022-12-29T06:08:07.051282Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def result2tsv(result1,filepath):\n",
    "    validData = pd.read_csv(filepath,sep='\\t')\n",
    "    dictvalidT =validData.to_dict(\"list\")\n",
    "\n",
    "    validPred = {}\n",
    "    validPred[\"Argument ID\"] = dictvalidT[\"Argument ID\"]\n",
    "    validPred[\"sentence\"] = dictvalidT[\"sentence\"]\n",
    "\n",
    "    for x in label_vocab:\n",
    "        validPred[x] = []\n",
    "    \n",
    "    for x in range(len(results1)):\n",
    "        types = results1[x].split(\",\")\n",
    "        if types == ['']:\n",
    "            for y in label_vocab:\n",
    "                validPred[y].append(0)\n",
    "        else:  \n",
    "            for z in label_vocab:\n",
    "                if z in types:\n",
    "                    validPred[z].append(1)\n",
    "                else:\n",
    "                    validPred[z].append(0)\n",
    "    validData = pd.read_csv(filepath,sep='\\t')\n",
    "    for x in label_vocab:\n",
    "        for y in range(len(validData[x])):\n",
    "            validData[x].iloc[y] = validPred[x][y]\n",
    "    \n",
    "    validData.drop(columns=[\"sentence\"],inplace=True)\n",
    "    return validData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73e6b25e-b3c5-425d-90ee-47447bfdec49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:08:08.559408Z",
     "iopub.status.busy": "2022-12-29T06:08:08.558355Z",
     "iopub.status.idle": "2022-12-29T06:08:08.567310Z",
     "shell.execute_reply": "2022-12-29T06:08:08.566038Z",
     "shell.execute_reply.started": "2022-12-29T06:08:08.559346Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data\r\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd8602c2-fe6f-49fe-b86c-f992801c221d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:08:21.330078Z",
     "iopub.status.busy": "2022-12-29T06:08:21.329301Z",
     "iopub.status.idle": "2022-12-29T06:08:25.453027Z",
     "shell.execute_reply": "2022-12-29T06:08:25.452128Z",
     "shell.execute_reply.started": "2022-12-29T06:08:21.330036Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "valid = result2tsv(results1,\"validation.tsv\")\n",
    "valid.to_csv('validERNIE2.0.tsv',columns=valid.columns.tolist(),\n",
    "            sep='\\t',\n",
    "            index=False)\n",
    "\n",
    "validzhihu = result2tsv(results,\"zhihu_validation.tsv\")\n",
    "validzhihu.to_csv('validERNIE2.0zhihu.tsv',columns=validzhihu.columns.tolist(),\n",
    "            sep='\\t',\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52af89b4-1bfa-4d05-b06d-52ce952fb5e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:47:34.058323Z",
     "iopub.status.busy": "2022-12-29T06:47:34.057566Z",
     "iopub.status.idle": "2022-12-29T06:47:34.064933Z",
     "shell.execute_reply": "2022-12-29T06:47:34.064121Z",
     "shell.execute_reply.started": "2022-12-29T06:47:34.058279Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 预测函数，对测试集结果进行预测\n",
    "def predict(model, criterion, metric, data_loader, label_vocab, if_return_results=True):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids = batch['input_ids'], batch['token_type_ids']\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        probs = logits\n",
    "        if if_return_results:\n",
    "            probs = probs.tolist()\n",
    "            for prob in probs:\n",
    "                result = []\n",
    "                for c, pred in enumerate(prob):\n",
    "                    if pred > 0:\n",
    "                        result.append(label_vocab[c])\n",
    "                        # result.append(str(c))\n",
    "                results.append(','.join(result))\n",
    "    if if_return_results:\n",
    "        return results\n",
    "    else:\n",
    "        return f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc1ba009-35e7-4d48-902d-6dd4a617df08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:55:47.243970Z",
     "iopub.status.busy": "2022-12-29T06:55:47.242994Z",
     "iopub.status.idle": "2022-12-29T06:55:47.252569Z",
     "shell.execute_reply": "2022-12-29T06:55:47.251144Z",
     "shell.execute_reply.started": "2022-12-29T06:55:47.243926Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testOutput(results2):\n",
    "    testData = pd.read_csv(\"test.tsv\",sep='\\t')\n",
    "    dicttestT =testData.to_dict(\"list\")\n",
    "\n",
    "    testPred = {}\n",
    "    testPred[\"Argument ID\"] = dicttestT[\"Argument ID\"]\n",
    "    testPred[\"sentence\"] = dicttestT[\"sentence\"]\n",
    "\n",
    "    for x in label_vocab:\n",
    "        testPred[x] = []\n",
    "\n",
    "    for x in range(len(results2)):\n",
    "        types = results2[x].split(\",\")\n",
    "        if types == ['']:\n",
    "            for y in label_vocab:\n",
    "                testPred[y].append(0)\n",
    "        else:  \n",
    "            for z in label_vocab:\n",
    "                if z in types:\n",
    "                    testPred[z].append(1)\n",
    "                else:\n",
    "                    testPred[z].append(0)\n",
    "    testPredD = pd.DataFrame.from_dict(testPred)\n",
    "    testPredD.drop(columns=[\"sentence\"],inplace=True)\n",
    "\n",
    "    return testPredD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd9f21ab-6972-4e68-a647-4357ba858f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:47:51.184695Z",
     "iopub.status.busy": "2022-12-29T06:47:51.184017Z",
     "iopub.status.idle": "2022-12-29T06:48:00.528359Z",
     "shell.execute_reply": "2022-12-29T06:48:00.527201Z",
     "shell.execute_reply.started": "2022-12-29T06:47:51.184643Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results2 = predict(model, criterion, metric, test_data_loader, label_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71a24002-2568-4f63-bfc4-93594c635ad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T06:55:52.930340Z",
     "iopub.status.busy": "2022-12-29T06:55:52.929687Z",
     "iopub.status.idle": "2022-12-29T06:55:52.961147Z",
     "shell.execute_reply": "2022-12-29T06:55:52.960402Z",
     "shell.execute_reply.started": "2022-12-29T06:55:52.930303Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = testOutput(results2)\n",
    "test.to_csv('testErnie2.0.tsv',columns=test.columns.tolist(),\n",
    "            sep='\\t',\n",
    "            index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
