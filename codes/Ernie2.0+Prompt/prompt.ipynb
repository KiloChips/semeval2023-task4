{
 "cells": [
  {
   "attachments": {
    "6ff4e7c9-9dd5-40f7-853a-68e7aa2253e0.png": {
     "image/png": "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"
    },
    "75e8d396-039c-49cf-97f6-82d16cf122ac.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0c30442a-9391-44bf-9882-76f8aa2e77bb",
   "metadata": {},
   "source": [
    "基于 Prompt API 实现人类价值观分类\n",
    "1. 任务说明\n",
    "随着预训练语言模型规模的增长，“预训练-微调”范式在下游自然语言处理任务上的表现越来越好，但与之相应地对训练数据量和计算存储资源的要求也越来越高。为了充分利用预训练语言模型学习到的知识，同时降低对数据和资源的依赖，提示学习（Prompt Learning）作为一种可能的新范式受到了越来越多的关注，在 FewCLUE、SuperGLUE 等榜单的小样本任务上取得了远优于传统微调范式的结果。\n",
    "\n",
    "提示学习（Prompt Learning）的核心思想是将下游任务转化为预训练阶段的掩码预测（MLM）任务。实现思路包括通过模板（Template）定义的提示语句，将原有任务转化为预测掩码位置的词，以及通过标签词（Verbalizer）的定义，建立预测词与真实标签之间的映射关系。\n",
    "\n",
    "以情感分类任务为例，“预训练-微调”范式和“预训练-提示”范式（以 PET 为例）之间的区别如下图所示\n",
    "![image.png](attachment:75e8d396-039c-49cf-97f6-82d16cf122ac.png)![image.png](attachment:6ff4e7c9-9dd5-40f7-853a-68e7aa2253e0.png)\n",
    "\n",
    "\n",
    "【微调学习】使用 [CLS] 来做分类，需要训练随机初始化的分类器，需要充分的训练数据来拟合。\n",
    "\n",
    "【提示学习】通过提示语句和标签词映射的定义，转化为 MLM 任务，无需训练新的参数，适用于小样本场景。\n",
    "\n",
    "本实践使用 PaddleNLP 的 Prompt API 来快速实现基于 ERNIE 2.0 的人类价值观分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b7582-ba6d-45dc-be71-2fa7e8f7d9f9",
   "metadata": {},
   "source": [
    "2. 实现思路及流程\n",
    "基于 Prompt API 实现文本分类的思路如下所示，模型的输入文本根据模板（Template）进行预处理，模型的输出结果经过标签词映射（Verbalizer）得到预测的映射词。\n",
    "\n",
    "在建模过程中，对于输入文本，首先将其处理为模板 API 能够处理的标准形式，根据任务定义模板和标签词映射，调用模板 API 进行文本模板组合和文本序列编码，获得文本的语义向量表示；然后经过预训练语言模型得到预测向量，调用标签词映射的 API 取出标签词对应的概率。\n",
    "\n",
    "根据上边介绍，基于 Prompt API 实现多标签分类的过程主要包括以下6个步骤：\n",
    "\n",
    "（1）模型构建：确定文本分类使用的模型，本实践使用ERNIE-3.0 Base模型进行文本编码和标签词预测。\n",
    "\n",
    "（2）数据准备：对于输入的文本进行相应的处理，包括数据标准化、模板定义、标签词映射、文本编码等。\n",
    "\n",
    "（3）训练配置：配置训练参数，使用 PromptTrainer API 进行环境、模型、优化器、训练预测等流程的自动初始化。\n",
    "\n",
    "（4）模型训练：训练模型参数，以达到最优效果。\n",
    "\n",
    "（5）模型评估：对训练好的模型进行评估测试，观察准确率和损失函数的变化情况。\n",
    "\n",
    "（6）模型预测：选取一段新闻，判断新闻类别。\n",
    "\n",
    "以下分别介绍每个步骤的具体实现过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7244d9-0280-4014-bf2e-e151a3456f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:04:18.722858Z",
     "iopub.status.busy": "2023-01-15T14:04:18.722091Z",
     "iopub.status.idle": "2023-01-15T14:04:43.905250Z",
     "shell.execute_reply": "2023-01-15T14:04:43.904288Z",
     "shell.execute_reply.started": "2023-01-15T14:04:18.722823Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.4.2)\r\n",
      "Collecting paddlenlp\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a5/de/3f20df026e48eae755ea06cbd587dd845767ac2d04e3bcf5e24cdb62cc4f/paddlenlp-2.5.0-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\r\n",
      "Collecting fastapi\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8f/89/adf4525d1870021b65ec562e83e9f46d96494ad95f238d0264ef1ab6b604/fastapi-0.89.1-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m45.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting huggingface-hub>=0.11.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a0/0b/e4c1165bb954036551e61e1d7858e3293347f360d8f84854092f3ad38446/huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m219.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.4.0)\r\n",
      "Collecting uvicorn\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/96/f3/f39ac8ac3bdf356b4934b8f7e56173e96681f67ef0cd92bd33a5059fae9e/uvicorn-0.20.0-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m33.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.1.96)\r\n",
      "Requirement already satisfied: rich in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (12.6.0)\r\n",
      "Requirement already satisfied: dill<0.3.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.3.3)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\r\n",
      "Requirement already satisfied: paddle2onnx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: paddlefsl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (3.20.0)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.7.0)\r\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\r\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.64.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\r\n",
      "Collecting typer\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0d/44/56c3f48d2bb83d76f5c970aef8e2c3ebd6a832f09e3621c5395371fe6999/typer-0.7.0-py3-none-any.whl (38 kB)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (5.1.2)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2022.11.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (4.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.19.5)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (10.0.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2.24.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.1.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.1.5)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.8.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (4.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (3.0.12)\r\n",
      "Collecting starlette==0.22.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1d/4e/30eda84159d5b3ad7fe663c40c49b16dd17436abe838f10a56c34bee44e8/starlette-0.22.0-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m55.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6f/6a/a3b9a51b886eeee570ddb32ae64a8d2fd00cd25cb1daaf82260188d2d1e4/pydantic-1.10.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from starlette==0.22.0->fastapi->paddlenlp) (3.6.1)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (2.13.0)\r\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (0.9.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from typer->paddlenlp) (8.0.4)\r\n",
      "Collecting h11>=0.8\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m42.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\r\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (8.2.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.16.0)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\r\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (3.0.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.1.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.7.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (0.13.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (22.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (6.0.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.25.11)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2019.9.11)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp) (3.8.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (2.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\r\n",
      "Installing collected packages: pydantic, h11, starlette, huggingface-hub, uvicorn, typer, fastapi, paddlenlp\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.11.0\r\n",
      "    Uninstalling huggingface-hub-0.11.0:\r\n",
      "      Successfully uninstalled huggingface-hub-0.11.0\r\n",
      "  Attempting uninstall: paddlenlp\r\n",
      "    Found existing installation: paddlenlp 2.4.2\r\n",
      "    Uninstalling paddlenlp-2.4.2:\r\n",
      "      Successfully uninstalled paddlenlp-2.4.2\r\n",
      "Successfully installed fastapi-0.89.1 h11-0.14.0 huggingface-hub-0.11.1 paddlenlp-2.5.0 pydantic-1.10.4 starlette-0.22.0 typer-0.7.0 uvicorn-0.20.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a564365d-3912-436e-8273-93ab1e50644a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:04:43.916405Z",
     "iopub.status.busy": "2023-01-15T14:04:43.916113Z",
     "iopub.status.idle": "2023-01-15T14:04:52.001953Z",
     "shell.execute_reply": "2023-01-15T14:04:52.000841Z",
     "shell.execute_reply.started": "2023-01-15T14:04:43.916376Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: paddle2onnx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.0.0)\r\n",
      "Collecting paddle2onnx\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1a/c6/4623d898ba5acb05da2d83e2fbd93e1fe8734ec6b002872ef3ae24853580/paddle2onnx-1.0.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\r\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0mThe history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: paddle2onnx\r\n",
      "  Attempting uninstall: paddle2onnx\r\n",
      "    Found existing installation: paddle2onnx 1.0.0\r\n",
      "    Uninstalling paddle2onnx-1.0.0:\r\n",
      "      Successfully uninstalled paddle2onnx-1.0.0\r\n",
      "Successfully installed paddle2onnx-1.0.5\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddle2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d8764-ed3d-40c3-96a1-bc1cfe945cd8",
   "metadata": {},
   "source": [
    "3. 模型构建\n",
    "我们使用ERNIE 2.0 Large作为预训练模型用于新闻分类。提示学习本质上是掩码预测（MLM）任务，因此可以使用 AutoModelForMaskedLM 来加载模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfba296-70ea-415f-815d-e79d78d16fa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:05:23.150215Z",
     "iopub.status.busy": "2023-01-15T14:05:23.149876Z",
     "iopub.status.idle": "2023-01-15T14:05:23.154247Z",
     "shell.execute_reply": "2023-01-15T14:05:23.153647Z",
     "shell.execute_reply.started": "2023-01-15T14:05:23.150190Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "from paddlenlp.prompt import (\n",
    "    AutoTemplate,\n",
    "    PromptModelForSequenceClassification,\n",
    "    PromptTrainer,\n",
    "    PromptTuningArguments,\n",
    "    SoftVerbalizer,\n",
    ")\n",
    "from paddlenlp.trainer import EarlyStoppingCallback, PdArgumentParser\n",
    "from paddlenlp.transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from paddlenlp.utils.log import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c6dedf-4440-4d5a-aa03-ebee5e58a53e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:05:27.712961Z",
     "iopub.status.busy": "2023-01-15T14:05:27.712270Z",
     "iopub.status.idle": "2023-01-15T14:06:04.125179Z",
     "shell.execute_reply": "2023-01-15T14:06:04.124497Z",
     "shell.execute_reply.started": "2023-01-15T14:05:27.712927Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-15 22:05:27,714] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForMaskedLM'> to load 'ernie-2.0-large-en'.\r\n",
      "[2023-01-15 22:05:27,717] [    INFO] - Model config ErnieConfig {\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"enable_recompute\": false,\r\n",
      "  \"fuse\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 4096,\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 512,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 24,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"pool_act\": \"tanh\",\r\n",
      "  \"task_id\": 0,\r\n",
      "  \"task_type_vocab_size\": 3,\r\n",
      "  \"type_vocab_size\": 4,\r\n",
      "  \"use_task_id\": true,\r\n",
      "  \"vocab_size\": 30522\r\n",
      "}\r\n",
      "\r\n",
      "[2023-01-15 22:05:27,720] [    INFO] - Configuration saved in /home/aistudio/.paddlenlp/models/ernie-2.0-large-en/config.json\r\n",
      "[2023-01-15 22:05:27,722] [    INFO] - Downloading ernie_v2_eng_large.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_v2_large/ernie_v2_eng_large.pdparams\r\n",
      "100%|██████████| 1.25G/1.25G [00:30<00:00, 43.5MB/s]\r\n",
      "W0115 22:06:02.041462   278 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0115 22:06:02.045009   278 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2023-01-15 22:06:03,704] [    INFO] - All model checkpoint weights were used when initializing ErnieForMaskedLM.\r\n",
      "\r\n",
      "[2023-01-15 22:06:03,707] [ WARNING] - Some weights of ErnieForMaskedLM were not initialized from the model checkpoint at ernie-2.0-large-en and are newly initialized: ['cls.predictions.transform.weight', 'cls.predictions.decoder_weight', 'ernie.embeddings.task_type_embeddings.weight', 'cls.predictions.layer_norm.bias', 'cls.predictions.layer_norm.weight', 'cls.predictions.decoder_bias', 'cls.predictions.transform.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "[2023-01-15 22:06:03,711] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-2.0-large-en'.\r\n",
      "[2023-01-15 22:06:03,713] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_v2_large/vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-2.0-large-en\r\n",
      "[2023-01-15 22:06:03,844] [    INFO] - Downloading vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_v2_large/vocab.txt\r\n",
      "100%|██████████| 226k/226k [00:00<00:00, 2.43MB/s]\r\n",
      "[2023-01-15 22:06:04,118] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-2.0-large-en/tokenizer_config.json\r\n",
      "[2023-01-15 22:06:04,121] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-2.0-large-en/special_tokens_map.json\r\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"ernie-2.0-large-en\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ernie-2.0-large-en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf223db-4b4a-4dfc-ab27-76a25c18b9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-04T12:04:13.331041Z",
     "iopub.status.busy": "2023-01-04T12:04:13.330506Z",
     "iopub.status.idle": "2023-01-04T12:04:13.338265Z",
     "shell.execute_reply": "2023-01-04T12:04:13.337119Z",
     "shell.execute_reply.started": "2023-01-04T12:04:13.331010Z"
    }
   },
   "source": [
    "4. 数据准备\n",
    "数据准备过程包括数据集确定、数据标准化、模板定义、标签词映射定义等步骤。本实践使用 PromptTrainer 进行训练，该 API 封装了 Prompt 相关的数据预处理过程，如模板文本组合和文本分词、编码的过程，因此不需要构造 DataLoader。\n",
    "\n",
    "（1）数据集确定\n",
    "FewCLUE 是专门用于中文小样本学习能力测评的榜单，涵盖了情感分析、新闻分类、语义匹配、指代消歧等阅读理解任务。这里我们使用其中的新闻分类数据集 TNEWS 作为示例，共包括15个新闻类别，每个类别有16条标注数据用于训练。除此之外，有240条标注数据用于验证，2010条数据用于测试。\n",
    "\n",
    "PaddleNLP 中内置了该数据集，可直接调用 load_dataset 加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec3f021-8063-4ddd-bd07-b563f521c024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:07:26.941852Z",
     "iopub.status.busy": "2023-01-15T14:07:26.940963Z",
     "iopub.status.idle": "2023-01-15T14:07:26.948703Z",
     "shell.execute_reply": "2023-01-15T14:07:26.948052Z",
     "shell.execute_reply.started": "2023-01-15T14:07:26.941819Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "def load_local_dataset(data_path, splits, label_list):\n",
    "    \"\"\"\n",
    "    Load dataset for multi-label classification from files, where\n",
    "    there is one example per line. Text and label are seperated\n",
    "    by '\\t', and multiple labels are delimited by ','.\n",
    "    Args:\n",
    "        data_path (str):\n",
    "            Path to the dataset directory, including label.txt, train.txt,\n",
    "            dev.txt (and data.txt).\n",
    "        splits (list):\n",
    "            Which file(s) to load, such as ['train', 'dev', 'test'].\n",
    "        label_list (dict):\n",
    "            The dictionary that maps labels to indeces.\n",
    "    \"\"\"\n",
    "\n",
    "    def _reader(data_file, label_list):\n",
    "        with open(data_file, \"r\", encoding=\"utf-8\") as fp:\n",
    "            next(fp)\n",
    "            for idx, line in enumerate(fp):\n",
    "                data = line.strip().split(\"\\t\")\n",
    "                if len(data) == 2:\n",
    "                    yield {\"text_a\": data[1]}\n",
    "                else:\n",
    "                    text= data[1]\n",
    "                    label = data[2] \n",
    "                    label = label[1:-1].strip().split(\",\")\n",
    "                    label = [float(x) for x in label]\n",
    "                    yield {\"text_a\": text, \"labels\": label}\n",
    "\n",
    "    split_map = {\"train\": \"train.tsv\", \"dev\": \"dev.tsv\", \"test\": \"test.tsv\"}\n",
    "    datasets = []\n",
    "    for split in splits:\n",
    "        data_file = os.path.join(data_path, split_map[split])\n",
    "        datasets.append(load_dataset(_reader, data_file=data_file, label_list=label_list, lazy=False))\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeddd20-f2a8-4dd4-abb9-7b52ef95a0c9",
   "metadata": {},
   "source": [
    "数据标准化\n",
    "Prompt API 规定了输入数据的格式，我们需要先将已有数据转化为 InputExample 封装的标准格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e9ca64-6640-4f2e-a2ab-b6571573a76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:06:32.391114Z",
     "iopub.status.busy": "2023-01-15T14:06:32.390243Z",
     "iopub.status.idle": "2023-01-15T14:06:32.408068Z",
     "shell.execute_reply": "2023-01-15T14:06:32.407379Z",
     "shell.execute_reply.started": "2023-01-15T14:06:32.391080Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paddlenlp.prompt import SoftVerbalizer\n",
    "from collections import defaultdict\n",
    "\n",
    "label_file =  \"label.txt\"\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as fp:\n",
    "    label_words = defaultdict(list)\n",
    "    for line in fp:\n",
    "        data = line.strip().split(\"==\")\n",
    "        word = data[1] if len(data) > 1 else data[0].split(\"##\")[-1]\n",
    "        label_words[data[0]].append(word)\n",
    "\n",
    "verbalizer = SoftVerbalizer(label_words, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dfe6140-c265-4e71-8458-a6ec0430162c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:06:37.522531Z",
     "iopub.status.busy": "2023-01-15T14:06:37.521571Z",
     "iopub.status.idle": "2023-01-15T14:06:37.881419Z",
     "shell.execute_reply": "2023-01-15T14:06:37.880455Z",
     "shell.execute_reply.started": "2023-01-15T14:06:37.522493Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.ipynb               dataprocessprompt.ipynb  prompt.ipynb\r\n",
      "checkpoint/            label.txt                Untitled1.ipynb\r\n",
      "checkpoints/           main.ipynb               valid_zhihuERNIE2.0Prompt.tsv\r\n",
      "data/                  model/                   work/\r\n",
      "dataprocess (2).ipynb  prompt/                  第一次才行.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0afb659a-6c2e-47e0-9bff-15c60004564e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:08:06.619389Z",
     "iopub.status.busy": "2023-01-15T14:08:06.618485Z",
     "iopub.status.idle": "2023-01-15T14:08:06.673538Z",
     "shell.execute_reply": "2023-01-15T14:08:06.672509Z",
     "shell.execute_reply.started": "2023-01-15T14:08:06.619353Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "train_ds, dev_ds, test_ds = load_local_dataset(\n",
    "        \"data/\", splits=[\"train\", \"dev\", \"test\"], label_list=verbalizer.labels_to_ids\n",
    "    )\n",
    "\n",
    "# test_ds,test2_ds = load_local_dataset(\n",
    "#          \"data/\", splits=[\"test\",\"test2\"], label_list=verbalizer.labels_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9316e4-6e81-452a-9335-125c9becc3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:37:18.842143Z",
     "iopub.status.busy": "2023-01-10T04:37:18.841386Z",
     "iopub.status.idle": "2023-01-10T04:37:18.853568Z",
     "shell.execute_reply": "2023-01-10T04:37:18.852424Z",
     "shell.execute_reply.started": "2023-01-10T04:37:18.842095Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_a': '\"Imagine someone is arguing in favor of \"\"Entrapment should be legalized\"\" by saying: \"\"if entrapment can serve to more easily capture wanted criminals, then why shouldn\\'t it be legal?\"\".\"',\n",
       " 'labels': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b3d63a9-9c99-4611-b86b-b251d4dd824e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:08:11.723194Z",
     "iopub.status.busy": "2023-01-15T14:08:11.722290Z",
     "iopub.status.idle": "2023-01-15T14:08:11.726953Z",
     "shell.execute_reply": "2023-01-15T14:08:11.726324Z",
     "shell.execute_reply.started": "2023-01-15T14:08:11.723160Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paddlenlp.prompt import AutoTemplate\n",
    "\n",
    "prompt = \"The values implicit in this sentence include:\"\n",
    "template = AutoTemplate.create_from(\n",
    "        prompt,\n",
    "        tokenizer,\n",
    "        max_length=512,\n",
    "        model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d976e035-5fd3-4b9e-9d71-a7042eb69955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:08:12.656796Z",
     "iopub.status.busy": "2023-01-15T14:08:12.655886Z",
     "iopub.status.idle": "2023-01-15T14:08:12.660293Z",
     "shell.execute_reply": "2023-01-15T14:08:12.659655Z",
     "shell.execute_reply.started": "2023-01-15T14:08:12.656763Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_model = PromptModelForSequenceClassification(\n",
    "        model, template, verbalizer, freeze_plm=False, freeze_dropout=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29f3eede-3220-407f-9d2e-da4df1cee5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T14:08:20.138751Z",
     "iopub.status.busy": "2023-01-15T14:08:20.137857Z",
     "iopub.status.idle": "2023-01-15T14:08:20.152003Z",
     "shell.execute_reply": "2023-01-15T14:08:20.151390Z",
     "shell.execute_reply.started": "2023-01-15T14:08:20.138717Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptModelForSequenceClassification(\n",
       "  (plm): ErnieForMaskedLM(\n",
       "    (ernie): ErnieModel(\n",
       "      (embeddings): ErnieEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 1024, padding_idx=0, sparse=False)\n",
       "        (position_embeddings): Embedding(512, 1024, sparse=False)\n",
       "        (token_type_embeddings): Embedding(4, 1024, sparse=False)\n",
       "        (task_type_embeddings): Embedding(3, 1024, sparse=False)\n",
       "        (layer_norm): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "        (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "      )\n",
       "      (encoder): TransformerEncoder(\n",
       "        (layers): LayerList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (12): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (13): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (14): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (15): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (16): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (17): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (18): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (19): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (20): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (21): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (22): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "          (23): TransformerEncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "            )\n",
       "            (linear1): Linear(in_features=1024, out_features=4096, dtype=float32)\n",
       "            (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)\n",
       "            (linear2): Linear(in_features=4096, out_features=1024, dtype=float32)\n",
       "            (norm1): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (norm2): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "            (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "            (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): ErniePooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (cls): MaskedLMIdentity()\n",
       "  )\n",
       "  (template): ManualTemplate()\n",
       "  (verbalizer): SoftVerbalizer(\n",
       "    (head): ErnieLMPredictionHead(\n",
       "      (transform): Linear(in_features=1024, out_features=1024, dtype=float32)\n",
       "      (layer_norm): LayerNorm(normalized_shape=[1024], epsilon=1e-12)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b4d4e-0ce6-4e43-b3a6-5392acedde7e",
   "metadata": {},
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2432d5c2-9cfe-4ef9-870c-628140a7018e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:37:25.889937Z",
     "iopub.status.busy": "2023-01-10T04:37:25.889189Z",
     "iopub.status.idle": "2023-01-10T04:37:25.902012Z",
     "shell.execute_reply": "2023-01-10T04:37:25.901105Z",
     "shell.execute_reply.started": "2023-01-10T04:37:25.889889Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 12:37:25,897] [    INFO] - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\r\n"
     ]
    }
   ],
   "source": [
    "# 训练参数\n",
    "config = [\"--output_dir\", \"./checkpoints/\", \n",
    "          \"--learning_rate\", \"3e-5\",\n",
    "          \"--ppt_learning_rate\", \"3e-4\",\n",
    "          \"--num_train_epochs\", \"20\",\n",
    "          \"--logging_steps\", \"5\",\n",
    "          \"--per_device_train_batch_size\", \"8\",\n",
    "          \"--per_device_eval_batch_size\", \"8\",\n",
    "          \"--metric_for_best_model\", \"macro_f1_score\",\n",
    "          \"--load_best_model_at_end\", \"True\",\n",
    "          \"--evaluation_strategy\", \"epoch\",\n",
    "          \"--save_strategy\", \"epoch\",\n",
    "          \"--load_best_model_at_end\", \"True\",\n",
    "          \"--save_total_limit\", \"1\"\n",
    "         ]\n",
    "parser = PdArgumentParser((PromptTuningArguments,))\n",
    "training_args = parser.parse_args_into_dataclasses(args=config,\n",
    "                                                   look_for_args_file=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc07e845-54cf-4497-af6a-8a5bf872f628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:38:33.408724Z",
     "iopub.status.busy": "2023-01-10T04:38:33.407966Z",
     "iopub.status.idle": "2023-01-10T04:38:33.413508Z",
     "shell.execute_reply": "2023-01-10T04:38:33.412657Z",
     "shell.execute_reply.started": "2023-01-10T04:38:33.408678Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the criterion.\n",
    "criterion = paddle.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb73d447-7ef0-4f73-89a7-bf21f18e8483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:38:36.439125Z",
     "iopub.status.busy": "2023-01-10T04:38:36.438321Z",
     "iopub.status.idle": "2023-01-10T04:38:36.467020Z",
     "shell.execute_reply": "2023-01-10T04:38:36.466202Z",
     "shell.execute_reply.started": "2023-01-10T04:38:36.439082Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from paddle.metric import Metric\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from paddlenlp.utils.log import logger\n",
    "\n",
    "\n",
    "class MetricReport(Metric):\n",
    "    \"\"\"\n",
    "    F1 score for multi-label text classification task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"MetricReport\", average=\"micro\"):\n",
    "        super(MetricReport, self).__init__()\n",
    "        self.average = average\n",
    "        self._name = name\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets all of the metric state.\n",
    "        \"\"\"\n",
    "        self.y_prob = None\n",
    "        self.y_true = None\n",
    "\n",
    "    def f1_score(self, y_prob):\n",
    "        \"\"\"\n",
    "        Compute micro f1 score and macro f1 score\n",
    "        \"\"\"\n",
    "        threshold = 0.5\n",
    "        self.y_pred = y_prob > threshold\n",
    "        micro_f1_score = f1_score(y_pred=self.y_pred, y_true=self.y_true, average=\"micro\")\n",
    "        macro_f1_score = f1_score(y_pred=self.y_pred, y_true=self.y_true, average=\"macro\")\n",
    "        return micro_f1_score, macro_f1_score\n",
    "\n",
    "    def update(self, probs, labels):\n",
    "        \"\"\"\n",
    "        Update the probability and label\n",
    "        \"\"\"\n",
    "        if self.y_prob is not None:\n",
    "            self.y_prob = np.append(self.y_prob, probs.numpy(), axis=0)\n",
    "        else:\n",
    "            self.y_prob = probs.numpy()\n",
    "        if self.y_true is not None:\n",
    "            self.y_true = np.append(self.y_true, labels.numpy(), axis=0)\n",
    "        else:\n",
    "            self.y_true = labels.numpy()\n",
    "\n",
    "    def accumulate(self):\n",
    "        \"\"\"\n",
    "        Returns micro f1 score and macro f1 score\n",
    "        \"\"\"\n",
    "        micro_f1_score, macro_f1_score = self.f1_score(y_prob=self.y_prob)\n",
    "        return micro_f1_score, macro_f1_score\n",
    "\n",
    "    def report(self):\n",
    "        \"\"\"\n",
    "        Returns classification report\n",
    "        \"\"\"\n",
    "        self.y_pred = self.y_prob > 0.5\n",
    "        logger.info(\"classification report:\\n\" + classification_report(self.y_true, self.y_pred, digits=4))\n",
    "\n",
    "    def name(self):\n",
    "        \"\"\"\n",
    "        Returns metric name\n",
    "        \"\"\"\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4818a6bc-01c8-40af-9214-800b3a6ed620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:38:38.295751Z",
     "iopub.status.busy": "2023-01-10T04:38:38.294944Z",
     "iopub.status.idle": "2023-01-10T04:38:38.301055Z",
     "shell.execute_reply": "2023-01-10T04:38:38.300203Z",
     "shell.execute_reply.started": "2023-01-10T04:38:38.295694Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Define the metric function.\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = MetricReport()\n",
    "    preds = F.sigmoid(paddle.to_tensor(eval_preds.predictions))\n",
    "    metric.update(preds, paddle.to_tensor(eval_preds.label_ids))\n",
    "    micro_f1_score, macro_f1_score = metric.accumulate()\n",
    "    return {\"micro_f1_score\": micro_f1_score, \"macro_f1_score\": macro_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0232ff12-af3e-42e6-80ea-9d31ba576718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-04T14:11:45.809955Z",
     "iopub.status.busy": "2023-01-04T14:11:45.808561Z",
     "iopub.status.idle": "2023-01-04T14:11:45.813831Z",
     "shell.execute_reply": "2023-01-04T14:11:45.812917Z",
     "shell.execute_reply.started": "2023-01-04T14:11:45.809907Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deine the early-stopping callback.\n",
    "#callbacks = [EarlyStoppingCallback(early_stopping_patience=4, early_stopping_threshold=0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc29e5e-255a-43e5-a348-fa4766e17efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:38:59.666182Z",
     "iopub.status.busy": "2023-01-10T04:38:59.665417Z",
     "iopub.status.idle": "2023-01-10T04:38:59.960155Z",
     "shell.execute_reply": "2023-01-10T04:38:59.959147Z",
     "shell.execute_reply.started": "2023-01-10T04:38:59.666137Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 12:38:59,759] [    INFO] - ============================================================\r\n",
      "[2023-01-10 12:38:59,762] [    INFO] -     Training Configuration Arguments    \r\n",
      "[2023-01-10 12:38:59,764] [    INFO] - paddle commit id              :3fa7a736e32508e797616b6344d97814c37d3ff8\r\n",
      "[2023-01-10 12:38:59,766] [    INFO] - _no_sync_in_gradient_accumulation:True\r\n",
      "[2023-01-10 12:38:59,768] [    INFO] - adam_beta1                    :0.9\r\n",
      "[2023-01-10 12:38:59,770] [    INFO] - adam_beta2                    :0.999\r\n",
      "[2023-01-10 12:38:59,772] [    INFO] - adam_epsilon                  :1e-08\r\n",
      "[2023-01-10 12:38:59,774] [    INFO] - alpha_rdrop                   :5.0\r\n",
      "[2023-01-10 12:38:59,776] [    INFO] - alpha_rgl                     :0.5\r\n",
      "[2023-01-10 12:38:59,778] [    INFO] - bf16                          :False\r\n",
      "[2023-01-10 12:38:59,780] [    INFO] - bf16_full_eval                :False\r\n",
      "[2023-01-10 12:38:59,782] [    INFO] - current_device                :gpu:0\r\n",
      "[2023-01-10 12:38:59,784] [    INFO] - dataloader_drop_last          :False\r\n",
      "[2023-01-10 12:38:59,785] [    INFO] - dataloader_num_workers        :0\r\n",
      "[2023-01-10 12:38:59,787] [    INFO] - device                        :gpu\r\n",
      "[2023-01-10 12:38:59,789] [    INFO] - disable_tqdm                  :False\r\n",
      "[2023-01-10 12:38:59,791] [    INFO] - do_eval                       :True\r\n",
      "[2023-01-10 12:38:59,793] [    INFO] - do_export                     :False\r\n",
      "[2023-01-10 12:38:59,795] [    INFO] - do_predict                    :False\r\n",
      "[2023-01-10 12:38:59,798] [    INFO] - do_train                      :False\r\n",
      "[2023-01-10 12:38:59,800] [    INFO] - eval_batch_size               :8\r\n",
      "[2023-01-10 12:38:59,802] [    INFO] - eval_steps                    :None\r\n",
      "[2023-01-10 12:38:59,805] [    INFO] - evaluation_strategy           :IntervalStrategy.EPOCH\r\n",
      "[2023-01-10 12:38:59,807] [    INFO] - fp16                          :False\r\n",
      "[2023-01-10 12:38:59,809] [    INFO] - fp16_full_eval                :False\r\n",
      "[2023-01-10 12:38:59,811] [    INFO] - fp16_opt_level                :O1\r\n",
      "[2023-01-10 12:38:59,814] [    INFO] - freeze_dropout                :False\r\n",
      "[2023-01-10 12:38:59,816] [    INFO] - freeze_plm                    :False\r\n",
      "[2023-01-10 12:38:59,818] [    INFO] - gradient_accumulation_steps   :1\r\n",
      "[2023-01-10 12:38:59,821] [    INFO] - greater_is_better             :True\r\n",
      "[2023-01-10 12:38:59,823] [    INFO] - ignore_data_skip              :False\r\n",
      "[2023-01-10 12:38:59,825] [    INFO] - label_names                   :None\r\n",
      "[2023-01-10 12:38:59,827] [    INFO] - learning_rate                 :3e-05\r\n",
      "[2023-01-10 12:38:59,830] [    INFO] - load_best_model_at_end        :True\r\n",
      "[2023-01-10 12:38:59,832] [    INFO] - local_process_index           :0\r\n",
      "[2023-01-10 12:38:59,834] [    INFO] - local_rank                    :-1\r\n",
      "[2023-01-10 12:38:59,837] [    INFO] - log_level                     :-1\r\n",
      "[2023-01-10 12:38:59,839] [    INFO] - log_level_replica             :-1\r\n",
      "[2023-01-10 12:38:59,841] [    INFO] - log_on_each_node              :True\r\n",
      "[2023-01-10 12:38:59,844] [    INFO] - logging_dir                   :./checkpoints/runs/Jan10_12-37-25_jupyter-1549728-5372639\r\n",
      "[2023-01-10 12:38:59,846] [    INFO] - logging_first_step            :False\r\n",
      "[2023-01-10 12:38:59,848] [    INFO] - logging_steps                 :5\r\n",
      "[2023-01-10 12:38:59,850] [    INFO] - logging_strategy              :IntervalStrategy.STEPS\r\n",
      "[2023-01-10 12:38:59,853] [    INFO] - lr_scheduler_type             :SchedulerType.LINEAR\r\n",
      "[2023-01-10 12:38:59,855] [    INFO] - max_grad_norm                 :1.0\r\n",
      "[2023-01-10 12:38:59,858] [    INFO] - max_seq_length                :512\r\n",
      "[2023-01-10 12:38:59,860] [    INFO] - max_steps                     :-1\r\n",
      "[2023-01-10 12:38:59,862] [    INFO] - metric_for_best_model         :macro_f1_score\r\n",
      "[2023-01-10 12:38:59,865] [    INFO] - minimum_eval_times            :None\r\n",
      "[2023-01-10 12:38:59,867] [    INFO] - no_cuda                       :False\r\n",
      "[2023-01-10 12:38:59,869] [    INFO] - num_train_epochs              :20.0\r\n",
      "[2023-01-10 12:38:59,872] [    INFO] - optim                         :OptimizerNames.ADAMW\r\n",
      "[2023-01-10 12:38:59,874] [    INFO] - output_dir                    :./checkpoints/\r\n",
      "[2023-01-10 12:38:59,876] [    INFO] - overwrite_output_dir          :False\r\n",
      "[2023-01-10 12:38:59,878] [    INFO] - past_index                    :-1\r\n",
      "[2023-01-10 12:38:59,881] [    INFO] - per_device_eval_batch_size    :8\r\n",
      "[2023-01-10 12:38:59,883] [    INFO] - per_device_train_batch_size   :8\r\n",
      "[2023-01-10 12:38:59,885] [    INFO] - ppt_adam_beta1                :0.9\r\n",
      "[2023-01-10 12:38:59,887] [    INFO] - ppt_adam_beta2                :0.999\r\n",
      "[2023-01-10 12:38:59,890] [    INFO] - ppt_adam_epsilon              :1e-08\r\n",
      "[2023-01-10 12:38:59,892] [    INFO] - ppt_learning_rate             :0.0003\r\n",
      "[2023-01-10 12:38:59,894] [    INFO] - ppt_weight_decay              :0.0\r\n",
      "[2023-01-10 12:38:59,897] [    INFO] - prediction_loss_only          :False\r\n",
      "[2023-01-10 12:38:59,899] [    INFO] - process_index                 :0\r\n",
      "[2023-01-10 12:38:59,901] [    INFO] - recompute                     :False\r\n",
      "[2023-01-10 12:38:59,903] [    INFO] - remove_unused_columns         :True\r\n",
      "[2023-01-10 12:38:59,906] [    INFO] - report_to                     :['visualdl']\r\n",
      "[2023-01-10 12:38:59,908] [    INFO] - resume_from_checkpoint        :None\r\n",
      "[2023-01-10 12:38:59,910] [    INFO] - run_name                      :./checkpoints/\r\n",
      "[2023-01-10 12:38:59,913] [    INFO] - save_on_each_node             :False\r\n",
      "[2023-01-10 12:38:59,915] [    INFO] - save_steps                    :500\r\n",
      "[2023-01-10 12:38:59,918] [    INFO] - save_strategy                 :IntervalStrategy.EPOCH\r\n",
      "[2023-01-10 12:38:59,921] [    INFO] - save_total_limit              :1\r\n",
      "[2023-01-10 12:38:59,923] [    INFO] - scale_loss                    :32768\r\n",
      "[2023-01-10 12:38:59,925] [    INFO] - seed                          :42\r\n",
      "[2023-01-10 12:38:59,927] [    INFO] - sharding                      :[]\r\n",
      "[2023-01-10 12:38:59,930] [    INFO] - sharding_degree               :-1\r\n",
      "[2023-01-10 12:38:59,932] [    INFO] - should_log                    :True\r\n",
      "[2023-01-10 12:38:59,934] [    INFO] - should_save                   :True\r\n",
      "[2023-01-10 12:38:59,937] [    INFO] - skip_memory_metrics           :True\r\n",
      "[2023-01-10 12:38:59,939] [    INFO] - train_batch_size              :8\r\n",
      "[2023-01-10 12:38:59,941] [    INFO] - use_rdrop                     :False\r\n",
      "[2023-01-10 12:38:59,943] [    INFO] - use_rgl                       :False\r\n",
      "[2023-01-10 12:38:59,946] [    INFO] - warmup_ratio                  :0.0\r\n",
      "[2023-01-10 12:38:59,948] [    INFO] - warmup_steps                  :0\r\n",
      "[2023-01-10 12:38:59,950] [    INFO] - weight_decay                  :0.0\r\n",
      "[2023-01-10 12:38:59,953] [    INFO] - world_size                    :1\r\n",
      "[2023-01-10 12:38:59,955] [    INFO] - \r\n"
     ]
    }
   ],
   "source": [
    "# Trainer 定义\n",
    "trainer = PromptTrainer(model=prompt_model,\n",
    "                        tokenizer=tokenizer,\n",
    "                        args=training_args,\n",
    "                        criterion=criterion,\n",
    "                        train_dataset=train_ds,\n",
    "                        eval_dataset=dev_ds,\n",
    "                        #callbacks=callbacks,\n",
    "                        compute_metrics=compute_metrics)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97701509-a927-47f1-9361-38c160d63b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T02:38:28.575006Z",
     "iopub.status.busy": "2023-01-10T02:38:28.574374Z",
     "iopub.status.idle": "2023-01-10T03:24:27.096618Z",
     "shell.execute_reply": "2023-01-10T03:24:27.095618Z",
     "shell.execute_reply.started": "2023-01-10T02:38:28.574965Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:38:28,580] [    INFO] - ***** Running training *****\r\n",
      "[2023-01-10 10:38:28,583] [    INFO] -   Num examples = 5393\r\n",
      "[2023-01-10 10:38:28,586] [    INFO] -   Num Epochs = 20\r\n",
      "[2023-01-10 10:38:28,588] [    INFO] -   Instantaneous batch size per device = 8\r\n",
      "[2023-01-10 10:38:28,590] [    INFO] -   Total train batch size (w. parallel, distributed & accumulation) = 8\r\n",
      "[2023-01-10 10:38:28,592] [    INFO] -   Gradient Accumulation steps = 1\r\n",
      "[2023-01-10 10:38:28,593] [    INFO] -   Total optimization steps = 13500.0\r\n",
      "[2023-01-10 10:38:28,595] [    INFO] -   Total num train samples = 107860.0\r\n",
      "[2023-01-10 10:38:28,609] [    INFO] -   Number of trainable parameters = 336219156\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262ad9512d7f47d3a3f7b1c8a5dabb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.60583401, learning_rate: 2.999e-05, global_step: 5, interval_runtime: 1.8059, interval_samples_per_second: 22.15, interval_steps_per_second: 2.769, epoch: 0.0074\r\n",
      "loss: 0.48748026, learning_rate: 2.998e-05, global_step: 10, interval_runtime: 0.7857, interval_samples_per_second: 50.912, interval_steps_per_second: 6.364, epoch: 0.0148\r\n",
      "loss: 0.43271046, learning_rate: 2.997e-05, global_step: 15, interval_runtime: 0.8399, interval_samples_per_second: 47.627, interval_steps_per_second: 5.953, epoch: 0.0222\r\n",
      "loss: 0.45458364, learning_rate: 2.996e-05, global_step: 20, interval_runtime: 0.8402, interval_samples_per_second: 47.607, interval_steps_per_second: 5.951, epoch: 0.0296\r\n",
      "loss: 0.42122793, learning_rate: 2.994e-05, global_step: 25, interval_runtime: 0.7586, interval_samples_per_second: 52.728, interval_steps_per_second: 6.591, epoch: 0.037\r\n",
      "loss: 0.40803399, learning_rate: 2.993e-05, global_step: 30, interval_runtime: 0.8822, interval_samples_per_second: 45.34, interval_steps_per_second: 5.667, epoch: 0.0444\r\n",
      "loss: 0.41308718, learning_rate: 2.992e-05, global_step: 35, interval_runtime: 0.8337, interval_samples_per_second: 47.979, interval_steps_per_second: 5.997, epoch: 0.0519\r\n",
      "loss: 0.43444395, learning_rate: 2.991e-05, global_step: 40, interval_runtime: 0.9226, interval_samples_per_second: 43.356, interval_steps_per_second: 5.42, epoch: 0.0593\r\n",
      "loss: 0.48516655, learning_rate: 2.99e-05, global_step: 45, interval_runtime: 0.7447, interval_samples_per_second: 53.714, interval_steps_per_second: 6.714, epoch: 0.0667\r\n",
      "loss: 0.44099874, learning_rate: 2.989e-05, global_step: 50, interval_runtime: 0.7767, interval_samples_per_second: 51.502, interval_steps_per_second: 6.438, epoch: 0.0741\r\n",
      "loss: 0.39061134, learning_rate: 2.988e-05, global_step: 55, interval_runtime: 0.8079, interval_samples_per_second: 49.511, interval_steps_per_second: 6.189, epoch: 0.0815\r\n",
      "loss: 0.39067528, learning_rate: 2.987e-05, global_step: 60, interval_runtime: 0.7299, interval_samples_per_second: 54.804, interval_steps_per_second: 6.851, epoch: 0.0889\r\n",
      "loss: 0.36265447, learning_rate: 2.986e-05, global_step: 65, interval_runtime: 0.7584, interval_samples_per_second: 52.745, interval_steps_per_second: 6.593, epoch: 0.0963\r\n",
      "loss: 0.39995027, learning_rate: 2.984e-05, global_step: 70, interval_runtime: 0.9166, interval_samples_per_second: 43.639, interval_steps_per_second: 5.455, epoch: 0.1037\r\n",
      "loss: 0.40269985, learning_rate: 2.983e-05, global_step: 75, interval_runtime: 0.8434, interval_samples_per_second: 47.427, interval_steps_per_second: 5.928, epoch: 0.1111\r\n",
      "loss: 0.43393807, learning_rate: 2.982e-05, global_step: 80, interval_runtime: 0.8394, interval_samples_per_second: 47.652, interval_steps_per_second: 5.957, epoch: 0.1185\r\n",
      "loss: 0.36971576, learning_rate: 2.981e-05, global_step: 85, interval_runtime: 0.9198, interval_samples_per_second: 43.486, interval_steps_per_second: 5.436, epoch: 0.1259\r\n",
      "loss: 0.33472018, learning_rate: 2.98e-05, global_step: 90, interval_runtime: 0.7121, interval_samples_per_second: 56.169, interval_steps_per_second: 7.021, epoch: 0.1333\r\n",
      "loss: 0.37944648, learning_rate: 2.979e-05, global_step: 95, interval_runtime: 0.7543, interval_samples_per_second: 53.03, interval_steps_per_second: 6.629, epoch: 0.1407\r\n",
      "loss: 0.39137464, learning_rate: 2.978e-05, global_step: 100, interval_runtime: 0.8897, interval_samples_per_second: 44.96, interval_steps_per_second: 5.62, epoch: 0.1481\r\n",
      "loss: 0.40848169, learning_rate: 2.977e-05, global_step: 105, interval_runtime: 0.7436, interval_samples_per_second: 53.795, interval_steps_per_second: 6.724, epoch: 0.1556\r\n",
      "loss: 0.3365833, learning_rate: 2.976e-05, global_step: 110, interval_runtime: 0.8382, interval_samples_per_second: 47.722, interval_steps_per_second: 5.965, epoch: 0.163\r\n",
      "loss: 0.3600461, learning_rate: 2.974e-05, global_step: 115, interval_runtime: 0.8227, interval_samples_per_second: 48.619, interval_steps_per_second: 6.077, epoch: 0.1704\r\n",
      "loss: 0.36783905, learning_rate: 2.973e-05, global_step: 120, interval_runtime: 0.7085, interval_samples_per_second: 56.457, interval_steps_per_second: 7.057, epoch: 0.1778\r\n",
      "loss: 0.37102895, learning_rate: 2.972e-05, global_step: 125, interval_runtime: 0.8431, interval_samples_per_second: 47.441, interval_steps_per_second: 5.93, epoch: 0.1852\r\n",
      "loss: 0.40070753, learning_rate: 2.971e-05, global_step: 130, interval_runtime: 0.8354, interval_samples_per_second: 47.88, interval_steps_per_second: 5.985, epoch: 0.1926\r\n",
      "loss: 0.39871857, learning_rate: 2.97e-05, global_step: 135, interval_runtime: 0.7113, interval_samples_per_second: 56.232, interval_steps_per_second: 7.029, epoch: 0.2\r\n",
      "loss: 0.3251951, learning_rate: 2.969e-05, global_step: 140, interval_runtime: 0.7983, interval_samples_per_second: 50.105, interval_steps_per_second: 6.263, epoch: 0.2074\r\n",
      "loss: 0.32641706, learning_rate: 2.968e-05, global_step: 145, interval_runtime: 0.989, interval_samples_per_second: 40.447, interval_steps_per_second: 5.056, epoch: 0.2148\r\n",
      "loss: 0.36592503, learning_rate: 2.967e-05, global_step: 150, interval_runtime: 0.8855, interval_samples_per_second: 45.172, interval_steps_per_second: 5.647, epoch: 0.2222\r\n",
      "loss: 0.35815132, learning_rate: 2.966e-05, global_step: 155, interval_runtime: 0.8375, interval_samples_per_second: 47.763, interval_steps_per_second: 5.97, epoch: 0.2296\r\n",
      "loss: 0.33616045, learning_rate: 2.964e-05, global_step: 160, interval_runtime: 0.7218, interval_samples_per_second: 55.414, interval_steps_per_second: 6.927, epoch: 0.237\r\n",
      "loss: 0.36327481, learning_rate: 2.963e-05, global_step: 165, interval_runtime: 0.8528, interval_samples_per_second: 46.904, interval_steps_per_second: 5.863, epoch: 0.2444\r\n",
      "loss: 0.35368125, learning_rate: 2.962e-05, global_step: 170, interval_runtime: 0.8907, interval_samples_per_second: 44.909, interval_steps_per_second: 5.614, epoch: 0.2519\r\n",
      "loss: 0.40223064, learning_rate: 2.961e-05, global_step: 175, interval_runtime: 0.9586, interval_samples_per_second: 41.728, interval_steps_per_second: 5.216, epoch: 0.2593\r\n",
      "loss: 0.38928115, learning_rate: 2.96e-05, global_step: 180, interval_runtime: 0.7091, interval_samples_per_second: 56.408, interval_steps_per_second: 7.051, epoch: 0.2667\r\n",
      "loss: 0.32600541, learning_rate: 2.959e-05, global_step: 185, interval_runtime: 0.7342, interval_samples_per_second: 54.478, interval_steps_per_second: 6.81, epoch: 0.2741\r\n",
      "loss: 0.38056586, learning_rate: 2.958e-05, global_step: 190, interval_runtime: 0.8785, interval_samples_per_second: 45.532, interval_steps_per_second: 5.691, epoch: 0.2815\r\n",
      "loss: 0.3506757, learning_rate: 2.957e-05, global_step: 195, interval_runtime: 0.9941, interval_samples_per_second: 40.238, interval_steps_per_second: 5.03, epoch: 0.2889\r\n",
      "loss: 0.33366344, learning_rate: 2.956e-05, global_step: 200, interval_runtime: 0.8454, interval_samples_per_second: 47.316, interval_steps_per_second: 5.914, epoch: 0.2963\r\n",
      "loss: 0.36502533, learning_rate: 2.954e-05, global_step: 205, interval_runtime: 0.7712, interval_samples_per_second: 51.864, interval_steps_per_second: 6.483, epoch: 0.3037\r\n",
      "loss: 0.33443606, learning_rate: 2.953e-05, global_step: 210, interval_runtime: 0.8034, interval_samples_per_second: 49.787, interval_steps_per_second: 6.223, epoch: 0.3111\r\n",
      "loss: 0.31549301, learning_rate: 2.952e-05, global_step: 215, interval_runtime: 0.919, interval_samples_per_second: 43.528, interval_steps_per_second: 5.441, epoch: 0.3185\r\n",
      "loss: 0.34058411, learning_rate: 2.951e-05, global_step: 220, interval_runtime: 0.8111, interval_samples_per_second: 49.317, interval_steps_per_second: 6.165, epoch: 0.3259\r\n",
      "loss: 0.48189311, learning_rate: 2.95e-05, global_step: 225, interval_runtime: 0.7868, interval_samples_per_second: 50.839, interval_steps_per_second: 6.355, epoch: 0.3333\r\n",
      "loss: 0.44214015, learning_rate: 2.949e-05, global_step: 230, interval_runtime: 0.8193, interval_samples_per_second: 48.825, interval_steps_per_second: 6.103, epoch: 0.3407\r\n",
      "loss: 0.43533111, learning_rate: 2.948e-05, global_step: 235, interval_runtime: 0.7821, interval_samples_per_second: 51.143, interval_steps_per_second: 6.393, epoch: 0.3481\r\n",
      "loss: 0.45812225, learning_rate: 2.947e-05, global_step: 240, interval_runtime: 0.7574, interval_samples_per_second: 52.81, interval_steps_per_second: 6.601, epoch: 0.3556\r\n",
      "loss: 0.33150899, learning_rate: 2.946e-05, global_step: 245, interval_runtime: 0.713, interval_samples_per_second: 56.101, interval_steps_per_second: 7.013, epoch: 0.363\r\n",
      "loss: 0.33891449, learning_rate: 2.944e-05, global_step: 250, interval_runtime: 0.789, interval_samples_per_second: 50.697, interval_steps_per_second: 6.337, epoch: 0.3704\r\n",
      "loss: 0.37166383, learning_rate: 2.943e-05, global_step: 255, interval_runtime: 0.784, interval_samples_per_second: 51.019, interval_steps_per_second: 6.377, epoch: 0.3778\r\n",
      "loss: 0.38790288, learning_rate: 2.942e-05, global_step: 260, interval_runtime: 0.7976, interval_samples_per_second: 50.151, interval_steps_per_second: 6.269, epoch: 0.3852\r\n",
      "loss: 0.31768706, learning_rate: 2.941e-05, global_step: 265, interval_runtime: 0.8325, interval_samples_per_second: 48.046, interval_steps_per_second: 6.006, epoch: 0.3926\r\n",
      "loss: 0.36736274, learning_rate: 2.94e-05, global_step: 270, interval_runtime: 0.9024, interval_samples_per_second: 44.328, interval_steps_per_second: 5.541, epoch: 0.4\r\n",
      "loss: 0.3085727, learning_rate: 2.939e-05, global_step: 275, interval_runtime: 0.8603, interval_samples_per_second: 46.494, interval_steps_per_second: 5.812, epoch: 0.4074\r\n",
      "loss: 0.31930292, learning_rate: 2.938e-05, global_step: 280, interval_runtime: 0.8185, interval_samples_per_second: 48.869, interval_steps_per_second: 6.109, epoch: 0.4148\r\n",
      "loss: 0.33535466, learning_rate: 2.937e-05, global_step: 285, interval_runtime: 0.8782, interval_samples_per_second: 45.546, interval_steps_per_second: 5.693, epoch: 0.4222\r\n",
      "loss: 0.32567682, learning_rate: 2.936e-05, global_step: 290, interval_runtime: 0.8063, interval_samples_per_second: 49.61, interval_steps_per_second: 6.201, epoch: 0.4296\r\n",
      "loss: 0.38392165, learning_rate: 2.934e-05, global_step: 295, interval_runtime: 0.9247, interval_samples_per_second: 43.258, interval_steps_per_second: 5.407, epoch: 0.437\r\n",
      "loss: 0.38808627, learning_rate: 2.933e-05, global_step: 300, interval_runtime: 0.9062, interval_samples_per_second: 44.141, interval_steps_per_second: 5.518, epoch: 0.4444\r\n",
      "loss: 0.3336082, learning_rate: 2.932e-05, global_step: 305, interval_runtime: 0.8284, interval_samples_per_second: 48.287, interval_steps_per_second: 6.036, epoch: 0.4519\r\n",
      "loss: 0.31504593, learning_rate: 2.931e-05, global_step: 310, interval_runtime: 0.8917, interval_samples_per_second: 44.86, interval_steps_per_second: 5.608, epoch: 0.4593\r\n",
      "loss: 0.31913881, learning_rate: 2.93e-05, global_step: 315, interval_runtime: 0.8185, interval_samples_per_second: 48.87, interval_steps_per_second: 6.109, epoch: 0.4667\r\n",
      "loss: 0.38529744, learning_rate: 2.929e-05, global_step: 320, interval_runtime: 0.7713, interval_samples_per_second: 51.862, interval_steps_per_second: 6.483, epoch: 0.4741\r\n",
      "loss: 0.34065518, learning_rate: 2.928e-05, global_step: 325, interval_runtime: 0.7999, interval_samples_per_second: 50.008, interval_steps_per_second: 6.251, epoch: 0.4815\r\n",
      "loss: 0.32045755, learning_rate: 2.927e-05, global_step: 330, interval_runtime: 0.8463, interval_samples_per_second: 47.264, interval_steps_per_second: 5.908, epoch: 0.4889\r\n",
      "loss: 0.33273613, learning_rate: 2.926e-05, global_step: 335, interval_runtime: 0.7692, interval_samples_per_second: 52.003, interval_steps_per_second: 6.5, epoch: 0.4963\r\n",
      "loss: 0.33500435, learning_rate: 2.924e-05, global_step: 340, interval_runtime: 0.946, interval_samples_per_second: 42.282, interval_steps_per_second: 5.285, epoch: 0.5037\r\n",
      "loss: 0.34977889, learning_rate: 2.923e-05, global_step: 345, interval_runtime: 0.9144, interval_samples_per_second: 43.744, interval_steps_per_second: 5.468, epoch: 0.5111\r\n",
      "loss: 0.34370937, learning_rate: 2.922e-05, global_step: 350, interval_runtime: 0.8539, interval_samples_per_second: 46.844, interval_steps_per_second: 5.856, epoch: 0.5185\r\n",
      "loss: 0.37692628, learning_rate: 2.921e-05, global_step: 355, interval_runtime: 0.7828, interval_samples_per_second: 51.096, interval_steps_per_second: 6.387, epoch: 0.5259\r\n",
      "loss: 0.32285695, learning_rate: 2.92e-05, global_step: 360, interval_runtime: 0.8402, interval_samples_per_second: 47.606, interval_steps_per_second: 5.951, epoch: 0.5333\r\n",
      "loss: 0.30966866, learning_rate: 2.919e-05, global_step: 365, interval_runtime: 0.766, interval_samples_per_second: 52.216, interval_steps_per_second: 6.527, epoch: 0.5407\r\n",
      "loss: 0.33998795, learning_rate: 2.918e-05, global_step: 370, interval_runtime: 0.9106, interval_samples_per_second: 43.928, interval_steps_per_second: 5.491, epoch: 0.5481\r\n",
      "loss: 0.31108887, learning_rate: 2.917e-05, global_step: 375, interval_runtime: 0.9656, interval_samples_per_second: 41.425, interval_steps_per_second: 5.178, epoch: 0.5556\r\n",
      "loss: 0.34653475, learning_rate: 2.916e-05, global_step: 380, interval_runtime: 0.9444, interval_samples_per_second: 42.353, interval_steps_per_second: 5.294, epoch: 0.563\r\n",
      "loss: 0.36452641, learning_rate: 2.914e-05, global_step: 385, interval_runtime: 0.8741, interval_samples_per_second: 45.762, interval_steps_per_second: 5.72, epoch: 0.5704\r\n",
      "loss: 0.31055269, learning_rate: 2.913e-05, global_step: 390, interval_runtime: 0.7538, interval_samples_per_second: 53.064, interval_steps_per_second: 6.633, epoch: 0.5778\r\n",
      "loss: 0.27061551, learning_rate: 2.912e-05, global_step: 395, interval_runtime: 0.8668, interval_samples_per_second: 46.145, interval_steps_per_second: 5.768, epoch: 0.5852\r\n",
      "loss: 0.35122879, learning_rate: 2.911e-05, global_step: 400, interval_runtime: 0.7578, interval_samples_per_second: 52.784, interval_steps_per_second: 6.598, epoch: 0.5926\r\n",
      "loss: 0.37229209, learning_rate: 2.91e-05, global_step: 405, interval_runtime: 0.7623, interval_samples_per_second: 52.475, interval_steps_per_second: 6.559, epoch: 0.6\r\n",
      "loss: 0.35011272, learning_rate: 2.909e-05, global_step: 410, interval_runtime: 0.7881, interval_samples_per_second: 50.753, interval_steps_per_second: 6.344, epoch: 0.6074\r\n",
      "loss: 0.28314583, learning_rate: 2.908e-05, global_step: 415, interval_runtime: 0.8387, interval_samples_per_second: 47.693, interval_steps_per_second: 5.962, epoch: 0.6148\r\n",
      "loss: 0.34368939, learning_rate: 2.907e-05, global_step: 420, interval_runtime: 0.8363, interval_samples_per_second: 47.83, interval_steps_per_second: 5.979, epoch: 0.6222\r\n",
      "loss: 0.31569841, learning_rate: 2.906e-05, global_step: 425, interval_runtime: 0.8487, interval_samples_per_second: 47.128, interval_steps_per_second: 5.891, epoch: 0.6296\r\n",
      "loss: 0.32948661, learning_rate: 2.904e-05, global_step: 430, interval_runtime: 0.7795, interval_samples_per_second: 51.313, interval_steps_per_second: 6.414, epoch: 0.637\r\n",
      "loss: 0.28650486, learning_rate: 2.903e-05, global_step: 435, interval_runtime: 0.7755, interval_samples_per_second: 51.58, interval_steps_per_second: 6.448, epoch: 0.6444\r\n",
      "loss: 0.35079043, learning_rate: 2.902e-05, global_step: 440, interval_runtime: 0.7768, interval_samples_per_second: 51.495, interval_steps_per_second: 6.437, epoch: 0.6519\r\n",
      "loss: 0.32820222, learning_rate: 2.901e-05, global_step: 445, interval_runtime: 1.021, interval_samples_per_second: 39.179, interval_steps_per_second: 4.897, epoch: 0.6593\r\n",
      "loss: 0.3766397, learning_rate: 2.9e-05, global_step: 450, interval_runtime: 0.8117, interval_samples_per_second: 49.28, interval_steps_per_second: 6.16, epoch: 0.6667\r\n",
      "loss: 0.34913058, learning_rate: 2.899e-05, global_step: 455, interval_runtime: 0.9205, interval_samples_per_second: 43.456, interval_steps_per_second: 5.432, epoch: 0.6741\r\n",
      "loss: 0.31191292, learning_rate: 2.898e-05, global_step: 460, interval_runtime: 1.0027, interval_samples_per_second: 39.891, interval_steps_per_second: 4.986, epoch: 0.6815\r\n",
      "loss: 0.36356483, learning_rate: 2.897e-05, global_step: 465, interval_runtime: 0.8338, interval_samples_per_second: 47.973, interval_steps_per_second: 5.997, epoch: 0.6889\r\n",
      "loss: 0.32917285, learning_rate: 2.896e-05, global_step: 470, interval_runtime: 0.7729, interval_samples_per_second: 51.754, interval_steps_per_second: 6.469, epoch: 0.6963\r\n",
      "loss: 0.32558875, learning_rate: 2.894e-05, global_step: 475, interval_runtime: 0.8174, interval_samples_per_second: 48.935, interval_steps_per_second: 6.117, epoch: 0.7037\r\n",
      "loss: 0.35986283, learning_rate: 2.893e-05, global_step: 480, interval_runtime: 0.8252, interval_samples_per_second: 48.472, interval_steps_per_second: 6.059, epoch: 0.7111\r\n",
      "loss: 0.34172356, learning_rate: 2.892e-05, global_step: 485, interval_runtime: 0.878, interval_samples_per_second: 45.557, interval_steps_per_second: 5.695, epoch: 0.7185\r\n",
      "loss: 0.32993152, learning_rate: 2.891e-05, global_step: 490, interval_runtime: 0.9386, interval_samples_per_second: 42.616, interval_steps_per_second: 5.327, epoch: 0.7259\r\n",
      "loss: 0.3002455, learning_rate: 2.89e-05, global_step: 495, interval_runtime: 0.8024, interval_samples_per_second: 49.848, interval_steps_per_second: 6.231, epoch: 0.7333\r\n",
      "loss: 0.31129525, learning_rate: 2.889e-05, global_step: 500, interval_runtime: 0.6808, interval_samples_per_second: 58.757, interval_steps_per_second: 7.345, epoch: 0.7407\r\n",
      "loss: 0.32458372, learning_rate: 2.888e-05, global_step: 505, interval_runtime: 0.905, interval_samples_per_second: 44.201, interval_steps_per_second: 5.525, epoch: 0.7481\r\n",
      "loss: 0.33174148, learning_rate: 2.887e-05, global_step: 510, interval_runtime: 0.8818, interval_samples_per_second: 45.36, interval_steps_per_second: 5.67, epoch: 0.7556\r\n",
      "loss: 0.28101141, learning_rate: 2.886e-05, global_step: 515, interval_runtime: 0.7302, interval_samples_per_second: 54.78, interval_steps_per_second: 6.847, epoch: 0.763\r\n",
      "loss: 0.32631154, learning_rate: 2.884e-05, global_step: 520, interval_runtime: 0.7363, interval_samples_per_second: 54.326, interval_steps_per_second: 6.791, epoch: 0.7704\r\n",
      "loss: 0.28916018, learning_rate: 2.883e-05, global_step: 525, interval_runtime: 0.8103, interval_samples_per_second: 49.363, interval_steps_per_second: 6.17, epoch: 0.7778\r\n",
      "loss: 0.34880581, learning_rate: 2.882e-05, global_step: 530, interval_runtime: 0.882, interval_samples_per_second: 45.349, interval_steps_per_second: 5.669, epoch: 0.7852\r\n",
      "loss: 0.38284135, learning_rate: 2.881e-05, global_step: 535, interval_runtime: 0.85, interval_samples_per_second: 47.061, interval_steps_per_second: 5.883, epoch: 0.7926\r\n",
      "loss: 0.34646385, learning_rate: 2.88e-05, global_step: 540, interval_runtime: 0.9047, interval_samples_per_second: 44.213, interval_steps_per_second: 5.527, epoch: 0.8\r\n",
      "loss: 0.31832638, learning_rate: 2.879e-05, global_step: 545, interval_runtime: 0.9398, interval_samples_per_second: 42.56, interval_steps_per_second: 5.32, epoch: 0.8074\r\n",
      "loss: 0.34194098, learning_rate: 2.878e-05, global_step: 550, interval_runtime: 0.9753, interval_samples_per_second: 41.013, interval_steps_per_second: 5.127, epoch: 0.8148\r\n",
      "loss: 0.2856317, learning_rate: 2.877e-05, global_step: 555, interval_runtime: 0.8106, interval_samples_per_second: 49.347, interval_steps_per_second: 6.168, epoch: 0.8222\r\n",
      "loss: 0.38707864, learning_rate: 2.876e-05, global_step: 560, interval_runtime: 0.7439, interval_samples_per_second: 53.774, interval_steps_per_second: 6.722, epoch: 0.8296\r\n",
      "loss: 0.290118, learning_rate: 2.874e-05, global_step: 565, interval_runtime: 0.7009, interval_samples_per_second: 57.065, interval_steps_per_second: 7.133, epoch: 0.837\r\n",
      "loss: 0.35712299, learning_rate: 2.873e-05, global_step: 570, interval_runtime: 0.8786, interval_samples_per_second: 45.527, interval_steps_per_second: 5.691, epoch: 0.8444\r\n",
      "loss: 0.32233839, learning_rate: 2.872e-05, global_step: 575, interval_runtime: 0.7283, interval_samples_per_second: 54.919, interval_steps_per_second: 6.865, epoch: 0.8519\r\n",
      "loss: 0.33658576, learning_rate: 2.871e-05, global_step: 580, interval_runtime: 0.7515, interval_samples_per_second: 53.225, interval_steps_per_second: 6.653, epoch: 0.8593\r\n",
      "loss: 0.36231155, learning_rate: 2.87e-05, global_step: 585, interval_runtime: 0.7543, interval_samples_per_second: 53.032, interval_steps_per_second: 6.629, epoch: 0.8667\r\n",
      "loss: 0.34039593, learning_rate: 2.869e-05, global_step: 590, interval_runtime: 0.765, interval_samples_per_second: 52.287, interval_steps_per_second: 6.536, epoch: 0.8741\r\n",
      "loss: 0.34841642, learning_rate: 2.868e-05, global_step: 595, interval_runtime: 0.7934, interval_samples_per_second: 50.416, interval_steps_per_second: 6.302, epoch: 0.8815\r\n",
      "loss: 0.32863326, learning_rate: 2.867e-05, global_step: 600, interval_runtime: 0.7399, interval_samples_per_second: 54.06, interval_steps_per_second: 6.758, epoch: 0.8889\r\n",
      "loss: 0.33313062, learning_rate: 2.866e-05, global_step: 605, interval_runtime: 0.9271, interval_samples_per_second: 43.146, interval_steps_per_second: 5.393, epoch: 0.8963\r\n",
      "loss: 0.32006297, learning_rate: 2.864e-05, global_step: 610, interval_runtime: 0.7888, interval_samples_per_second: 50.713, interval_steps_per_second: 6.339, epoch: 0.9037\r\n",
      "loss: 0.31780293, learning_rate: 2.863e-05, global_step: 615, interval_runtime: 0.7543, interval_samples_per_second: 53.032, interval_steps_per_second: 6.629, epoch: 0.9111\r\n",
      "loss: 0.37134612, learning_rate: 2.862e-05, global_step: 620, interval_runtime: 0.8508, interval_samples_per_second: 47.013, interval_steps_per_second: 5.877, epoch: 0.9185\r\n",
      "loss: 0.35236447, learning_rate: 2.861e-05, global_step: 625, interval_runtime: 0.8819, interval_samples_per_second: 45.356, interval_steps_per_second: 5.669, epoch: 0.9259\r\n",
      "loss: 0.30883582, learning_rate: 2.86e-05, global_step: 630, interval_runtime: 0.8408, interval_samples_per_second: 47.573, interval_steps_per_second: 5.947, epoch: 0.9333\r\n",
      "loss: 0.31637135, learning_rate: 2.859e-05, global_step: 635, interval_runtime: 0.7485, interval_samples_per_second: 53.44, interval_steps_per_second: 6.68, epoch: 0.9407\r\n",
      "loss: 0.34702706, learning_rate: 2.858e-05, global_step: 640, interval_runtime: 0.862, interval_samples_per_second: 46.404, interval_steps_per_second: 5.8, epoch: 0.9481\r\n",
      "loss: 0.31877348, learning_rate: 2.857e-05, global_step: 645, interval_runtime: 0.8804, interval_samples_per_second: 45.432, interval_steps_per_second: 5.679, epoch: 0.9556\r\n",
      "loss: 0.31647673, learning_rate: 2.856e-05, global_step: 650, interval_runtime: 0.7449, interval_samples_per_second: 53.702, interval_steps_per_second: 6.713, epoch: 0.963\r\n",
      "loss: 0.35588734, learning_rate: 2.854e-05, global_step: 655, interval_runtime: 0.9387, interval_samples_per_second: 42.61, interval_steps_per_second: 5.326, epoch: 0.9704\r\n",
      "loss: 0.30275912, learning_rate: 2.853e-05, global_step: 660, interval_runtime: 0.9027, interval_samples_per_second: 44.312, interval_steps_per_second: 5.539, epoch: 0.9778\r\n",
      "loss: 0.36422696, learning_rate: 2.852e-05, global_step: 665, interval_runtime: 0.832, interval_samples_per_second: 48.079, interval_steps_per_second: 6.01, epoch: 0.9852\r\n",
      "loss: 0.31503644, learning_rate: 2.851e-05, global_step: 670, interval_runtime: 0.7486, interval_samples_per_second: 53.436, interval_steps_per_second: 6.679, epoch: 0.9926\r\n",
      "loss: 0.32482226, learning_rate: 2.85e-05, global_step: 675, interval_runtime: 0.6421, interval_samples_per_second: 62.296, interval_steps_per_second: 7.787, epoch: 1.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:40:21,280] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:40:21,283] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:40:21,286] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:40:21,288] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:40:21,290] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.34305626153945923, eval_micro_f1_score: 0.45333608332473957, eval_macro_f1_score: 0.31962178108586725, eval_runtime: 13.1788, eval_samples_per_second: 143.867, eval_steps_per_second: 17.983, epoch: 1.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:40:34,464] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-675\r\n",
      "[2023-01-10 10:40:34,468] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:40:37,802] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-675/tokenizer_config.json\r\n",
      "[2023-01-10 10:40:37,807] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-675/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30353346, learning_rate: 2.849e-05, global_step: 680, interval_runtime: 24.3326, interval_samples_per_second: 1.644, interval_steps_per_second: 0.205, epoch: 1.0074\r\n",
      "loss: 0.30747335, learning_rate: 2.848e-05, global_step: 685, interval_runtime: 0.7643, interval_samples_per_second: 52.338, interval_steps_per_second: 6.542, epoch: 1.0148\r\n",
      "loss: 0.26996644, learning_rate: 2.847e-05, global_step: 690, interval_runtime: 0.8061, interval_samples_per_second: 49.62, interval_steps_per_second: 6.203, epoch: 1.0222\r\n",
      "loss: 0.28456342, learning_rate: 2.846e-05, global_step: 695, interval_runtime: 0.8879, interval_samples_per_second: 45.053, interval_steps_per_second: 5.632, epoch: 1.0296\r\n",
      "loss: 0.2915633, learning_rate: 2.844e-05, global_step: 700, interval_runtime: 0.8424, interval_samples_per_second: 47.482, interval_steps_per_second: 5.935, epoch: 1.037\r\n",
      "loss: 0.27819288, learning_rate: 2.843e-05, global_step: 705, interval_runtime: 0.8292, interval_samples_per_second: 48.238, interval_steps_per_second: 6.03, epoch: 1.0444\r\n",
      "loss: 0.26213384, learning_rate: 2.842e-05, global_step: 710, interval_runtime: 0.7986, interval_samples_per_second: 50.085, interval_steps_per_second: 6.261, epoch: 1.0519\r\n",
      "loss: 0.30339682, learning_rate: 2.841e-05, global_step: 715, interval_runtime: 0.9102, interval_samples_per_second: 43.945, interval_steps_per_second: 5.493, epoch: 1.0593\r\n",
      "loss: 0.30115833, learning_rate: 2.84e-05, global_step: 720, interval_runtime: 0.8105, interval_samples_per_second: 49.351, interval_steps_per_second: 6.169, epoch: 1.0667\r\n",
      "loss: 0.27643666, learning_rate: 2.839e-05, global_step: 725, interval_runtime: 0.8226, interval_samples_per_second: 48.624, interval_steps_per_second: 6.078, epoch: 1.0741\r\n",
      "loss: 0.33368437, learning_rate: 2.838e-05, global_step: 730, interval_runtime: 0.8187, interval_samples_per_second: 48.856, interval_steps_per_second: 6.107, epoch: 1.0815\r\n",
      "loss: 0.29913146, learning_rate: 2.837e-05, global_step: 735, interval_runtime: 0.8387, interval_samples_per_second: 47.692, interval_steps_per_second: 5.962, epoch: 1.0889\r\n",
      "loss: 0.30250957, learning_rate: 2.836e-05, global_step: 740, interval_runtime: 0.8348, interval_samples_per_second: 47.915, interval_steps_per_second: 5.989, epoch: 1.0963\r\n",
      "loss: 0.28081229, learning_rate: 2.834e-05, global_step: 745, interval_runtime: 0.7482, interval_samples_per_second: 53.459, interval_steps_per_second: 6.682, epoch: 1.1037\r\n",
      "loss: 0.29626098, learning_rate: 2.833e-05, global_step: 750, interval_runtime: 0.9602, interval_samples_per_second: 41.659, interval_steps_per_second: 5.207, epoch: 1.1111\r\n",
      "loss: 0.28905423, learning_rate: 2.832e-05, global_step: 755, interval_runtime: 0.872, interval_samples_per_second: 45.869, interval_steps_per_second: 5.734, epoch: 1.1185\r\n",
      "loss: 0.29984837, learning_rate: 2.831e-05, global_step: 760, interval_runtime: 0.8173, interval_samples_per_second: 48.944, interval_steps_per_second: 6.118, epoch: 1.1259\r\n",
      "loss: 0.30081015, learning_rate: 2.83e-05, global_step: 765, interval_runtime: 0.7798, interval_samples_per_second: 51.297, interval_steps_per_second: 6.412, epoch: 1.1333\r\n",
      "loss: 0.27474005, learning_rate: 2.829e-05, global_step: 770, interval_runtime: 1.1104, interval_samples_per_second: 36.023, interval_steps_per_second: 4.503, epoch: 1.1407\r\n",
      "loss: 0.33627884, learning_rate: 2.828e-05, global_step: 775, interval_runtime: 0.9603, interval_samples_per_second: 41.655, interval_steps_per_second: 5.207, epoch: 1.1481\r\n",
      "loss: 0.30149055, learning_rate: 2.827e-05, global_step: 780, interval_runtime: 0.8102, interval_samples_per_second: 49.369, interval_steps_per_second: 6.171, epoch: 1.1556\r\n",
      "loss: 0.2915585, learning_rate: 2.826e-05, global_step: 785, interval_runtime: 0.8164, interval_samples_per_second: 48.997, interval_steps_per_second: 6.125, epoch: 1.163\r\n",
      "loss: 0.3213151, learning_rate: 2.824e-05, global_step: 790, interval_runtime: 0.7655, interval_samples_per_second: 52.254, interval_steps_per_second: 6.532, epoch: 1.1704\r\n",
      "loss: 0.27061796, learning_rate: 2.823e-05, global_step: 795, interval_runtime: 0.7548, interval_samples_per_second: 52.998, interval_steps_per_second: 6.625, epoch: 1.1778\r\n",
      "loss: 0.2768918, learning_rate: 2.822e-05, global_step: 800, interval_runtime: 0.9255, interval_samples_per_second: 43.219, interval_steps_per_second: 5.402, epoch: 1.1852\r\n",
      "loss: 0.27006691, learning_rate: 2.821e-05, global_step: 805, interval_runtime: 0.8935, interval_samples_per_second: 44.767, interval_steps_per_second: 5.596, epoch: 1.1926\r\n",
      "loss: 0.31023445, learning_rate: 2.82e-05, global_step: 810, interval_runtime: 0.7872, interval_samples_per_second: 50.812, interval_steps_per_second: 6.351, epoch: 1.2\r\n",
      "loss: 0.28523912, learning_rate: 2.819e-05, global_step: 815, interval_runtime: 1.1632, interval_samples_per_second: 34.387, interval_steps_per_second: 4.298, epoch: 1.2074\r\n",
      "loss: 0.24991984, learning_rate: 2.818e-05, global_step: 820, interval_runtime: 0.8913, interval_samples_per_second: 44.876, interval_steps_per_second: 5.61, epoch: 1.2148\r\n",
      "loss: 0.25139928, learning_rate: 2.817e-05, global_step: 825, interval_runtime: 0.9288, interval_samples_per_second: 43.064, interval_steps_per_second: 5.383, epoch: 1.2222\r\n",
      "loss: 0.32350566, learning_rate: 2.816e-05, global_step: 830, interval_runtime: 0.8565, interval_samples_per_second: 46.701, interval_steps_per_second: 5.838, epoch: 1.2296\r\n",
      "loss: 0.29555669, learning_rate: 2.814e-05, global_step: 835, interval_runtime: 0.7827, interval_samples_per_second: 51.107, interval_steps_per_second: 6.388, epoch: 1.237\r\n",
      "loss: 0.2896771, learning_rate: 2.813e-05, global_step: 840, interval_runtime: 0.8898, interval_samples_per_second: 44.954, interval_steps_per_second: 5.619, epoch: 1.2444\r\n",
      "loss: 0.29817166, learning_rate: 2.812e-05, global_step: 845, interval_runtime: 0.9971, interval_samples_per_second: 40.116, interval_steps_per_second: 5.014, epoch: 1.2519\r\n",
      "loss: 0.2661351, learning_rate: 2.811e-05, global_step: 850, interval_runtime: 0.8013, interval_samples_per_second: 49.92, interval_steps_per_second: 6.24, epoch: 1.2593\r\n",
      "loss: 0.27896385, learning_rate: 2.81e-05, global_step: 855, interval_runtime: 0.7491, interval_samples_per_second: 53.398, interval_steps_per_second: 6.675, epoch: 1.2667\r\n",
      "loss: 0.29575973, learning_rate: 2.809e-05, global_step: 860, interval_runtime: 0.7719, interval_samples_per_second: 51.82, interval_steps_per_second: 6.478, epoch: 1.2741\r\n",
      "loss: 0.28081832, learning_rate: 2.808e-05, global_step: 865, interval_runtime: 0.8313, interval_samples_per_second: 48.118, interval_steps_per_second: 6.015, epoch: 1.2815\r\n",
      "loss: 0.30772324, learning_rate: 2.807e-05, global_step: 870, interval_runtime: 0.8408, interval_samples_per_second: 47.572, interval_steps_per_second: 5.947, epoch: 1.2889\r\n",
      "loss: 0.33002722, learning_rate: 2.806e-05, global_step: 875, interval_runtime: 0.8759, interval_samples_per_second: 45.666, interval_steps_per_second: 5.708, epoch: 1.2963\r\n",
      "loss: 0.29229918, learning_rate: 2.804e-05, global_step: 880, interval_runtime: 0.7526, interval_samples_per_second: 53.146, interval_steps_per_second: 6.643, epoch: 1.3037\r\n",
      "loss: 0.26706109, learning_rate: 2.803e-05, global_step: 885, interval_runtime: 0.7051, interval_samples_per_second: 56.727, interval_steps_per_second: 7.091, epoch: 1.3111\r\n",
      "loss: 0.31439075, learning_rate: 2.802e-05, global_step: 890, interval_runtime: 0.8919, interval_samples_per_second: 44.848, interval_steps_per_second: 5.606, epoch: 1.3185\r\n",
      "loss: 0.30994616, learning_rate: 2.801e-05, global_step: 895, interval_runtime: 0.7825, interval_samples_per_second: 51.118, interval_steps_per_second: 6.39, epoch: 1.3259\r\n",
      "loss: 0.29854372, learning_rate: 2.8e-05, global_step: 900, interval_runtime: 0.7823, interval_samples_per_second: 51.131, interval_steps_per_second: 6.391, epoch: 1.3333\r\n",
      "loss: 0.27181582, learning_rate: 2.799e-05, global_step: 905, interval_runtime: 0.8395, interval_samples_per_second: 47.645, interval_steps_per_second: 5.956, epoch: 1.3407\r\n",
      "loss: 0.31303873, learning_rate: 2.798e-05, global_step: 910, interval_runtime: 0.9109, interval_samples_per_second: 43.911, interval_steps_per_second: 5.489, epoch: 1.3481\r\n",
      "loss: 0.32468536, learning_rate: 2.797e-05, global_step: 915, interval_runtime: 0.8687, interval_samples_per_second: 46.046, interval_steps_per_second: 5.756, epoch: 1.3556\r\n",
      "loss: 0.25819149, learning_rate: 2.796e-05, global_step: 920, interval_runtime: 0.7903, interval_samples_per_second: 50.613, interval_steps_per_second: 6.327, epoch: 1.363\r\n",
      "loss: 0.27931454, learning_rate: 2.794e-05, global_step: 925, interval_runtime: 0.8389, interval_samples_per_second: 47.679, interval_steps_per_second: 5.96, epoch: 1.3704\r\n",
      "loss: 0.28799262, learning_rate: 2.793e-05, global_step: 930, interval_runtime: 0.847, interval_samples_per_second: 47.227, interval_steps_per_second: 5.903, epoch: 1.3778\r\n",
      "loss: 0.26749802, learning_rate: 2.792e-05, global_step: 935, interval_runtime: 0.729, interval_samples_per_second: 54.867, interval_steps_per_second: 6.858, epoch: 1.3852\r\n",
      "loss: 0.31311576, learning_rate: 2.791e-05, global_step: 940, interval_runtime: 0.8572, interval_samples_per_second: 46.661, interval_steps_per_second: 5.833, epoch: 1.3926\r\n",
      "loss: 0.23626218, learning_rate: 2.79e-05, global_step: 945, interval_runtime: 0.8902, interval_samples_per_second: 44.933, interval_steps_per_second: 5.617, epoch: 1.4\r\n",
      "loss: 0.27809196, learning_rate: 2.789e-05, global_step: 950, interval_runtime: 0.9032, interval_samples_per_second: 44.289, interval_steps_per_second: 5.536, epoch: 1.4074\r\n",
      "loss: 0.28605573, learning_rate: 2.788e-05, global_step: 955, interval_runtime: 0.8843, interval_samples_per_second: 45.231, interval_steps_per_second: 5.654, epoch: 1.4148\r\n",
      "loss: 0.31129775, learning_rate: 2.787e-05, global_step: 960, interval_runtime: 0.699, interval_samples_per_second: 57.222, interval_steps_per_second: 7.153, epoch: 1.4222\r\n",
      "loss: 0.30557032, learning_rate: 2.786e-05, global_step: 965, interval_runtime: 0.794, interval_samples_per_second: 50.378, interval_steps_per_second: 6.297, epoch: 1.4296\r\n",
      "loss: 0.30995574, learning_rate: 2.784e-05, global_step: 970, interval_runtime: 0.814, interval_samples_per_second: 49.142, interval_steps_per_second: 6.143, epoch: 1.437\r\n",
      "loss: 0.27636418, learning_rate: 2.783e-05, global_step: 975, interval_runtime: 0.7626, interval_samples_per_second: 52.45, interval_steps_per_second: 6.556, epoch: 1.4444\r\n",
      "loss: 0.28766413, learning_rate: 2.782e-05, global_step: 980, interval_runtime: 0.8327, interval_samples_per_second: 48.035, interval_steps_per_second: 6.004, epoch: 1.4519\r\n",
      "loss: 0.28583841, learning_rate: 2.781e-05, global_step: 985, interval_runtime: 0.7554, interval_samples_per_second: 52.955, interval_steps_per_second: 6.619, epoch: 1.4593\r\n",
      "loss: 0.31957054, learning_rate: 2.78e-05, global_step: 990, interval_runtime: 0.8506, interval_samples_per_second: 47.027, interval_steps_per_second: 5.878, epoch: 1.4667\r\n",
      "loss: 0.27313905, learning_rate: 2.779e-05, global_step: 995, interval_runtime: 0.8134, interval_samples_per_second: 49.175, interval_steps_per_second: 6.147, epoch: 1.4741\r\n",
      "loss: 0.29716904, learning_rate: 2.778e-05, global_step: 1000, interval_runtime: 1.0624, interval_samples_per_second: 37.65, interval_steps_per_second: 4.706, epoch: 1.4815\r\n",
      "loss: 0.26826603, learning_rate: 2.777e-05, global_step: 1005, interval_runtime: 0.7996, interval_samples_per_second: 50.026, interval_steps_per_second: 6.253, epoch: 1.4889\r\n",
      "loss: 0.27915471, learning_rate: 2.776e-05, global_step: 1010, interval_runtime: 0.8118, interval_samples_per_second: 49.275, interval_steps_per_second: 6.159, epoch: 1.4963\r\n",
      "loss: 0.27027133, learning_rate: 2.774e-05, global_step: 1015, interval_runtime: 0.8008, interval_samples_per_second: 49.951, interval_steps_per_second: 6.244, epoch: 1.5037\r\n",
      "loss: 0.26654193, learning_rate: 2.773e-05, global_step: 1020, interval_runtime: 0.8778, interval_samples_per_second: 45.567, interval_steps_per_second: 5.696, epoch: 1.5111\r\n",
      "loss: 0.29680884, learning_rate: 2.772e-05, global_step: 1025, interval_runtime: 0.7933, interval_samples_per_second: 50.422, interval_steps_per_second: 6.303, epoch: 1.5185\r\n",
      "loss: 0.27363806, learning_rate: 2.771e-05, global_step: 1030, interval_runtime: 0.9258, interval_samples_per_second: 43.206, interval_steps_per_second: 5.401, epoch: 1.5259\r\n",
      "loss: 0.23476391, learning_rate: 2.77e-05, global_step: 1035, interval_runtime: 0.8297, interval_samples_per_second: 48.209, interval_steps_per_second: 6.026, epoch: 1.5333\r\n",
      "loss: 0.30927293, learning_rate: 2.769e-05, global_step: 1040, interval_runtime: 0.8709, interval_samples_per_second: 45.93, interval_steps_per_second: 5.741, epoch: 1.5407\r\n",
      "loss: 0.29172864, learning_rate: 2.768e-05, global_step: 1045, interval_runtime: 0.9781, interval_samples_per_second: 40.896, interval_steps_per_second: 5.112, epoch: 1.5481\r\n",
      "loss: 0.30469151, learning_rate: 2.767e-05, global_step: 1050, interval_runtime: 0.9713, interval_samples_per_second: 41.183, interval_steps_per_second: 5.148, epoch: 1.5556\r\n",
      "loss: 0.33460529, learning_rate: 2.766e-05, global_step: 1055, interval_runtime: 0.9069, interval_samples_per_second: 44.107, interval_steps_per_second: 5.513, epoch: 1.563\r\n",
      "loss: 0.30541191, learning_rate: 2.764e-05, global_step: 1060, interval_runtime: 0.8369, interval_samples_per_second: 47.796, interval_steps_per_second: 5.974, epoch: 1.5704\r\n",
      "loss: 0.2841295, learning_rate: 2.763e-05, global_step: 1065, interval_runtime: 0.9515, interval_samples_per_second: 42.04, interval_steps_per_second: 5.255, epoch: 1.5778\r\n",
      "loss: 0.29581211, learning_rate: 2.762e-05, global_step: 1070, interval_runtime: 0.91, interval_samples_per_second: 43.955, interval_steps_per_second: 5.494, epoch: 1.5852\r\n",
      "loss: 0.33691449, learning_rate: 2.761e-05, global_step: 1075, interval_runtime: 0.7348, interval_samples_per_second: 54.437, interval_steps_per_second: 6.805, epoch: 1.5926\r\n",
      "loss: 0.26489918, learning_rate: 2.76e-05, global_step: 1080, interval_runtime: 0.7932, interval_samples_per_second: 50.426, interval_steps_per_second: 6.303, epoch: 1.6\r\n",
      "loss: 0.27176681, learning_rate: 2.759e-05, global_step: 1085, interval_runtime: 0.8468, interval_samples_per_second: 47.234, interval_steps_per_second: 5.904, epoch: 1.6074\r\n",
      "loss: 0.29279504, learning_rate: 2.758e-05, global_step: 1090, interval_runtime: 0.702, interval_samples_per_second: 56.982, interval_steps_per_second: 7.123, epoch: 1.6148\r\n",
      "loss: 0.29366918, learning_rate: 2.757e-05, global_step: 1095, interval_runtime: 0.8876, interval_samples_per_second: 45.066, interval_steps_per_second: 5.633, epoch: 1.6222\r\n",
      "loss: 0.23855743, learning_rate: 2.756e-05, global_step: 1100, interval_runtime: 0.8394, interval_samples_per_second: 47.656, interval_steps_per_second: 5.957, epoch: 1.6296\r\n",
      "loss: 0.30365593, learning_rate: 2.754e-05, global_step: 1105, interval_runtime: 0.8515, interval_samples_per_second: 46.977, interval_steps_per_second: 5.872, epoch: 1.637\r\n",
      "loss: 0.27715468, learning_rate: 2.753e-05, global_step: 1110, interval_runtime: 0.9069, interval_samples_per_second: 44.108, interval_steps_per_second: 5.514, epoch: 1.6444\r\n",
      "loss: 0.3045238, learning_rate: 2.752e-05, global_step: 1115, interval_runtime: 0.777, interval_samples_per_second: 51.478, interval_steps_per_second: 6.435, epoch: 1.6519\r\n",
      "loss: 0.29668531, learning_rate: 2.751e-05, global_step: 1120, interval_runtime: 0.9096, interval_samples_per_second: 43.977, interval_steps_per_second: 5.497, epoch: 1.6593\r\n",
      "loss: 0.31881011, learning_rate: 2.75e-05, global_step: 1125, interval_runtime: 0.8636, interval_samples_per_second: 46.316, interval_steps_per_second: 5.79, epoch: 1.6667\r\n",
      "loss: 0.31608362, learning_rate: 2.749e-05, global_step: 1130, interval_runtime: 0.8833, interval_samples_per_second: 45.285, interval_steps_per_second: 5.661, epoch: 1.6741\r\n",
      "loss: 0.29207277, learning_rate: 2.748e-05, global_step: 1135, interval_runtime: 0.8417, interval_samples_per_second: 47.524, interval_steps_per_second: 5.941, epoch: 1.6815\r\n",
      "loss: 0.31615558, learning_rate: 2.747e-05, global_step: 1140, interval_runtime: 0.744, interval_samples_per_second: 53.761, interval_steps_per_second: 6.72, epoch: 1.6889\r\n",
      "loss: 0.30585594, learning_rate: 2.746e-05, global_step: 1145, interval_runtime: 0.8485, interval_samples_per_second: 47.142, interval_steps_per_second: 5.893, epoch: 1.6963\r\n",
      "loss: 0.30912738, learning_rate: 2.744e-05, global_step: 1150, interval_runtime: 0.6967, interval_samples_per_second: 57.415, interval_steps_per_second: 7.177, epoch: 1.7037\r\n",
      "loss: 0.32202499, learning_rate: 2.743e-05, global_step: 1155, interval_runtime: 0.7846, interval_samples_per_second: 50.98, interval_steps_per_second: 6.373, epoch: 1.7111\r\n",
      "loss: 0.26548219, learning_rate: 2.742e-05, global_step: 1160, interval_runtime: 0.7598, interval_samples_per_second: 52.644, interval_steps_per_second: 6.58, epoch: 1.7185\r\n",
      "loss: 0.26235666, learning_rate: 2.741e-05, global_step: 1165, interval_runtime: 0.8017, interval_samples_per_second: 49.891, interval_steps_per_second: 6.236, epoch: 1.7259\r\n",
      "loss: 0.29499018, learning_rate: 2.74e-05, global_step: 1170, interval_runtime: 1.0445, interval_samples_per_second: 38.295, interval_steps_per_second: 4.787, epoch: 1.7333\r\n",
      "loss: 0.26696484, learning_rate: 2.739e-05, global_step: 1175, interval_runtime: 0.8819, interval_samples_per_second: 45.359, interval_steps_per_second: 5.67, epoch: 1.7407\r\n",
      "loss: 0.29522691, learning_rate: 2.738e-05, global_step: 1180, interval_runtime: 0.8204, interval_samples_per_second: 48.758, interval_steps_per_second: 6.095, epoch: 1.7481\r\n",
      "loss: 0.27753274, learning_rate: 2.737e-05, global_step: 1185, interval_runtime: 0.7056, interval_samples_per_second: 56.692, interval_steps_per_second: 7.087, epoch: 1.7556\r\n",
      "loss: 0.26736686, learning_rate: 2.736e-05, global_step: 1190, interval_runtime: 0.8461, interval_samples_per_second: 47.278, interval_steps_per_second: 5.91, epoch: 1.763\r\n",
      "loss: 0.26893163, learning_rate: 2.734e-05, global_step: 1195, interval_runtime: 0.7534, interval_samples_per_second: 53.091, interval_steps_per_second: 6.636, epoch: 1.7704\r\n",
      "loss: 0.29711452, learning_rate: 2.733e-05, global_step: 1200, interval_runtime: 0.8249, interval_samples_per_second: 48.489, interval_steps_per_second: 6.061, epoch: 1.7778\r\n",
      "loss: 0.30807903, learning_rate: 2.732e-05, global_step: 1205, interval_runtime: 0.8496, interval_samples_per_second: 47.081, interval_steps_per_second: 5.885, epoch: 1.7852\r\n",
      "loss: 0.33138769, learning_rate: 2.731e-05, global_step: 1210, interval_runtime: 0.7705, interval_samples_per_second: 51.914, interval_steps_per_second: 6.489, epoch: 1.7926\r\n",
      "loss: 0.28816009, learning_rate: 2.73e-05, global_step: 1215, interval_runtime: 0.8226, interval_samples_per_second: 48.629, interval_steps_per_second: 6.079, epoch: 1.8\r\n",
      "loss: 0.28918588, learning_rate: 2.729e-05, global_step: 1220, interval_runtime: 0.6801, interval_samples_per_second: 58.818, interval_steps_per_second: 7.352, epoch: 1.8074\r\n",
      "loss: 0.25816059, learning_rate: 2.728e-05, global_step: 1225, interval_runtime: 0.8865, interval_samples_per_second: 45.123, interval_steps_per_second: 5.64, epoch: 1.8148\r\n",
      "loss: 0.3372889, learning_rate: 2.727e-05, global_step: 1230, interval_runtime: 0.8071, interval_samples_per_second: 49.558, interval_steps_per_second: 6.195, epoch: 1.8222\r\n",
      "loss: 0.30461795, learning_rate: 2.726e-05, global_step: 1235, interval_runtime: 0.7949, interval_samples_per_second: 50.319, interval_steps_per_second: 6.29, epoch: 1.8296\r\n",
      "loss: 0.29395461, learning_rate: 2.724e-05, global_step: 1240, interval_runtime: 0.8552, interval_samples_per_second: 46.773, interval_steps_per_second: 5.847, epoch: 1.837\r\n",
      "loss: 0.27142982, learning_rate: 2.723e-05, global_step: 1245, interval_runtime: 0.9921, interval_samples_per_second: 40.319, interval_steps_per_second: 5.04, epoch: 1.8444\r\n",
      "loss: 0.26074467, learning_rate: 2.722e-05, global_step: 1250, interval_runtime: 0.9277, interval_samples_per_second: 43.116, interval_steps_per_second: 5.39, epoch: 1.8519\r\n",
      "loss: 0.28136935, learning_rate: 2.721e-05, global_step: 1255, interval_runtime: 0.8053, interval_samples_per_second: 49.674, interval_steps_per_second: 6.209, epoch: 1.8593\r\n",
      "loss: 0.27915158, learning_rate: 2.72e-05, global_step: 1260, interval_runtime: 0.7801, interval_samples_per_second: 51.272, interval_steps_per_second: 6.409, epoch: 1.8667\r\n",
      "loss: 0.31020083, learning_rate: 2.719e-05, global_step: 1265, interval_runtime: 0.9384, interval_samples_per_second: 42.626, interval_steps_per_second: 5.328, epoch: 1.8741\r\n",
      "loss: 0.2835752, learning_rate: 2.718e-05, global_step: 1270, interval_runtime: 0.8962, interval_samples_per_second: 44.631, interval_steps_per_second: 5.579, epoch: 1.8815\r\n",
      "loss: 0.29474144, learning_rate: 2.717e-05, global_step: 1275, interval_runtime: 0.8059, interval_samples_per_second: 49.634, interval_steps_per_second: 6.204, epoch: 1.8889\r\n",
      "loss: 0.32082829, learning_rate: 2.716e-05, global_step: 1280, interval_runtime: 0.7777, interval_samples_per_second: 51.433, interval_steps_per_second: 6.429, epoch: 1.8963\r\n",
      "loss: 0.28735611, learning_rate: 2.714e-05, global_step: 1285, interval_runtime: 0.7685, interval_samples_per_second: 52.049, interval_steps_per_second: 6.506, epoch: 1.9037\r\n",
      "loss: 0.28641357, learning_rate: 2.713e-05, global_step: 1290, interval_runtime: 0.8544, interval_samples_per_second: 46.818, interval_steps_per_second: 5.852, epoch: 1.9111\r\n",
      "loss: 0.31749628, learning_rate: 2.712e-05, global_step: 1295, interval_runtime: 0.8232, interval_samples_per_second: 48.593, interval_steps_per_second: 6.074, epoch: 1.9185\r\n",
      "loss: 0.32754581, learning_rate: 2.711e-05, global_step: 1300, interval_runtime: 0.8475, interval_samples_per_second: 47.2, interval_steps_per_second: 5.9, epoch: 1.9259\r\n",
      "loss: 0.29044547, learning_rate: 2.71e-05, global_step: 1305, interval_runtime: 0.8777, interval_samples_per_second: 45.573, interval_steps_per_second: 5.697, epoch: 1.9333\r\n",
      "loss: 0.25153465, learning_rate: 2.709e-05, global_step: 1310, interval_runtime: 0.7345, interval_samples_per_second: 54.457, interval_steps_per_second: 6.807, epoch: 1.9407\r\n",
      "loss: 0.28070602, learning_rate: 2.708e-05, global_step: 1315, interval_runtime: 0.7878, interval_samples_per_second: 50.773, interval_steps_per_second: 6.347, epoch: 1.9481\r\n",
      "loss: 0.29856393, learning_rate: 2.707e-05, global_step: 1320, interval_runtime: 0.9428, interval_samples_per_second: 42.426, interval_steps_per_second: 5.303, epoch: 1.9556\r\n",
      "loss: 0.28027885, learning_rate: 2.706e-05, global_step: 1325, interval_runtime: 0.9026, interval_samples_per_second: 44.316, interval_steps_per_second: 5.54, epoch: 1.963\r\n",
      "loss: 0.32121606, learning_rate: 2.704e-05, global_step: 1330, interval_runtime: 0.9745, interval_samples_per_second: 41.046, interval_steps_per_second: 5.131, epoch: 1.9704\r\n",
      "loss: 0.26394806, learning_rate: 2.703e-05, global_step: 1335, interval_runtime: 0.8072, interval_samples_per_second: 49.554, interval_steps_per_second: 6.194, epoch: 1.9778\r\n",
      "loss: 0.30429134, learning_rate: 2.702e-05, global_step: 1340, interval_runtime: 0.7791, interval_samples_per_second: 51.341, interval_steps_per_second: 6.418, epoch: 1.9852\r\n",
      "loss: 0.24089196, learning_rate: 2.701e-05, global_step: 1345, interval_runtime: 0.8766, interval_samples_per_second: 45.631, interval_steps_per_second: 5.704, epoch: 1.9926\r\n",
      "loss: 0.35613432, learning_rate: 2.7e-05, global_step: 1350, interval_runtime: 0.7495, interval_samples_per_second: 53.365, interval_steps_per_second: 6.671, epoch: 2.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:42:38,345] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:42:38,348] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:42:38,350] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:42:38,352] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:42:38,354] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.32000669836997986, eval_micro_f1_score: 0.5280076997112608, eval_macro_f1_score: 0.37985157790690055, eval_runtime: 13.2288, eval_samples_per_second: 143.323, eval_steps_per_second: 17.915, epoch: 2.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:42:51,578] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-1350\r\n",
      "[2023-01-10 10:42:51,581] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:42:54,930] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-1350/tokenizer_config.json\r\n",
      "[2023-01-10 10:42:54,934] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-1350/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.21933849, learning_rate: 2.699e-05, global_step: 1355, interval_runtime: 24.1269, interval_samples_per_second: 1.658, interval_steps_per_second: 0.207, epoch: 2.0074\r\n",
      "loss: 0.18335265, learning_rate: 2.698e-05, global_step: 1360, interval_runtime: 0.7755, interval_samples_per_second: 51.576, interval_steps_per_second: 6.447, epoch: 2.0148\r\n",
      "loss: 0.26420326, learning_rate: 2.697e-05, global_step: 1365, interval_runtime: 0.8134, interval_samples_per_second: 49.179, interval_steps_per_second: 6.147, epoch: 2.0222\r\n",
      "loss: 0.2123024, learning_rate: 2.696e-05, global_step: 1370, interval_runtime: 0.8973, interval_samples_per_second: 44.577, interval_steps_per_second: 5.572, epoch: 2.0296\r\n",
      "loss: 0.26496542, learning_rate: 2.694e-05, global_step: 1375, interval_runtime: 0.8129, interval_samples_per_second: 49.204, interval_steps_per_second: 6.151, epoch: 2.037\r\n",
      "loss: 0.24980605, learning_rate: 2.693e-05, global_step: 1380, interval_runtime: 0.7877, interval_samples_per_second: 50.779, interval_steps_per_second: 6.347, epoch: 2.0444\r\n",
      "loss: 0.2516036, learning_rate: 2.692e-05, global_step: 1385, interval_runtime: 0.8697, interval_samples_per_second: 45.995, interval_steps_per_second: 5.749, epoch: 2.0519\r\n",
      "loss: 0.24248869, learning_rate: 2.691e-05, global_step: 1390, interval_runtime: 0.8015, interval_samples_per_second: 49.906, interval_steps_per_second: 6.238, epoch: 2.0593\r\n",
      "loss: 0.25540161, learning_rate: 2.69e-05, global_step: 1395, interval_runtime: 0.8453, interval_samples_per_second: 47.323, interval_steps_per_second: 5.915, epoch: 2.0667\r\n",
      "loss: 0.24781775, learning_rate: 2.689e-05, global_step: 1400, interval_runtime: 0.7602, interval_samples_per_second: 52.62, interval_steps_per_second: 6.577, epoch: 2.0741\r\n",
      "loss: 0.22122316, learning_rate: 2.688e-05, global_step: 1405, interval_runtime: 0.8251, interval_samples_per_second: 48.476, interval_steps_per_second: 6.06, epoch: 2.0815\r\n",
      "loss: 0.21499946, learning_rate: 2.687e-05, global_step: 1410, interval_runtime: 0.9629, interval_samples_per_second: 41.542, interval_steps_per_second: 5.193, epoch: 2.0889\r\n",
      "loss: 0.24096801, learning_rate: 2.686e-05, global_step: 1415, interval_runtime: 0.8526, interval_samples_per_second: 46.914, interval_steps_per_second: 5.864, epoch: 2.0963\r\n",
      "loss: 0.21063886, learning_rate: 2.684e-05, global_step: 1420, interval_runtime: 0.862, interval_samples_per_second: 46.406, interval_steps_per_second: 5.801, epoch: 2.1037\r\n",
      "loss: 0.26962826, learning_rate: 2.683e-05, global_step: 1425, interval_runtime: 0.8136, interval_samples_per_second: 49.162, interval_steps_per_second: 6.145, epoch: 2.1111\r\n",
      "loss: 0.22214215, learning_rate: 2.682e-05, global_step: 1430, interval_runtime: 0.7765, interval_samples_per_second: 51.514, interval_steps_per_second: 6.439, epoch: 2.1185\r\n",
      "loss: 0.22467256, learning_rate: 2.681e-05, global_step: 1435, interval_runtime: 0.8447, interval_samples_per_second: 47.356, interval_steps_per_second: 5.919, epoch: 2.1259\r\n",
      "loss: 0.21774905, learning_rate: 2.68e-05, global_step: 1440, interval_runtime: 0.9332, interval_samples_per_second: 42.864, interval_steps_per_second: 5.358, epoch: 2.1333\r\n",
      "loss: 0.26710715, learning_rate: 2.679e-05, global_step: 1445, interval_runtime: 0.8797, interval_samples_per_second: 45.471, interval_steps_per_second: 5.684, epoch: 2.1407\r\n",
      "loss: 0.26241384, learning_rate: 2.678e-05, global_step: 1450, interval_runtime: 0.8306, interval_samples_per_second: 48.16, interval_steps_per_second: 6.02, epoch: 2.1481\r\n",
      "loss: 0.24862852, learning_rate: 2.677e-05, global_step: 1455, interval_runtime: 0.8355, interval_samples_per_second: 47.876, interval_steps_per_second: 5.984, epoch: 2.1556\r\n",
      "loss: 0.2495024, learning_rate: 2.676e-05, global_step: 1460, interval_runtime: 1.0234, interval_samples_per_second: 39.086, interval_steps_per_second: 4.886, epoch: 2.163\r\n",
      "loss: 0.22947409, learning_rate: 2.674e-05, global_step: 1465, interval_runtime: 0.942, interval_samples_per_second: 42.463, interval_steps_per_second: 5.308, epoch: 2.1704\r\n",
      "loss: 0.22096386, learning_rate: 2.673e-05, global_step: 1470, interval_runtime: 0.7662, interval_samples_per_second: 52.204, interval_steps_per_second: 6.525, epoch: 2.1778\r\n",
      "loss: 0.23170671, learning_rate: 2.672e-05, global_step: 1475, interval_runtime: 0.7847, interval_samples_per_second: 50.972, interval_steps_per_second: 6.371, epoch: 2.1852\r\n",
      "loss: 0.21022673, learning_rate: 2.671e-05, global_step: 1480, interval_runtime: 0.7471, interval_samples_per_second: 53.539, interval_steps_per_second: 6.692, epoch: 2.1926\r\n",
      "loss: 0.23042297, learning_rate: 2.67e-05, global_step: 1485, interval_runtime: 0.8017, interval_samples_per_second: 49.893, interval_steps_per_second: 6.237, epoch: 2.2\r\n",
      "loss: 0.20909452, learning_rate: 2.669e-05, global_step: 1490, interval_runtime: 0.9073, interval_samples_per_second: 44.085, interval_steps_per_second: 5.511, epoch: 2.2074\r\n",
      "loss: 0.2666543, learning_rate: 2.668e-05, global_step: 1495, interval_runtime: 0.8189, interval_samples_per_second: 48.849, interval_steps_per_second: 6.106, epoch: 2.2148\r\n",
      "loss: 0.2032974, learning_rate: 2.667e-05, global_step: 1500, interval_runtime: 0.8677, interval_samples_per_second: 46.1, interval_steps_per_second: 5.763, epoch: 2.2222\r\n",
      "loss: 0.23754711, learning_rate: 2.666e-05, global_step: 1505, interval_runtime: 0.792, interval_samples_per_second: 50.504, interval_steps_per_second: 6.313, epoch: 2.2296\r\n",
      "loss: 0.25583391, learning_rate: 2.664e-05, global_step: 1510, interval_runtime: 1.0207, interval_samples_per_second: 39.19, interval_steps_per_second: 4.899, epoch: 2.237\r\n",
      "loss: 0.25297801, learning_rate: 2.663e-05, global_step: 1515, interval_runtime: 0.7829, interval_samples_per_second: 51.095, interval_steps_per_second: 6.387, epoch: 2.2444\r\n",
      "loss: 0.26587517, learning_rate: 2.662e-05, global_step: 1520, interval_runtime: 0.8651, interval_samples_per_second: 46.24, interval_steps_per_second: 5.78, epoch: 2.2519\r\n",
      "loss: 0.28568177, learning_rate: 2.661e-05, global_step: 1525, interval_runtime: 0.8013, interval_samples_per_second: 49.918, interval_steps_per_second: 6.24, epoch: 2.2593\r\n",
      "loss: 0.28657355, learning_rate: 2.66e-05, global_step: 1530, interval_runtime: 0.8364, interval_samples_per_second: 47.825, interval_steps_per_second: 5.978, epoch: 2.2667\r\n",
      "loss: 0.2457624, learning_rate: 2.659e-05, global_step: 1535, interval_runtime: 0.6904, interval_samples_per_second: 57.938, interval_steps_per_second: 7.242, epoch: 2.2741\r\n",
      "loss: 0.23953676, learning_rate: 2.658e-05, global_step: 1540, interval_runtime: 0.9717, interval_samples_per_second: 41.165, interval_steps_per_second: 5.146, epoch: 2.2815\r\n",
      "loss: 0.24768188, learning_rate: 2.657e-05, global_step: 1545, interval_runtime: 0.926, interval_samples_per_second: 43.198, interval_steps_per_second: 5.4, epoch: 2.2889\r\n",
      "loss: 0.2439806, learning_rate: 2.656e-05, global_step: 1550, interval_runtime: 0.776, interval_samples_per_second: 51.549, interval_steps_per_second: 6.444, epoch: 2.2963\r\n",
      "loss: 0.23686531, learning_rate: 2.654e-05, global_step: 1555, interval_runtime: 0.7739, interval_samples_per_second: 51.686, interval_steps_per_second: 6.461, epoch: 2.3037\r\n",
      "loss: 0.23422859, learning_rate: 2.653e-05, global_step: 1560, interval_runtime: 0.8674, interval_samples_per_second: 46.117, interval_steps_per_second: 5.765, epoch: 2.3111\r\n",
      "loss: 0.24352906, learning_rate: 2.652e-05, global_step: 1565, interval_runtime: 0.8094, interval_samples_per_second: 49.422, interval_steps_per_second: 6.178, epoch: 2.3185\r\n",
      "loss: 0.2310925, learning_rate: 2.651e-05, global_step: 1570, interval_runtime: 0.8427, interval_samples_per_second: 47.464, interval_steps_per_second: 5.933, epoch: 2.3259\r\n",
      "loss: 0.22588174, learning_rate: 2.65e-05, global_step: 1575, interval_runtime: 0.8696, interval_samples_per_second: 45.997, interval_steps_per_second: 5.75, epoch: 2.3333\r\n",
      "loss: 0.21609821, learning_rate: 2.649e-05, global_step: 1580, interval_runtime: 0.8679, interval_samples_per_second: 46.091, interval_steps_per_second: 5.761, epoch: 2.3407\r\n",
      "loss: 0.25692196, learning_rate: 2.648e-05, global_step: 1585, interval_runtime: 0.8203, interval_samples_per_second: 48.763, interval_steps_per_second: 6.095, epoch: 2.3481\r\n",
      "loss: 0.22542264, learning_rate: 2.647e-05, global_step: 1590, interval_runtime: 0.856, interval_samples_per_second: 46.728, interval_steps_per_second: 5.841, epoch: 2.3556\r\n",
      "loss: 0.28128974, learning_rate: 2.646e-05, global_step: 1595, interval_runtime: 0.7754, interval_samples_per_second: 51.585, interval_steps_per_second: 6.448, epoch: 2.363\r\n",
      "loss: 0.25055704, learning_rate: 2.644e-05, global_step: 1600, interval_runtime: 0.9107, interval_samples_per_second: 43.922, interval_steps_per_second: 5.49, epoch: 2.3704\r\n",
      "loss: 0.24054117, learning_rate: 2.643e-05, global_step: 1605, interval_runtime: 0.9453, interval_samples_per_second: 42.314, interval_steps_per_second: 5.289, epoch: 2.3778\r\n",
      "loss: 0.22556605, learning_rate: 2.642e-05, global_step: 1610, interval_runtime: 0.6799, interval_samples_per_second: 58.832, interval_steps_per_second: 7.354, epoch: 2.3852\r\n",
      "loss: 0.20232697, learning_rate: 2.641e-05, global_step: 1615, interval_runtime: 0.7331, interval_samples_per_second: 54.564, interval_steps_per_second: 6.82, epoch: 2.3926\r\n",
      "loss: 0.24723344, learning_rate: 2.64e-05, global_step: 1620, interval_runtime: 0.7177, interval_samples_per_second: 55.735, interval_steps_per_second: 6.967, epoch: 2.4\r\n",
      "loss: 0.22200899, learning_rate: 2.639e-05, global_step: 1625, interval_runtime: 0.8766, interval_samples_per_second: 45.628, interval_steps_per_second: 5.704, epoch: 2.4074\r\n",
      "loss: 0.25004361, learning_rate: 2.638e-05, global_step: 1630, interval_runtime: 1.1414, interval_samples_per_second: 35.043, interval_steps_per_second: 4.38, epoch: 2.4148\r\n",
      "loss: 0.20726223, learning_rate: 2.637e-05, global_step: 1635, interval_runtime: 0.9031, interval_samples_per_second: 44.294, interval_steps_per_second: 5.537, epoch: 2.4222\r\n",
      "loss: 0.22353518, learning_rate: 2.636e-05, global_step: 1640, interval_runtime: 0.8716, interval_samples_per_second: 45.895, interval_steps_per_second: 5.737, epoch: 2.4296\r\n",
      "loss: 0.21357117, learning_rate: 2.634e-05, global_step: 1645, interval_runtime: 0.8728, interval_samples_per_second: 45.831, interval_steps_per_second: 5.729, epoch: 2.437\r\n",
      "loss: 0.22566779, learning_rate: 2.633e-05, global_step: 1650, interval_runtime: 0.8653, interval_samples_per_second: 46.224, interval_steps_per_second: 5.778, epoch: 2.4444\r\n",
      "loss: 0.22763922, learning_rate: 2.632e-05, global_step: 1655, interval_runtime: 0.8456, interval_samples_per_second: 47.305, interval_steps_per_second: 5.913, epoch: 2.4519\r\n",
      "loss: 0.23029535, learning_rate: 2.631e-05, global_step: 1660, interval_runtime: 0.8657, interval_samples_per_second: 46.208, interval_steps_per_second: 5.776, epoch: 2.4593\r\n",
      "loss: 0.21735187, learning_rate: 2.63e-05, global_step: 1665, interval_runtime: 0.7365, interval_samples_per_second: 54.312, interval_steps_per_second: 6.789, epoch: 2.4667\r\n",
      "loss: 0.21734591, learning_rate: 2.629e-05, global_step: 1670, interval_runtime: 0.8043, interval_samples_per_second: 49.735, interval_steps_per_second: 6.217, epoch: 2.4741\r\n",
      "loss: 0.26242487, learning_rate: 2.628e-05, global_step: 1675, interval_runtime: 0.8641, interval_samples_per_second: 46.29, interval_steps_per_second: 5.786, epoch: 2.4815\r\n",
      "loss: 0.24244275, learning_rate: 2.627e-05, global_step: 1680, interval_runtime: 0.9134, interval_samples_per_second: 43.792, interval_steps_per_second: 5.474, epoch: 2.4889\r\n",
      "loss: 0.28867276, learning_rate: 2.626e-05, global_step: 1685, interval_runtime: 1.0017, interval_samples_per_second: 39.932, interval_steps_per_second: 4.992, epoch: 2.4963\r\n",
      "loss: 0.23018484, learning_rate: 2.624e-05, global_step: 1690, interval_runtime: 0.8962, interval_samples_per_second: 44.631, interval_steps_per_second: 5.579, epoch: 2.5037\r\n",
      "loss: 0.21574554, learning_rate: 2.623e-05, global_step: 1695, interval_runtime: 0.7711, interval_samples_per_second: 51.872, interval_steps_per_second: 6.484, epoch: 2.5111\r\n",
      "loss: 0.25602326, learning_rate: 2.622e-05, global_step: 1700, interval_runtime: 0.9134, interval_samples_per_second: 43.791, interval_steps_per_second: 5.474, epoch: 2.5185\r\n",
      "loss: 0.26390886, learning_rate: 2.621e-05, global_step: 1705, interval_runtime: 0.8145, interval_samples_per_second: 49.109, interval_steps_per_second: 6.139, epoch: 2.5259\r\n",
      "loss: 0.23072348, learning_rate: 2.62e-05, global_step: 1710, interval_runtime: 0.8424, interval_samples_per_second: 47.484, interval_steps_per_second: 5.935, epoch: 2.5333\r\n",
      "loss: 0.25158525, learning_rate: 2.619e-05, global_step: 1715, interval_runtime: 0.9561, interval_samples_per_second: 41.836, interval_steps_per_second: 5.229, epoch: 2.5407\r\n",
      "loss: 0.25757375, learning_rate: 2.618e-05, global_step: 1720, interval_runtime: 0.8028, interval_samples_per_second: 49.824, interval_steps_per_second: 6.228, epoch: 2.5481\r\n",
      "loss: 0.23536158, learning_rate: 2.617e-05, global_step: 1725, interval_runtime: 0.8398, interval_samples_per_second: 47.63, interval_steps_per_second: 5.954, epoch: 2.5556\r\n",
      "loss: 0.23133333, learning_rate: 2.616e-05, global_step: 1730, interval_runtime: 0.9057, interval_samples_per_second: 44.167, interval_steps_per_second: 5.521, epoch: 2.563\r\n",
      "loss: 0.23170607, learning_rate: 2.614e-05, global_step: 1735, interval_runtime: 0.9372, interval_samples_per_second: 42.681, interval_steps_per_second: 5.335, epoch: 2.5704\r\n",
      "loss: 0.25578058, learning_rate: 2.613e-05, global_step: 1740, interval_runtime: 0.8697, interval_samples_per_second: 45.994, interval_steps_per_second: 5.749, epoch: 2.5778\r\n",
      "loss: 0.22206397, learning_rate: 2.612e-05, global_step: 1745, interval_runtime: 0.8232, interval_samples_per_second: 48.59, interval_steps_per_second: 6.074, epoch: 2.5852\r\n",
      "loss: 0.23316019, learning_rate: 2.611e-05, global_step: 1750, interval_runtime: 0.7824, interval_samples_per_second: 51.123, interval_steps_per_second: 6.39, epoch: 2.5926\r\n",
      "loss: 0.23931551, learning_rate: 2.61e-05, global_step: 1755, interval_runtime: 0.7514, interval_samples_per_second: 53.232, interval_steps_per_second: 6.654, epoch: 2.6\r\n",
      "loss: 0.26366904, learning_rate: 2.609e-05, global_step: 1760, interval_runtime: 0.8881, interval_samples_per_second: 45.041, interval_steps_per_second: 5.63, epoch: 2.6074\r\n",
      "loss: 0.24875572, learning_rate: 2.608e-05, global_step: 1765, interval_runtime: 0.8182, interval_samples_per_second: 48.885, interval_steps_per_second: 6.111, epoch: 2.6148\r\n",
      "loss: 0.27009306, learning_rate: 2.607e-05, global_step: 1770, interval_runtime: 1.0627, interval_samples_per_second: 37.642, interval_steps_per_second: 4.705, epoch: 2.6222\r\n",
      "loss: 0.24344101, learning_rate: 2.606e-05, global_step: 1775, interval_runtime: 0.9077, interval_samples_per_second: 44.068, interval_steps_per_second: 5.509, epoch: 2.6296\r\n",
      "loss: 0.26779013, learning_rate: 2.604e-05, global_step: 1780, interval_runtime: 0.9843, interval_samples_per_second: 40.639, interval_steps_per_second: 5.08, epoch: 2.637\r\n",
      "loss: 0.25424681, learning_rate: 2.603e-05, global_step: 1785, interval_runtime: 0.8926, interval_samples_per_second: 44.81, interval_steps_per_second: 5.601, epoch: 2.6444\r\n",
      "loss: 0.26768675, learning_rate: 2.602e-05, global_step: 1790, interval_runtime: 0.8055, interval_samples_per_second: 49.661, interval_steps_per_second: 6.208, epoch: 2.6519\r\n",
      "loss: 0.25334294, learning_rate: 2.601e-05, global_step: 1795, interval_runtime: 0.9078, interval_samples_per_second: 44.065, interval_steps_per_second: 5.508, epoch: 2.6593\r\n",
      "loss: 0.2493356, learning_rate: 2.6e-05, global_step: 1800, interval_runtime: 0.9517, interval_samples_per_second: 42.031, interval_steps_per_second: 5.254, epoch: 2.6667\r\n",
      "loss: 0.24100299, learning_rate: 2.599e-05, global_step: 1805, interval_runtime: 0.9367, interval_samples_per_second: 42.704, interval_steps_per_second: 5.338, epoch: 2.6741\r\n",
      "loss: 0.21306112, learning_rate: 2.598e-05, global_step: 1810, interval_runtime: 0.7649, interval_samples_per_second: 52.293, interval_steps_per_second: 6.537, epoch: 2.6815\r\n",
      "loss: 0.24367151, learning_rate: 2.597e-05, global_step: 1815, interval_runtime: 0.7417, interval_samples_per_second: 53.933, interval_steps_per_second: 6.742, epoch: 2.6889\r\n",
      "loss: 0.202806, learning_rate: 2.596e-05, global_step: 1820, interval_runtime: 0.8045, interval_samples_per_second: 49.72, interval_steps_per_second: 6.215, epoch: 2.6963\r\n",
      "loss: 0.24549389, learning_rate: 2.594e-05, global_step: 1825, interval_runtime: 0.7651, interval_samples_per_second: 52.28, interval_steps_per_second: 6.535, epoch: 2.7037\r\n",
      "loss: 0.30376098, learning_rate: 2.593e-05, global_step: 1830, interval_runtime: 0.7337, interval_samples_per_second: 54.518, interval_steps_per_second: 6.815, epoch: 2.7111\r\n",
      "loss: 0.23556674, learning_rate: 2.592e-05, global_step: 1835, interval_runtime: 0.849, interval_samples_per_second: 47.114, interval_steps_per_second: 5.889, epoch: 2.7185\r\n",
      "loss: 0.20746291, learning_rate: 2.591e-05, global_step: 1840, interval_runtime: 0.7383, interval_samples_per_second: 54.175, interval_steps_per_second: 6.772, epoch: 2.7259\r\n",
      "loss: 0.27837148, learning_rate: 2.59e-05, global_step: 1845, interval_runtime: 0.9697, interval_samples_per_second: 41.251, interval_steps_per_second: 5.156, epoch: 2.7333\r\n",
      "loss: 0.23661268, learning_rate: 2.589e-05, global_step: 1850, interval_runtime: 0.8161, interval_samples_per_second: 49.014, interval_steps_per_second: 6.127, epoch: 2.7407\r\n",
      "loss: 0.19511993, learning_rate: 2.588e-05, global_step: 1855, interval_runtime: 0.7711, interval_samples_per_second: 51.874, interval_steps_per_second: 6.484, epoch: 2.7481\r\n",
      "loss: 0.26218448, learning_rate: 2.587e-05, global_step: 1860, interval_runtime: 0.711, interval_samples_per_second: 56.261, interval_steps_per_second: 7.033, epoch: 2.7556\r\n",
      "loss: 0.24673193, learning_rate: 2.586e-05, global_step: 1865, interval_runtime: 0.78, interval_samples_per_second: 51.281, interval_steps_per_second: 6.41, epoch: 2.763\r\n",
      "loss: 0.25159557, learning_rate: 2.584e-05, global_step: 1870, interval_runtime: 0.8894, interval_samples_per_second: 44.972, interval_steps_per_second: 5.621, epoch: 2.7704\r\n",
      "loss: 0.22347682, learning_rate: 2.583e-05, global_step: 1875, interval_runtime: 0.8727, interval_samples_per_second: 45.833, interval_steps_per_second: 5.729, epoch: 2.7778\r\n",
      "loss: 0.26255455, learning_rate: 2.582e-05, global_step: 1880, interval_runtime: 0.7426, interval_samples_per_second: 53.867, interval_steps_per_second: 6.733, epoch: 2.7852\r\n",
      "loss: 0.23020692, learning_rate: 2.581e-05, global_step: 1885, interval_runtime: 0.7107, interval_samples_per_second: 56.286, interval_steps_per_second: 7.036, epoch: 2.7926\r\n",
      "loss: 0.25303702, learning_rate: 2.58e-05, global_step: 1890, interval_runtime: 0.8986, interval_samples_per_second: 44.512, interval_steps_per_second: 5.564, epoch: 2.8\r\n",
      "loss: 0.25541975, learning_rate: 2.579e-05, global_step: 1895, interval_runtime: 0.7735, interval_samples_per_second: 51.711, interval_steps_per_second: 6.464, epoch: 2.8074\r\n",
      "loss: 0.19188509, learning_rate: 2.578e-05, global_step: 1900, interval_runtime: 0.7387, interval_samples_per_second: 54.148, interval_steps_per_second: 6.769, epoch: 2.8148\r\n",
      "loss: 0.23933423, learning_rate: 2.577e-05, global_step: 1905, interval_runtime: 0.7588, interval_samples_per_second: 52.715, interval_steps_per_second: 6.589, epoch: 2.8222\r\n",
      "loss: 0.25084124, learning_rate: 2.576e-05, global_step: 1910, interval_runtime: 0.8072, interval_samples_per_second: 49.553, interval_steps_per_second: 6.194, epoch: 2.8296\r\n",
      "loss: 0.26106017, learning_rate: 2.574e-05, global_step: 1915, interval_runtime: 0.9231, interval_samples_per_second: 43.331, interval_steps_per_second: 5.416, epoch: 2.837\r\n",
      "loss: 0.27656903, learning_rate: 2.573e-05, global_step: 1920, interval_runtime: 0.8657, interval_samples_per_second: 46.204, interval_steps_per_second: 5.776, epoch: 2.8444\r\n",
      "loss: 0.22348003, learning_rate: 2.572e-05, global_step: 1925, interval_runtime: 0.861, interval_samples_per_second: 46.456, interval_steps_per_second: 5.807, epoch: 2.8519\r\n",
      "loss: 0.2481535, learning_rate: 2.571e-05, global_step: 1930, interval_runtime: 0.9083, interval_samples_per_second: 44.04, interval_steps_per_second: 5.505, epoch: 2.8593\r\n",
      "loss: 0.27178621, learning_rate: 2.57e-05, global_step: 1935, interval_runtime: 0.8687, interval_samples_per_second: 46.048, interval_steps_per_second: 5.756, epoch: 2.8667\r\n",
      "loss: 0.24680591, learning_rate: 2.569e-05, global_step: 1940, interval_runtime: 0.8636, interval_samples_per_second: 46.319, interval_steps_per_second: 5.79, epoch: 2.8741\r\n",
      "loss: 0.26386538, learning_rate: 2.568e-05, global_step: 1945, interval_runtime: 0.9644, interval_samples_per_second: 41.475, interval_steps_per_second: 5.184, epoch: 2.8815\r\n",
      "loss: 0.22025576, learning_rate: 2.567e-05, global_step: 1950, interval_runtime: 0.7843, interval_samples_per_second: 51.002, interval_steps_per_second: 6.375, epoch: 2.8889\r\n",
      "loss: 0.22496481, learning_rate: 2.566e-05, global_step: 1955, interval_runtime: 0.7721, interval_samples_per_second: 51.808, interval_steps_per_second: 6.476, epoch: 2.8963\r\n",
      "loss: 0.23630588, learning_rate: 2.564e-05, global_step: 1960, interval_runtime: 0.925, interval_samples_per_second: 43.242, interval_steps_per_second: 5.405, epoch: 2.9037\r\n",
      "loss: 0.22506485, learning_rate: 2.563e-05, global_step: 1965, interval_runtime: 0.8104, interval_samples_per_second: 49.361, interval_steps_per_second: 6.17, epoch: 2.9111\r\n",
      "loss: 0.25995219, learning_rate: 2.562e-05, global_step: 1970, interval_runtime: 0.786, interval_samples_per_second: 50.893, interval_steps_per_second: 6.362, epoch: 2.9185\r\n",
      "loss: 0.21863563, learning_rate: 2.561e-05, global_step: 1975, interval_runtime: 0.8816, interval_samples_per_second: 45.371, interval_steps_per_second: 5.671, epoch: 2.9259\r\n",
      "loss: 0.32803831, learning_rate: 2.56e-05, global_step: 1980, interval_runtime: 0.8403, interval_samples_per_second: 47.602, interval_steps_per_second: 5.95, epoch: 2.9333\r\n",
      "loss: 0.24357388, learning_rate: 2.559e-05, global_step: 1985, interval_runtime: 0.887, interval_samples_per_second: 45.094, interval_steps_per_second: 5.637, epoch: 2.9407\r\n",
      "loss: 0.25118804, learning_rate: 2.558e-05, global_step: 1990, interval_runtime: 0.9762, interval_samples_per_second: 40.976, interval_steps_per_second: 5.122, epoch: 2.9481\r\n",
      "loss: 0.2728334, learning_rate: 2.557e-05, global_step: 1995, interval_runtime: 0.8311, interval_samples_per_second: 48.13, interval_steps_per_second: 6.016, epoch: 2.9556\r\n",
      "loss: 0.2541307, learning_rate: 2.556e-05, global_step: 2000, interval_runtime: 0.8359, interval_samples_per_second: 47.851, interval_steps_per_second: 5.981, epoch: 2.963\r\n",
      "loss: 0.25875263, learning_rate: 2.554e-05, global_step: 2005, interval_runtime: 1.0264, interval_samples_per_second: 38.972, interval_steps_per_second: 4.872, epoch: 2.9704\r\n",
      "loss: 0.25191505, learning_rate: 2.553e-05, global_step: 2010, interval_runtime: 0.7795, interval_samples_per_second: 51.312, interval_steps_per_second: 6.414, epoch: 2.9778\r\n",
      "loss: 0.20254705, learning_rate: 2.552e-05, global_step: 2015, interval_runtime: 0.776, interval_samples_per_second: 51.546, interval_steps_per_second: 6.443, epoch: 2.9852\r\n",
      "loss: 0.2375185, learning_rate: 2.551e-05, global_step: 2020, interval_runtime: 0.7448, interval_samples_per_second: 53.707, interval_steps_per_second: 6.713, epoch: 2.9926\r\n",
      "loss: 0.29188535, learning_rate: 2.55e-05, global_step: 2025, interval_runtime: 0.6483, interval_samples_per_second: 61.702, interval_steps_per_second: 7.713, epoch: 3.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:44:55,663] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:44:55,667] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:44:55,670] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:44:55,673] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:44:55,676] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.3333713710308075, eval_micro_f1_score: 0.5463423622627602, eval_macro_f1_score: 0.41665955970107804, eval_runtime: 13.3859, eval_samples_per_second: 141.641, eval_steps_per_second: 17.705, epoch: 3.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:45:09,055] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-2025\r\n",
      "[2023-01-10 10:45:09,058] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:45:12,290] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-2025/tokenizer_config.json\r\n",
      "[2023-01-10 10:45:12,293] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-2025/special_tokens_map.json\r\n",
      "[2023-01-10 10:45:18,818] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-675] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.19616252, learning_rate: 2.549e-05, global_step: 2030, interval_runtime: 24.7463, interval_samples_per_second: 1.616, interval_steps_per_second: 0.202, epoch: 3.0074\r\n",
      "loss: 0.18160574, learning_rate: 2.548e-05, global_step: 2035, interval_runtime: 0.8083, interval_samples_per_second: 49.484, interval_steps_per_second: 6.186, epoch: 3.0148\r\n",
      "loss: 0.17199868, learning_rate: 2.547e-05, global_step: 2040, interval_runtime: 0.9484, interval_samples_per_second: 42.178, interval_steps_per_second: 5.272, epoch: 3.0222\r\n",
      "loss: 0.17732526, learning_rate: 2.546e-05, global_step: 2045, interval_runtime: 0.9113, interval_samples_per_second: 43.895, interval_steps_per_second: 5.487, epoch: 3.0296\r\n",
      "loss: 0.15982647, learning_rate: 2.544e-05, global_step: 2050, interval_runtime: 0.8097, interval_samples_per_second: 49.402, interval_steps_per_second: 6.175, epoch: 3.037\r\n",
      "loss: 0.20033178, learning_rate: 2.543e-05, global_step: 2055, interval_runtime: 0.823, interval_samples_per_second: 48.6, interval_steps_per_second: 6.075, epoch: 3.0444\r\n",
      "loss: 0.22154975, learning_rate: 2.542e-05, global_step: 2060, interval_runtime: 0.7258, interval_samples_per_second: 55.11, interval_steps_per_second: 6.889, epoch: 3.0519\r\n",
      "loss: 0.20967019, learning_rate: 2.541e-05, global_step: 2065, interval_runtime: 0.7675, interval_samples_per_second: 52.117, interval_steps_per_second: 6.515, epoch: 3.0593\r\n",
      "loss: 0.1827379, learning_rate: 2.54e-05, global_step: 2070, interval_runtime: 0.85, interval_samples_per_second: 47.056, interval_steps_per_second: 5.882, epoch: 3.0667\r\n",
      "loss: 0.21452086, learning_rate: 2.539e-05, global_step: 2075, interval_runtime: 0.805, interval_samples_per_second: 49.689, interval_steps_per_second: 6.211, epoch: 3.0741\r\n",
      "loss: 0.15085011, learning_rate: 2.538e-05, global_step: 2080, interval_runtime: 0.9021, interval_samples_per_second: 44.339, interval_steps_per_second: 5.542, epoch: 3.0815\r\n",
      "loss: 0.18560896, learning_rate: 2.537e-05, global_step: 2085, interval_runtime: 0.7377, interval_samples_per_second: 54.224, interval_steps_per_second: 6.778, epoch: 3.0889\r\n",
      "loss: 0.18111155, learning_rate: 2.536e-05, global_step: 2090, interval_runtime: 0.7655, interval_samples_per_second: 52.252, interval_steps_per_second: 6.532, epoch: 3.0963\r\n",
      "loss: 0.1712394, learning_rate: 2.534e-05, global_step: 2095, interval_runtime: 0.7895, interval_samples_per_second: 50.663, interval_steps_per_second: 6.333, epoch: 3.1037\r\n",
      "loss: 0.17088172, learning_rate: 2.533e-05, global_step: 2100, interval_runtime: 0.8875, interval_samples_per_second: 45.07, interval_steps_per_second: 5.634, epoch: 3.1111\r\n",
      "loss: 0.15474528, learning_rate: 2.532e-05, global_step: 2105, interval_runtime: 0.7921, interval_samples_per_second: 50.497, interval_steps_per_second: 6.312, epoch: 3.1185\r\n",
      "loss: 0.19380145, learning_rate: 2.531e-05, global_step: 2110, interval_runtime: 0.8056, interval_samples_per_second: 49.655, interval_steps_per_second: 6.207, epoch: 3.1259\r\n",
      "loss: 0.17277738, learning_rate: 2.53e-05, global_step: 2115, interval_runtime: 0.9638, interval_samples_per_second: 41.502, interval_steps_per_second: 5.188, epoch: 3.1333\r\n",
      "loss: 0.18423045, learning_rate: 2.529e-05, global_step: 2120, interval_runtime: 0.7539, interval_samples_per_second: 53.057, interval_steps_per_second: 6.632, epoch: 3.1407\r\n",
      "loss: 0.16703956, learning_rate: 2.528e-05, global_step: 2125, interval_runtime: 0.8332, interval_samples_per_second: 48.009, interval_steps_per_second: 6.001, epoch: 3.1481\r\n",
      "loss: 0.20668309, learning_rate: 2.527e-05, global_step: 2130, interval_runtime: 0.8599, interval_samples_per_second: 46.516, interval_steps_per_second: 5.815, epoch: 3.1556\r\n",
      "loss: 0.20535135, learning_rate: 2.526e-05, global_step: 2135, interval_runtime: 0.7155, interval_samples_per_second: 55.907, interval_steps_per_second: 6.988, epoch: 3.163\r\n",
      "loss: 0.20574584, learning_rate: 2.524e-05, global_step: 2140, interval_runtime: 0.7994, interval_samples_per_second: 50.037, interval_steps_per_second: 6.255, epoch: 3.1704\r\n",
      "loss: 0.19873579, learning_rate: 2.523e-05, global_step: 2145, interval_runtime: 0.9713, interval_samples_per_second: 41.18, interval_steps_per_second: 5.148, epoch: 3.1778\r\n",
      "loss: 0.20934868, learning_rate: 2.522e-05, global_step: 2150, interval_runtime: 0.8957, interval_samples_per_second: 44.658, interval_steps_per_second: 5.582, epoch: 3.1852\r\n",
      "loss: 0.17404833, learning_rate: 2.521e-05, global_step: 2155, interval_runtime: 0.866, interval_samples_per_second: 46.19, interval_steps_per_second: 5.774, epoch: 3.1926\r\n",
      "loss: 0.14853925, learning_rate: 2.52e-05, global_step: 2160, interval_runtime: 0.9555, interval_samples_per_second: 41.861, interval_steps_per_second: 5.233, epoch: 3.2\r\n",
      "loss: 0.16023394, learning_rate: 2.519e-05, global_step: 2165, interval_runtime: 0.7441, interval_samples_per_second: 53.754, interval_steps_per_second: 6.719, epoch: 3.2074\r\n",
      "loss: 0.19560978, learning_rate: 2.518e-05, global_step: 2170, interval_runtime: 0.8108, interval_samples_per_second: 49.333, interval_steps_per_second: 6.167, epoch: 3.2148\r\n",
      "loss: 0.17688048, learning_rate: 2.517e-05, global_step: 2175, interval_runtime: 0.8097, interval_samples_per_second: 49.399, interval_steps_per_second: 6.175, epoch: 3.2222\r\n",
      "loss: 0.20118914, learning_rate: 2.516e-05, global_step: 2180, interval_runtime: 0.7875, interval_samples_per_second: 50.794, interval_steps_per_second: 6.349, epoch: 3.2296\r\n",
      "loss: 0.19562652, learning_rate: 2.514e-05, global_step: 2185, interval_runtime: 0.9675, interval_samples_per_second: 41.343, interval_steps_per_second: 5.168, epoch: 3.237\r\n",
      "loss: 0.16286376, learning_rate: 2.513e-05, global_step: 2190, interval_runtime: 0.7621, interval_samples_per_second: 52.489, interval_steps_per_second: 6.561, epoch: 3.2444\r\n",
      "loss: 0.20996571, learning_rate: 2.512e-05, global_step: 2195, interval_runtime: 0.7816, interval_samples_per_second: 51.179, interval_steps_per_second: 6.397, epoch: 3.2519\r\n",
      "loss: 0.21508267, learning_rate: 2.511e-05, global_step: 2200, interval_runtime: 0.7558, interval_samples_per_second: 52.926, interval_steps_per_second: 6.616, epoch: 3.2593\r\n",
      "loss: 0.1698686, learning_rate: 2.51e-05, global_step: 2205, interval_runtime: 0.7653, interval_samples_per_second: 52.27, interval_steps_per_second: 6.534, epoch: 3.2667\r\n",
      "loss: 0.18785224, learning_rate: 2.509e-05, global_step: 2210, interval_runtime: 0.7482, interval_samples_per_second: 53.461, interval_steps_per_second: 6.683, epoch: 3.2741\r\n",
      "loss: 0.18433533, learning_rate: 2.508e-05, global_step: 2215, interval_runtime: 0.9942, interval_samples_per_second: 40.232, interval_steps_per_second: 5.029, epoch: 3.2815\r\n",
      "loss: 0.19137638, learning_rate: 2.507e-05, global_step: 2220, interval_runtime: 0.8588, interval_samples_per_second: 46.575, interval_steps_per_second: 5.822, epoch: 3.2889\r\n",
      "loss: 0.18132787, learning_rate: 2.506e-05, global_step: 2225, interval_runtime: 0.8184, interval_samples_per_second: 48.876, interval_steps_per_second: 6.109, epoch: 3.2963\r\n",
      "loss: 0.21294756, learning_rate: 2.504e-05, global_step: 2230, interval_runtime: 0.8613, interval_samples_per_second: 46.442, interval_steps_per_second: 5.805, epoch: 3.3037\r\n",
      "loss: 0.16970755, learning_rate: 2.503e-05, global_step: 2235, interval_runtime: 0.84, interval_samples_per_second: 47.617, interval_steps_per_second: 5.952, epoch: 3.3111\r\n",
      "loss: 0.17060307, learning_rate: 2.502e-05, global_step: 2240, interval_runtime: 0.7897, interval_samples_per_second: 50.654, interval_steps_per_second: 6.332, epoch: 3.3185\r\n",
      "loss: 0.1930253, learning_rate: 2.501e-05, global_step: 2245, interval_runtime: 0.8122, interval_samples_per_second: 49.25, interval_steps_per_second: 6.156, epoch: 3.3259\r\n",
      "loss: 0.17486932, learning_rate: 2.5e-05, global_step: 2250, interval_runtime: 0.9166, interval_samples_per_second: 43.638, interval_steps_per_second: 5.455, epoch: 3.3333\r\n",
      "loss: 0.24550688, learning_rate: 2.499e-05, global_step: 2255, interval_runtime: 0.9489, interval_samples_per_second: 42.155, interval_steps_per_second: 5.269, epoch: 3.3407\r\n",
      "loss: 0.17447678, learning_rate: 2.498e-05, global_step: 2260, interval_runtime: 1.0552, interval_samples_per_second: 37.908, interval_steps_per_second: 4.738, epoch: 3.3481\r\n",
      "loss: 0.21616688, learning_rate: 2.497e-05, global_step: 2265, interval_runtime: 0.8693, interval_samples_per_second: 46.012, interval_steps_per_second: 5.751, epoch: 3.3556\r\n",
      "loss: 0.23251662, learning_rate: 2.496e-05, global_step: 2270, interval_runtime: 0.8365, interval_samples_per_second: 47.819, interval_steps_per_second: 5.977, epoch: 3.363\r\n",
      "loss: 0.19669112, learning_rate: 2.494e-05, global_step: 2275, interval_runtime: 0.8187, interval_samples_per_second: 48.856, interval_steps_per_second: 6.107, epoch: 3.3704\r\n",
      "loss: 0.19743541, learning_rate: 2.493e-05, global_step: 2280, interval_runtime: 1.1486, interval_samples_per_second: 34.824, interval_steps_per_second: 4.353, epoch: 3.3778\r\n",
      "loss: 0.20521088, learning_rate: 2.492e-05, global_step: 2285, interval_runtime: 0.812, interval_samples_per_second: 49.261, interval_steps_per_second: 6.158, epoch: 3.3852\r\n",
      "loss: 0.2027545, learning_rate: 2.491e-05, global_step: 2290, interval_runtime: 1.0366, interval_samples_per_second: 38.587, interval_steps_per_second: 4.823, epoch: 3.3926\r\n",
      "loss: 0.17557081, learning_rate: 2.49e-05, global_step: 2295, interval_runtime: 0.8352, interval_samples_per_second: 47.895, interval_steps_per_second: 5.987, epoch: 3.4\r\n",
      "loss: 0.22238834, learning_rate: 2.489e-05, global_step: 2300, interval_runtime: 0.9008, interval_samples_per_second: 44.407, interval_steps_per_second: 5.551, epoch: 3.4074\r\n",
      "loss: 0.1938077, learning_rate: 2.488e-05, global_step: 2305, interval_runtime: 0.8443, interval_samples_per_second: 47.377, interval_steps_per_second: 5.922, epoch: 3.4148\r\n",
      "loss: 0.1965642, learning_rate: 2.487e-05, global_step: 2310, interval_runtime: 0.7442, interval_samples_per_second: 53.75, interval_steps_per_second: 6.719, epoch: 3.4222\r\n",
      "loss: 0.22891123, learning_rate: 2.486e-05, global_step: 2315, interval_runtime: 0.9039, interval_samples_per_second: 44.251, interval_steps_per_second: 5.531, epoch: 3.4296\r\n",
      "loss: 0.18130025, learning_rate: 2.484e-05, global_step: 2320, interval_runtime: 0.8857, interval_samples_per_second: 45.161, interval_steps_per_second: 5.645, epoch: 3.437\r\n",
      "loss: 0.18469777, learning_rate: 2.483e-05, global_step: 2325, interval_runtime: 0.9362, interval_samples_per_second: 42.726, interval_steps_per_second: 5.341, epoch: 3.4444\r\n",
      "loss: 0.18977543, learning_rate: 2.482e-05, global_step: 2330, interval_runtime: 0.7766, interval_samples_per_second: 51.506, interval_steps_per_second: 6.438, epoch: 3.4519\r\n",
      "loss: 0.20116806, learning_rate: 2.481e-05, global_step: 2335, interval_runtime: 0.7836, interval_samples_per_second: 51.048, interval_steps_per_second: 6.381, epoch: 3.4593\r\n",
      "loss: 0.18138216, learning_rate: 2.48e-05, global_step: 2340, interval_runtime: 1.0788, interval_samples_per_second: 37.077, interval_steps_per_second: 4.635, epoch: 3.4667\r\n",
      "loss: 0.19861375, learning_rate: 2.479e-05, global_step: 2345, interval_runtime: 0.8466, interval_samples_per_second: 47.249, interval_steps_per_second: 5.906, epoch: 3.4741\r\n",
      "loss: 0.17270695, learning_rate: 2.478e-05, global_step: 2350, interval_runtime: 0.7738, interval_samples_per_second: 51.692, interval_steps_per_second: 6.461, epoch: 3.4815\r\n",
      "loss: 0.19015049, learning_rate: 2.477e-05, global_step: 2355, interval_runtime: 0.9112, interval_samples_per_second: 43.9, interval_steps_per_second: 5.488, epoch: 3.4889\r\n",
      "loss: 0.20286193, learning_rate: 2.476e-05, global_step: 2360, interval_runtime: 0.8643, interval_samples_per_second: 46.281, interval_steps_per_second: 5.785, epoch: 3.4963\r\n",
      "loss: 0.2034091, learning_rate: 2.474e-05, global_step: 2365, interval_runtime: 0.7562, interval_samples_per_second: 52.897, interval_steps_per_second: 6.612, epoch: 3.5037\r\n",
      "loss: 0.19575534, learning_rate: 2.473e-05, global_step: 2370, interval_runtime: 0.7787, interval_samples_per_second: 51.366, interval_steps_per_second: 6.421, epoch: 3.5111\r\n",
      "loss: 0.16818739, learning_rate: 2.472e-05, global_step: 2375, interval_runtime: 0.8862, interval_samples_per_second: 45.134, interval_steps_per_second: 5.642, epoch: 3.5185\r\n",
      "loss: 0.19638191, learning_rate: 2.471e-05, global_step: 2380, interval_runtime: 0.7874, interval_samples_per_second: 50.799, interval_steps_per_second: 6.35, epoch: 3.5259\r\n",
      "loss: 0.15856203, learning_rate: 2.47e-05, global_step: 2385, interval_runtime: 0.8292, interval_samples_per_second: 48.24, interval_steps_per_second: 6.03, epoch: 3.5333\r\n",
      "loss: 0.17662636, learning_rate: 2.469e-05, global_step: 2390, interval_runtime: 0.738, interval_samples_per_second: 54.203, interval_steps_per_second: 6.775, epoch: 3.5407\r\n",
      "loss: 0.19889292, learning_rate: 2.468e-05, global_step: 2395, interval_runtime: 0.9762, interval_samples_per_second: 40.977, interval_steps_per_second: 5.122, epoch: 3.5481\r\n",
      "loss: 0.15420763, learning_rate: 2.467e-05, global_step: 2400, interval_runtime: 0.7736, interval_samples_per_second: 51.707, interval_steps_per_second: 6.463, epoch: 3.5556\r\n",
      "loss: 0.1837322, learning_rate: 2.466e-05, global_step: 2405, interval_runtime: 0.708, interval_samples_per_second: 56.496, interval_steps_per_second: 7.062, epoch: 3.563\r\n",
      "loss: 0.20772631, learning_rate: 2.464e-05, global_step: 2410, interval_runtime: 0.8823, interval_samples_per_second: 45.335, interval_steps_per_second: 5.667, epoch: 3.5704\r\n",
      "loss: 0.18281054, learning_rate: 2.463e-05, global_step: 2415, interval_runtime: 0.9412, interval_samples_per_second: 42.497, interval_steps_per_second: 5.312, epoch: 3.5778\r\n",
      "loss: 0.21455371, learning_rate: 2.462e-05, global_step: 2420, interval_runtime: 0.7775, interval_samples_per_second: 51.445, interval_steps_per_second: 6.431, epoch: 3.5852\r\n",
      "loss: 0.20511754, learning_rate: 2.461e-05, global_step: 2425, interval_runtime: 0.7342, interval_samples_per_second: 54.484, interval_steps_per_second: 6.81, epoch: 3.5926\r\n",
      "loss: 0.20939255, learning_rate: 2.46e-05, global_step: 2430, interval_runtime: 0.8615, interval_samples_per_second: 46.43, interval_steps_per_second: 5.804, epoch: 3.6\r\n",
      "loss: 0.17427702, learning_rate: 2.459e-05, global_step: 2435, interval_runtime: 0.923, interval_samples_per_second: 43.336, interval_steps_per_second: 5.417, epoch: 3.6074\r\n",
      "loss: 0.18364522, learning_rate: 2.458e-05, global_step: 2440, interval_runtime: 0.85, interval_samples_per_second: 47.061, interval_steps_per_second: 5.883, epoch: 3.6148\r\n",
      "loss: 0.187589, learning_rate: 2.457e-05, global_step: 2445, interval_runtime: 0.742, interval_samples_per_second: 53.908, interval_steps_per_second: 6.739, epoch: 3.6222\r\n",
      "loss: 0.21665406, learning_rate: 2.456e-05, global_step: 2450, interval_runtime: 0.8681, interval_samples_per_second: 46.076, interval_steps_per_second: 5.76, epoch: 3.6296\r\n",
      "loss: 0.19420935, learning_rate: 2.454e-05, global_step: 2455, interval_runtime: 0.8659, interval_samples_per_second: 46.194, interval_steps_per_second: 5.774, epoch: 3.637\r\n",
      "loss: 0.2060267, learning_rate: 2.453e-05, global_step: 2460, interval_runtime: 0.942, interval_samples_per_second: 42.465, interval_steps_per_second: 5.308, epoch: 3.6444\r\n",
      "loss: 0.19333713, learning_rate: 2.452e-05, global_step: 2465, interval_runtime: 0.8272, interval_samples_per_second: 48.357, interval_steps_per_second: 6.045, epoch: 3.6519\r\n",
      "loss: 0.17059734, learning_rate: 2.451e-05, global_step: 2470, interval_runtime: 0.9646, interval_samples_per_second: 41.468, interval_steps_per_second: 5.183, epoch: 3.6593\r\n",
      "loss: 0.23110187, learning_rate: 2.45e-05, global_step: 2475, interval_runtime: 0.7607, interval_samples_per_second: 52.584, interval_steps_per_second: 6.573, epoch: 3.6667\r\n",
      "loss: 0.20735004, learning_rate: 2.449e-05, global_step: 2480, interval_runtime: 0.8592, interval_samples_per_second: 46.557, interval_steps_per_second: 5.82, epoch: 3.6741\r\n",
      "loss: 0.20750418, learning_rate: 2.448e-05, global_step: 2485, interval_runtime: 0.925, interval_samples_per_second: 43.245, interval_steps_per_second: 5.406, epoch: 3.6815\r\n",
      "loss: 0.19326496, learning_rate: 2.447e-05, global_step: 2490, interval_runtime: 0.9001, interval_samples_per_second: 44.44, interval_steps_per_second: 5.555, epoch: 3.6889\r\n",
      "loss: 0.19879334, learning_rate: 2.446e-05, global_step: 2495, interval_runtime: 0.8837, interval_samples_per_second: 45.264, interval_steps_per_second: 5.658, epoch: 3.6963\r\n",
      "loss: 0.19931741, learning_rate: 2.444e-05, global_step: 2500, interval_runtime: 0.8557, interval_samples_per_second: 46.745, interval_steps_per_second: 5.843, epoch: 3.7037\r\n",
      "loss: 0.20890422, learning_rate: 2.443e-05, global_step: 2505, interval_runtime: 0.7837, interval_samples_per_second: 51.038, interval_steps_per_second: 6.38, epoch: 3.7111\r\n",
      "loss: 0.18385236, learning_rate: 2.442e-05, global_step: 2510, interval_runtime: 0.8174, interval_samples_per_second: 48.935, interval_steps_per_second: 6.117, epoch: 3.7185\r\n",
      "loss: 0.21169658, learning_rate: 2.441e-05, global_step: 2515, interval_runtime: 0.7955, interval_samples_per_second: 50.28, interval_steps_per_second: 6.285, epoch: 3.7259\r\n",
      "loss: 0.16347481, learning_rate: 2.44e-05, global_step: 2520, interval_runtime: 0.8721, interval_samples_per_second: 45.867, interval_steps_per_second: 5.733, epoch: 3.7333\r\n",
      "loss: 0.17743456, learning_rate: 2.439e-05, global_step: 2525, interval_runtime: 0.7761, interval_samples_per_second: 51.541, interval_steps_per_second: 6.443, epoch: 3.7407\r\n",
      "loss: 0.21320188, learning_rate: 2.438e-05, global_step: 2530, interval_runtime: 0.9744, interval_samples_per_second: 41.051, interval_steps_per_second: 5.131, epoch: 3.7481\r\n",
      "loss: 0.21901963, learning_rate: 2.437e-05, global_step: 2535, interval_runtime: 0.8818, interval_samples_per_second: 45.363, interval_steps_per_second: 5.67, epoch: 3.7556\r\n",
      "loss: 0.18994067, learning_rate: 2.436e-05, global_step: 2540, interval_runtime: 0.7525, interval_samples_per_second: 53.154, interval_steps_per_second: 6.644, epoch: 3.763\r\n",
      "loss: 0.18167348, learning_rate: 2.434e-05, global_step: 2545, interval_runtime: 0.8555, interval_samples_per_second: 46.758, interval_steps_per_second: 5.845, epoch: 3.7704\r\n",
      "loss: 0.18323104, learning_rate: 2.433e-05, global_step: 2550, interval_runtime: 0.8868, interval_samples_per_second: 45.106, interval_steps_per_second: 5.638, epoch: 3.7778\r\n",
      "loss: 0.18556662, learning_rate: 2.432e-05, global_step: 2555, interval_runtime: 0.7104, interval_samples_per_second: 56.304, interval_steps_per_second: 7.038, epoch: 3.7852\r\n",
      "loss: 0.19796761, learning_rate: 2.431e-05, global_step: 2560, interval_runtime: 0.8387, interval_samples_per_second: 47.692, interval_steps_per_second: 5.961, epoch: 3.7926\r\n",
      "loss: 0.19290756, learning_rate: 2.43e-05, global_step: 2565, interval_runtime: 0.9492, interval_samples_per_second: 42.141, interval_steps_per_second: 5.268, epoch: 3.8\r\n",
      "loss: 0.17306373, learning_rate: 2.429e-05, global_step: 2570, interval_runtime: 0.7483, interval_samples_per_second: 53.457, interval_steps_per_second: 6.682, epoch: 3.8074\r\n",
      "loss: 0.19924589, learning_rate: 2.428e-05, global_step: 2575, interval_runtime: 0.976, interval_samples_per_second: 40.982, interval_steps_per_second: 5.123, epoch: 3.8148\r\n",
      "loss: 0.20233672, learning_rate: 2.427e-05, global_step: 2580, interval_runtime: 0.7402, interval_samples_per_second: 54.041, interval_steps_per_second: 6.755, epoch: 3.8222\r\n",
      "loss: 0.22837186, learning_rate: 2.426e-05, global_step: 2585, interval_runtime: 0.8435, interval_samples_per_second: 47.421, interval_steps_per_second: 5.928, epoch: 3.8296\r\n",
      "loss: 0.19994957, learning_rate: 2.424e-05, global_step: 2590, interval_runtime: 0.8143, interval_samples_per_second: 49.12, interval_steps_per_second: 6.14, epoch: 3.837\r\n",
      "loss: 0.18670138, learning_rate: 2.423e-05, global_step: 2595, interval_runtime: 0.9207, interval_samples_per_second: 43.445, interval_steps_per_second: 5.431, epoch: 3.8444\r\n",
      "loss: 0.1843805, learning_rate: 2.422e-05, global_step: 2600, interval_runtime: 0.8384, interval_samples_per_second: 47.71, interval_steps_per_second: 5.964, epoch: 3.8519\r\n",
      "loss: 0.21315563, learning_rate: 2.421e-05, global_step: 2605, interval_runtime: 0.7243, interval_samples_per_second: 55.225, interval_steps_per_second: 6.903, epoch: 3.8593\r\n",
      "loss: 0.18795928, learning_rate: 2.42e-05, global_step: 2610, interval_runtime: 0.6868, interval_samples_per_second: 58.241, interval_steps_per_second: 7.28, epoch: 3.8667\r\n",
      "loss: 0.17678792, learning_rate: 2.419e-05, global_step: 2615, interval_runtime: 0.8293, interval_samples_per_second: 48.235, interval_steps_per_second: 6.029, epoch: 3.8741\r\n",
      "loss: 0.22631407, learning_rate: 2.418e-05, global_step: 2620, interval_runtime: 0.7762, interval_samples_per_second: 51.531, interval_steps_per_second: 6.441, epoch: 3.8815\r\n",
      "loss: 0.22225406, learning_rate: 2.417e-05, global_step: 2625, interval_runtime: 0.8509, interval_samples_per_second: 47.01, interval_steps_per_second: 5.876, epoch: 3.8889\r\n",
      "loss: 0.18380082, learning_rate: 2.416e-05, global_step: 2630, interval_runtime: 0.7219, interval_samples_per_second: 55.408, interval_steps_per_second: 6.926, epoch: 3.8963\r\n",
      "loss: 0.19467424, learning_rate: 2.414e-05, global_step: 2635, interval_runtime: 0.7191, interval_samples_per_second: 55.625, interval_steps_per_second: 6.953, epoch: 3.9037\r\n",
      "loss: 0.1934883, learning_rate: 2.413e-05, global_step: 2640, interval_runtime: 0.7502, interval_samples_per_second: 53.318, interval_steps_per_second: 6.665, epoch: 3.9111\r\n",
      "loss: 0.18068945, learning_rate: 2.412e-05, global_step: 2645, interval_runtime: 0.757, interval_samples_per_second: 52.842, interval_steps_per_second: 6.605, epoch: 3.9185\r\n",
      "loss: 0.21038749, learning_rate: 2.411e-05, global_step: 2650, interval_runtime: 0.7895, interval_samples_per_second: 50.662, interval_steps_per_second: 6.333, epoch: 3.9259\r\n",
      "loss: 0.1779407, learning_rate: 2.41e-05, global_step: 2655, interval_runtime: 0.9648, interval_samples_per_second: 41.458, interval_steps_per_second: 5.182, epoch: 3.9333\r\n",
      "loss: 0.18107932, learning_rate: 2.409e-05, global_step: 2660, interval_runtime: 0.8046, interval_samples_per_second: 49.716, interval_steps_per_second: 6.215, epoch: 3.9407\r\n",
      "loss: 0.16478444, learning_rate: 2.408e-05, global_step: 2665, interval_runtime: 0.7631, interval_samples_per_second: 52.421, interval_steps_per_second: 6.553, epoch: 3.9481\r\n",
      "loss: 0.21778052, learning_rate: 2.407e-05, global_step: 2670, interval_runtime: 0.8097, interval_samples_per_second: 49.402, interval_steps_per_second: 6.175, epoch: 3.9556\r\n",
      "loss: 0.17705938, learning_rate: 2.406e-05, global_step: 2675, interval_runtime: 0.9799, interval_samples_per_second: 40.821, interval_steps_per_second: 5.103, epoch: 3.963\r\n",
      "loss: 0.19981315, learning_rate: 2.404e-05, global_step: 2680, interval_runtime: 0.9349, interval_samples_per_second: 42.786, interval_steps_per_second: 5.348, epoch: 3.9704\r\n",
      "loss: 0.18238146, learning_rate: 2.403e-05, global_step: 2685, interval_runtime: 0.724, interval_samples_per_second: 55.25, interval_steps_per_second: 6.906, epoch: 3.9778\r\n",
      "loss: 0.20974336, learning_rate: 2.402e-05, global_step: 2690, interval_runtime: 0.8787, interval_samples_per_second: 45.524, interval_steps_per_second: 5.691, epoch: 3.9852\r\n",
      "loss: 0.17950395, learning_rate: 2.401e-05, global_step: 2695, interval_runtime: 0.8326, interval_samples_per_second: 48.043, interval_steps_per_second: 6.005, epoch: 3.9926\r\n",
      "loss: 0.18876172, learning_rate: 2.4e-05, global_step: 2700, interval_runtime: 0.6332, interval_samples_per_second: 63.17, interval_steps_per_second: 7.896, epoch: 4.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:47:12,892] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:47:12,894] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:47:12,896] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:47:12,898] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:47:12,900] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.3620966374874115, eval_micro_f1_score: 0.5579797285689745, eval_macro_f1_score: 0.44693361641892615, eval_runtime: 13.4828, eval_samples_per_second: 140.623, eval_steps_per_second: 17.578, epoch: 4.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:47:26,379] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-2700\r\n",
      "[2023-01-10 10:47:26,382] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:47:29,769] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-2700/tokenizer_config.json\r\n",
      "[2023-01-10 10:47:29,773] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-2700/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.18128819, learning_rate: 2.399e-05, global_step: 2705, interval_runtime: 24.4379, interval_samples_per_second: 1.637, interval_steps_per_second: 0.205, epoch: 4.0074\r\n",
      "loss: 0.18819149, learning_rate: 2.398e-05, global_step: 2710, interval_runtime: 0.7737, interval_samples_per_second: 51.701, interval_steps_per_second: 6.463, epoch: 4.0148\r\n",
      "loss: 0.13497393, learning_rate: 2.397e-05, global_step: 2715, interval_runtime: 0.9755, interval_samples_per_second: 41.006, interval_steps_per_second: 5.126, epoch: 4.0222\r\n",
      "loss: 0.15265527, learning_rate: 2.396e-05, global_step: 2720, interval_runtime: 0.7794, interval_samples_per_second: 51.324, interval_steps_per_second: 6.415, epoch: 4.0296\r\n",
      "loss: 0.14972367, learning_rate: 2.394e-05, global_step: 2725, interval_runtime: 0.9459, interval_samples_per_second: 42.29, interval_steps_per_second: 5.286, epoch: 4.037\r\n",
      "loss: 0.16381774, learning_rate: 2.393e-05, global_step: 2730, interval_runtime: 0.926, interval_samples_per_second: 43.195, interval_steps_per_second: 5.399, epoch: 4.0444\r\n",
      "loss: 0.14712337, learning_rate: 2.392e-05, global_step: 2735, interval_runtime: 0.9265, interval_samples_per_second: 43.174, interval_steps_per_second: 5.397, epoch: 4.0519\r\n",
      "loss: 0.13029628, learning_rate: 2.391e-05, global_step: 2740, interval_runtime: 0.8692, interval_samples_per_second: 46.018, interval_steps_per_second: 5.752, epoch: 4.0593\r\n",
      "loss: 0.13766923, learning_rate: 2.39e-05, global_step: 2745, interval_runtime: 0.9497, interval_samples_per_second: 42.119, interval_steps_per_second: 5.265, epoch: 4.0667\r\n",
      "loss: 0.14721011, learning_rate: 2.389e-05, global_step: 2750, interval_runtime: 0.7091, interval_samples_per_second: 56.41, interval_steps_per_second: 7.051, epoch: 4.0741\r\n",
      "loss: 0.11533448, learning_rate: 2.388e-05, global_step: 2755, interval_runtime: 0.8478, interval_samples_per_second: 47.183, interval_steps_per_second: 5.898, epoch: 4.0815\r\n",
      "loss: 0.13256643, learning_rate: 2.387e-05, global_step: 2760, interval_runtime: 0.901, interval_samples_per_second: 44.394, interval_steps_per_second: 5.549, epoch: 4.0889\r\n",
      "loss: 0.13081419, learning_rate: 2.386e-05, global_step: 2765, interval_runtime: 0.8703, interval_samples_per_second: 45.959, interval_steps_per_second: 5.745, epoch: 4.0963\r\n",
      "loss: 0.12028612, learning_rate: 2.384e-05, global_step: 2770, interval_runtime: 0.8684, interval_samples_per_second: 46.061, interval_steps_per_second: 5.758, epoch: 4.1037\r\n",
      "loss: 0.12810041, learning_rate: 2.383e-05, global_step: 2775, interval_runtime: 0.8837, interval_samples_per_second: 45.264, interval_steps_per_second: 5.658, epoch: 4.1111\r\n",
      "loss: 0.14457638, learning_rate: 2.382e-05, global_step: 2780, interval_runtime: 0.7624, interval_samples_per_second: 52.466, interval_steps_per_second: 6.558, epoch: 4.1185\r\n",
      "loss: 0.13081119, learning_rate: 2.381e-05, global_step: 2785, interval_runtime: 0.7972, interval_samples_per_second: 50.176, interval_steps_per_second: 6.272, epoch: 4.1259\r\n",
      "loss: 0.14751004, learning_rate: 2.38e-05, global_step: 2790, interval_runtime: 0.8485, interval_samples_per_second: 47.14, interval_steps_per_second: 5.892, epoch: 4.1333\r\n",
      "loss: 0.12145345, learning_rate: 2.379e-05, global_step: 2795, interval_runtime: 0.8763, interval_samples_per_second: 45.647, interval_steps_per_second: 5.706, epoch: 4.1407\r\n",
      "loss: 0.11356342, learning_rate: 2.378e-05, global_step: 2800, interval_runtime: 0.805, interval_samples_per_second: 49.689, interval_steps_per_second: 6.211, epoch: 4.1481\r\n",
      "loss: 0.14025083, learning_rate: 2.377e-05, global_step: 2805, interval_runtime: 0.9743, interval_samples_per_second: 41.055, interval_steps_per_second: 5.132, epoch: 4.1556\r\n",
      "loss: 0.1363223, learning_rate: 2.376e-05, global_step: 2810, interval_runtime: 1.0094, interval_samples_per_second: 39.628, interval_steps_per_second: 4.954, epoch: 4.163\r\n",
      "loss: 0.1171223, learning_rate: 2.374e-05, global_step: 2815, interval_runtime: 0.7267, interval_samples_per_second: 55.046, interval_steps_per_second: 6.881, epoch: 4.1704\r\n",
      "loss: 0.14062285, learning_rate: 2.373e-05, global_step: 2820, interval_runtime: 0.7883, interval_samples_per_second: 50.743, interval_steps_per_second: 6.343, epoch: 4.1778\r\n",
      "loss: 0.14557414, learning_rate: 2.372e-05, global_step: 2825, interval_runtime: 0.7567, interval_samples_per_second: 52.861, interval_steps_per_second: 6.608, epoch: 4.1852\r\n",
      "loss: 0.13003651, learning_rate: 2.371e-05, global_step: 2830, interval_runtime: 0.7218, interval_samples_per_second: 55.415, interval_steps_per_second: 6.927, epoch: 4.1926\r\n",
      "loss: 0.1086761, learning_rate: 2.37e-05, global_step: 2835, interval_runtime: 0.9718, interval_samples_per_second: 41.159, interval_steps_per_second: 5.145, epoch: 4.2\r\n",
      "loss: 0.17949799, learning_rate: 2.369e-05, global_step: 2840, interval_runtime: 0.9411, interval_samples_per_second: 42.501, interval_steps_per_second: 5.313, epoch: 4.2074\r\n",
      "loss: 0.1395059, learning_rate: 2.368e-05, global_step: 2845, interval_runtime: 0.7259, interval_samples_per_second: 55.101, interval_steps_per_second: 6.888, epoch: 4.2148\r\n",
      "loss: 0.12884859, learning_rate: 2.367e-05, global_step: 2850, interval_runtime: 0.8509, interval_samples_per_second: 47.007, interval_steps_per_second: 5.876, epoch: 4.2222\r\n",
      "loss: 0.17379452, learning_rate: 2.366e-05, global_step: 2855, interval_runtime: 1.003, interval_samples_per_second: 39.881, interval_steps_per_second: 4.985, epoch: 4.2296\r\n",
      "loss: 0.11603463, learning_rate: 2.364e-05, global_step: 2860, interval_runtime: 0.7755, interval_samples_per_second: 51.583, interval_steps_per_second: 6.448, epoch: 4.237\r\n",
      "loss: 0.14869177, learning_rate: 2.363e-05, global_step: 2865, interval_runtime: 0.8575, interval_samples_per_second: 46.646, interval_steps_per_second: 5.831, epoch: 4.2444\r\n",
      "loss: 0.15288532, learning_rate: 2.362e-05, global_step: 2870, interval_runtime: 0.9168, interval_samples_per_second: 43.632, interval_steps_per_second: 5.454, epoch: 4.2519\r\n",
      "loss: 0.11526763, learning_rate: 2.361e-05, global_step: 2875, interval_runtime: 0.7479, interval_samples_per_second: 53.482, interval_steps_per_second: 6.685, epoch: 4.2593\r\n",
      "loss: 0.13084743, learning_rate: 2.36e-05, global_step: 2880, interval_runtime: 0.7252, interval_samples_per_second: 55.159, interval_steps_per_second: 6.895, epoch: 4.2667\r\n",
      "loss: 0.12343295, learning_rate: 2.359e-05, global_step: 2885, interval_runtime: 0.6993, interval_samples_per_second: 57.197, interval_steps_per_second: 7.15, epoch: 4.2741\r\n",
      "loss: 0.1579024, learning_rate: 2.358e-05, global_step: 2890, interval_runtime: 0.7616, interval_samples_per_second: 52.523, interval_steps_per_second: 6.565, epoch: 4.2815\r\n",
      "loss: 0.1339139, learning_rate: 2.357e-05, global_step: 2895, interval_runtime: 0.8415, interval_samples_per_second: 47.536, interval_steps_per_second: 5.942, epoch: 4.2889\r\n",
      "loss: 0.12690809, learning_rate: 2.356e-05, global_step: 2900, interval_runtime: 0.7965, interval_samples_per_second: 50.217, interval_steps_per_second: 6.277, epoch: 4.2963\r\n",
      "loss: 0.15661898, learning_rate: 2.354e-05, global_step: 2905, interval_runtime: 0.8336, interval_samples_per_second: 47.982, interval_steps_per_second: 5.998, epoch: 4.3037\r\n",
      "loss: 0.12548668, learning_rate: 2.353e-05, global_step: 2910, interval_runtime: 0.9512, interval_samples_per_second: 42.054, interval_steps_per_second: 5.257, epoch: 4.3111\r\n",
      "loss: 0.14270372, learning_rate: 2.352e-05, global_step: 2915, interval_runtime: 0.8406, interval_samples_per_second: 47.585, interval_steps_per_second: 5.948, epoch: 4.3185\r\n",
      "loss: 0.14752092, learning_rate: 2.351e-05, global_step: 2920, interval_runtime: 0.9418, interval_samples_per_second: 42.47, interval_steps_per_second: 5.309, epoch: 4.3259\r\n",
      "loss: 0.15396309, learning_rate: 2.35e-05, global_step: 2925, interval_runtime: 0.8854, interval_samples_per_second: 45.176, interval_steps_per_second: 5.647, epoch: 4.3333\r\n",
      "loss: 0.1465817, learning_rate: 2.349e-05, global_step: 2930, interval_runtime: 1.0491, interval_samples_per_second: 38.127, interval_steps_per_second: 4.766, epoch: 4.3407\r\n",
      "loss: 0.11157563, learning_rate: 2.348e-05, global_step: 2935, interval_runtime: 0.7618, interval_samples_per_second: 52.507, interval_steps_per_second: 6.563, epoch: 4.3481\r\n",
      "loss: 0.14816344, learning_rate: 2.347e-05, global_step: 2940, interval_runtime: 0.7675, interval_samples_per_second: 52.117, interval_steps_per_second: 6.515, epoch: 4.3556\r\n",
      "loss: 0.14200628, learning_rate: 2.346e-05, global_step: 2945, interval_runtime: 0.7605, interval_samples_per_second: 52.595, interval_steps_per_second: 6.574, epoch: 4.363\r\n",
      "loss: 0.1400143, learning_rate: 2.344e-05, global_step: 2950, interval_runtime: 0.8734, interval_samples_per_second: 45.8, interval_steps_per_second: 5.725, epoch: 4.3704\r\n",
      "loss: 0.13918833, learning_rate: 2.343e-05, global_step: 2955, interval_runtime: 0.894, interval_samples_per_second: 44.742, interval_steps_per_second: 5.593, epoch: 4.3778\r\n",
      "loss: 0.12648033, learning_rate: 2.342e-05, global_step: 2960, interval_runtime: 1.0995, interval_samples_per_second: 36.379, interval_steps_per_second: 4.547, epoch: 4.3852\r\n",
      "loss: 0.12697622, learning_rate: 2.341e-05, global_step: 2965, interval_runtime: 0.8787, interval_samples_per_second: 45.523, interval_steps_per_second: 5.69, epoch: 4.3926\r\n",
      "loss: 0.12937826, learning_rate: 2.34e-05, global_step: 2970, interval_runtime: 0.8622, interval_samples_per_second: 46.392, interval_steps_per_second: 5.799, epoch: 4.4\r\n",
      "loss: 0.11460876, learning_rate: 2.339e-05, global_step: 2975, interval_runtime: 0.8795, interval_samples_per_second: 45.48, interval_steps_per_second: 5.685, epoch: 4.4074\r\n",
      "loss: 0.1301584, learning_rate: 2.338e-05, global_step: 2980, interval_runtime: 0.8184, interval_samples_per_second: 48.875, interval_steps_per_second: 6.109, epoch: 4.4148\r\n",
      "loss: 0.1432322, learning_rate: 2.337e-05, global_step: 2985, interval_runtime: 0.8708, interval_samples_per_second: 45.935, interval_steps_per_second: 5.742, epoch: 4.4222\r\n",
      "loss: 0.13173912, learning_rate: 2.336e-05, global_step: 2990, interval_runtime: 0.9324, interval_samples_per_second: 42.9, interval_steps_per_second: 5.363, epoch: 4.4296\r\n",
      "loss: 0.12261559, learning_rate: 2.334e-05, global_step: 2995, interval_runtime: 0.8231, interval_samples_per_second: 48.597, interval_steps_per_second: 6.075, epoch: 4.437\r\n",
      "loss: 0.11776032, learning_rate: 2.333e-05, global_step: 3000, interval_runtime: 0.9491, interval_samples_per_second: 42.145, interval_steps_per_second: 5.268, epoch: 4.4444\r\n",
      "loss: 0.14019339, learning_rate: 2.332e-05, global_step: 3005, interval_runtime: 0.7539, interval_samples_per_second: 53.056, interval_steps_per_second: 6.632, epoch: 4.4519\r\n",
      "loss: 0.14260936, learning_rate: 2.331e-05, global_step: 3010, interval_runtime: 0.8016, interval_samples_per_second: 49.903, interval_steps_per_second: 6.238, epoch: 4.4593\r\n",
      "loss: 0.13624911, learning_rate: 2.33e-05, global_step: 3015, interval_runtime: 0.8657, interval_samples_per_second: 46.204, interval_steps_per_second: 5.776, epoch: 4.4667\r\n",
      "loss: 0.12029806, learning_rate: 2.329e-05, global_step: 3020, interval_runtime: 0.9711, interval_samples_per_second: 41.189, interval_steps_per_second: 5.149, epoch: 4.4741\r\n",
      "loss: 0.12030158, learning_rate: 2.328e-05, global_step: 3025, interval_runtime: 0.848, interval_samples_per_second: 47.172, interval_steps_per_second: 5.896, epoch: 4.4815\r\n",
      "loss: 0.12510782, learning_rate: 2.327e-05, global_step: 3030, interval_runtime: 0.7647, interval_samples_per_second: 52.308, interval_steps_per_second: 6.539, epoch: 4.4889\r\n",
      "loss: 0.18416969, learning_rate: 2.326e-05, global_step: 3035, interval_runtime: 0.7905, interval_samples_per_second: 50.603, interval_steps_per_second: 6.325, epoch: 4.4963\r\n",
      "loss: 0.12130798, learning_rate: 2.324e-05, global_step: 3040, interval_runtime: 0.8781, interval_samples_per_second: 45.553, interval_steps_per_second: 5.694, epoch: 4.5037\r\n",
      "loss: 0.16344485, learning_rate: 2.323e-05, global_step: 3045, interval_runtime: 0.9995, interval_samples_per_second: 40.022, interval_steps_per_second: 5.003, epoch: 4.5111\r\n",
      "loss: 0.13964983, learning_rate: 2.322e-05, global_step: 3050, interval_runtime: 0.7328, interval_samples_per_second: 54.582, interval_steps_per_second: 6.823, epoch: 4.5185\r\n",
      "loss: 0.1049685, learning_rate: 2.321e-05, global_step: 3055, interval_runtime: 0.7633, interval_samples_per_second: 52.406, interval_steps_per_second: 6.551, epoch: 4.5259\r\n",
      "loss: 0.1247792, learning_rate: 2.32e-05, global_step: 3060, interval_runtime: 0.9054, interval_samples_per_second: 44.182, interval_steps_per_second: 5.523, epoch: 4.5333\r\n",
      "loss: 0.16429775, learning_rate: 2.319e-05, global_step: 3065, interval_runtime: 0.7704, interval_samples_per_second: 51.922, interval_steps_per_second: 6.49, epoch: 4.5407\r\n",
      "loss: 0.15830913, learning_rate: 2.318e-05, global_step: 3070, interval_runtime: 0.7457, interval_samples_per_second: 53.638, interval_steps_per_second: 6.705, epoch: 4.5481\r\n",
      "loss: 0.14599211, learning_rate: 2.317e-05, global_step: 3075, interval_runtime: 0.7901, interval_samples_per_second: 50.627, interval_steps_per_second: 6.328, epoch: 4.5556\r\n",
      "loss: 0.14316685, learning_rate: 2.316e-05, global_step: 3080, interval_runtime: 0.9063, interval_samples_per_second: 44.137, interval_steps_per_second: 5.517, epoch: 4.563\r\n",
      "loss: 0.13128129, learning_rate: 2.314e-05, global_step: 3085, interval_runtime: 0.7041, interval_samples_per_second: 56.812, interval_steps_per_second: 7.101, epoch: 4.5704\r\n",
      "loss: 0.13468511, learning_rate: 2.313e-05, global_step: 3090, interval_runtime: 0.824, interval_samples_per_second: 48.543, interval_steps_per_second: 6.068, epoch: 4.5778\r\n",
      "loss: 0.14807434, learning_rate: 2.312e-05, global_step: 3095, interval_runtime: 0.8096, interval_samples_per_second: 49.407, interval_steps_per_second: 6.176, epoch: 4.5852\r\n",
      "loss: 0.11620061, learning_rate: 2.311e-05, global_step: 3100, interval_runtime: 0.8799, interval_samples_per_second: 45.462, interval_steps_per_second: 5.683, epoch: 4.5926\r\n",
      "loss: 0.14342625, learning_rate: 2.31e-05, global_step: 3105, interval_runtime: 0.7819, interval_samples_per_second: 51.155, interval_steps_per_second: 6.394, epoch: 4.6\r\n",
      "loss: 0.12633668, learning_rate: 2.309e-05, global_step: 3110, interval_runtime: 0.7706, interval_samples_per_second: 51.909, interval_steps_per_second: 6.489, epoch: 4.6074\r\n",
      "loss: 0.14692883, learning_rate: 2.308e-05, global_step: 3115, interval_runtime: 0.8056, interval_samples_per_second: 49.651, interval_steps_per_second: 6.206, epoch: 4.6148\r\n",
      "loss: 0.15847439, learning_rate: 2.307e-05, global_step: 3120, interval_runtime: 0.8545, interval_samples_per_second: 46.814, interval_steps_per_second: 5.852, epoch: 4.6222\r\n",
      "loss: 0.12531538, learning_rate: 2.306e-05, global_step: 3125, interval_runtime: 0.9098, interval_samples_per_second: 43.964, interval_steps_per_second: 5.495, epoch: 4.6296\r\n",
      "loss: 0.11235552, learning_rate: 2.304e-05, global_step: 3130, interval_runtime: 0.9086, interval_samples_per_second: 44.023, interval_steps_per_second: 5.503, epoch: 4.637\r\n",
      "loss: 0.15645094, learning_rate: 2.303e-05, global_step: 3135, interval_runtime: 0.8294, interval_samples_per_second: 48.225, interval_steps_per_second: 6.028, epoch: 4.6444\r\n",
      "loss: 0.16243107, learning_rate: 2.302e-05, global_step: 3140, interval_runtime: 0.7751, interval_samples_per_second: 51.606, interval_steps_per_second: 6.451, epoch: 4.6519\r\n",
      "loss: 0.11825739, learning_rate: 2.301e-05, global_step: 3145, interval_runtime: 0.831, interval_samples_per_second: 48.134, interval_steps_per_second: 6.017, epoch: 4.6593\r\n",
      "loss: 0.17322271, learning_rate: 2.3e-05, global_step: 3150, interval_runtime: 0.8975, interval_samples_per_second: 44.57, interval_steps_per_second: 5.571, epoch: 4.6667\r\n",
      "loss: 0.15391378, learning_rate: 2.299e-05, global_step: 3155, interval_runtime: 0.9089, interval_samples_per_second: 44.009, interval_steps_per_second: 5.501, epoch: 4.6741\r\n",
      "loss: 0.14270811, learning_rate: 2.298e-05, global_step: 3160, interval_runtime: 0.8318, interval_samples_per_second: 48.091, interval_steps_per_second: 6.011, epoch: 4.6815\r\n",
      "loss: 0.21114144, learning_rate: 2.297e-05, global_step: 3165, interval_runtime: 0.9856, interval_samples_per_second: 40.583, interval_steps_per_second: 5.073, epoch: 4.6889\r\n",
      "loss: 0.1408097, learning_rate: 2.296e-05, global_step: 3170, interval_runtime: 0.9468, interval_samples_per_second: 42.246, interval_steps_per_second: 5.281, epoch: 4.6963\r\n",
      "loss: 0.15652047, learning_rate: 2.294e-05, global_step: 3175, interval_runtime: 0.839, interval_samples_per_second: 47.673, interval_steps_per_second: 5.959, epoch: 4.7037\r\n",
      "loss: 0.14216516, learning_rate: 2.293e-05, global_step: 3180, interval_runtime: 0.9651, interval_samples_per_second: 41.446, interval_steps_per_second: 5.181, epoch: 4.7111\r\n",
      "loss: 0.14050052, learning_rate: 2.292e-05, global_step: 3185, interval_runtime: 0.9665, interval_samples_per_second: 41.387, interval_steps_per_second: 5.173, epoch: 4.7185\r\n",
      "loss: 0.13005478, learning_rate: 2.291e-05, global_step: 3190, interval_runtime: 0.7958, interval_samples_per_second: 50.261, interval_steps_per_second: 6.283, epoch: 4.7259\r\n",
      "loss: 0.15938084, learning_rate: 2.29e-05, global_step: 3195, interval_runtime: 0.8207, interval_samples_per_second: 48.739, interval_steps_per_second: 6.092, epoch: 4.7333\r\n",
      "loss: 0.17210751, learning_rate: 2.289e-05, global_step: 3200, interval_runtime: 0.7419, interval_samples_per_second: 53.915, interval_steps_per_second: 6.739, epoch: 4.7407\r\n",
      "loss: 0.15633141, learning_rate: 2.288e-05, global_step: 3205, interval_runtime: 0.8008, interval_samples_per_second: 49.948, interval_steps_per_second: 6.243, epoch: 4.7481\r\n",
      "loss: 0.15577539, learning_rate: 2.287e-05, global_step: 3210, interval_runtime: 0.8055, interval_samples_per_second: 49.658, interval_steps_per_second: 6.207, epoch: 4.7556\r\n",
      "loss: 0.12737283, learning_rate: 2.286e-05, global_step: 3215, interval_runtime: 0.863, interval_samples_per_second: 46.349, interval_steps_per_second: 5.794, epoch: 4.763\r\n",
      "loss: 0.16025119, learning_rate: 2.284e-05, global_step: 3220, interval_runtime: 0.8067, interval_samples_per_second: 49.584, interval_steps_per_second: 6.198, epoch: 4.7704\r\n",
      "loss: 0.1450094, learning_rate: 2.283e-05, global_step: 3225, interval_runtime: 0.9009, interval_samples_per_second: 44.401, interval_steps_per_second: 5.55, epoch: 4.7778\r\n",
      "loss: 0.11902833, learning_rate: 2.282e-05, global_step: 3230, interval_runtime: 0.8801, interval_samples_per_second: 45.447, interval_steps_per_second: 5.681, epoch: 4.7852\r\n",
      "loss: 0.1209058, learning_rate: 2.281e-05, global_step: 3235, interval_runtime: 0.786, interval_samples_per_second: 50.891, interval_steps_per_second: 6.361, epoch: 4.7926\r\n",
      "loss: 0.13225613, learning_rate: 2.28e-05, global_step: 3240, interval_runtime: 0.7726, interval_samples_per_second: 51.771, interval_steps_per_second: 6.471, epoch: 4.8\r\n",
      "loss: 0.14808359, learning_rate: 2.279e-05, global_step: 3245, interval_runtime: 1.0057, interval_samples_per_second: 39.774, interval_steps_per_second: 4.972, epoch: 4.8074\r\n",
      "loss: 0.16654967, learning_rate: 2.278e-05, global_step: 3250, interval_runtime: 0.8317, interval_samples_per_second: 48.093, interval_steps_per_second: 6.012, epoch: 4.8148\r\n",
      "loss: 0.14087608, learning_rate: 2.277e-05, global_step: 3255, interval_runtime: 0.7713, interval_samples_per_second: 51.857, interval_steps_per_second: 6.482, epoch: 4.8222\r\n",
      "loss: 0.14319988, learning_rate: 2.276e-05, global_step: 3260, interval_runtime: 0.8338, interval_samples_per_second: 47.974, interval_steps_per_second: 5.997, epoch: 4.8296\r\n",
      "loss: 0.1298789, learning_rate: 2.274e-05, global_step: 3265, interval_runtime: 0.7625, interval_samples_per_second: 52.456, interval_steps_per_second: 6.557, epoch: 4.837\r\n",
      "loss: 0.11313293, learning_rate: 2.273e-05, global_step: 3270, interval_runtime: 0.7845, interval_samples_per_second: 50.986, interval_steps_per_second: 6.373, epoch: 4.8444\r\n",
      "loss: 0.14392217, learning_rate: 2.272e-05, global_step: 3275, interval_runtime: 1.0446, interval_samples_per_second: 38.291, interval_steps_per_second: 4.786, epoch: 4.8519\r\n",
      "loss: 0.13187886, learning_rate: 2.271e-05, global_step: 3280, interval_runtime: 0.9185, interval_samples_per_second: 43.55, interval_steps_per_second: 5.444, epoch: 4.8593\r\n",
      "loss: 0.18622165, learning_rate: 2.27e-05, global_step: 3285, interval_runtime: 0.9186, interval_samples_per_second: 43.544, interval_steps_per_second: 5.443, epoch: 4.8667\r\n",
      "loss: 0.14771494, learning_rate: 2.269e-05, global_step: 3290, interval_runtime: 0.918, interval_samples_per_second: 43.574, interval_steps_per_second: 5.447, epoch: 4.8741\r\n",
      "loss: 0.16686404, learning_rate: 2.268e-05, global_step: 3295, interval_runtime: 0.9001, interval_samples_per_second: 44.438, interval_steps_per_second: 5.555, epoch: 4.8815\r\n",
      "loss: 0.13376426, learning_rate: 2.267e-05, global_step: 3300, interval_runtime: 0.7812, interval_samples_per_second: 51.203, interval_steps_per_second: 6.4, epoch: 4.8889\r\n",
      "loss: 0.14127599, learning_rate: 2.266e-05, global_step: 3305, interval_runtime: 0.7146, interval_samples_per_second: 55.972, interval_steps_per_second: 6.996, epoch: 4.8963\r\n",
      "loss: 0.13910376, learning_rate: 2.264e-05, global_step: 3310, interval_runtime: 0.8325, interval_samples_per_second: 48.05, interval_steps_per_second: 6.006, epoch: 4.9037\r\n",
      "loss: 0.13220122, learning_rate: 2.263e-05, global_step: 3315, interval_runtime: 0.6935, interval_samples_per_second: 57.679, interval_steps_per_second: 7.21, epoch: 4.9111\r\n",
      "loss: 0.10243752, learning_rate: 2.262e-05, global_step: 3320, interval_runtime: 0.8613, interval_samples_per_second: 46.444, interval_steps_per_second: 5.806, epoch: 4.9185\r\n",
      "loss: 0.13949742, learning_rate: 2.261e-05, global_step: 3325, interval_runtime: 0.7703, interval_samples_per_second: 51.928, interval_steps_per_second: 6.491, epoch: 4.9259\r\n",
      "loss: 0.13556037, learning_rate: 2.26e-05, global_step: 3330, interval_runtime: 0.8066, interval_samples_per_second: 49.589, interval_steps_per_second: 6.199, epoch: 4.9333\r\n",
      "loss: 0.17940913, learning_rate: 2.259e-05, global_step: 3335, interval_runtime: 0.9762, interval_samples_per_second: 40.976, interval_steps_per_second: 5.122, epoch: 4.9407\r\n",
      "loss: 0.15564721, learning_rate: 2.258e-05, global_step: 3340, interval_runtime: 0.9029, interval_samples_per_second: 44.301, interval_steps_per_second: 5.538, epoch: 4.9481\r\n",
      "loss: 0.14332291, learning_rate: 2.257e-05, global_step: 3345, interval_runtime: 0.8049, interval_samples_per_second: 49.693, interval_steps_per_second: 6.212, epoch: 4.9556\r\n",
      "loss: 0.14694533, learning_rate: 2.256e-05, global_step: 3350, interval_runtime: 0.7384, interval_samples_per_second: 54.17, interval_steps_per_second: 6.771, epoch: 4.963\r\n",
      "loss: 0.12375064, learning_rate: 2.254e-05, global_step: 3355, interval_runtime: 0.7346, interval_samples_per_second: 54.449, interval_steps_per_second: 6.806, epoch: 4.9704\r\n",
      "loss: 0.1472231, learning_rate: 2.253e-05, global_step: 3360, interval_runtime: 0.7819, interval_samples_per_second: 51.155, interval_steps_per_second: 6.394, epoch: 4.9778\r\n",
      "loss: 0.11878148, learning_rate: 2.252e-05, global_step: 3365, interval_runtime: 0.916, interval_samples_per_second: 43.666, interval_steps_per_second: 5.458, epoch: 4.9852\r\n",
      "loss: 0.16985092, learning_rate: 2.251e-05, global_step: 3370, interval_runtime: 0.8811, interval_samples_per_second: 45.399, interval_steps_per_second: 5.675, epoch: 4.9926\r\n",
      "loss: 0.17245035, learning_rate: 2.25e-05, global_step: 3375, interval_runtime: 0.747, interval_samples_per_second: 53.547, interval_steps_per_second: 6.693, epoch: 5.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:49:30,831] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:49:30,833] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:49:30,835] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:49:30,837] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:49:30,839] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.4195989966392517, eval_micro_f1_score: 0.5431812092524784, eval_macro_f1_score: 0.43004224098999144, eval_runtime: 13.6094, eval_samples_per_second: 139.316, eval_steps_per_second: 17.414, epoch: 5.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:49:44,445] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-3375\r\n",
      "[2023-01-10 10:49:44,448] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:49:47,696] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-3375/tokenizer_config.json\r\n",
      "[2023-01-10 10:49:47,700] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-3375/special_tokens_map.json\r\n",
      "[2023-01-10 10:49:54,517] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-2025] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0950968, learning_rate: 2.249e-05, global_step: 3380, interval_runtime: 25.1848, interval_samples_per_second: 1.588, interval_steps_per_second: 0.199, epoch: 5.0074\r\n",
      "loss: 0.09288552, learning_rate: 2.248e-05, global_step: 3385, interval_runtime: 0.7527, interval_samples_per_second: 53.142, interval_steps_per_second: 6.643, epoch: 5.0148\r\n",
      "loss: 0.08349071, learning_rate: 2.247e-05, global_step: 3390, interval_runtime: 0.7067, interval_samples_per_second: 56.598, interval_steps_per_second: 7.075, epoch: 5.0222\r\n",
      "loss: 0.08601072, learning_rate: 2.246e-05, global_step: 3395, interval_runtime: 0.9038, interval_samples_per_second: 44.257, interval_steps_per_second: 5.532, epoch: 5.0296\r\n",
      "loss: 0.08438233, learning_rate: 2.244e-05, global_step: 3400, interval_runtime: 0.8988, interval_samples_per_second: 44.503, interval_steps_per_second: 5.563, epoch: 5.037\r\n",
      "loss: 0.08300222, learning_rate: 2.243e-05, global_step: 3405, interval_runtime: 0.7511, interval_samples_per_second: 53.256, interval_steps_per_second: 6.657, epoch: 5.0444\r\n",
      "loss: 0.10808761, learning_rate: 2.242e-05, global_step: 3410, interval_runtime: 1.0519, interval_samples_per_second: 38.026, interval_steps_per_second: 4.753, epoch: 5.0519\r\n",
      "loss: 0.08797123, learning_rate: 2.241e-05, global_step: 3415, interval_runtime: 0.8362, interval_samples_per_second: 47.836, interval_steps_per_second: 5.979, epoch: 5.0593\r\n",
      "loss: 0.08371355, learning_rate: 2.24e-05, global_step: 3420, interval_runtime: 0.8063, interval_samples_per_second: 49.608, interval_steps_per_second: 6.201, epoch: 5.0667\r\n",
      "loss: 0.06664556, learning_rate: 2.239e-05, global_step: 3425, interval_runtime: 0.9299, interval_samples_per_second: 43.014, interval_steps_per_second: 5.377, epoch: 5.0741\r\n",
      "loss: 0.09131806, learning_rate: 2.238e-05, global_step: 3430, interval_runtime: 0.9592, interval_samples_per_second: 41.703, interval_steps_per_second: 5.213, epoch: 5.0815\r\n",
      "loss: 0.09786136, learning_rate: 2.237e-05, global_step: 3435, interval_runtime: 0.8639, interval_samples_per_second: 46.301, interval_steps_per_second: 5.788, epoch: 5.0889\r\n",
      "loss: 0.12185627, learning_rate: 2.236e-05, global_step: 3440, interval_runtime: 0.8556, interval_samples_per_second: 46.753, interval_steps_per_second: 5.844, epoch: 5.0963\r\n",
      "loss: 0.07348729, learning_rate: 2.234e-05, global_step: 3445, interval_runtime: 0.9001, interval_samples_per_second: 44.438, interval_steps_per_second: 5.555, epoch: 5.1037\r\n",
      "loss: 0.07680851, learning_rate: 2.233e-05, global_step: 3450, interval_runtime: 0.9502, interval_samples_per_second: 42.097, interval_steps_per_second: 5.262, epoch: 5.1111\r\n",
      "loss: 0.11254179, learning_rate: 2.232e-05, global_step: 3455, interval_runtime: 0.8097, interval_samples_per_second: 49.401, interval_steps_per_second: 6.175, epoch: 5.1185\r\n",
      "loss: 0.10848806, learning_rate: 2.231e-05, global_step: 3460, interval_runtime: 0.9112, interval_samples_per_second: 43.899, interval_steps_per_second: 5.487, epoch: 5.1259\r\n",
      "loss: 0.12338616, learning_rate: 2.23e-05, global_step: 3465, interval_runtime: 0.7658, interval_samples_per_second: 52.23, interval_steps_per_second: 6.529, epoch: 5.1333\r\n",
      "loss: 0.09930713, learning_rate: 2.229e-05, global_step: 3470, interval_runtime: 0.7896, interval_samples_per_second: 50.661, interval_steps_per_second: 6.333, epoch: 5.1407\r\n",
      "loss: 0.08733768, learning_rate: 2.228e-05, global_step: 3475, interval_runtime: 0.7765, interval_samples_per_second: 51.516, interval_steps_per_second: 6.439, epoch: 5.1481\r\n",
      "loss: 0.09645329, learning_rate: 2.227e-05, global_step: 3480, interval_runtime: 0.8179, interval_samples_per_second: 48.906, interval_steps_per_second: 6.113, epoch: 5.1556\r\n",
      "loss: 0.06282164, learning_rate: 2.226e-05, global_step: 3485, interval_runtime: 0.8549, interval_samples_per_second: 46.791, interval_steps_per_second: 5.849, epoch: 5.163\r\n",
      "loss: 0.09722323, learning_rate: 2.224e-05, global_step: 3490, interval_runtime: 0.9218, interval_samples_per_second: 43.395, interval_steps_per_second: 5.424, epoch: 5.1704\r\n",
      "loss: 0.09474213, learning_rate: 2.223e-05, global_step: 3495, interval_runtime: 0.796, interval_samples_per_second: 50.251, interval_steps_per_second: 6.281, epoch: 5.1778\r\n",
      "loss: 0.09761266, learning_rate: 2.222e-05, global_step: 3500, interval_runtime: 0.7662, interval_samples_per_second: 52.202, interval_steps_per_second: 6.525, epoch: 5.1852\r\n",
      "loss: 0.09018415, learning_rate: 2.221e-05, global_step: 3505, interval_runtime: 0.9186, interval_samples_per_second: 43.544, interval_steps_per_second: 5.443, epoch: 5.1926\r\n",
      "loss: 0.10858408, learning_rate: 2.22e-05, global_step: 3510, interval_runtime: 0.8663, interval_samples_per_second: 46.174, interval_steps_per_second: 5.772, epoch: 5.2\r\n",
      "loss: 0.10604078, learning_rate: 2.219e-05, global_step: 3515, interval_runtime: 0.925, interval_samples_per_second: 43.243, interval_steps_per_second: 5.405, epoch: 5.2074\r\n",
      "loss: 0.08846734, learning_rate: 2.218e-05, global_step: 3520, interval_runtime: 0.8314, interval_samples_per_second: 48.112, interval_steps_per_second: 6.014, epoch: 5.2148\r\n",
      "loss: 0.11435823, learning_rate: 2.217e-05, global_step: 3525, interval_runtime: 0.8161, interval_samples_per_second: 49.017, interval_steps_per_second: 6.127, epoch: 5.2222\r\n",
      "loss: 0.09392075, learning_rate: 2.216e-05, global_step: 3530, interval_runtime: 0.7062, interval_samples_per_second: 56.638, interval_steps_per_second: 7.08, epoch: 5.2296\r\n",
      "loss: 0.08439407, learning_rate: 2.214e-05, global_step: 3535, interval_runtime: 0.8242, interval_samples_per_second: 48.532, interval_steps_per_second: 6.067, epoch: 5.237\r\n",
      "loss: 0.08660225, learning_rate: 2.213e-05, global_step: 3540, interval_runtime: 0.8163, interval_samples_per_second: 49.003, interval_steps_per_second: 6.125, epoch: 5.2444\r\n",
      "loss: 0.08434339, learning_rate: 2.212e-05, global_step: 3545, interval_runtime: 0.9079, interval_samples_per_second: 44.057, interval_steps_per_second: 5.507, epoch: 5.2519\r\n",
      "loss: 0.11196104, learning_rate: 2.211e-05, global_step: 3550, interval_runtime: 0.9391, interval_samples_per_second: 42.593, interval_steps_per_second: 5.324, epoch: 5.2593\r\n",
      "loss: 0.09856311, learning_rate: 2.21e-05, global_step: 3555, interval_runtime: 0.9676, interval_samples_per_second: 41.338, interval_steps_per_second: 5.167, epoch: 5.2667\r\n",
      "loss: 0.10872144, learning_rate: 2.209e-05, global_step: 3560, interval_runtime: 0.8793, interval_samples_per_second: 45.492, interval_steps_per_second: 5.686, epoch: 5.2741\r\n",
      "loss: 0.0710479, learning_rate: 2.208e-05, global_step: 3565, interval_runtime: 0.7562, interval_samples_per_second: 52.9, interval_steps_per_second: 6.612, epoch: 5.2815\r\n",
      "loss: 0.1009886, learning_rate: 2.207e-05, global_step: 3570, interval_runtime: 0.8333, interval_samples_per_second: 48.004, interval_steps_per_second: 6.0, epoch: 5.2889\r\n",
      "loss: 0.10320957, learning_rate: 2.206e-05, global_step: 3575, interval_runtime: 0.7297, interval_samples_per_second: 54.819, interval_steps_per_second: 6.852, epoch: 5.2963\r\n",
      "loss: 0.10529183, learning_rate: 2.204e-05, global_step: 3580, interval_runtime: 0.7986, interval_samples_per_second: 50.087, interval_steps_per_second: 6.261, epoch: 5.3037\r\n",
      "loss: 0.07922623, learning_rate: 2.203e-05, global_step: 3585, interval_runtime: 0.9358, interval_samples_per_second: 42.742, interval_steps_per_second: 5.343, epoch: 5.3111\r\n",
      "loss: 0.0845494, learning_rate: 2.202e-05, global_step: 3590, interval_runtime: 0.8834, interval_samples_per_second: 45.281, interval_steps_per_second: 5.66, epoch: 5.3185\r\n",
      "loss: 0.08677839, learning_rate: 2.201e-05, global_step: 3595, interval_runtime: 0.786, interval_samples_per_second: 50.888, interval_steps_per_second: 6.361, epoch: 5.3259\r\n",
      "loss: 0.09057848, learning_rate: 2.2e-05, global_step: 3600, interval_runtime: 0.985, interval_samples_per_second: 40.609, interval_steps_per_second: 5.076, epoch: 5.3333\r\n",
      "loss: 0.07815811, learning_rate: 2.199e-05, global_step: 3605, interval_runtime: 0.8586, interval_samples_per_second: 46.586, interval_steps_per_second: 5.823, epoch: 5.3407\r\n",
      "loss: 0.09194612, learning_rate: 2.198e-05, global_step: 3610, interval_runtime: 0.8234, interval_samples_per_second: 48.579, interval_steps_per_second: 6.072, epoch: 5.3481\r\n",
      "loss: 0.08425063, learning_rate: 2.197e-05, global_step: 3615, interval_runtime: 0.8681, interval_samples_per_second: 46.08, interval_steps_per_second: 5.76, epoch: 5.3556\r\n",
      "loss: 0.08809869, learning_rate: 2.196e-05, global_step: 3620, interval_runtime: 0.8917, interval_samples_per_second: 44.856, interval_steps_per_second: 5.607, epoch: 5.363\r\n",
      "loss: 0.11485782, learning_rate: 2.194e-05, global_step: 3625, interval_runtime: 0.8622, interval_samples_per_second: 46.39, interval_steps_per_second: 5.799, epoch: 5.3704\r\n",
      "loss: 0.10956309, learning_rate: 2.193e-05, global_step: 3630, interval_runtime: 0.8903, interval_samples_per_second: 44.93, interval_steps_per_second: 5.616, epoch: 5.3778\r\n",
      "loss: 0.1119417, learning_rate: 2.192e-05, global_step: 3635, interval_runtime: 0.8163, interval_samples_per_second: 49.004, interval_steps_per_second: 6.126, epoch: 5.3852\r\n",
      "loss: 0.09369439, learning_rate: 2.191e-05, global_step: 3640, interval_runtime: 0.8602, interval_samples_per_second: 46.503, interval_steps_per_second: 5.813, epoch: 5.3926\r\n",
      "loss: 0.08650366, learning_rate: 2.19e-05, global_step: 3645, interval_runtime: 0.9287, interval_samples_per_second: 43.07, interval_steps_per_second: 5.384, epoch: 5.4\r\n",
      "loss: 0.103992, learning_rate: 2.189e-05, global_step: 3650, interval_runtime: 0.8332, interval_samples_per_second: 48.008, interval_steps_per_second: 6.001, epoch: 5.4074\r\n",
      "loss: 0.08897692, learning_rate: 2.188e-05, global_step: 3655, interval_runtime: 0.8522, interval_samples_per_second: 46.937, interval_steps_per_second: 5.867, epoch: 5.4148\r\n",
      "loss: 0.09761607, learning_rate: 2.187e-05, global_step: 3660, interval_runtime: 0.8161, interval_samples_per_second: 49.015, interval_steps_per_second: 6.127, epoch: 5.4222\r\n",
      "loss: 0.11657383, learning_rate: 2.186e-05, global_step: 3665, interval_runtime: 0.9327, interval_samples_per_second: 42.885, interval_steps_per_second: 5.361, epoch: 5.4296\r\n",
      "loss: 0.0783851, learning_rate: 2.184e-05, global_step: 3670, interval_runtime: 0.8726, interval_samples_per_second: 45.84, interval_steps_per_second: 5.73, epoch: 5.437\r\n",
      "loss: 0.09309887, learning_rate: 2.183e-05, global_step: 3675, interval_runtime: 0.8962, interval_samples_per_second: 44.633, interval_steps_per_second: 5.579, epoch: 5.4444\r\n",
      "loss: 0.12938881, learning_rate: 2.182e-05, global_step: 3680, interval_runtime: 1.0157, interval_samples_per_second: 39.38, interval_steps_per_second: 4.923, epoch: 5.4519\r\n",
      "loss: 0.10548468, learning_rate: 2.181e-05, global_step: 3685, interval_runtime: 0.8048, interval_samples_per_second: 49.705, interval_steps_per_second: 6.213, epoch: 5.4593\r\n",
      "loss: 0.11378074, learning_rate: 2.18e-05, global_step: 3690, interval_runtime: 0.8177, interval_samples_per_second: 48.915, interval_steps_per_second: 6.114, epoch: 5.4667\r\n",
      "loss: 0.12021725, learning_rate: 2.179e-05, global_step: 3695, interval_runtime: 0.8695, interval_samples_per_second: 46.006, interval_steps_per_second: 5.751, epoch: 5.4741\r\n",
      "loss: 0.13044305, learning_rate: 2.178e-05, global_step: 3700, interval_runtime: 0.8445, interval_samples_per_second: 47.363, interval_steps_per_second: 5.92, epoch: 5.4815\r\n",
      "loss: 0.09610025, learning_rate: 2.177e-05, global_step: 3705, interval_runtime: 0.8295, interval_samples_per_second: 48.223, interval_steps_per_second: 6.028, epoch: 5.4889\r\n",
      "loss: 0.09268065, learning_rate: 2.176e-05, global_step: 3710, interval_runtime: 0.9051, interval_samples_per_second: 44.196, interval_steps_per_second: 5.524, epoch: 5.4963\r\n",
      "loss: 0.14589137, learning_rate: 2.174e-05, global_step: 3715, interval_runtime: 0.914, interval_samples_per_second: 43.764, interval_steps_per_second: 5.47, epoch: 5.5037\r\n",
      "loss: 0.10733495, learning_rate: 2.173e-05, global_step: 3720, interval_runtime: 0.9358, interval_samples_per_second: 42.743, interval_steps_per_second: 5.343, epoch: 5.5111\r\n",
      "loss: 0.08770475, learning_rate: 2.172e-05, global_step: 3725, interval_runtime: 0.8424, interval_samples_per_second: 47.484, interval_steps_per_second: 5.936, epoch: 5.5185\r\n",
      "loss: 0.09706918, learning_rate: 2.171e-05, global_step: 3730, interval_runtime: 0.8152, interval_samples_per_second: 49.066, interval_steps_per_second: 6.133, epoch: 5.5259\r\n",
      "loss: 0.08055238, learning_rate: 2.17e-05, global_step: 3735, interval_runtime: 0.8477, interval_samples_per_second: 47.188, interval_steps_per_second: 5.899, epoch: 5.5333\r\n",
      "loss: 0.10060524, learning_rate: 2.169e-05, global_step: 3740, interval_runtime: 0.7847, interval_samples_per_second: 50.975, interval_steps_per_second: 6.372, epoch: 5.5407\r\n",
      "loss: 0.08568485, learning_rate: 2.168e-05, global_step: 3745, interval_runtime: 0.8557, interval_samples_per_second: 46.747, interval_steps_per_second: 5.843, epoch: 5.5481\r\n",
      "loss: 0.10256524, learning_rate: 2.167e-05, global_step: 3750, interval_runtime: 0.7521, interval_samples_per_second: 53.183, interval_steps_per_second: 6.648, epoch: 5.5556\r\n",
      "loss: 0.08720562, learning_rate: 2.166e-05, global_step: 3755, interval_runtime: 0.8219, interval_samples_per_second: 48.668, interval_steps_per_second: 6.084, epoch: 5.563\r\n",
      "loss: 0.07393298, learning_rate: 2.164e-05, global_step: 3760, interval_runtime: 0.8514, interval_samples_per_second: 46.982, interval_steps_per_second: 5.873, epoch: 5.5704\r\n",
      "loss: 0.11734946, learning_rate: 2.163e-05, global_step: 3765, interval_runtime: 0.7977, interval_samples_per_second: 50.142, interval_steps_per_second: 6.268, epoch: 5.5778\r\n",
      "loss: 0.06977552, learning_rate: 2.162e-05, global_step: 3770, interval_runtime: 0.709, interval_samples_per_second: 56.417, interval_steps_per_second: 7.052, epoch: 5.5852\r\n",
      "loss: 0.110238, learning_rate: 2.161e-05, global_step: 3775, interval_runtime: 0.8325, interval_samples_per_second: 48.049, interval_steps_per_second: 6.006, epoch: 5.5926\r\n",
      "loss: 0.07893896, learning_rate: 2.16e-05, global_step: 3780, interval_runtime: 0.7356, interval_samples_per_second: 54.378, interval_steps_per_second: 6.797, epoch: 5.6\r\n",
      "loss: 0.12274592, learning_rate: 2.159e-05, global_step: 3785, interval_runtime: 0.841, interval_samples_per_second: 47.563, interval_steps_per_second: 5.945, epoch: 5.6074\r\n",
      "loss: 0.1070646, learning_rate: 2.158e-05, global_step: 3790, interval_runtime: 1.0478, interval_samples_per_second: 38.176, interval_steps_per_second: 4.772, epoch: 5.6148\r\n",
      "loss: 0.0932728, learning_rate: 2.157e-05, global_step: 3795, interval_runtime: 0.8259, interval_samples_per_second: 48.433, interval_steps_per_second: 6.054, epoch: 5.6222\r\n",
      "loss: 0.09699751, learning_rate: 2.156e-05, global_step: 3800, interval_runtime: 0.8483, interval_samples_per_second: 47.154, interval_steps_per_second: 5.894, epoch: 5.6296\r\n",
      "loss: 0.12762001, learning_rate: 2.154e-05, global_step: 3805, interval_runtime: 0.8037, interval_samples_per_second: 49.767, interval_steps_per_second: 6.221, epoch: 5.637\r\n",
      "loss: 0.10232549, learning_rate: 2.153e-05, global_step: 3810, interval_runtime: 1.0351, interval_samples_per_second: 38.645, interval_steps_per_second: 4.831, epoch: 5.6444\r\n",
      "loss: 0.10986923, learning_rate: 2.152e-05, global_step: 3815, interval_runtime: 0.9038, interval_samples_per_second: 44.259, interval_steps_per_second: 5.532, epoch: 5.6519\r\n",
      "loss: 0.09726076, learning_rate: 2.151e-05, global_step: 3820, interval_runtime: 0.7822, interval_samples_per_second: 51.135, interval_steps_per_second: 6.392, epoch: 5.6593\r\n",
      "loss: 0.09154096, learning_rate: 2.15e-05, global_step: 3825, interval_runtime: 0.8079, interval_samples_per_second: 49.512, interval_steps_per_second: 6.189, epoch: 5.6667\r\n",
      "loss: 0.08360745, learning_rate: 2.149e-05, global_step: 3830, interval_runtime: 0.8137, interval_samples_per_second: 49.16, interval_steps_per_second: 6.145, epoch: 5.6741\r\n",
      "loss: 0.12354752, learning_rate: 2.148e-05, global_step: 3835, interval_runtime: 0.9, interval_samples_per_second: 44.447, interval_steps_per_second: 5.556, epoch: 5.6815\r\n",
      "loss: 0.13793921, learning_rate: 2.147e-05, global_step: 3840, interval_runtime: 0.8782, interval_samples_per_second: 45.55, interval_steps_per_second: 5.694, epoch: 5.6889\r\n",
      "loss: 0.08752387, learning_rate: 2.146e-05, global_step: 3845, interval_runtime: 0.833, interval_samples_per_second: 48.017, interval_steps_per_second: 6.002, epoch: 5.6963\r\n",
      "loss: 0.08542532, learning_rate: 2.144e-05, global_step: 3850, interval_runtime: 0.8934, interval_samples_per_second: 44.771, interval_steps_per_second: 5.596, epoch: 5.7037\r\n",
      "loss: 0.10691948, learning_rate: 2.143e-05, global_step: 3855, interval_runtime: 0.7275, interval_samples_per_second: 54.981, interval_steps_per_second: 6.873, epoch: 5.7111\r\n",
      "loss: 0.07007451, learning_rate: 2.142e-05, global_step: 3860, interval_runtime: 0.8558, interval_samples_per_second: 46.739, interval_steps_per_second: 5.842, epoch: 5.7185\r\n",
      "loss: 0.10670393, learning_rate: 2.141e-05, global_step: 3865, interval_runtime: 0.962, interval_samples_per_second: 41.579, interval_steps_per_second: 5.197, epoch: 5.7259\r\n",
      "loss: 0.1338203, learning_rate: 2.14e-05, global_step: 3870, interval_runtime: 0.8555, interval_samples_per_second: 46.754, interval_steps_per_second: 5.844, epoch: 5.7333\r\n",
      "loss: 0.0831496, learning_rate: 2.139e-05, global_step: 3875, interval_runtime: 0.9001, interval_samples_per_second: 44.44, interval_steps_per_second: 5.555, epoch: 5.7407\r\n",
      "loss: 0.10499337, learning_rate: 2.138e-05, global_step: 3880, interval_runtime: 0.7775, interval_samples_per_second: 51.444, interval_steps_per_second: 6.43, epoch: 5.7481\r\n",
      "loss: 0.12383311, learning_rate: 2.137e-05, global_step: 3885, interval_runtime: 0.8359, interval_samples_per_second: 47.851, interval_steps_per_second: 5.981, epoch: 5.7556\r\n",
      "loss: 0.09731103, learning_rate: 2.136e-05, global_step: 3890, interval_runtime: 0.8849, interval_samples_per_second: 45.204, interval_steps_per_second: 5.651, epoch: 5.763\r\n",
      "loss: 0.12375801, learning_rate: 2.134e-05, global_step: 3895, interval_runtime: 0.828, interval_samples_per_second: 48.309, interval_steps_per_second: 6.039, epoch: 5.7704\r\n",
      "loss: 0.10923097, learning_rate: 2.133e-05, global_step: 3900, interval_runtime: 0.9217, interval_samples_per_second: 43.399, interval_steps_per_second: 5.425, epoch: 5.7778\r\n",
      "loss: 0.09047814, learning_rate: 2.132e-05, global_step: 3905, interval_runtime: 0.7321, interval_samples_per_second: 54.637, interval_steps_per_second: 6.83, epoch: 5.7852\r\n",
      "loss: 0.10603096, learning_rate: 2.131e-05, global_step: 3910, interval_runtime: 0.8623, interval_samples_per_second: 46.387, interval_steps_per_second: 5.798, epoch: 5.7926\r\n",
      "loss: 0.10152457, learning_rate: 2.13e-05, global_step: 3915, interval_runtime: 0.7664, interval_samples_per_second: 52.195, interval_steps_per_second: 6.524, epoch: 5.8\r\n",
      "loss: 0.11149297, learning_rate: 2.129e-05, global_step: 3920, interval_runtime: 0.883, interval_samples_per_second: 45.3, interval_steps_per_second: 5.663, epoch: 5.8074\r\n",
      "loss: 0.13885335, learning_rate: 2.128e-05, global_step: 3925, interval_runtime: 0.9638, interval_samples_per_second: 41.503, interval_steps_per_second: 5.188, epoch: 5.8148\r\n",
      "loss: 0.07926663, learning_rate: 2.127e-05, global_step: 3930, interval_runtime: 0.8008, interval_samples_per_second: 49.952, interval_steps_per_second: 6.244, epoch: 5.8222\r\n",
      "loss: 0.09589131, learning_rate: 2.126e-05, global_step: 3935, interval_runtime: 0.9268, interval_samples_per_second: 43.157, interval_steps_per_second: 5.395, epoch: 5.8296\r\n",
      "loss: 0.07964995, learning_rate: 2.124e-05, global_step: 3940, interval_runtime: 0.764, interval_samples_per_second: 52.354, interval_steps_per_second: 6.544, epoch: 5.837\r\n",
      "loss: 0.08519264, learning_rate: 2.123e-05, global_step: 3945, interval_runtime: 0.8822, interval_samples_per_second: 45.339, interval_steps_per_second: 5.667, epoch: 5.8444\r\n",
      "loss: 0.10155089, learning_rate: 2.122e-05, global_step: 3950, interval_runtime: 0.7938, interval_samples_per_second: 50.392, interval_steps_per_second: 6.299, epoch: 5.8519\r\n",
      "loss: 0.07313583, learning_rate: 2.121e-05, global_step: 3955, interval_runtime: 0.7749, interval_samples_per_second: 51.618, interval_steps_per_second: 6.452, epoch: 5.8593\r\n",
      "loss: 0.08070831, learning_rate: 2.12e-05, global_step: 3960, interval_runtime: 0.8268, interval_samples_per_second: 48.379, interval_steps_per_second: 6.047, epoch: 5.8667\r\n",
      "loss: 0.08386002, learning_rate: 2.119e-05, global_step: 3965, interval_runtime: 0.818, interval_samples_per_second: 48.899, interval_steps_per_second: 6.112, epoch: 5.8741\r\n",
      "loss: 0.07397997, learning_rate: 2.118e-05, global_step: 3970, interval_runtime: 0.8953, interval_samples_per_second: 44.676, interval_steps_per_second: 5.584, epoch: 5.8815\r\n",
      "loss: 0.0984724, learning_rate: 2.117e-05, global_step: 3975, interval_runtime: 0.8083, interval_samples_per_second: 49.486, interval_steps_per_second: 6.186, epoch: 5.8889\r\n",
      "loss: 0.11128088, learning_rate: 2.116e-05, global_step: 3980, interval_runtime: 0.7985, interval_samples_per_second: 50.093, interval_steps_per_second: 6.262, epoch: 5.8963\r\n",
      "loss: 0.10926704, learning_rate: 2.114e-05, global_step: 3985, interval_runtime: 0.7662, interval_samples_per_second: 52.206, interval_steps_per_second: 6.526, epoch: 5.9037\r\n",
      "loss: 0.105094, learning_rate: 2.113e-05, global_step: 3990, interval_runtime: 0.7051, interval_samples_per_second: 56.729, interval_steps_per_second: 7.091, epoch: 5.9111\r\n",
      "loss: 0.11006736, learning_rate: 2.112e-05, global_step: 3995, interval_runtime: 0.8788, interval_samples_per_second: 45.516, interval_steps_per_second: 5.69, epoch: 5.9185\r\n",
      "loss: 0.10582629, learning_rate: 2.111e-05, global_step: 4000, interval_runtime: 0.8033, interval_samples_per_second: 49.796, interval_steps_per_second: 6.225, epoch: 5.9259\r\n",
      "loss: 0.11232973, learning_rate: 2.11e-05, global_step: 4005, interval_runtime: 0.8398, interval_samples_per_second: 47.633, interval_steps_per_second: 5.954, epoch: 5.9333\r\n",
      "loss: 0.0989403, learning_rate: 2.109e-05, global_step: 4010, interval_runtime: 1.0105, interval_samples_per_second: 39.586, interval_steps_per_second: 4.948, epoch: 5.9407\r\n",
      "loss: 0.08940114, learning_rate: 2.108e-05, global_step: 4015, interval_runtime: 0.7832, interval_samples_per_second: 51.075, interval_steps_per_second: 6.384, epoch: 5.9481\r\n",
      "loss: 0.08085928, learning_rate: 2.107e-05, global_step: 4020, interval_runtime: 0.8048, interval_samples_per_second: 49.702, interval_steps_per_second: 6.213, epoch: 5.9556\r\n",
      "loss: 0.15836306, learning_rate: 2.106e-05, global_step: 4025, interval_runtime: 0.8889, interval_samples_per_second: 44.999, interval_steps_per_second: 5.625, epoch: 5.963\r\n",
      "loss: 0.11094257, learning_rate: 2.104e-05, global_step: 4030, interval_runtime: 0.8029, interval_samples_per_second: 49.818, interval_steps_per_second: 6.227, epoch: 5.9704\r\n",
      "loss: 0.07610014, learning_rate: 2.103e-05, global_step: 4035, interval_runtime: 0.8494, interval_samples_per_second: 47.095, interval_steps_per_second: 5.887, epoch: 5.9778\r\n",
      "loss: 0.1432875, learning_rate: 2.102e-05, global_step: 4040, interval_runtime: 0.6962, interval_samples_per_second: 57.453, interval_steps_per_second: 7.182, epoch: 5.9852\r\n",
      "loss: 0.11963174, learning_rate: 2.101e-05, global_step: 4045, interval_runtime: 0.8862, interval_samples_per_second: 45.135, interval_steps_per_second: 5.642, epoch: 5.9926\r\n",
      "loss: 0.10313182, learning_rate: 2.1e-05, global_step: 4050, interval_runtime: 0.7781, interval_samples_per_second: 51.408, interval_steps_per_second: 6.426, epoch: 6.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:51:49,636] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:51:49,639] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:51:49,641] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:51:49,643] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:51:49,645] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.47779902815818787, eval_micro_f1_score: 0.5581239530988276, eval_macro_f1_score: 0.4514080436529209, eval_runtime: 13.5578, eval_samples_per_second: 139.846, eval_steps_per_second: 17.481, epoch: 6.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:52:03,200] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-4050\r\n",
      "[2023-01-10 10:52:03,204] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:52:06,585] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-4050/tokenizer_config.json\r\n",
      "[2023-01-10 10:52:06,588] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-4050/special_tokens_map.json\r\n",
      "[2023-01-10 10:52:13,315] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-2700] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.09180706, learning_rate: 2.099e-05, global_step: 4055, interval_runtime: 25.3498, interval_samples_per_second: 1.578, interval_steps_per_second: 0.197, epoch: 6.0074\r\n",
      "loss: 0.0755252, learning_rate: 2.098e-05, global_step: 4060, interval_runtime: 0.7209, interval_samples_per_second: 55.489, interval_steps_per_second: 6.936, epoch: 6.0148\r\n",
      "loss: 0.06527491, learning_rate: 2.097e-05, global_step: 4065, interval_runtime: 0.9565, interval_samples_per_second: 41.818, interval_steps_per_second: 5.227, epoch: 6.0222\r\n",
      "loss: 0.07864873, learning_rate: 2.096e-05, global_step: 4070, interval_runtime: 0.8538, interval_samples_per_second: 46.847, interval_steps_per_second: 5.856, epoch: 6.0296\r\n",
      "loss: 0.05747454, learning_rate: 2.094e-05, global_step: 4075, interval_runtime: 0.8433, interval_samples_per_second: 47.434, interval_steps_per_second: 5.929, epoch: 6.037\r\n",
      "loss: 0.05860224, learning_rate: 2.093e-05, global_step: 4080, interval_runtime: 0.7265, interval_samples_per_second: 55.057, interval_steps_per_second: 6.882, epoch: 6.0444\r\n",
      "loss: 0.07916916, learning_rate: 2.092e-05, global_step: 4085, interval_runtime: 0.8047, interval_samples_per_second: 49.708, interval_steps_per_second: 6.213, epoch: 6.0519\r\n",
      "loss: 0.07829662, learning_rate: 2.091e-05, global_step: 4090, interval_runtime: 0.9871, interval_samples_per_second: 40.524, interval_steps_per_second: 5.065, epoch: 6.0593\r\n",
      "loss: 0.07359472, learning_rate: 2.09e-05, global_step: 4095, interval_runtime: 0.7511, interval_samples_per_second: 53.257, interval_steps_per_second: 6.657, epoch: 6.0667\r\n",
      "loss: 0.06786321, learning_rate: 2.089e-05, global_step: 4100, interval_runtime: 0.8735, interval_samples_per_second: 45.794, interval_steps_per_second: 5.724, epoch: 6.0741\r\n",
      "loss: 0.06628804, learning_rate: 2.088e-05, global_step: 4105, interval_runtime: 0.8448, interval_samples_per_second: 47.346, interval_steps_per_second: 5.918, epoch: 6.0815\r\n",
      "loss: 0.06351366, learning_rate: 2.087e-05, global_step: 4110, interval_runtime: 0.8285, interval_samples_per_second: 48.278, interval_steps_per_second: 6.035, epoch: 6.0889\r\n",
      "loss: 0.04855048, learning_rate: 2.086e-05, global_step: 4115, interval_runtime: 0.8284, interval_samples_per_second: 48.287, interval_steps_per_second: 6.036, epoch: 6.0963\r\n",
      "loss: 0.06669831, learning_rate: 2.084e-05, global_step: 4120, interval_runtime: 0.8296, interval_samples_per_second: 48.218, interval_steps_per_second: 6.027, epoch: 6.1037\r\n",
      "loss: 0.0657219, learning_rate: 2.083e-05, global_step: 4125, interval_runtime: 0.8335, interval_samples_per_second: 47.991, interval_steps_per_second: 5.999, epoch: 6.1111\r\n",
      "loss: 0.05099083, learning_rate: 2.082e-05, global_step: 4130, interval_runtime: 0.7548, interval_samples_per_second: 52.993, interval_steps_per_second: 6.624, epoch: 6.1185\r\n",
      "loss: 0.07214692, learning_rate: 2.081e-05, global_step: 4135, interval_runtime: 0.8274, interval_samples_per_second: 48.342, interval_steps_per_second: 6.043, epoch: 6.1259\r\n",
      "loss: 0.06926756, learning_rate: 2.08e-05, global_step: 4140, interval_runtime: 0.9764, interval_samples_per_second: 40.968, interval_steps_per_second: 5.121, epoch: 6.1333\r\n",
      "loss: 0.07768636, learning_rate: 2.079e-05, global_step: 4145, interval_runtime: 0.9121, interval_samples_per_second: 43.853, interval_steps_per_second: 5.482, epoch: 6.1407\r\n",
      "loss: 0.07974789, learning_rate: 2.078e-05, global_step: 4150, interval_runtime: 0.7247, interval_samples_per_second: 55.195, interval_steps_per_second: 6.899, epoch: 6.1481\r\n",
      "loss: 0.06602055, learning_rate: 2.077e-05, global_step: 4155, interval_runtime: 0.9564, interval_samples_per_second: 41.825, interval_steps_per_second: 5.228, epoch: 6.1556\r\n",
      "loss: 0.06098346, learning_rate: 2.076e-05, global_step: 4160, interval_runtime: 0.9028, interval_samples_per_second: 44.306, interval_steps_per_second: 5.538, epoch: 6.163\r\n",
      "loss: 0.06627498, learning_rate: 2.074e-05, global_step: 4165, interval_runtime: 1.0315, interval_samples_per_second: 38.777, interval_steps_per_second: 4.847, epoch: 6.1704\r\n",
      "loss: 0.0715277, learning_rate: 2.073e-05, global_step: 4170, interval_runtime: 0.8113, interval_samples_per_second: 49.303, interval_steps_per_second: 6.163, epoch: 6.1778\r\n",
      "loss: 0.06521139, learning_rate: 2.072e-05, global_step: 4175, interval_runtime: 0.7503, interval_samples_per_second: 53.315, interval_steps_per_second: 6.664, epoch: 6.1852\r\n",
      "loss: 0.06594623, learning_rate: 2.071e-05, global_step: 4180, interval_runtime: 0.8129, interval_samples_per_second: 49.206, interval_steps_per_second: 6.151, epoch: 6.1926\r\n",
      "loss: 0.05311655, learning_rate: 2.07e-05, global_step: 4185, interval_runtime: 0.9449, interval_samples_per_second: 42.333, interval_steps_per_second: 5.292, epoch: 6.2\r\n",
      "loss: 0.04747464, learning_rate: 2.069e-05, global_step: 4190, interval_runtime: 0.8771, interval_samples_per_second: 45.605, interval_steps_per_second: 5.701, epoch: 6.2074\r\n",
      "loss: 0.05175985, learning_rate: 2.068e-05, global_step: 4195, interval_runtime: 0.988, interval_samples_per_second: 40.484, interval_steps_per_second: 5.061, epoch: 6.2148\r\n",
      "loss: 0.04357125, learning_rate: 2.067e-05, global_step: 4200, interval_runtime: 1.1024, interval_samples_per_second: 36.285, interval_steps_per_second: 4.536, epoch: 6.2222\r\n",
      "loss: 0.07206798, learning_rate: 2.066e-05, global_step: 4205, interval_runtime: 0.7768, interval_samples_per_second: 51.496, interval_steps_per_second: 6.437, epoch: 6.2296\r\n",
      "loss: 0.08781389, learning_rate: 2.064e-05, global_step: 4210, interval_runtime: 0.8111, interval_samples_per_second: 49.314, interval_steps_per_second: 6.164, epoch: 6.237\r\n",
      "loss: 0.05356451, learning_rate: 2.063e-05, global_step: 4215, interval_runtime: 0.8775, interval_samples_per_second: 45.587, interval_steps_per_second: 5.698, epoch: 6.2444\r\n",
      "loss: 0.05584081, learning_rate: 2.062e-05, global_step: 4220, interval_runtime: 0.804, interval_samples_per_second: 49.75, interval_steps_per_second: 6.219, epoch: 6.2519\r\n",
      "loss: 0.05247471, learning_rate: 2.061e-05, global_step: 4225, interval_runtime: 0.9288, interval_samples_per_second: 43.068, interval_steps_per_second: 5.383, epoch: 6.2593\r\n",
      "loss: 0.07238373, learning_rate: 2.06e-05, global_step: 4230, interval_runtime: 0.9257, interval_samples_per_second: 43.208, interval_steps_per_second: 5.401, epoch: 6.2667\r\n",
      "loss: 0.08299299, learning_rate: 2.059e-05, global_step: 4235, interval_runtime: 0.8878, interval_samples_per_second: 45.054, interval_steps_per_second: 5.632, epoch: 6.2741\r\n",
      "loss: 0.0645427, learning_rate: 2.058e-05, global_step: 4240, interval_runtime: 0.7514, interval_samples_per_second: 53.232, interval_steps_per_second: 6.654, epoch: 6.2815\r\n",
      "loss: 0.0521795, learning_rate: 2.057e-05, global_step: 4245, interval_runtime: 0.7817, interval_samples_per_second: 51.171, interval_steps_per_second: 6.396, epoch: 6.2889\r\n",
      "loss: 0.05105258, learning_rate: 2.056e-05, global_step: 4250, interval_runtime: 0.8189, interval_samples_per_second: 48.845, interval_steps_per_second: 6.106, epoch: 6.2963\r\n",
      "loss: 0.06390302, learning_rate: 2.054e-05, global_step: 4255, interval_runtime: 0.8203, interval_samples_per_second: 48.762, interval_steps_per_second: 6.095, epoch: 6.3037\r\n",
      "loss: 0.06090382, learning_rate: 2.053e-05, global_step: 4260, interval_runtime: 0.9059, interval_samples_per_second: 44.153, interval_steps_per_second: 5.519, epoch: 6.3111\r\n",
      "loss: 0.0578099, learning_rate: 2.052e-05, global_step: 4265, interval_runtime: 0.8706, interval_samples_per_second: 45.946, interval_steps_per_second: 5.743, epoch: 6.3185\r\n",
      "loss: 0.04065579, learning_rate: 2.051e-05, global_step: 4270, interval_runtime: 0.823, interval_samples_per_second: 48.603, interval_steps_per_second: 6.075, epoch: 6.3259\r\n",
      "loss: 0.07406659, learning_rate: 2.05e-05, global_step: 4275, interval_runtime: 0.8774, interval_samples_per_second: 45.588, interval_steps_per_second: 5.699, epoch: 6.3333\r\n",
      "loss: 0.04892381, learning_rate: 2.049e-05, global_step: 4280, interval_runtime: 0.7994, interval_samples_per_second: 50.036, interval_steps_per_second: 6.255, epoch: 6.3407\r\n",
      "loss: 0.06636546, learning_rate: 2.048e-05, global_step: 4285, interval_runtime: 0.8739, interval_samples_per_second: 45.774, interval_steps_per_second: 5.722, epoch: 6.3481\r\n",
      "loss: 0.07342097, learning_rate: 2.047e-05, global_step: 4290, interval_runtime: 0.7515, interval_samples_per_second: 53.226, interval_steps_per_second: 6.653, epoch: 6.3556\r\n",
      "loss: 0.07645309, learning_rate: 2.046e-05, global_step: 4295, interval_runtime: 0.8059, interval_samples_per_second: 49.634, interval_steps_per_second: 6.204, epoch: 6.363\r\n",
      "loss: 0.07233262, learning_rate: 2.044e-05, global_step: 4300, interval_runtime: 0.9939, interval_samples_per_second: 40.244, interval_steps_per_second: 5.031, epoch: 6.3704\r\n",
      "loss: 0.05643882, learning_rate: 2.043e-05, global_step: 4305, interval_runtime: 0.7522, interval_samples_per_second: 53.178, interval_steps_per_second: 6.647, epoch: 6.3778\r\n",
      "loss: 0.05449097, learning_rate: 2.042e-05, global_step: 4310, interval_runtime: 0.7335, interval_samples_per_second: 54.535, interval_steps_per_second: 6.817, epoch: 6.3852\r\n",
      "loss: 0.08908437, learning_rate: 2.041e-05, global_step: 4315, interval_runtime: 0.8566, interval_samples_per_second: 46.697, interval_steps_per_second: 5.837, epoch: 6.3926\r\n",
      "loss: 0.07950405, learning_rate: 2.04e-05, global_step: 4320, interval_runtime: 0.804, interval_samples_per_second: 49.75, interval_steps_per_second: 6.219, epoch: 6.4\r\n",
      "loss: 0.06284208, learning_rate: 2.039e-05, global_step: 4325, interval_runtime: 0.8134, interval_samples_per_second: 49.176, interval_steps_per_second: 6.147, epoch: 6.4074\r\n",
      "loss: 0.07134178, learning_rate: 2.038e-05, global_step: 4330, interval_runtime: 0.8344, interval_samples_per_second: 47.939, interval_steps_per_second: 5.992, epoch: 6.4148\r\n",
      "loss: 0.05891594, learning_rate: 2.037e-05, global_step: 4335, interval_runtime: 0.8429, interval_samples_per_second: 47.454, interval_steps_per_second: 5.932, epoch: 6.4222\r\n",
      "loss: 0.06236061, learning_rate: 2.036e-05, global_step: 4340, interval_runtime: 0.7351, interval_samples_per_second: 54.417, interval_steps_per_second: 6.802, epoch: 6.4296\r\n",
      "loss: 0.08582425, learning_rate: 2.034e-05, global_step: 4345, interval_runtime: 0.7722, interval_samples_per_second: 51.802, interval_steps_per_second: 6.475, epoch: 6.437\r\n",
      "loss: 0.09009312, learning_rate: 2.033e-05, global_step: 4350, interval_runtime: 0.9336, interval_samples_per_second: 42.843, interval_steps_per_second: 5.355, epoch: 6.4444\r\n",
      "loss: 0.06246753, learning_rate: 2.032e-05, global_step: 4355, interval_runtime: 0.9077, interval_samples_per_second: 44.069, interval_steps_per_second: 5.509, epoch: 6.4519\r\n",
      "loss: 0.07946934, learning_rate: 2.031e-05, global_step: 4360, interval_runtime: 0.8209, interval_samples_per_second: 48.73, interval_steps_per_second: 6.091, epoch: 6.4593\r\n",
      "loss: 0.0556677, learning_rate: 2.03e-05, global_step: 4365, interval_runtime: 0.808, interval_samples_per_second: 49.503, interval_steps_per_second: 6.188, epoch: 6.4667\r\n",
      "loss: 0.0660467, learning_rate: 2.029e-05, global_step: 4370, interval_runtime: 0.7873, interval_samples_per_second: 50.806, interval_steps_per_second: 6.351, epoch: 6.4741\r\n",
      "loss: 0.05770767, learning_rate: 2.028e-05, global_step: 4375, interval_runtime: 0.7946, interval_samples_per_second: 50.341, interval_steps_per_second: 6.293, epoch: 6.4815\r\n",
      "loss: 0.05386708, learning_rate: 2.027e-05, global_step: 4380, interval_runtime: 0.8994, interval_samples_per_second: 44.472, interval_steps_per_second: 5.559, epoch: 6.4889\r\n",
      "loss: 0.07952014, learning_rate: 2.026e-05, global_step: 4385, interval_runtime: 0.8144, interval_samples_per_second: 49.114, interval_steps_per_second: 6.139, epoch: 6.4963\r\n",
      "loss: 0.05179778, learning_rate: 2.024e-05, global_step: 4390, interval_runtime: 0.815, interval_samples_per_second: 49.077, interval_steps_per_second: 6.135, epoch: 6.5037\r\n",
      "loss: 0.08857502, learning_rate: 2.023e-05, global_step: 4395, interval_runtime: 0.7697, interval_samples_per_second: 51.965, interval_steps_per_second: 6.496, epoch: 6.5111\r\n",
      "loss: 0.10852373, learning_rate: 2.022e-05, global_step: 4400, interval_runtime: 0.933, interval_samples_per_second: 42.87, interval_steps_per_second: 5.359, epoch: 6.5185\r\n",
      "loss: 0.06016526, learning_rate: 2.021e-05, global_step: 4405, interval_runtime: 0.755, interval_samples_per_second: 52.983, interval_steps_per_second: 6.623, epoch: 6.5259\r\n",
      "loss: 0.05310414, learning_rate: 2.02e-05, global_step: 4410, interval_runtime: 0.797, interval_samples_per_second: 50.19, interval_steps_per_second: 6.274, epoch: 6.5333\r\n",
      "loss: 0.07773744, learning_rate: 2.019e-05, global_step: 4415, interval_runtime: 0.8257, interval_samples_per_second: 48.444, interval_steps_per_second: 6.055, epoch: 6.5407\r\n",
      "loss: 0.06078762, learning_rate: 2.018e-05, global_step: 4420, interval_runtime: 0.9222, interval_samples_per_second: 43.375, interval_steps_per_second: 5.422, epoch: 6.5481\r\n",
      "loss: 0.0755127, learning_rate: 2.017e-05, global_step: 4425, interval_runtime: 0.905, interval_samples_per_second: 44.199, interval_steps_per_second: 5.525, epoch: 6.5556\r\n",
      "loss: 0.0937277, learning_rate: 2.016e-05, global_step: 4430, interval_runtime: 0.8582, interval_samples_per_second: 46.609, interval_steps_per_second: 5.826, epoch: 6.563\r\n",
      "loss: 0.07335509, learning_rate: 2.014e-05, global_step: 4435, interval_runtime: 0.9223, interval_samples_per_second: 43.369, interval_steps_per_second: 5.421, epoch: 6.5704\r\n",
      "loss: 0.06940966, learning_rate: 2.013e-05, global_step: 4440, interval_runtime: 0.8008, interval_samples_per_second: 49.949, interval_steps_per_second: 6.244, epoch: 6.5778\r\n",
      "loss: 0.06228377, learning_rate: 2.012e-05, global_step: 4445, interval_runtime: 0.7174, interval_samples_per_second: 55.754, interval_steps_per_second: 6.969, epoch: 6.5852\r\n",
      "loss: 0.0622384, learning_rate: 2.011e-05, global_step: 4450, interval_runtime: 0.8319, interval_samples_per_second: 48.082, interval_steps_per_second: 6.01, epoch: 6.5926\r\n",
      "loss: 0.06035618, learning_rate: 2.01e-05, global_step: 4455, interval_runtime: 0.9054, interval_samples_per_second: 44.179, interval_steps_per_second: 5.522, epoch: 6.6\r\n",
      "loss: 0.12284665, learning_rate: 2.009e-05, global_step: 4460, interval_runtime: 0.9162, interval_samples_per_second: 43.66, interval_steps_per_second: 5.457, epoch: 6.6074\r\n",
      "loss: 0.06608582, learning_rate: 2.008e-05, global_step: 4465, interval_runtime: 0.8038, interval_samples_per_second: 49.761, interval_steps_per_second: 6.22, epoch: 6.6148\r\n",
      "loss: 0.0578979, learning_rate: 2.007e-05, global_step: 4470, interval_runtime: 0.6866, interval_samples_per_second: 58.257, interval_steps_per_second: 7.282, epoch: 6.6222\r\n",
      "loss: 0.05645869, learning_rate: 2.006e-05, global_step: 4475, interval_runtime: 0.7285, interval_samples_per_second: 54.906, interval_steps_per_second: 6.863, epoch: 6.6296\r\n",
      "loss: 0.07408701, learning_rate: 2.004e-05, global_step: 4480, interval_runtime: 0.8584, interval_samples_per_second: 46.597, interval_steps_per_second: 5.825, epoch: 6.637\r\n",
      "loss: 0.08405635, learning_rate: 2.003e-05, global_step: 4485, interval_runtime: 0.8288, interval_samples_per_second: 48.263, interval_steps_per_second: 6.033, epoch: 6.6444\r\n",
      "loss: 0.08796346, learning_rate: 2.002e-05, global_step: 4490, interval_runtime: 0.8907, interval_samples_per_second: 44.908, interval_steps_per_second: 5.614, epoch: 6.6519\r\n",
      "loss: 0.07605867, learning_rate: 2.001e-05, global_step: 4495, interval_runtime: 0.7772, interval_samples_per_second: 51.468, interval_steps_per_second: 6.433, epoch: 6.6593\r\n",
      "loss: 0.05181084, learning_rate: 2e-05, global_step: 4500, interval_runtime: 0.8585, interval_samples_per_second: 46.593, interval_steps_per_second: 5.824, epoch: 6.6667\r\n",
      "loss: 0.08338159, learning_rate: 1.999e-05, global_step: 4505, interval_runtime: 0.7492, interval_samples_per_second: 53.393, interval_steps_per_second: 6.674, epoch: 6.6741\r\n",
      "loss: 0.07985007, learning_rate: 1.998e-05, global_step: 4510, interval_runtime: 0.9718, interval_samples_per_second: 41.162, interval_steps_per_second: 5.145, epoch: 6.6815\r\n",
      "loss: 0.08536121, learning_rate: 1.997e-05, global_step: 4515, interval_runtime: 0.9047, interval_samples_per_second: 44.212, interval_steps_per_second: 5.527, epoch: 6.6889\r\n",
      "loss: 0.08001161, learning_rate: 1.996e-05, global_step: 4520, interval_runtime: 0.7839, interval_samples_per_second: 51.027, interval_steps_per_second: 6.378, epoch: 6.6963\r\n",
      "loss: 0.09257239, learning_rate: 1.994e-05, global_step: 4525, interval_runtime: 0.7846, interval_samples_per_second: 50.98, interval_steps_per_second: 6.373, epoch: 6.7037\r\n",
      "loss: 0.06280038, learning_rate: 1.993e-05, global_step: 4530, interval_runtime: 0.806, interval_samples_per_second: 49.627, interval_steps_per_second: 6.203, epoch: 6.7111\r\n",
      "loss: 0.09654757, learning_rate: 1.992e-05, global_step: 4535, interval_runtime: 0.8063, interval_samples_per_second: 49.608, interval_steps_per_second: 6.201, epoch: 6.7185\r\n",
      "loss: 0.0937472, learning_rate: 1.991e-05, global_step: 4540, interval_runtime: 0.8719, interval_samples_per_second: 45.874, interval_steps_per_second: 5.734, epoch: 6.7259\r\n",
      "loss: 0.06266488, learning_rate: 1.99e-05, global_step: 4545, interval_runtime: 0.7841, interval_samples_per_second: 51.016, interval_steps_per_second: 6.377, epoch: 6.7333\r\n",
      "loss: 0.10116845, learning_rate: 1.989e-05, global_step: 4550, interval_runtime: 0.988, interval_samples_per_second: 40.485, interval_steps_per_second: 5.061, epoch: 6.7407\r\n",
      "loss: 0.06172, learning_rate: 1.988e-05, global_step: 4555, interval_runtime: 0.7577, interval_samples_per_second: 52.793, interval_steps_per_second: 6.599, epoch: 6.7481\r\n",
      "loss: 0.05923375, learning_rate: 1.987e-05, global_step: 4560, interval_runtime: 0.7294, interval_samples_per_second: 54.843, interval_steps_per_second: 6.855, epoch: 6.7556\r\n",
      "loss: 0.0697484, learning_rate: 1.986e-05, global_step: 4565, interval_runtime: 0.802, interval_samples_per_second: 49.875, interval_steps_per_second: 6.234, epoch: 6.763\r\n",
      "loss: 0.05975636, learning_rate: 1.984e-05, global_step: 4570, interval_runtime: 0.7309, interval_samples_per_second: 54.725, interval_steps_per_second: 6.841, epoch: 6.7704\r\n",
      "loss: 0.08168069, learning_rate: 1.983e-05, global_step: 4575, interval_runtime: 0.8746, interval_samples_per_second: 45.734, interval_steps_per_second: 5.717, epoch: 6.7778\r\n",
      "loss: 0.09605941, learning_rate: 1.982e-05, global_step: 4580, interval_runtime: 0.9112, interval_samples_per_second: 43.9, interval_steps_per_second: 5.487, epoch: 6.7852\r\n",
      "loss: 0.06598436, learning_rate: 1.981e-05, global_step: 4585, interval_runtime: 0.8502, interval_samples_per_second: 47.047, interval_steps_per_second: 5.881, epoch: 6.7926\r\n",
      "loss: 0.05285387, learning_rate: 1.98e-05, global_step: 4590, interval_runtime: 0.7948, interval_samples_per_second: 50.328, interval_steps_per_second: 6.291, epoch: 6.8\r\n",
      "loss: 0.11993836, learning_rate: 1.979e-05, global_step: 4595, interval_runtime: 0.7925, interval_samples_per_second: 50.475, interval_steps_per_second: 6.309, epoch: 6.8074\r\n",
      "loss: 0.06554799, learning_rate: 1.978e-05, global_step: 4600, interval_runtime: 0.9703, interval_samples_per_second: 41.223, interval_steps_per_second: 5.153, epoch: 6.8148\r\n",
      "loss: 0.08219352, learning_rate: 1.977e-05, global_step: 4605, interval_runtime: 0.8693, interval_samples_per_second: 46.014, interval_steps_per_second: 5.752, epoch: 6.8222\r\n",
      "loss: 0.072487, learning_rate: 1.976e-05, global_step: 4610, interval_runtime: 0.8133, interval_samples_per_second: 49.182, interval_steps_per_second: 6.148, epoch: 6.8296\r\n",
      "loss: 0.09236345, learning_rate: 1.974e-05, global_step: 4615, interval_runtime: 0.7791, interval_samples_per_second: 51.343, interval_steps_per_second: 6.418, epoch: 6.837\r\n",
      "loss: 0.06473207, learning_rate: 1.973e-05, global_step: 4620, interval_runtime: 0.8634, interval_samples_per_second: 46.327, interval_steps_per_second: 5.791, epoch: 6.8444\r\n",
      "loss: 0.06088334, learning_rate: 1.972e-05, global_step: 4625, interval_runtime: 0.8204, interval_samples_per_second: 48.756, interval_steps_per_second: 6.094, epoch: 6.8519\r\n",
      "loss: 0.07166115, learning_rate: 1.971e-05, global_step: 4630, interval_runtime: 0.965, interval_samples_per_second: 41.449, interval_steps_per_second: 5.181, epoch: 6.8593\r\n",
      "loss: 0.07789309, learning_rate: 1.97e-05, global_step: 4635, interval_runtime: 0.9972, interval_samples_per_second: 40.113, interval_steps_per_second: 5.014, epoch: 6.8667\r\n",
      "loss: 0.06759238, learning_rate: 1.969e-05, global_step: 4640, interval_runtime: 0.8179, interval_samples_per_second: 48.909, interval_steps_per_second: 6.114, epoch: 6.8741\r\n",
      "loss: 0.07957141, learning_rate: 1.968e-05, global_step: 4645, interval_runtime: 0.8154, interval_samples_per_second: 49.058, interval_steps_per_second: 6.132, epoch: 6.8815\r\n",
      "loss: 0.07574176, learning_rate: 1.967e-05, global_step: 4650, interval_runtime: 0.9195, interval_samples_per_second: 43.503, interval_steps_per_second: 5.438, epoch: 6.8889\r\n",
      "loss: 0.07757843, learning_rate: 1.966e-05, global_step: 4655, interval_runtime: 0.9742, interval_samples_per_second: 41.061, interval_steps_per_second: 5.133, epoch: 6.8963\r\n",
      "loss: 0.08599154, learning_rate: 1.964e-05, global_step: 4660, interval_runtime: 1.0482, interval_samples_per_second: 38.159, interval_steps_per_second: 4.77, epoch: 6.9037\r\n",
      "loss: 0.05916258, learning_rate: 1.963e-05, global_step: 4665, interval_runtime: 0.8352, interval_samples_per_second: 47.895, interval_steps_per_second: 5.987, epoch: 6.9111\r\n",
      "loss: 0.04656446, learning_rate: 1.962e-05, global_step: 4670, interval_runtime: 0.9046, interval_samples_per_second: 44.217, interval_steps_per_second: 5.527, epoch: 6.9185\r\n",
      "loss: 0.08143228, learning_rate: 1.961e-05, global_step: 4675, interval_runtime: 0.8994, interval_samples_per_second: 44.476, interval_steps_per_second: 5.56, epoch: 6.9259\r\n",
      "loss: 0.04907167, learning_rate: 1.96e-05, global_step: 4680, interval_runtime: 1.0922, interval_samples_per_second: 36.622, interval_steps_per_second: 4.578, epoch: 6.9333\r\n",
      "loss: 0.04918755, learning_rate: 1.959e-05, global_step: 4685, interval_runtime: 0.9049, interval_samples_per_second: 44.205, interval_steps_per_second: 5.526, epoch: 6.9407\r\n",
      "loss: 0.04928976, learning_rate: 1.958e-05, global_step: 4690, interval_runtime: 0.8414, interval_samples_per_second: 47.542, interval_steps_per_second: 5.943, epoch: 6.9481\r\n",
      "loss: 0.07346287, learning_rate: 1.957e-05, global_step: 4695, interval_runtime: 0.7826, interval_samples_per_second: 51.11, interval_steps_per_second: 6.389, epoch: 6.9556\r\n",
      "loss: 0.06217253, learning_rate: 1.956e-05, global_step: 4700, interval_runtime: 0.8725, interval_samples_per_second: 45.847, interval_steps_per_second: 5.731, epoch: 6.963\r\n",
      "loss: 0.05590104, learning_rate: 1.954e-05, global_step: 4705, interval_runtime: 0.786, interval_samples_per_second: 50.889, interval_steps_per_second: 6.361, epoch: 6.9704\r\n",
      "loss: 0.04369442, learning_rate: 1.953e-05, global_step: 4710, interval_runtime: 0.82, interval_samples_per_second: 48.782, interval_steps_per_second: 6.098, epoch: 6.9778\r\n",
      "loss: 0.09027849, learning_rate: 1.952e-05, global_step: 4715, interval_runtime: 0.846, interval_samples_per_second: 47.282, interval_steps_per_second: 5.91, epoch: 6.9852\r\n",
      "loss: 0.07330096, learning_rate: 1.951e-05, global_step: 4720, interval_runtime: 0.7658, interval_samples_per_second: 52.23, interval_steps_per_second: 6.529, epoch: 6.9926\r\n",
      "loss: 0.0483995, learning_rate: 1.95e-05, global_step: 4725, interval_runtime: 0.6977, interval_samples_per_second: 57.332, interval_steps_per_second: 7.167, epoch: 7.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:54:08,342] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:54:08,345] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:54:08,347] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:54:08,350] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:54:08,352] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.5402079820632935, eval_micro_f1_score: 0.5688695231178891, eval_macro_f1_score: 0.4594610313272208, eval_runtime: 13.4664, eval_samples_per_second: 140.795, eval_steps_per_second: 17.599, epoch: 7.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:54:21,814] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-4725\r\n",
      "[2023-01-10 10:54:21,818] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:54:25,206] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-4725/tokenizer_config.json\r\n",
      "[2023-01-10 10:54:25,210] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-4725/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.03994828, learning_rate: 1.949e-05, global_step: 4730, interval_runtime: 24.5949, interval_samples_per_second: 1.626, interval_steps_per_second: 0.203, epoch: 7.0074\r\n",
      "loss: 0.0646824, learning_rate: 1.948e-05, global_step: 4735, interval_runtime: 0.9077, interval_samples_per_second: 44.068, interval_steps_per_second: 5.508, epoch: 7.0148\r\n",
      "loss: 0.04042675, learning_rate: 1.947e-05, global_step: 4740, interval_runtime: 0.8332, interval_samples_per_second: 48.007, interval_steps_per_second: 6.001, epoch: 7.0222\r\n",
      "loss: 0.03297619, learning_rate: 1.946e-05, global_step: 4745, interval_runtime: 0.6825, interval_samples_per_second: 58.612, interval_steps_per_second: 7.327, epoch: 7.0296\r\n",
      "loss: 0.06960095, learning_rate: 1.944e-05, global_step: 4750, interval_runtime: 0.8032, interval_samples_per_second: 49.801, interval_steps_per_second: 6.225, epoch: 7.037\r\n",
      "loss: 0.05387878, learning_rate: 1.943e-05, global_step: 4755, interval_runtime: 0.8663, interval_samples_per_second: 46.172, interval_steps_per_second: 5.772, epoch: 7.0444\r\n",
      "loss: 0.04260097, learning_rate: 1.942e-05, global_step: 4760, interval_runtime: 0.8867, interval_samples_per_second: 45.111, interval_steps_per_second: 5.639, epoch: 7.0519\r\n",
      "loss: 0.04774262, learning_rate: 1.941e-05, global_step: 4765, interval_runtime: 0.818, interval_samples_per_second: 48.9, interval_steps_per_second: 6.113, epoch: 7.0593\r\n",
      "loss: 0.05141277, learning_rate: 1.94e-05, global_step: 4770, interval_runtime: 0.777, interval_samples_per_second: 51.478, interval_steps_per_second: 6.435, epoch: 7.0667\r\n",
      "loss: 0.03584124, learning_rate: 1.939e-05, global_step: 4775, interval_runtime: 0.7311, interval_samples_per_second: 54.711, interval_steps_per_second: 6.839, epoch: 7.0741\r\n",
      "loss: 0.04085315, learning_rate: 1.938e-05, global_step: 4780, interval_runtime: 0.9348, interval_samples_per_second: 42.792, interval_steps_per_second: 5.349, epoch: 7.0815\r\n",
      "loss: 0.02381654, learning_rate: 1.937e-05, global_step: 4785, interval_runtime: 0.9669, interval_samples_per_second: 41.368, interval_steps_per_second: 5.171, epoch: 7.0889\r\n",
      "loss: 0.04333158, learning_rate: 1.936e-05, global_step: 4790, interval_runtime: 0.919, interval_samples_per_second: 43.526, interval_steps_per_second: 5.441, epoch: 7.0963\r\n",
      "loss: 0.04548098, learning_rate: 1.934e-05, global_step: 4795, interval_runtime: 0.9083, interval_samples_per_second: 44.039, interval_steps_per_second: 5.505, epoch: 7.1037\r\n",
      "loss: 0.03525935, learning_rate: 1.933e-05, global_step: 4800, interval_runtime: 0.812, interval_samples_per_second: 49.261, interval_steps_per_second: 6.158, epoch: 7.1111\r\n",
      "loss: 0.0471778, learning_rate: 1.932e-05, global_step: 4805, interval_runtime: 0.8125, interval_samples_per_second: 49.231, interval_steps_per_second: 6.154, epoch: 7.1185\r\n",
      "loss: 0.04598796, learning_rate: 1.931e-05, global_step: 4810, interval_runtime: 0.8123, interval_samples_per_second: 49.24, interval_steps_per_second: 6.155, epoch: 7.1259\r\n",
      "loss: 0.02963116, learning_rate: 1.93e-05, global_step: 4815, interval_runtime: 0.967, interval_samples_per_second: 41.364, interval_steps_per_second: 5.17, epoch: 7.1333\r\n",
      "loss: 0.05149407, learning_rate: 1.929e-05, global_step: 4820, interval_runtime: 0.8977, interval_samples_per_second: 44.556, interval_steps_per_second: 5.57, epoch: 7.1407\r\n",
      "loss: 0.04845921, learning_rate: 1.928e-05, global_step: 4825, interval_runtime: 0.7883, interval_samples_per_second: 50.743, interval_steps_per_second: 6.343, epoch: 7.1481\r\n",
      "loss: 0.05432967, learning_rate: 1.927e-05, global_step: 4830, interval_runtime: 0.8571, interval_samples_per_second: 46.668, interval_steps_per_second: 5.834, epoch: 7.1556\r\n",
      "loss: 0.05017528, learning_rate: 1.926e-05, global_step: 4835, interval_runtime: 0.8386, interval_samples_per_second: 47.698, interval_steps_per_second: 5.962, epoch: 7.163\r\n",
      "loss: 0.06313829, learning_rate: 1.924e-05, global_step: 4840, interval_runtime: 0.8469, interval_samples_per_second: 47.231, interval_steps_per_second: 5.904, epoch: 7.1704\r\n",
      "loss: 0.03415049, learning_rate: 1.923e-05, global_step: 4845, interval_runtime: 0.8961, interval_samples_per_second: 44.638, interval_steps_per_second: 5.58, epoch: 7.1778\r\n",
      "loss: 0.04494302, learning_rate: 1.922e-05, global_step: 4850, interval_runtime: 0.9265, interval_samples_per_second: 43.175, interval_steps_per_second: 5.397, epoch: 7.1852\r\n",
      "loss: 0.03625299, learning_rate: 1.921e-05, global_step: 4855, interval_runtime: 0.7618, interval_samples_per_second: 52.508, interval_steps_per_second: 6.564, epoch: 7.1926\r\n",
      "loss: 0.04716056, learning_rate: 1.92e-05, global_step: 4860, interval_runtime: 0.8166, interval_samples_per_second: 48.986, interval_steps_per_second: 6.123, epoch: 7.2\r\n",
      "loss: 0.03769289, learning_rate: 1.919e-05, global_step: 4865, interval_runtime: 0.8458, interval_samples_per_second: 47.294, interval_steps_per_second: 5.912, epoch: 7.2074\r\n",
      "loss: 0.06278114, learning_rate: 1.918e-05, global_step: 4870, interval_runtime: 0.7588, interval_samples_per_second: 52.718, interval_steps_per_second: 6.59, epoch: 7.2148\r\n",
      "loss: 0.04654727, learning_rate: 1.917e-05, global_step: 4875, interval_runtime: 0.7717, interval_samples_per_second: 51.834, interval_steps_per_second: 6.479, epoch: 7.2222\r\n",
      "loss: 0.05095647, learning_rate: 1.916e-05, global_step: 4880, interval_runtime: 0.7726, interval_samples_per_second: 51.775, interval_steps_per_second: 6.472, epoch: 7.2296\r\n",
      "loss: 0.04996298, learning_rate: 1.914e-05, global_step: 4885, interval_runtime: 0.8212, interval_samples_per_second: 48.708, interval_steps_per_second: 6.088, epoch: 7.237\r\n",
      "loss: 0.05119534, learning_rate: 1.913e-05, global_step: 4890, interval_runtime: 0.9183, interval_samples_per_second: 43.558, interval_steps_per_second: 5.445, epoch: 7.2444\r\n",
      "loss: 0.04849735, learning_rate: 1.912e-05, global_step: 4895, interval_runtime: 0.8498, interval_samples_per_second: 47.072, interval_steps_per_second: 5.884, epoch: 7.2519\r\n",
      "loss: 0.03993562, learning_rate: 1.911e-05, global_step: 4900, interval_runtime: 0.8063, interval_samples_per_second: 49.612, interval_steps_per_second: 6.202, epoch: 7.2593\r\n",
      "loss: 0.04086449, learning_rate: 1.91e-05, global_step: 4905, interval_runtime: 0.7675, interval_samples_per_second: 52.118, interval_steps_per_second: 6.515, epoch: 7.2667\r\n",
      "loss: 0.03739309, learning_rate: 1.909e-05, global_step: 4910, interval_runtime: 0.8758, interval_samples_per_second: 45.671, interval_steps_per_second: 5.709, epoch: 7.2741\r\n",
      "loss: 0.04377522, learning_rate: 1.908e-05, global_step: 4915, interval_runtime: 0.8801, interval_samples_per_second: 45.449, interval_steps_per_second: 5.681, epoch: 7.2815\r\n",
      "loss: 0.05761702, learning_rate: 1.907e-05, global_step: 4920, interval_runtime: 0.8547, interval_samples_per_second: 46.799, interval_steps_per_second: 5.85, epoch: 7.2889\r\n",
      "loss: 0.03638099, learning_rate: 1.906e-05, global_step: 4925, interval_runtime: 0.7818, interval_samples_per_second: 51.163, interval_steps_per_second: 6.395, epoch: 7.2963\r\n",
      "loss: 0.04492078, learning_rate: 1.904e-05, global_step: 4930, interval_runtime: 0.7714, interval_samples_per_second: 51.856, interval_steps_per_second: 6.482, epoch: 7.3037\r\n",
      "loss: 0.0752215, learning_rate: 1.903e-05, global_step: 4935, interval_runtime: 0.8645, interval_samples_per_second: 46.267, interval_steps_per_second: 5.783, epoch: 7.3111\r\n",
      "loss: 0.04878451, learning_rate: 1.902e-05, global_step: 4940, interval_runtime: 0.8523, interval_samples_per_second: 46.931, interval_steps_per_second: 5.866, epoch: 7.3185\r\n",
      "loss: 0.05019285, learning_rate: 1.901e-05, global_step: 4945, interval_runtime: 0.824, interval_samples_per_second: 48.541, interval_steps_per_second: 6.068, epoch: 7.3259\r\n",
      "loss: 0.04084195, learning_rate: 1.9e-05, global_step: 4950, interval_runtime: 0.7321, interval_samples_per_second: 54.634, interval_steps_per_second: 6.829, epoch: 7.3333\r\n",
      "loss: 0.04135778, learning_rate: 1.899e-05, global_step: 4955, interval_runtime: 0.9295, interval_samples_per_second: 43.034, interval_steps_per_second: 5.379, epoch: 7.3407\r\n",
      "loss: 0.04524716, learning_rate: 1.898e-05, global_step: 4960, interval_runtime: 0.8255, interval_samples_per_second: 48.453, interval_steps_per_second: 6.057, epoch: 7.3481\r\n",
      "loss: 0.04088614, learning_rate: 1.897e-05, global_step: 4965, interval_runtime: 0.8786, interval_samples_per_second: 45.528, interval_steps_per_second: 5.691, epoch: 7.3556\r\n",
      "loss: 0.04670177, learning_rate: 1.896e-05, global_step: 4970, interval_runtime: 0.98, interval_samples_per_second: 40.816, interval_steps_per_second: 5.102, epoch: 7.363\r\n",
      "loss: 0.03001879, learning_rate: 1.894e-05, global_step: 4975, interval_runtime: 0.8401, interval_samples_per_second: 47.613, interval_steps_per_second: 5.952, epoch: 7.3704\r\n",
      "loss: 0.0373972, learning_rate: 1.893e-05, global_step: 4980, interval_runtime: 0.8607, interval_samples_per_second: 46.474, interval_steps_per_second: 5.809, epoch: 7.3778\r\n",
      "loss: 0.0495795, learning_rate: 1.892e-05, global_step: 4985, interval_runtime: 0.7934, interval_samples_per_second: 50.417, interval_steps_per_second: 6.302, epoch: 7.3852\r\n",
      "loss: 0.03521496, learning_rate: 1.891e-05, global_step: 4990, interval_runtime: 0.8242, interval_samples_per_second: 48.532, interval_steps_per_second: 6.066, epoch: 7.3926\r\n",
      "loss: 0.05632278, learning_rate: 1.89e-05, global_step: 4995, interval_runtime: 0.7521, interval_samples_per_second: 53.184, interval_steps_per_second: 6.648, epoch: 7.4\r\n",
      "loss: 0.07190156, learning_rate: 1.889e-05, global_step: 5000, interval_runtime: 0.9226, interval_samples_per_second: 43.358, interval_steps_per_second: 5.42, epoch: 7.4074\r\n",
      "loss: 0.04436135, learning_rate: 1.888e-05, global_step: 5005, interval_runtime: 0.8432, interval_samples_per_second: 47.44, interval_steps_per_second: 5.93, epoch: 7.4148\r\n",
      "loss: 0.04740015, learning_rate: 1.887e-05, global_step: 5010, interval_runtime: 0.726, interval_samples_per_second: 55.099, interval_steps_per_second: 6.887, epoch: 7.4222\r\n",
      "loss: 0.02918247, learning_rate: 1.886e-05, global_step: 5015, interval_runtime: 0.8102, interval_samples_per_second: 49.368, interval_steps_per_second: 6.171, epoch: 7.4296\r\n",
      "loss: 0.03355222, learning_rate: 1.884e-05, global_step: 5020, interval_runtime: 0.8285, interval_samples_per_second: 48.281, interval_steps_per_second: 6.035, epoch: 7.437\r\n",
      "loss: 0.02883328, learning_rate: 1.883e-05, global_step: 5025, interval_runtime: 0.763, interval_samples_per_second: 52.422, interval_steps_per_second: 6.553, epoch: 7.4444\r\n",
      "loss: 0.05387144, learning_rate: 1.882e-05, global_step: 5030, interval_runtime: 0.7874, interval_samples_per_second: 50.801, interval_steps_per_second: 6.35, epoch: 7.4519\r\n",
      "loss: 0.03667576, learning_rate: 1.881e-05, global_step: 5035, interval_runtime: 0.8472, interval_samples_per_second: 47.212, interval_steps_per_second: 5.901, epoch: 7.4593\r\n",
      "loss: 0.03229308, learning_rate: 1.88e-05, global_step: 5040, interval_runtime: 0.7434, interval_samples_per_second: 53.81, interval_steps_per_second: 6.726, epoch: 7.4667\r\n",
      "loss: 0.04847705, learning_rate: 1.879e-05, global_step: 5045, interval_runtime: 0.8768, interval_samples_per_second: 45.621, interval_steps_per_second: 5.703, epoch: 7.4741\r\n",
      "loss: 0.05773824, learning_rate: 1.878e-05, global_step: 5050, interval_runtime: 0.8994, interval_samples_per_second: 44.474, interval_steps_per_second: 5.559, epoch: 7.4815\r\n",
      "loss: 0.04388987, learning_rate: 1.877e-05, global_step: 5055, interval_runtime: 0.8166, interval_samples_per_second: 48.985, interval_steps_per_second: 6.123, epoch: 7.4889\r\n",
      "loss: 0.07303041, learning_rate: 1.876e-05, global_step: 5060, interval_runtime: 0.864, interval_samples_per_second: 46.294, interval_steps_per_second: 5.787, epoch: 7.4963\r\n",
      "loss: 0.06338159, learning_rate: 1.874e-05, global_step: 5065, interval_runtime: 0.7349, interval_samples_per_second: 54.426, interval_steps_per_second: 6.803, epoch: 7.5037\r\n",
      "loss: 0.07855015, learning_rate: 1.873e-05, global_step: 5070, interval_runtime: 0.8387, interval_samples_per_second: 47.69, interval_steps_per_second: 5.961, epoch: 7.5111\r\n",
      "loss: 0.0474686, learning_rate: 1.872e-05, global_step: 5075, interval_runtime: 0.7656, interval_samples_per_second: 52.249, interval_steps_per_second: 6.531, epoch: 7.5185\r\n",
      "loss: 0.05706263, learning_rate: 1.871e-05, global_step: 5080, interval_runtime: 0.8126, interval_samples_per_second: 49.223, interval_steps_per_second: 6.153, epoch: 7.5259\r\n",
      "loss: 0.0660421, learning_rate: 1.87e-05, global_step: 5085, interval_runtime: 0.7742, interval_samples_per_second: 51.664, interval_steps_per_second: 6.458, epoch: 7.5333\r\n",
      "loss: 0.04446811, learning_rate: 1.869e-05, global_step: 5090, interval_runtime: 0.8592, interval_samples_per_second: 46.553, interval_steps_per_second: 5.819, epoch: 7.5407\r\n",
      "loss: 0.06527966, learning_rate: 1.868e-05, global_step: 5095, interval_runtime: 0.7826, interval_samples_per_second: 51.112, interval_steps_per_second: 6.389, epoch: 7.5481\r\n",
      "loss: 0.07673583, learning_rate: 1.867e-05, global_step: 5100, interval_runtime: 0.727, interval_samples_per_second: 55.024, interval_steps_per_second: 6.878, epoch: 7.5556\r\n",
      "loss: 0.043414, learning_rate: 1.866e-05, global_step: 5105, interval_runtime: 0.9155, interval_samples_per_second: 43.69, interval_steps_per_second: 5.461, epoch: 7.563\r\n",
      "loss: 0.05070013, learning_rate: 1.864e-05, global_step: 5110, interval_runtime: 0.905, interval_samples_per_second: 44.201, interval_steps_per_second: 5.525, epoch: 7.5704\r\n",
      "loss: 0.0570665, learning_rate: 1.863e-05, global_step: 5115, interval_runtime: 0.7048, interval_samples_per_second: 56.757, interval_steps_per_second: 7.095, epoch: 7.5778\r\n",
      "loss: 0.03574632, learning_rate: 1.862e-05, global_step: 5120, interval_runtime: 0.7461, interval_samples_per_second: 53.615, interval_steps_per_second: 6.702, epoch: 7.5852\r\n",
      "loss: 0.04713041, learning_rate: 1.861e-05, global_step: 5125, interval_runtime: 0.7386, interval_samples_per_second: 54.156, interval_steps_per_second: 6.77, epoch: 7.5926\r\n",
      "loss: 0.05329382, learning_rate: 1.86e-05, global_step: 5130, interval_runtime: 0.8114, interval_samples_per_second: 49.299, interval_steps_per_second: 6.162, epoch: 7.6\r\n",
      "loss: 0.04092678, learning_rate: 1.859e-05, global_step: 5135, interval_runtime: 0.7987, interval_samples_per_second: 50.081, interval_steps_per_second: 6.26, epoch: 7.6074\r\n",
      "loss: 0.03457789, learning_rate: 1.858e-05, global_step: 5140, interval_runtime: 0.7755, interval_samples_per_second: 51.577, interval_steps_per_second: 6.447, epoch: 7.6148\r\n",
      "loss: 0.08925169, learning_rate: 1.857e-05, global_step: 5145, interval_runtime: 0.7534, interval_samples_per_second: 53.093, interval_steps_per_second: 6.637, epoch: 7.6222\r\n",
      "loss: 0.0435901, learning_rate: 1.856e-05, global_step: 5150, interval_runtime: 0.7561, interval_samples_per_second: 52.905, interval_steps_per_second: 6.613, epoch: 7.6296\r\n",
      "loss: 0.06297415, learning_rate: 1.854e-05, global_step: 5155, interval_runtime: 0.8401, interval_samples_per_second: 47.613, interval_steps_per_second: 5.952, epoch: 7.637\r\n",
      "loss: 0.06344414, learning_rate: 1.853e-05, global_step: 5160, interval_runtime: 0.846, interval_samples_per_second: 47.282, interval_steps_per_second: 5.91, epoch: 7.6444\r\n",
      "loss: 0.05127308, learning_rate: 1.852e-05, global_step: 5165, interval_runtime: 0.9788, interval_samples_per_second: 40.864, interval_steps_per_second: 5.108, epoch: 7.6519\r\n",
      "loss: 0.07375414, learning_rate: 1.851e-05, global_step: 5170, interval_runtime: 0.8683, interval_samples_per_second: 46.067, interval_steps_per_second: 5.758, epoch: 7.6593\r\n",
      "loss: 0.04399787, learning_rate: 1.85e-05, global_step: 5175, interval_runtime: 0.8783, interval_samples_per_second: 45.543, interval_steps_per_second: 5.693, epoch: 7.6667\r\n",
      "loss: 0.0365261, learning_rate: 1.849e-05, global_step: 5180, interval_runtime: 0.9644, interval_samples_per_second: 41.478, interval_steps_per_second: 5.185, epoch: 7.6741\r\n",
      "loss: 0.05006426, learning_rate: 1.848e-05, global_step: 5185, interval_runtime: 0.766, interval_samples_per_second: 52.218, interval_steps_per_second: 6.527, epoch: 7.6815\r\n",
      "loss: 0.03079811, learning_rate: 1.847e-05, global_step: 5190, interval_runtime: 0.7545, interval_samples_per_second: 53.018, interval_steps_per_second: 6.627, epoch: 7.6889\r\n",
      "loss: 0.05002446, learning_rate: 1.846e-05, global_step: 5195, interval_runtime: 0.8242, interval_samples_per_second: 48.53, interval_steps_per_second: 6.066, epoch: 7.6963\r\n",
      "loss: 0.05903054, learning_rate: 1.844e-05, global_step: 5200, interval_runtime: 0.7703, interval_samples_per_second: 51.931, interval_steps_per_second: 6.491, epoch: 7.7037\r\n",
      "loss: 0.041897, learning_rate: 1.843e-05, global_step: 5205, interval_runtime: 0.9192, interval_samples_per_second: 43.517, interval_steps_per_second: 5.44, epoch: 7.7111\r\n",
      "loss: 0.03910211, learning_rate: 1.842e-05, global_step: 5210, interval_runtime: 0.7585, interval_samples_per_second: 52.737, interval_steps_per_second: 6.592, epoch: 7.7185\r\n",
      "loss: 0.04023289, learning_rate: 1.841e-05, global_step: 5215, interval_runtime: 0.7928, interval_samples_per_second: 50.457, interval_steps_per_second: 6.307, epoch: 7.7259\r\n",
      "loss: 0.04619275, learning_rate: 1.84e-05, global_step: 5220, interval_runtime: 0.9472, interval_samples_per_second: 42.23, interval_steps_per_second: 5.279, epoch: 7.7333\r\n",
      "loss: 0.09086056, learning_rate: 1.839e-05, global_step: 5225, interval_runtime: 0.8997, interval_samples_per_second: 44.459, interval_steps_per_second: 5.557, epoch: 7.7407\r\n",
      "loss: 0.04146971, learning_rate: 1.838e-05, global_step: 5230, interval_runtime: 0.7556, interval_samples_per_second: 52.935, interval_steps_per_second: 6.617, epoch: 7.7481\r\n",
      "loss: 0.0395227, learning_rate: 1.837e-05, global_step: 5235, interval_runtime: 0.8557, interval_samples_per_second: 46.746, interval_steps_per_second: 5.843, epoch: 7.7556\r\n",
      "loss: 0.04167145, learning_rate: 1.836e-05, global_step: 5240, interval_runtime: 0.7905, interval_samples_per_second: 50.598, interval_steps_per_second: 6.325, epoch: 7.763\r\n",
      "loss: 0.04996265, learning_rate: 1.834e-05, global_step: 5245, interval_runtime: 1.0016, interval_samples_per_second: 39.935, interval_steps_per_second: 4.992, epoch: 7.7704\r\n",
      "loss: 0.04063523, learning_rate: 1.833e-05, global_step: 5250, interval_runtime: 1.0608, interval_samples_per_second: 37.708, interval_steps_per_second: 4.714, epoch: 7.7778\r\n",
      "loss: 0.04428566, learning_rate: 1.832e-05, global_step: 5255, interval_runtime: 0.9393, interval_samples_per_second: 42.587, interval_steps_per_second: 5.323, epoch: 7.7852\r\n",
      "loss: 0.04589045, learning_rate: 1.831e-05, global_step: 5260, interval_runtime: 0.8109, interval_samples_per_second: 49.325, interval_steps_per_second: 6.166, epoch: 7.7926\r\n",
      "loss: 0.04733567, learning_rate: 1.83e-05, global_step: 5265, interval_runtime: 0.8197, interval_samples_per_second: 48.801, interval_steps_per_second: 6.1, epoch: 7.8\r\n",
      "loss: 0.04146165, learning_rate: 1.829e-05, global_step: 5270, interval_runtime: 0.8057, interval_samples_per_second: 49.647, interval_steps_per_second: 6.206, epoch: 7.8074\r\n",
      "loss: 0.04373538, learning_rate: 1.828e-05, global_step: 5275, interval_runtime: 0.7899, interval_samples_per_second: 50.638, interval_steps_per_second: 6.33, epoch: 7.8148\r\n",
      "loss: 0.05128847, learning_rate: 1.827e-05, global_step: 5280, interval_runtime: 0.7986, interval_samples_per_second: 50.085, interval_steps_per_second: 6.261, epoch: 7.8222\r\n",
      "loss: 0.03704664, learning_rate: 1.826e-05, global_step: 5285, interval_runtime: 0.9191, interval_samples_per_second: 43.523, interval_steps_per_second: 5.44, epoch: 7.8296\r\n",
      "loss: 0.04255328, learning_rate: 1.824e-05, global_step: 5290, interval_runtime: 0.8938, interval_samples_per_second: 44.753, interval_steps_per_second: 5.594, epoch: 7.837\r\n",
      "loss: 0.05092322, learning_rate: 1.823e-05, global_step: 5295, interval_runtime: 0.7685, interval_samples_per_second: 52.049, interval_steps_per_second: 6.506, epoch: 7.8444\r\n",
      "loss: 0.0535611, learning_rate: 1.822e-05, global_step: 5300, interval_runtime: 0.8166, interval_samples_per_second: 48.984, interval_steps_per_second: 6.123, epoch: 7.8519\r\n",
      "loss: 0.04131101, learning_rate: 1.821e-05, global_step: 5305, interval_runtime: 1.0183, interval_samples_per_second: 39.281, interval_steps_per_second: 4.91, epoch: 7.8593\r\n",
      "loss: 0.04308035, learning_rate: 1.82e-05, global_step: 5310, interval_runtime: 0.8076, interval_samples_per_second: 49.529, interval_steps_per_second: 6.191, epoch: 7.8667\r\n",
      "loss: 0.04382736, learning_rate: 1.819e-05, global_step: 5315, interval_runtime: 0.7457, interval_samples_per_second: 53.644, interval_steps_per_second: 6.706, epoch: 7.8741\r\n",
      "loss: 0.06279242, learning_rate: 1.818e-05, global_step: 5320, interval_runtime: 0.8759, interval_samples_per_second: 45.669, interval_steps_per_second: 5.709, epoch: 7.8815\r\n",
      "loss: 0.06054, learning_rate: 1.817e-05, global_step: 5325, interval_runtime: 0.8248, interval_samples_per_second: 48.499, interval_steps_per_second: 6.062, epoch: 7.8889\r\n",
      "loss: 0.07252886, learning_rate: 1.816e-05, global_step: 5330, interval_runtime: 0.8265, interval_samples_per_second: 48.4, interval_steps_per_second: 6.05, epoch: 7.8963\r\n",
      "loss: 0.06321803, learning_rate: 1.814e-05, global_step: 5335, interval_runtime: 0.953, interval_samples_per_second: 41.972, interval_steps_per_second: 5.246, epoch: 7.9037\r\n",
      "loss: 0.03958213, learning_rate: 1.813e-05, global_step: 5340, interval_runtime: 0.825, interval_samples_per_second: 48.487, interval_steps_per_second: 6.061, epoch: 7.9111\r\n",
      "loss: 0.05427783, learning_rate: 1.812e-05, global_step: 5345, interval_runtime: 0.736, interval_samples_per_second: 54.351, interval_steps_per_second: 6.794, epoch: 7.9185\r\n",
      "loss: 0.07811643, learning_rate: 1.811e-05, global_step: 5350, interval_runtime: 0.9183, interval_samples_per_second: 43.557, interval_steps_per_second: 5.445, epoch: 7.9259\r\n",
      "loss: 0.06306387, learning_rate: 1.81e-05, global_step: 5355, interval_runtime: 0.9314, interval_samples_per_second: 42.944, interval_steps_per_second: 5.368, epoch: 7.9333\r\n",
      "loss: 0.0540355, learning_rate: 1.809e-05, global_step: 5360, interval_runtime: 0.8783, interval_samples_per_second: 45.544, interval_steps_per_second: 5.693, epoch: 7.9407\r\n",
      "loss: 0.08594086, learning_rate: 1.808e-05, global_step: 5365, interval_runtime: 0.8773, interval_samples_per_second: 45.594, interval_steps_per_second: 5.699, epoch: 7.9481\r\n",
      "loss: 0.03710879, learning_rate: 1.807e-05, global_step: 5370, interval_runtime: 0.837, interval_samples_per_second: 47.788, interval_steps_per_second: 5.973, epoch: 7.9556\r\n",
      "loss: 0.04604543, learning_rate: 1.806e-05, global_step: 5375, interval_runtime: 0.7843, interval_samples_per_second: 51.0, interval_steps_per_second: 6.375, epoch: 7.963\r\n",
      "loss: 0.03672615, learning_rate: 1.804e-05, global_step: 5380, interval_runtime: 0.9027, interval_samples_per_second: 44.309, interval_steps_per_second: 5.539, epoch: 7.9704\r\n",
      "loss: 0.02834565, learning_rate: 1.803e-05, global_step: 5385, interval_runtime: 0.894, interval_samples_per_second: 44.743, interval_steps_per_second: 5.593, epoch: 7.9778\r\n",
      "loss: 0.05772412, learning_rate: 1.802e-05, global_step: 5390, interval_runtime: 0.7953, interval_samples_per_second: 50.296, interval_steps_per_second: 6.287, epoch: 7.9852\r\n",
      "loss: 0.05746835, learning_rate: 1.801e-05, global_step: 5395, interval_runtime: 0.8739, interval_samples_per_second: 45.774, interval_steps_per_second: 5.722, epoch: 7.9926\r\n",
      "loss: 0.04344295, learning_rate: 1.8e-05, global_step: 5400, interval_runtime: 0.7239, interval_samples_per_second: 55.255, interval_steps_per_second: 6.907, epoch: 8.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:56:25,031] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:56:25,033] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:56:25,035] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:56:25,037] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:56:25,039] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.5685014128684998, eval_micro_f1_score: 0.5568547703779022, eval_macro_f1_score: 0.443681983491271, eval_runtime: 13.6994, eval_samples_per_second: 138.4, eval_steps_per_second: 17.3, epoch: 8.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:56:38,735] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-5400\r\n",
      "[2023-01-10 10:56:38,737] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:56:42,035] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-5400/tokenizer_config.json\r\n",
      "[2023-01-10 10:56:42,039] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-5400/special_tokens_map.json\r\n",
      "[2023-01-10 10:56:48,687] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-4050] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.03047122, learning_rate: 1.799e-05, global_step: 5405, interval_runtime: 25.1786, interval_samples_per_second: 1.589, interval_steps_per_second: 0.199, epoch: 8.0074\r\n",
      "loss: 0.03011718, learning_rate: 1.798e-05, global_step: 5410, interval_runtime: 0.8991, interval_samples_per_second: 44.487, interval_steps_per_second: 5.561, epoch: 8.0148\r\n",
      "loss: 0.02130408, learning_rate: 1.797e-05, global_step: 5415, interval_runtime: 0.8031, interval_samples_per_second: 49.805, interval_steps_per_second: 6.226, epoch: 8.0222\r\n",
      "loss: 0.0420265, learning_rate: 1.796e-05, global_step: 5420, interval_runtime: 0.9277, interval_samples_per_second: 43.119, interval_steps_per_second: 5.39, epoch: 8.0296\r\n",
      "loss: 0.04547487, learning_rate: 1.794e-05, global_step: 5425, interval_runtime: 0.8056, interval_samples_per_second: 49.653, interval_steps_per_second: 6.207, epoch: 8.037\r\n",
      "loss: 0.01750719, learning_rate: 1.793e-05, global_step: 5430, interval_runtime: 0.8021, interval_samples_per_second: 49.868, interval_steps_per_second: 6.233, epoch: 8.0444\r\n",
      "loss: 0.02360779, learning_rate: 1.792e-05, global_step: 5435, interval_runtime: 0.785, interval_samples_per_second: 50.955, interval_steps_per_second: 6.369, epoch: 8.0519\r\n",
      "loss: 0.04702019, learning_rate: 1.791e-05, global_step: 5440, interval_runtime: 0.7832, interval_samples_per_second: 51.075, interval_steps_per_second: 6.384, epoch: 8.0593\r\n",
      "loss: 0.04443707, learning_rate: 1.79e-05, global_step: 5445, interval_runtime: 0.9212, interval_samples_per_second: 43.423, interval_steps_per_second: 5.428, epoch: 8.0667\r\n",
      "loss: 0.03061105, learning_rate: 1.789e-05, global_step: 5450, interval_runtime: 0.8132, interval_samples_per_second: 49.188, interval_steps_per_second: 6.148, epoch: 8.0741\r\n",
      "loss: 0.02892559, learning_rate: 1.788e-05, global_step: 5455, interval_runtime: 0.9947, interval_samples_per_second: 40.214, interval_steps_per_second: 5.027, epoch: 8.0815\r\n",
      "loss: 0.04083819, learning_rate: 1.787e-05, global_step: 5460, interval_runtime: 0.8467, interval_samples_per_second: 47.244, interval_steps_per_second: 5.906, epoch: 8.0889\r\n",
      "loss: 0.03189481, learning_rate: 1.786e-05, global_step: 5465, interval_runtime: 0.8545, interval_samples_per_second: 46.81, interval_steps_per_second: 5.851, epoch: 8.0963\r\n",
      "loss: 0.0382493, learning_rate: 1.784e-05, global_step: 5470, interval_runtime: 0.8505, interval_samples_per_second: 47.032, interval_steps_per_second: 5.879, epoch: 8.1037\r\n",
      "loss: 0.03373781, learning_rate: 1.783e-05, global_step: 5475, interval_runtime: 0.8885, interval_samples_per_second: 45.02, interval_steps_per_second: 5.628, epoch: 8.1111\r\n",
      "loss: 0.03030167, learning_rate: 1.782e-05, global_step: 5480, interval_runtime: 0.828, interval_samples_per_second: 48.309, interval_steps_per_second: 6.039, epoch: 8.1185\r\n",
      "loss: 0.02814352, learning_rate: 1.781e-05, global_step: 5485, interval_runtime: 0.7335, interval_samples_per_second: 54.53, interval_steps_per_second: 6.816, epoch: 8.1259\r\n",
      "loss: 0.03283865, learning_rate: 1.78e-05, global_step: 5490, interval_runtime: 0.8703, interval_samples_per_second: 45.961, interval_steps_per_second: 5.745, epoch: 8.1333\r\n",
      "loss: 0.02483424, learning_rate: 1.779e-05, global_step: 5495, interval_runtime: 0.7813, interval_samples_per_second: 51.199, interval_steps_per_second: 6.4, epoch: 8.1407\r\n",
      "loss: 0.04023084, learning_rate: 1.778e-05, global_step: 5500, interval_runtime: 0.7276, interval_samples_per_second: 54.977, interval_steps_per_second: 6.872, epoch: 8.1481\r\n",
      "loss: 0.02897835, learning_rate: 1.777e-05, global_step: 5505, interval_runtime: 0.7928, interval_samples_per_second: 50.451, interval_steps_per_second: 6.306, epoch: 8.1556\r\n",
      "loss: 0.05867919, learning_rate: 1.776e-05, global_step: 5510, interval_runtime: 0.8596, interval_samples_per_second: 46.536, interval_steps_per_second: 5.817, epoch: 8.163\r\n",
      "loss: 0.0522626, learning_rate: 1.774e-05, global_step: 5515, interval_runtime: 0.7893, interval_samples_per_second: 50.681, interval_steps_per_second: 6.335, epoch: 8.1704\r\n",
      "loss: 0.02951986, learning_rate: 1.773e-05, global_step: 5520, interval_runtime: 0.9261, interval_samples_per_second: 43.192, interval_steps_per_second: 5.399, epoch: 8.1778\r\n",
      "loss: 0.03540546, learning_rate: 1.772e-05, global_step: 5525, interval_runtime: 0.7796, interval_samples_per_second: 51.306, interval_steps_per_second: 6.413, epoch: 8.1852\r\n",
      "loss: 0.02549302, learning_rate: 1.771e-05, global_step: 5530, interval_runtime: 0.8461, interval_samples_per_second: 47.278, interval_steps_per_second: 5.91, epoch: 8.1926\r\n",
      "loss: 0.0400371, learning_rate: 1.77e-05, global_step: 5535, interval_runtime: 0.7334, interval_samples_per_second: 54.54, interval_steps_per_second: 6.817, epoch: 8.2\r\n",
      "loss: 0.0290108, learning_rate: 1.769e-05, global_step: 5540, interval_runtime: 0.7337, interval_samples_per_second: 54.521, interval_steps_per_second: 6.815, epoch: 8.2074\r\n",
      "loss: 0.05197744, learning_rate: 1.768e-05, global_step: 5545, interval_runtime: 0.7811, interval_samples_per_second: 51.211, interval_steps_per_second: 6.401, epoch: 8.2148\r\n",
      "loss: 0.02455088, learning_rate: 1.767e-05, global_step: 5550, interval_runtime: 0.8756, interval_samples_per_second: 45.683, interval_steps_per_second: 5.71, epoch: 8.2222\r\n",
      "loss: 0.03995454, learning_rate: 1.766e-05, global_step: 5555, interval_runtime: 0.7612, interval_samples_per_second: 52.552, interval_steps_per_second: 6.569, epoch: 8.2296\r\n",
      "loss: 0.04123304, learning_rate: 1.764e-05, global_step: 5560, interval_runtime: 0.8804, interval_samples_per_second: 45.434, interval_steps_per_second: 5.679, epoch: 8.237\r\n",
      "loss: 0.04308642, learning_rate: 1.763e-05, global_step: 5565, interval_runtime: 0.9333, interval_samples_per_second: 42.861, interval_steps_per_second: 5.358, epoch: 8.2444\r\n",
      "loss: 0.03116261, learning_rate: 1.762e-05, global_step: 5570, interval_runtime: 0.7927, interval_samples_per_second: 50.462, interval_steps_per_second: 6.308, epoch: 8.2519\r\n",
      "loss: 0.02599674, learning_rate: 1.761e-05, global_step: 5575, interval_runtime: 0.7773, interval_samples_per_second: 51.461, interval_steps_per_second: 6.433, epoch: 8.2593\r\n",
      "loss: 0.03202642, learning_rate: 1.76e-05, global_step: 5580, interval_runtime: 0.7519, interval_samples_per_second: 53.197, interval_steps_per_second: 6.65, epoch: 8.2667\r\n",
      "loss: 0.03144808, learning_rate: 1.759e-05, global_step: 5585, interval_runtime: 0.9171, interval_samples_per_second: 43.614, interval_steps_per_second: 5.452, epoch: 8.2741\r\n",
      "loss: 0.02241305, learning_rate: 1.758e-05, global_step: 5590, interval_runtime: 0.899, interval_samples_per_second: 44.495, interval_steps_per_second: 5.562, epoch: 8.2815\r\n",
      "loss: 0.03020582, learning_rate: 1.757e-05, global_step: 5595, interval_runtime: 0.9257, interval_samples_per_second: 43.212, interval_steps_per_second: 5.401, epoch: 8.2889\r\n",
      "loss: 0.02505467, learning_rate: 1.756e-05, global_step: 5600, interval_runtime: 0.8086, interval_samples_per_second: 49.469, interval_steps_per_second: 6.184, epoch: 8.2963\r\n",
      "loss: 0.04428203, learning_rate: 1.754e-05, global_step: 5605, interval_runtime: 0.7648, interval_samples_per_second: 52.299, interval_steps_per_second: 6.537, epoch: 8.3037\r\n",
      "loss: 0.02127499, learning_rate: 1.753e-05, global_step: 5610, interval_runtime: 0.8287, interval_samples_per_second: 48.269, interval_steps_per_second: 6.034, epoch: 8.3111\r\n",
      "loss: 0.02752022, learning_rate: 1.752e-05, global_step: 5615, interval_runtime: 0.8669, interval_samples_per_second: 46.142, interval_steps_per_second: 5.768, epoch: 8.3185\r\n",
      "loss: 0.03613062, learning_rate: 1.751e-05, global_step: 5620, interval_runtime: 0.7212, interval_samples_per_second: 55.465, interval_steps_per_second: 6.933, epoch: 8.3259\r\n",
      "loss: 0.02153808, learning_rate: 1.75e-05, global_step: 5625, interval_runtime: 0.7612, interval_samples_per_second: 52.546, interval_steps_per_second: 6.568, epoch: 8.3333\r\n",
      "loss: 0.03343602, learning_rate: 1.749e-05, global_step: 5630, interval_runtime: 0.9554, interval_samples_per_second: 41.866, interval_steps_per_second: 5.233, epoch: 8.3407\r\n",
      "loss: 0.03683568, learning_rate: 1.748e-05, global_step: 5635, interval_runtime: 0.8166, interval_samples_per_second: 48.983, interval_steps_per_second: 6.123, epoch: 8.3481\r\n",
      "loss: 0.03654951, learning_rate: 1.747e-05, global_step: 5640, interval_runtime: 0.8068, interval_samples_per_second: 49.577, interval_steps_per_second: 6.197, epoch: 8.3556\r\n",
      "loss: 0.05981641, learning_rate: 1.746e-05, global_step: 5645, interval_runtime: 0.7597, interval_samples_per_second: 52.652, interval_steps_per_second: 6.582, epoch: 8.363\r\n",
      "loss: 0.03814844, learning_rate: 1.744e-05, global_step: 5650, interval_runtime: 0.8264, interval_samples_per_second: 48.401, interval_steps_per_second: 6.05, epoch: 8.3704\r\n",
      "loss: 0.02596214, learning_rate: 1.743e-05, global_step: 5655, interval_runtime: 0.8892, interval_samples_per_second: 44.986, interval_steps_per_second: 5.623, epoch: 8.3778\r\n",
      "loss: 0.01856044, learning_rate: 1.742e-05, global_step: 5660, interval_runtime: 0.8168, interval_samples_per_second: 48.969, interval_steps_per_second: 6.121, epoch: 8.3852\r\n",
      "loss: 0.03913967, learning_rate: 1.741e-05, global_step: 5665, interval_runtime: 0.8455, interval_samples_per_second: 47.307, interval_steps_per_second: 5.913, epoch: 8.3926\r\n",
      "loss: 0.02863216, learning_rate: 1.74e-05, global_step: 5670, interval_runtime: 0.8952, interval_samples_per_second: 44.682, interval_steps_per_second: 5.585, epoch: 8.4\r\n",
      "loss: 0.02448263, learning_rate: 1.739e-05, global_step: 5675, interval_runtime: 0.8267, interval_samples_per_second: 48.383, interval_steps_per_second: 6.048, epoch: 8.4074\r\n",
      "loss: 0.0207926, learning_rate: 1.738e-05, global_step: 5680, interval_runtime: 0.8521, interval_samples_per_second: 46.94, interval_steps_per_second: 5.868, epoch: 8.4148\r\n",
      "loss: 0.08017437, learning_rate: 1.737e-05, global_step: 5685, interval_runtime: 0.9957, interval_samples_per_second: 40.174, interval_steps_per_second: 5.022, epoch: 8.4222\r\n",
      "loss: 0.03835588, learning_rate: 1.736e-05, global_step: 5690, interval_runtime: 0.806, interval_samples_per_second: 49.627, interval_steps_per_second: 6.203, epoch: 8.4296\r\n",
      "loss: 0.03889633, learning_rate: 1.734e-05, global_step: 5695, interval_runtime: 0.8645, interval_samples_per_second: 46.267, interval_steps_per_second: 5.783, epoch: 8.437\r\n",
      "loss: 0.05142503, learning_rate: 1.733e-05, global_step: 5700, interval_runtime: 0.9035, interval_samples_per_second: 44.272, interval_steps_per_second: 5.534, epoch: 8.4444\r\n",
      "loss: 0.04500822, learning_rate: 1.732e-05, global_step: 5705, interval_runtime: 0.8861, interval_samples_per_second: 45.144, interval_steps_per_second: 5.643, epoch: 8.4519\r\n",
      "loss: 0.02695781, learning_rate: 1.731e-05, global_step: 5710, interval_runtime: 0.8073, interval_samples_per_second: 49.551, interval_steps_per_second: 6.194, epoch: 8.4593\r\n",
      "loss: 0.02511344, learning_rate: 1.73e-05, global_step: 5715, interval_runtime: 0.7785, interval_samples_per_second: 51.383, interval_steps_per_second: 6.423, epoch: 8.4667\r\n",
      "loss: 0.01666173, learning_rate: 1.729e-05, global_step: 5720, interval_runtime: 0.9674, interval_samples_per_second: 41.349, interval_steps_per_second: 5.169, epoch: 8.4741\r\n",
      "loss: 0.02852083, learning_rate: 1.728e-05, global_step: 5725, interval_runtime: 0.8252, interval_samples_per_second: 48.474, interval_steps_per_second: 6.059, epoch: 8.4815\r\n",
      "loss: 0.03188487, learning_rate: 1.727e-05, global_step: 5730, interval_runtime: 0.8257, interval_samples_per_second: 48.442, interval_steps_per_second: 6.055, epoch: 8.4889\r\n",
      "loss: 0.02909606, learning_rate: 1.726e-05, global_step: 5735, interval_runtime: 0.7207, interval_samples_per_second: 55.504, interval_steps_per_second: 6.938, epoch: 8.4963\r\n",
      "loss: 0.03192822, learning_rate: 1.724e-05, global_step: 5740, interval_runtime: 0.8443, interval_samples_per_second: 47.377, interval_steps_per_second: 5.922, epoch: 8.5037\r\n",
      "loss: 0.03812929, learning_rate: 1.723e-05, global_step: 5745, interval_runtime: 1.0035, interval_samples_per_second: 39.859, interval_steps_per_second: 4.982, epoch: 8.5111\r\n",
      "loss: 0.02053269, learning_rate: 1.722e-05, global_step: 5750, interval_runtime: 0.7544, interval_samples_per_second: 53.022, interval_steps_per_second: 6.628, epoch: 8.5185\r\n",
      "loss: 0.02715631, learning_rate: 1.721e-05, global_step: 5755, interval_runtime: 0.8577, interval_samples_per_second: 46.635, interval_steps_per_second: 5.829, epoch: 8.5259\r\n",
      "loss: 0.04545576, learning_rate: 1.72e-05, global_step: 5760, interval_runtime: 0.8257, interval_samples_per_second: 48.442, interval_steps_per_second: 6.055, epoch: 8.5333\r\n",
      "loss: 0.03542922, learning_rate: 1.719e-05, global_step: 5765, interval_runtime: 0.8237, interval_samples_per_second: 48.563, interval_steps_per_second: 6.07, epoch: 8.5407\r\n",
      "loss: 0.04134554, learning_rate: 1.718e-05, global_step: 5770, interval_runtime: 0.9801, interval_samples_per_second: 40.813, interval_steps_per_second: 5.102, epoch: 8.5481\r\n",
      "loss: 0.03420343, learning_rate: 1.717e-05, global_step: 5775, interval_runtime: 0.9135, interval_samples_per_second: 43.789, interval_steps_per_second: 5.474, epoch: 8.5556\r\n",
      "loss: 0.03111185, learning_rate: 1.716e-05, global_step: 5780, interval_runtime: 0.9522, interval_samples_per_second: 42.01, interval_steps_per_second: 5.251, epoch: 8.563\r\n",
      "loss: 0.04985045, learning_rate: 1.714e-05, global_step: 5785, interval_runtime: 0.8585, interval_samples_per_second: 46.592, interval_steps_per_second: 5.824, epoch: 8.5704\r\n",
      "loss: 0.03418409, learning_rate: 1.713e-05, global_step: 5790, interval_runtime: 0.7445, interval_samples_per_second: 53.728, interval_steps_per_second: 6.716, epoch: 8.5778\r\n",
      "loss: 0.02166957, learning_rate: 1.712e-05, global_step: 5795, interval_runtime: 0.895, interval_samples_per_second: 44.693, interval_steps_per_second: 5.587, epoch: 8.5852\r\n",
      "loss: 0.03931794, learning_rate: 1.711e-05, global_step: 5800, interval_runtime: 0.9986, interval_samples_per_second: 40.054, interval_steps_per_second: 5.007, epoch: 8.5926\r\n",
      "loss: 0.02582474, learning_rate: 1.71e-05, global_step: 5805, interval_runtime: 0.838, interval_samples_per_second: 47.731, interval_steps_per_second: 5.966, epoch: 8.6\r\n",
      "loss: 0.02952082, learning_rate: 1.709e-05, global_step: 5810, interval_runtime: 0.9085, interval_samples_per_second: 44.027, interval_steps_per_second: 5.503, epoch: 8.6074\r\n",
      "loss: 0.03781709, learning_rate: 1.708e-05, global_step: 5815, interval_runtime: 0.7517, interval_samples_per_second: 53.212, interval_steps_per_second: 6.652, epoch: 8.6148\r\n",
      "loss: 0.04704319, learning_rate: 1.707e-05, global_step: 5820, interval_runtime: 0.8926, interval_samples_per_second: 44.812, interval_steps_per_second: 5.602, epoch: 8.6222\r\n",
      "loss: 0.03985811, learning_rate: 1.706e-05, global_step: 5825, interval_runtime: 0.8126, interval_samples_per_second: 49.224, interval_steps_per_second: 6.153, epoch: 8.6296\r\n",
      "loss: 0.06084434, learning_rate: 1.704e-05, global_step: 5830, interval_runtime: 0.9225, interval_samples_per_second: 43.361, interval_steps_per_second: 5.42, epoch: 8.637\r\n",
      "loss: 0.05229592, learning_rate: 1.703e-05, global_step: 5835, interval_runtime: 0.7834, interval_samples_per_second: 51.062, interval_steps_per_second: 6.383, epoch: 8.6444\r\n",
      "loss: 0.04334223, learning_rate: 1.702e-05, global_step: 5840, interval_runtime: 0.9845, interval_samples_per_second: 40.631, interval_steps_per_second: 5.079, epoch: 8.6519\r\n",
      "loss: 0.06848308, learning_rate: 1.701e-05, global_step: 5845, interval_runtime: 0.8337, interval_samples_per_second: 47.977, interval_steps_per_second: 5.997, epoch: 8.6593\r\n",
      "loss: 0.04892902, learning_rate: 1.7e-05, global_step: 5850, interval_runtime: 0.7581, interval_samples_per_second: 52.76, interval_steps_per_second: 6.595, epoch: 8.6667\r\n",
      "loss: 0.03737405, learning_rate: 1.699e-05, global_step: 5855, interval_runtime: 0.8783, interval_samples_per_second: 45.541, interval_steps_per_second: 5.693, epoch: 8.6741\r\n",
      "loss: 0.0416506, learning_rate: 1.698e-05, global_step: 5860, interval_runtime: 0.9222, interval_samples_per_second: 43.373, interval_steps_per_second: 5.422, epoch: 8.6815\r\n",
      "loss: 0.0625495, learning_rate: 1.697e-05, global_step: 5865, interval_runtime: 0.814, interval_samples_per_second: 49.137, interval_steps_per_second: 6.142, epoch: 8.6889\r\n",
      "loss: 0.03418576, learning_rate: 1.696e-05, global_step: 5870, interval_runtime: 0.732, interval_samples_per_second: 54.644, interval_steps_per_second: 6.83, epoch: 8.6963\r\n",
      "loss: 0.03088306, learning_rate: 1.694e-05, global_step: 5875, interval_runtime: 0.8306, interval_samples_per_second: 48.157, interval_steps_per_second: 6.02, epoch: 8.7037\r\n",
      "loss: 0.02892244, learning_rate: 1.693e-05, global_step: 5880, interval_runtime: 0.8022, interval_samples_per_second: 49.861, interval_steps_per_second: 6.233, epoch: 8.7111\r\n",
      "loss: 0.06263893, learning_rate: 1.692e-05, global_step: 5885, interval_runtime: 0.9393, interval_samples_per_second: 42.585, interval_steps_per_second: 5.323, epoch: 8.7185\r\n",
      "loss: 0.04146143, learning_rate: 1.691e-05, global_step: 5890, interval_runtime: 0.9885, interval_samples_per_second: 40.464, interval_steps_per_second: 5.058, epoch: 8.7259\r\n",
      "loss: 0.02542934, learning_rate: 1.69e-05, global_step: 5895, interval_runtime: 0.7649, interval_samples_per_second: 52.297, interval_steps_per_second: 6.537, epoch: 8.7333\r\n",
      "loss: 0.03882879, learning_rate: 1.689e-05, global_step: 5900, interval_runtime: 0.9038, interval_samples_per_second: 44.258, interval_steps_per_second: 5.532, epoch: 8.7407\r\n",
      "loss: 0.05821466, learning_rate: 1.688e-05, global_step: 5905, interval_runtime: 1.0491, interval_samples_per_second: 38.127, interval_steps_per_second: 4.766, epoch: 8.7481\r\n",
      "loss: 0.02692873, learning_rate: 1.687e-05, global_step: 5910, interval_runtime: 0.8414, interval_samples_per_second: 47.538, interval_steps_per_second: 5.942, epoch: 8.7556\r\n",
      "loss: 0.05204991, learning_rate: 1.686e-05, global_step: 5915, interval_runtime: 0.7891, interval_samples_per_second: 50.694, interval_steps_per_second: 6.337, epoch: 8.763\r\n",
      "loss: 0.02528914, learning_rate: 1.684e-05, global_step: 5920, interval_runtime: 0.9004, interval_samples_per_second: 44.423, interval_steps_per_second: 5.553, epoch: 8.7704\r\n",
      "loss: 0.0371705, learning_rate: 1.683e-05, global_step: 5925, interval_runtime: 0.8364, interval_samples_per_second: 47.824, interval_steps_per_second: 5.978, epoch: 8.7778\r\n",
      "loss: 0.04015164, learning_rate: 1.682e-05, global_step: 5930, interval_runtime: 0.8574, interval_samples_per_second: 46.651, interval_steps_per_second: 5.831, epoch: 8.7852\r\n",
      "loss: 0.04310506, learning_rate: 1.681e-05, global_step: 5935, interval_runtime: 0.8558, interval_samples_per_second: 46.738, interval_steps_per_second: 5.842, epoch: 8.7926\r\n",
      "loss: 0.0543492, learning_rate: 1.68e-05, global_step: 5940, interval_runtime: 0.8433, interval_samples_per_second: 47.433, interval_steps_per_second: 5.929, epoch: 8.8\r\n",
      "loss: 0.03539, learning_rate: 1.679e-05, global_step: 5945, interval_runtime: 0.9129, interval_samples_per_second: 43.816, interval_steps_per_second: 5.477, epoch: 8.8074\r\n",
      "loss: 0.03741551, learning_rate: 1.678e-05, global_step: 5950, interval_runtime: 0.8901, interval_samples_per_second: 44.941, interval_steps_per_second: 5.618, epoch: 8.8148\r\n",
      "loss: 0.03615205, learning_rate: 1.677e-05, global_step: 5955, interval_runtime: 0.9182, interval_samples_per_second: 43.564, interval_steps_per_second: 5.445, epoch: 8.8222\r\n",
      "loss: 0.02904591, learning_rate: 1.676e-05, global_step: 5960, interval_runtime: 0.7342, interval_samples_per_second: 54.482, interval_steps_per_second: 6.81, epoch: 8.8296\r\n",
      "loss: 0.03472018, learning_rate: 1.674e-05, global_step: 5965, interval_runtime: 0.8421, interval_samples_per_second: 47.501, interval_steps_per_second: 5.938, epoch: 8.837\r\n",
      "loss: 0.02488859, learning_rate: 1.673e-05, global_step: 5970, interval_runtime: 0.899, interval_samples_per_second: 44.494, interval_steps_per_second: 5.562, epoch: 8.8444\r\n",
      "loss: 0.05152856, learning_rate: 1.672e-05, global_step: 5975, interval_runtime: 0.792, interval_samples_per_second: 50.504, interval_steps_per_second: 6.313, epoch: 8.8519\r\n",
      "loss: 0.05797871, learning_rate: 1.671e-05, global_step: 5980, interval_runtime: 0.875, interval_samples_per_second: 45.716, interval_steps_per_second: 5.715, epoch: 8.8593\r\n",
      "loss: 0.01979162, learning_rate: 1.67e-05, global_step: 5985, interval_runtime: 0.6992, interval_samples_per_second: 57.206, interval_steps_per_second: 7.151, epoch: 8.8667\r\n",
      "loss: 0.03537231, learning_rate: 1.669e-05, global_step: 5990, interval_runtime: 0.8134, interval_samples_per_second: 49.177, interval_steps_per_second: 6.147, epoch: 8.8741\r\n",
      "loss: 0.04354581, learning_rate: 1.668e-05, global_step: 5995, interval_runtime: 0.8523, interval_samples_per_second: 46.931, interval_steps_per_second: 5.866, epoch: 8.8815\r\n",
      "loss: 0.03920768, learning_rate: 1.667e-05, global_step: 6000, interval_runtime: 0.8147, interval_samples_per_second: 49.095, interval_steps_per_second: 6.137, epoch: 8.8889\r\n",
      "loss: 0.03605783, learning_rate: 1.666e-05, global_step: 6005, interval_runtime: 0.97, interval_samples_per_second: 41.235, interval_steps_per_second: 5.154, epoch: 8.8963\r\n",
      "loss: 0.0765874, learning_rate: 1.664e-05, global_step: 6010, interval_runtime: 0.8841, interval_samples_per_second: 45.246, interval_steps_per_second: 5.656, epoch: 8.9037\r\n",
      "loss: 0.03187912, learning_rate: 1.663e-05, global_step: 6015, interval_runtime: 0.7845, interval_samples_per_second: 50.99, interval_steps_per_second: 6.374, epoch: 8.9111\r\n",
      "loss: 0.07495174, learning_rate: 1.662e-05, global_step: 6020, interval_runtime: 1.0153, interval_samples_per_second: 39.399, interval_steps_per_second: 4.925, epoch: 8.9185\r\n",
      "loss: 0.05091799, learning_rate: 1.661e-05, global_step: 6025, interval_runtime: 0.9685, interval_samples_per_second: 41.3, interval_steps_per_second: 5.163, epoch: 8.9259\r\n",
      "loss: 0.0258057, learning_rate: 1.66e-05, global_step: 6030, interval_runtime: 0.8698, interval_samples_per_second: 45.989, interval_steps_per_second: 5.749, epoch: 8.9333\r\n",
      "loss: 0.03099294, learning_rate: 1.659e-05, global_step: 6035, interval_runtime: 0.9288, interval_samples_per_second: 43.068, interval_steps_per_second: 5.384, epoch: 8.9407\r\n",
      "loss: 0.04103144, learning_rate: 1.658e-05, global_step: 6040, interval_runtime: 0.8354, interval_samples_per_second: 47.88, interval_steps_per_second: 5.985, epoch: 8.9481\r\n",
      "loss: 0.03886276, learning_rate: 1.657e-05, global_step: 6045, interval_runtime: 0.7718, interval_samples_per_second: 51.83, interval_steps_per_second: 6.479, epoch: 8.9556\r\n",
      "loss: 0.01960592, learning_rate: 1.656e-05, global_step: 6050, interval_runtime: 0.8003, interval_samples_per_second: 49.983, interval_steps_per_second: 6.248, epoch: 8.963\r\n",
      "loss: 0.03617445, learning_rate: 1.654e-05, global_step: 6055, interval_runtime: 0.802, interval_samples_per_second: 49.875, interval_steps_per_second: 6.234, epoch: 8.9704\r\n",
      "loss: 0.0423089, learning_rate: 1.653e-05, global_step: 6060, interval_runtime: 0.8596, interval_samples_per_second: 46.532, interval_steps_per_second: 5.816, epoch: 8.9778\r\n",
      "loss: 0.05187854, learning_rate: 1.652e-05, global_step: 6065, interval_runtime: 0.9836, interval_samples_per_second: 40.668, interval_steps_per_second: 5.084, epoch: 8.9852\r\n",
      "loss: 0.04752218, learning_rate: 1.651e-05, global_step: 6070, interval_runtime: 0.8455, interval_samples_per_second: 47.309, interval_steps_per_second: 5.914, epoch: 8.9926\r\n",
      "loss: 0.09612017, learning_rate: 1.65e-05, global_step: 6075, interval_runtime: 0.7048, interval_samples_per_second: 56.754, interval_steps_per_second: 7.094, epoch: 9.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:58:43,858] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 10:58:43,860] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 10:58:43,862] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 10:58:43,864] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 10:58:43,866] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.6083846688270569, eval_micro_f1_score: 0.5616350177019633, eval_macro_f1_score: 0.4619679200333904, eval_runtime: 13.6776, eval_samples_per_second: 138.62, eval_steps_per_second: 17.328, epoch: 9.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 10:58:57,541] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-6075\r\n",
      "[2023-01-10 10:58:57,546] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 10:59:00,884] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-6075/tokenizer_config.json\r\n",
      "[2023-01-10 10:59:00,889] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-6075/special_tokens_map.json\r\n",
      "[2023-01-10 10:59:07,608] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-4725] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.02060741, learning_rate: 1.649e-05, global_step: 6080, interval_runtime: 25.2105, interval_samples_per_second: 1.587, interval_steps_per_second: 0.198, epoch: 9.0074\r\n",
      "loss: 0.01604954, learning_rate: 1.648e-05, global_step: 6085, interval_runtime: 0.933, interval_samples_per_second: 42.87, interval_steps_per_second: 5.359, epoch: 9.0148\r\n",
      "loss: 0.02877992, learning_rate: 1.647e-05, global_step: 6090, interval_runtime: 0.804, interval_samples_per_second: 49.751, interval_steps_per_second: 6.219, epoch: 9.0222\r\n",
      "loss: 0.02106849, learning_rate: 1.646e-05, global_step: 6095, interval_runtime: 0.7558, interval_samples_per_second: 52.923, interval_steps_per_second: 6.615, epoch: 9.0296\r\n",
      "loss: 0.01702064, learning_rate: 1.644e-05, global_step: 6100, interval_runtime: 0.7604, interval_samples_per_second: 52.605, interval_steps_per_second: 6.576, epoch: 9.037\r\n",
      "loss: 0.01815653, learning_rate: 1.643e-05, global_step: 6105, interval_runtime: 0.8095, interval_samples_per_second: 49.41, interval_steps_per_second: 6.176, epoch: 9.0444\r\n",
      "loss: 0.01943537, learning_rate: 1.642e-05, global_step: 6110, interval_runtime: 0.9983, interval_samples_per_second: 40.067, interval_steps_per_second: 5.008, epoch: 9.0519\r\n",
      "loss: 0.01584991, learning_rate: 1.641e-05, global_step: 6115, interval_runtime: 0.7628, interval_samples_per_second: 52.441, interval_steps_per_second: 6.555, epoch: 9.0593\r\n",
      "loss: 0.01564537, learning_rate: 1.64e-05, global_step: 6120, interval_runtime: 0.866, interval_samples_per_second: 46.191, interval_steps_per_second: 5.774, epoch: 9.0667\r\n",
      "loss: 0.04442019, learning_rate: 1.639e-05, global_step: 6125, interval_runtime: 0.8668, interval_samples_per_second: 46.149, interval_steps_per_second: 5.769, epoch: 9.0741\r\n",
      "loss: 0.01858243, learning_rate: 1.638e-05, global_step: 6130, interval_runtime: 0.8799, interval_samples_per_second: 45.462, interval_steps_per_second: 5.683, epoch: 9.0815\r\n",
      "loss: 0.01318035, learning_rate: 1.637e-05, global_step: 6135, interval_runtime: 0.8326, interval_samples_per_second: 48.042, interval_steps_per_second: 6.005, epoch: 9.0889\r\n",
      "loss: 0.0292134, learning_rate: 1.636e-05, global_step: 6140, interval_runtime: 0.8488, interval_samples_per_second: 47.128, interval_steps_per_second: 5.891, epoch: 9.0963\r\n",
      "loss: 0.0311955, learning_rate: 1.634e-05, global_step: 6145, interval_runtime: 0.7311, interval_samples_per_second: 54.715, interval_steps_per_second: 6.839, epoch: 9.1037\r\n",
      "loss: 0.03151597, learning_rate: 1.633e-05, global_step: 6150, interval_runtime: 0.8303, interval_samples_per_second: 48.176, interval_steps_per_second: 6.022, epoch: 9.1111\r\n",
      "loss: 0.03344522, learning_rate: 1.632e-05, global_step: 6155, interval_runtime: 0.84, interval_samples_per_second: 47.618, interval_steps_per_second: 5.952, epoch: 9.1185\r\n",
      "loss: 0.02310631, learning_rate: 1.631e-05, global_step: 6160, interval_runtime: 0.8118, interval_samples_per_second: 49.273, interval_steps_per_second: 6.159, epoch: 9.1259\r\n",
      "loss: 0.0316127, learning_rate: 1.63e-05, global_step: 6165, interval_runtime: 0.8333, interval_samples_per_second: 48.0, interval_steps_per_second: 6.0, epoch: 9.1333\r\n",
      "loss: 0.0209758, learning_rate: 1.629e-05, global_step: 6170, interval_runtime: 0.9554, interval_samples_per_second: 41.868, interval_steps_per_second: 5.234, epoch: 9.1407\r\n",
      "loss: 0.03683001, learning_rate: 1.628e-05, global_step: 6175, interval_runtime: 0.8126, interval_samples_per_second: 49.223, interval_steps_per_second: 6.153, epoch: 9.1481\r\n",
      "loss: 0.03487391, learning_rate: 1.627e-05, global_step: 6180, interval_runtime: 0.8564, interval_samples_per_second: 46.707, interval_steps_per_second: 5.838, epoch: 9.1556\r\n",
      "loss: 0.03145679, learning_rate: 1.626e-05, global_step: 6185, interval_runtime: 0.8522, interval_samples_per_second: 46.939, interval_steps_per_second: 5.867, epoch: 9.163\r\n",
      "loss: 0.0252649, learning_rate: 1.624e-05, global_step: 6190, interval_runtime: 0.7442, interval_samples_per_second: 53.747, interval_steps_per_second: 6.718, epoch: 9.1704\r\n",
      "loss: 0.01952061, learning_rate: 1.623e-05, global_step: 6195, interval_runtime: 0.8783, interval_samples_per_second: 45.542, interval_steps_per_second: 5.693, epoch: 9.1778\r\n",
      "loss: 0.03730337, learning_rate: 1.622e-05, global_step: 6200, interval_runtime: 0.7591, interval_samples_per_second: 52.694, interval_steps_per_second: 6.587, epoch: 9.1852\r\n",
      "loss: 0.01878382, learning_rate: 1.621e-05, global_step: 6205, interval_runtime: 0.8662, interval_samples_per_second: 46.179, interval_steps_per_second: 5.772, epoch: 9.1926\r\n",
      "loss: 0.01432519, learning_rate: 1.62e-05, global_step: 6210, interval_runtime: 0.822, interval_samples_per_second: 48.663, interval_steps_per_second: 6.083, epoch: 9.2\r\n",
      "loss: 0.0286269, learning_rate: 1.619e-05, global_step: 6215, interval_runtime: 0.9344, interval_samples_per_second: 42.808, interval_steps_per_second: 5.351, epoch: 9.2074\r\n",
      "loss: 0.02448772, learning_rate: 1.618e-05, global_step: 6220, interval_runtime: 0.8526, interval_samples_per_second: 46.914, interval_steps_per_second: 5.864, epoch: 9.2148\r\n",
      "loss: 0.02728029, learning_rate: 1.617e-05, global_step: 6225, interval_runtime: 0.8411, interval_samples_per_second: 47.558, interval_steps_per_second: 5.945, epoch: 9.2222\r\n",
      "loss: 0.02974491, learning_rate: 1.616e-05, global_step: 6230, interval_runtime: 0.756, interval_samples_per_second: 52.908, interval_steps_per_second: 6.613, epoch: 9.2296\r\n",
      "loss: 0.03223764, learning_rate: 1.614e-05, global_step: 6235, interval_runtime: 0.8084, interval_samples_per_second: 49.479, interval_steps_per_second: 6.185, epoch: 9.237\r\n",
      "loss: 0.01665914, learning_rate: 1.613e-05, global_step: 6240, interval_runtime: 0.8028, interval_samples_per_second: 49.826, interval_steps_per_second: 6.228, epoch: 9.2444\r\n",
      "loss: 0.03842579, learning_rate: 1.612e-05, global_step: 6245, interval_runtime: 1.0103, interval_samples_per_second: 39.592, interval_steps_per_second: 4.949, epoch: 9.2519\r\n",
      "loss: 0.02394888, learning_rate: 1.611e-05, global_step: 6250, interval_runtime: 0.8662, interval_samples_per_second: 46.18, interval_steps_per_second: 5.772, epoch: 9.2593\r\n",
      "loss: 0.03541156, learning_rate: 1.61e-05, global_step: 6255, interval_runtime: 0.9344, interval_samples_per_second: 42.81, interval_steps_per_second: 5.351, epoch: 9.2667\r\n",
      "loss: 0.02865075, learning_rate: 1.609e-05, global_step: 6260, interval_runtime: 0.8801, interval_samples_per_second: 45.447, interval_steps_per_second: 5.681, epoch: 9.2741\r\n",
      "loss: 0.02394255, learning_rate: 1.608e-05, global_step: 6265, interval_runtime: 0.8731, interval_samples_per_second: 45.813, interval_steps_per_second: 5.727, epoch: 9.2815\r\n",
      "loss: 0.01722073, learning_rate: 1.607e-05, global_step: 6270, interval_runtime: 0.7715, interval_samples_per_second: 51.85, interval_steps_per_second: 6.481, epoch: 9.2889\r\n",
      "loss: 0.02623134, learning_rate: 1.606e-05, global_step: 6275, interval_runtime: 0.8231, interval_samples_per_second: 48.599, interval_steps_per_second: 6.075, epoch: 9.2963\r\n",
      "loss: 0.03325261, learning_rate: 1.604e-05, global_step: 6280, interval_runtime: 0.8708, interval_samples_per_second: 45.936, interval_steps_per_second: 5.742, epoch: 9.3037\r\n",
      "loss: 0.04264607, learning_rate: 1.603e-05, global_step: 6285, interval_runtime: 0.7333, interval_samples_per_second: 54.55, interval_steps_per_second: 6.819, epoch: 9.3111\r\n",
      "loss: 0.02016112, learning_rate: 1.602e-05, global_step: 6290, interval_runtime: 0.8332, interval_samples_per_second: 48.008, interval_steps_per_second: 6.001, epoch: 9.3185\r\n",
      "loss: 0.02443599, learning_rate: 1.601e-05, global_step: 6295, interval_runtime: 1.0783, interval_samples_per_second: 37.096, interval_steps_per_second: 4.637, epoch: 9.3259\r\n",
      "loss: 0.03618547, learning_rate: 1.6e-05, global_step: 6300, interval_runtime: 0.8644, interval_samples_per_second: 46.277, interval_steps_per_second: 5.785, epoch: 9.3333\r\n",
      "loss: 0.02667313, learning_rate: 1.599e-05, global_step: 6305, interval_runtime: 0.8453, interval_samples_per_second: 47.32, interval_steps_per_second: 5.915, epoch: 9.3407\r\n",
      "loss: 0.04297858, learning_rate: 1.598e-05, global_step: 6310, interval_runtime: 0.7693, interval_samples_per_second: 51.994, interval_steps_per_second: 6.499, epoch: 9.3481\r\n",
      "loss: 0.01161362, learning_rate: 1.597e-05, global_step: 6315, interval_runtime: 0.752, interval_samples_per_second: 53.192, interval_steps_per_second: 6.649, epoch: 9.3556\r\n",
      "loss: 0.03837636, learning_rate: 1.596e-05, global_step: 6320, interval_runtime: 0.7735, interval_samples_per_second: 51.714, interval_steps_per_second: 6.464, epoch: 9.363\r\n",
      "loss: 0.03355785, learning_rate: 1.594e-05, global_step: 6325, interval_runtime: 1.1021, interval_samples_per_second: 36.295, interval_steps_per_second: 4.537, epoch: 9.3704\r\n",
      "loss: 0.02798401, learning_rate: 1.593e-05, global_step: 6330, interval_runtime: 0.9985, interval_samples_per_second: 40.059, interval_steps_per_second: 5.007, epoch: 9.3778\r\n",
      "loss: 0.0361619, learning_rate: 1.592e-05, global_step: 6335, interval_runtime: 0.7803, interval_samples_per_second: 51.261, interval_steps_per_second: 6.408, epoch: 9.3852\r\n",
      "loss: 0.01230633, learning_rate: 1.591e-05, global_step: 6340, interval_runtime: 0.7872, interval_samples_per_second: 50.812, interval_steps_per_second: 6.352, epoch: 9.3926\r\n",
      "loss: 0.0286426, learning_rate: 1.59e-05, global_step: 6345, interval_runtime: 0.8299, interval_samples_per_second: 48.2, interval_steps_per_second: 6.025, epoch: 9.4\r\n",
      "loss: 0.02110145, learning_rate: 1.589e-05, global_step: 6350, interval_runtime: 0.7946, interval_samples_per_second: 50.339, interval_steps_per_second: 6.292, epoch: 9.4074\r\n",
      "loss: 0.02494695, learning_rate: 1.588e-05, global_step: 6355, interval_runtime: 0.9652, interval_samples_per_second: 41.441, interval_steps_per_second: 5.18, epoch: 9.4148\r\n",
      "loss: 0.0426055, learning_rate: 1.587e-05, global_step: 6360, interval_runtime: 0.8203, interval_samples_per_second: 48.76, interval_steps_per_second: 6.095, epoch: 9.4222\r\n",
      "loss: 0.02972175, learning_rate: 1.586e-05, global_step: 6365, interval_runtime: 0.8326, interval_samples_per_second: 48.042, interval_steps_per_second: 6.005, epoch: 9.4296\r\n",
      "loss: 0.01882634, learning_rate: 1.584e-05, global_step: 6370, interval_runtime: 0.8833, interval_samples_per_second: 45.284, interval_steps_per_second: 5.661, epoch: 9.437\r\n",
      "loss: 0.04210494, learning_rate: 1.583e-05, global_step: 6375, interval_runtime: 0.9194, interval_samples_per_second: 43.509, interval_steps_per_second: 5.439, epoch: 9.4444\r\n",
      "loss: 0.0171609, learning_rate: 1.582e-05, global_step: 6380, interval_runtime: 0.8806, interval_samples_per_second: 45.424, interval_steps_per_second: 5.678, epoch: 9.4519\r\n",
      "loss: 0.02339701, learning_rate: 1.581e-05, global_step: 6385, interval_runtime: 0.7924, interval_samples_per_second: 50.477, interval_steps_per_second: 6.31, epoch: 9.4593\r\n",
      "loss: 0.01141865, learning_rate: 1.58e-05, global_step: 6390, interval_runtime: 0.8643, interval_samples_per_second: 46.278, interval_steps_per_second: 5.785, epoch: 9.4667\r\n",
      "loss: 0.02082113, learning_rate: 1.579e-05, global_step: 6395, interval_runtime: 0.9139, interval_samples_per_second: 43.771, interval_steps_per_second: 5.471, epoch: 9.4741\r\n",
      "loss: 0.03190143, learning_rate: 1.578e-05, global_step: 6400, interval_runtime: 0.7169, interval_samples_per_second: 55.795, interval_steps_per_second: 6.974, epoch: 9.4815\r\n",
      "loss: 0.02786924, learning_rate: 1.577e-05, global_step: 6405, interval_runtime: 0.7879, interval_samples_per_second: 50.766, interval_steps_per_second: 6.346, epoch: 9.4889\r\n",
      "loss: 0.02788763, learning_rate: 1.576e-05, global_step: 6410, interval_runtime: 0.8571, interval_samples_per_second: 46.667, interval_steps_per_second: 5.833, epoch: 9.4963\r\n",
      "loss: 0.01806704, learning_rate: 1.574e-05, global_step: 6415, interval_runtime: 0.8645, interval_samples_per_second: 46.269, interval_steps_per_second: 5.784, epoch: 9.5037\r\n",
      "loss: 0.0301983, learning_rate: 1.573e-05, global_step: 6420, interval_runtime: 0.8403, interval_samples_per_second: 47.604, interval_steps_per_second: 5.95, epoch: 9.5111\r\n",
      "loss: 0.0268396, learning_rate: 1.572e-05, global_step: 6425, interval_runtime: 0.875, interval_samples_per_second: 45.716, interval_steps_per_second: 5.714, epoch: 9.5185\r\n",
      "loss: 0.01588222, learning_rate: 1.571e-05, global_step: 6430, interval_runtime: 0.9502, interval_samples_per_second: 42.098, interval_steps_per_second: 5.262, epoch: 9.5259\r\n",
      "loss: 0.01501436, learning_rate: 1.57e-05, global_step: 6435, interval_runtime: 0.8206, interval_samples_per_second: 48.746, interval_steps_per_second: 6.093, epoch: 9.5333\r\n",
      "loss: 0.01941724, learning_rate: 1.569e-05, global_step: 6440, interval_runtime: 1.0044, interval_samples_per_second: 39.825, interval_steps_per_second: 4.978, epoch: 9.5407\r\n",
      "loss: 0.01581293, learning_rate: 1.568e-05, global_step: 6445, interval_runtime: 0.8548, interval_samples_per_second: 46.797, interval_steps_per_second: 5.85, epoch: 9.5481\r\n",
      "loss: 0.06153075, learning_rate: 1.567e-05, global_step: 6450, interval_runtime: 0.9219, interval_samples_per_second: 43.387, interval_steps_per_second: 5.423, epoch: 9.5556\r\n",
      "loss: 0.01649916, learning_rate: 1.566e-05, global_step: 6455, interval_runtime: 0.8993, interval_samples_per_second: 44.478, interval_steps_per_second: 5.56, epoch: 9.563\r\n",
      "loss: 0.02340645, learning_rate: 1.564e-05, global_step: 6460, interval_runtime: 0.8505, interval_samples_per_second: 47.029, interval_steps_per_second: 5.879, epoch: 9.5704\r\n",
      "loss: 0.02785826, learning_rate: 1.563e-05, global_step: 6465, interval_runtime: 0.8687, interval_samples_per_second: 46.045, interval_steps_per_second: 5.756, epoch: 9.5778\r\n",
      "loss: 0.03082794, learning_rate: 1.562e-05, global_step: 6470, interval_runtime: 0.7441, interval_samples_per_second: 53.76, interval_steps_per_second: 6.72, epoch: 9.5852\r\n",
      "loss: 0.01736467, learning_rate: 1.561e-05, global_step: 6475, interval_runtime: 0.9146, interval_samples_per_second: 43.735, interval_steps_per_second: 5.467, epoch: 9.5926\r\n",
      "loss: 0.02621824, learning_rate: 1.56e-05, global_step: 6480, interval_runtime: 0.9413, interval_samples_per_second: 42.494, interval_steps_per_second: 5.312, epoch: 9.6\r\n",
      "loss: 0.0366877, learning_rate: 1.559e-05, global_step: 6485, interval_runtime: 0.8803, interval_samples_per_second: 45.438, interval_steps_per_second: 5.68, epoch: 9.6074\r\n",
      "loss: 0.04988563, learning_rate: 1.558e-05, global_step: 6490, interval_runtime: 0.8661, interval_samples_per_second: 46.186, interval_steps_per_second: 5.773, epoch: 9.6148\r\n",
      "loss: 0.03756415, learning_rate: 1.557e-05, global_step: 6495, interval_runtime: 0.7592, interval_samples_per_second: 52.687, interval_steps_per_second: 6.586, epoch: 9.6222\r\n",
      "loss: 0.01689349, learning_rate: 1.556e-05, global_step: 6500, interval_runtime: 0.8131, interval_samples_per_second: 49.194, interval_steps_per_second: 6.149, epoch: 9.6296\r\n",
      "loss: 0.02117081, learning_rate: 1.554e-05, global_step: 6505, interval_runtime: 0.7758, interval_samples_per_second: 51.562, interval_steps_per_second: 6.445, epoch: 9.637\r\n",
      "loss: 0.03343148, learning_rate: 1.553e-05, global_step: 6510, interval_runtime: 0.7665, interval_samples_per_second: 52.187, interval_steps_per_second: 6.523, epoch: 9.6444\r\n",
      "loss: 0.06101823, learning_rate: 1.552e-05, global_step: 6515, interval_runtime: 0.9085, interval_samples_per_second: 44.028, interval_steps_per_second: 5.503, epoch: 9.6519\r\n",
      "loss: 0.02707055, learning_rate: 1.551e-05, global_step: 6520, interval_runtime: 0.815, interval_samples_per_second: 49.078, interval_steps_per_second: 6.135, epoch: 9.6593\r\n",
      "loss: 0.01854425, learning_rate: 1.55e-05, global_step: 6525, interval_runtime: 0.8219, interval_samples_per_second: 48.668, interval_steps_per_second: 6.083, epoch: 9.6667\r\n",
      "loss: 0.04249819, learning_rate: 1.549e-05, global_step: 6530, interval_runtime: 0.8064, interval_samples_per_second: 49.602, interval_steps_per_second: 6.2, epoch: 9.6741\r\n",
      "loss: 0.02208796, learning_rate: 1.548e-05, global_step: 6535, interval_runtime: 0.9551, interval_samples_per_second: 41.881, interval_steps_per_second: 5.235, epoch: 9.6815\r\n",
      "loss: 0.04332218, learning_rate: 1.547e-05, global_step: 6540, interval_runtime: 0.8619, interval_samples_per_second: 46.411, interval_steps_per_second: 5.801, epoch: 9.6889\r\n",
      "loss: 0.05063721, learning_rate: 1.546e-05, global_step: 6545, interval_runtime: 0.7904, interval_samples_per_second: 50.607, interval_steps_per_second: 6.326, epoch: 9.6963\r\n",
      "loss: 0.03144694, learning_rate: 1.544e-05, global_step: 6550, interval_runtime: 0.7813, interval_samples_per_second: 51.2, interval_steps_per_second: 6.4, epoch: 9.7037\r\n",
      "loss: 0.02488547, learning_rate: 1.543e-05, global_step: 6555, interval_runtime: 0.8927, interval_samples_per_second: 44.807, interval_steps_per_second: 5.601, epoch: 9.7111\r\n",
      "loss: 0.02972566, learning_rate: 1.542e-05, global_step: 6560, interval_runtime: 0.825, interval_samples_per_second: 48.484, interval_steps_per_second: 6.06, epoch: 9.7185\r\n",
      "loss: 0.03891962, learning_rate: 1.541e-05, global_step: 6565, interval_runtime: 0.849, interval_samples_per_second: 47.115, interval_steps_per_second: 5.889, epoch: 9.7259\r\n",
      "loss: 0.03759075, learning_rate: 1.54e-05, global_step: 6570, interval_runtime: 1.0132, interval_samples_per_second: 39.481, interval_steps_per_second: 4.935, epoch: 9.7333\r\n",
      "loss: 0.02547646, learning_rate: 1.539e-05, global_step: 6575, interval_runtime: 0.8818, interval_samples_per_second: 45.362, interval_steps_per_second: 5.67, epoch: 9.7407\r\n",
      "loss: 0.02224337, learning_rate: 1.538e-05, global_step: 6580, interval_runtime: 0.9356, interval_samples_per_second: 42.755, interval_steps_per_second: 5.344, epoch: 9.7481\r\n",
      "loss: 0.02323897, learning_rate: 1.537e-05, global_step: 6585, interval_runtime: 0.8117, interval_samples_per_second: 49.277, interval_steps_per_second: 6.16, epoch: 9.7556\r\n",
      "loss: 0.02044814, learning_rate: 1.536e-05, global_step: 6590, interval_runtime: 0.8606, interval_samples_per_second: 46.477, interval_steps_per_second: 5.81, epoch: 9.763\r\n",
      "loss: 0.02196609, learning_rate: 1.534e-05, global_step: 6595, interval_runtime: 0.7652, interval_samples_per_second: 52.275, interval_steps_per_second: 6.534, epoch: 9.7704\r\n",
      "loss: 0.01914491, learning_rate: 1.533e-05, global_step: 6600, interval_runtime: 0.7294, interval_samples_per_second: 54.84, interval_steps_per_second: 6.855, epoch: 9.7778\r\n",
      "loss: 0.03150291, learning_rate: 1.532e-05, global_step: 6605, interval_runtime: 0.9148, interval_samples_per_second: 43.728, interval_steps_per_second: 5.466, epoch: 9.7852\r\n",
      "loss: 0.01943101, learning_rate: 1.531e-05, global_step: 6610, interval_runtime: 0.9586, interval_samples_per_second: 41.73, interval_steps_per_second: 5.216, epoch: 9.7926\r\n",
      "loss: 0.04662305, learning_rate: 1.53e-05, global_step: 6615, interval_runtime: 0.8622, interval_samples_per_second: 46.394, interval_steps_per_second: 5.799, epoch: 9.8\r\n",
      "loss: 0.0264752, learning_rate: 1.529e-05, global_step: 6620, interval_runtime: 0.881, interval_samples_per_second: 45.404, interval_steps_per_second: 5.676, epoch: 9.8074\r\n",
      "loss: 0.0152073, learning_rate: 1.528e-05, global_step: 6625, interval_runtime: 0.9202, interval_samples_per_second: 43.467, interval_steps_per_second: 5.433, epoch: 9.8148\r\n",
      "loss: 0.01287795, learning_rate: 1.527e-05, global_step: 6630, interval_runtime: 0.9006, interval_samples_per_second: 44.415, interval_steps_per_second: 5.552, epoch: 9.8222\r\n",
      "loss: 0.04566624, learning_rate: 1.526e-05, global_step: 6635, interval_runtime: 0.939, interval_samples_per_second: 42.597, interval_steps_per_second: 5.325, epoch: 9.8296\r\n",
      "loss: 0.02102626, learning_rate: 1.524e-05, global_step: 6640, interval_runtime: 0.8496, interval_samples_per_second: 47.083, interval_steps_per_second: 5.885, epoch: 9.837\r\n",
      "loss: 0.02263661, learning_rate: 1.523e-05, global_step: 6645, interval_runtime: 0.8525, interval_samples_per_second: 46.921, interval_steps_per_second: 5.865, epoch: 9.8444\r\n",
      "loss: 0.04548497, learning_rate: 1.522e-05, global_step: 6650, interval_runtime: 0.9162, interval_samples_per_second: 43.656, interval_steps_per_second: 5.457, epoch: 9.8519\r\n",
      "loss: 0.02063361, learning_rate: 1.521e-05, global_step: 6655, interval_runtime: 0.8976, interval_samples_per_second: 44.565, interval_steps_per_second: 5.571, epoch: 9.8593\r\n",
      "loss: 0.03007206, learning_rate: 1.52e-05, global_step: 6660, interval_runtime: 0.8913, interval_samples_per_second: 44.878, interval_steps_per_second: 5.61, epoch: 9.8667\r\n",
      "loss: 0.05610166, learning_rate: 1.519e-05, global_step: 6665, interval_runtime: 0.8676, interval_samples_per_second: 46.107, interval_steps_per_second: 5.763, epoch: 9.8741\r\n",
      "loss: 0.02586669, learning_rate: 1.518e-05, global_step: 6670, interval_runtime: 0.8351, interval_samples_per_second: 47.898, interval_steps_per_second: 5.987, epoch: 9.8815\r\n",
      "loss: 0.01605417, learning_rate: 1.517e-05, global_step: 6675, interval_runtime: 0.8531, interval_samples_per_second: 46.887, interval_steps_per_second: 5.861, epoch: 9.8889\r\n",
      "loss: 0.02054712, learning_rate: 1.516e-05, global_step: 6680, interval_runtime: 0.8968, interval_samples_per_second: 44.604, interval_steps_per_second: 5.576, epoch: 9.8963\r\n",
      "loss: 0.01155388, learning_rate: 1.514e-05, global_step: 6685, interval_runtime: 0.7302, interval_samples_per_second: 54.782, interval_steps_per_second: 6.848, epoch: 9.9037\r\n",
      "loss: 0.0347393, learning_rate: 1.513e-05, global_step: 6690, interval_runtime: 0.8666, interval_samples_per_second: 46.157, interval_steps_per_second: 5.77, epoch: 9.9111\r\n",
      "loss: 0.01564463, learning_rate: 1.512e-05, global_step: 6695, interval_runtime: 0.6914, interval_samples_per_second: 57.854, interval_steps_per_second: 7.232, epoch: 9.9185\r\n",
      "loss: 0.02688612, learning_rate: 1.511e-05, global_step: 6700, interval_runtime: 0.8637, interval_samples_per_second: 46.31, interval_steps_per_second: 5.789, epoch: 9.9259\r\n",
      "loss: 0.0302072, learning_rate: 1.51e-05, global_step: 6705, interval_runtime: 0.9317, interval_samples_per_second: 42.933, interval_steps_per_second: 5.367, epoch: 9.9333\r\n",
      "loss: 0.0242977, learning_rate: 1.509e-05, global_step: 6710, interval_runtime: 0.9385, interval_samples_per_second: 42.623, interval_steps_per_second: 5.328, epoch: 9.9407\r\n",
      "loss: 0.03562271, learning_rate: 1.508e-05, global_step: 6715, interval_runtime: 0.7401, interval_samples_per_second: 54.05, interval_steps_per_second: 6.756, epoch: 9.9481\r\n",
      "loss: 0.0166772, learning_rate: 1.507e-05, global_step: 6720, interval_runtime: 0.7539, interval_samples_per_second: 53.056, interval_steps_per_second: 6.632, epoch: 9.9556\r\n",
      "loss: 0.01925512, learning_rate: 1.506e-05, global_step: 6725, interval_runtime: 0.7156, interval_samples_per_second: 55.896, interval_steps_per_second: 6.987, epoch: 9.963\r\n",
      "loss: 0.01947982, learning_rate: 1.504e-05, global_step: 6730, interval_runtime: 0.7119, interval_samples_per_second: 56.185, interval_steps_per_second: 7.023, epoch: 9.9704\r\n",
      "loss: 0.03558101, learning_rate: 1.503e-05, global_step: 6735, interval_runtime: 0.774, interval_samples_per_second: 51.679, interval_steps_per_second: 6.46, epoch: 9.9778\r\n",
      "loss: 0.02252122, learning_rate: 1.502e-05, global_step: 6740, interval_runtime: 0.9435, interval_samples_per_second: 42.393, interval_steps_per_second: 5.299, epoch: 9.9852\r\n",
      "loss: 0.02478569, learning_rate: 1.501e-05, global_step: 6745, interval_runtime: 0.8354, interval_samples_per_second: 47.88, interval_steps_per_second: 5.985, epoch: 9.9926\r\n",
      "loss: 0.02678521, learning_rate: 1.5e-05, global_step: 6750, interval_runtime: 0.8331, interval_samples_per_second: 48.016, interval_steps_per_second: 6.002, epoch: 10.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:01:03,063] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:01:03,066] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:01:03,068] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:01:03,070] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:01:03,072] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.6367492079734802, eval_micro_f1_score: 0.5662070653504121, eval_macro_f1_score: 0.4621369223558752, eval_runtime: 13.5789, eval_samples_per_second: 139.629, eval_steps_per_second: 17.454, epoch: 10.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:01:16,647] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-6750\r\n",
      "[2023-01-10 11:01:16,651] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:01:20,080] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-6750/tokenizer_config.json\r\n",
      "[2023-01-10 11:01:20,084] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-6750/special_tokens_map.json\r\n",
      "[2023-01-10 11:01:26,858] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-5400] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.02897286, learning_rate: 1.499e-05, global_step: 6755, interval_runtime: 25.4965, interval_samples_per_second: 1.569, interval_steps_per_second: 0.196, epoch: 10.0074\r\n",
      "loss: 0.0176739, learning_rate: 1.498e-05, global_step: 6760, interval_runtime: 0.9024, interval_samples_per_second: 44.325, interval_steps_per_second: 5.541, epoch: 10.0148\r\n",
      "loss: 0.01518709, learning_rate: 1.497e-05, global_step: 6765, interval_runtime: 0.8948, interval_samples_per_second: 44.705, interval_steps_per_second: 5.588, epoch: 10.0222\r\n",
      "loss: 0.01634071, learning_rate: 1.496e-05, global_step: 6770, interval_runtime: 0.7976, interval_samples_per_second: 50.15, interval_steps_per_second: 6.269, epoch: 10.0296\r\n",
      "loss: 0.05015285, learning_rate: 1.494e-05, global_step: 6775, interval_runtime: 0.8687, interval_samples_per_second: 46.044, interval_steps_per_second: 5.756, epoch: 10.037\r\n",
      "loss: 0.01841262, learning_rate: 1.493e-05, global_step: 6780, interval_runtime: 0.986, interval_samples_per_second: 40.57, interval_steps_per_second: 5.071, epoch: 10.0444\r\n",
      "loss: 0.02059149, learning_rate: 1.492e-05, global_step: 6785, interval_runtime: 0.7917, interval_samples_per_second: 50.527, interval_steps_per_second: 6.316, epoch: 10.0519\r\n",
      "loss: 0.01271303, learning_rate: 1.491e-05, global_step: 6790, interval_runtime: 0.8623, interval_samples_per_second: 46.389, interval_steps_per_second: 5.799, epoch: 10.0593\r\n",
      "loss: 0.03107786, learning_rate: 1.49e-05, global_step: 6795, interval_runtime: 0.8531, interval_samples_per_second: 46.887, interval_steps_per_second: 5.861, epoch: 10.0667\r\n",
      "loss: 0.01979486, learning_rate: 1.489e-05, global_step: 6800, interval_runtime: 0.7564, interval_samples_per_second: 52.883, interval_steps_per_second: 6.61, epoch: 10.0741\r\n",
      "loss: 0.00887193, learning_rate: 1.488e-05, global_step: 6805, interval_runtime: 0.8375, interval_samples_per_second: 47.76, interval_steps_per_second: 5.97, epoch: 10.0815\r\n",
      "loss: 0.0160063, learning_rate: 1.487e-05, global_step: 6810, interval_runtime: 0.7664, interval_samples_per_second: 52.189, interval_steps_per_second: 6.524, epoch: 10.0889\r\n",
      "loss: 0.01253625, learning_rate: 1.486e-05, global_step: 6815, interval_runtime: 0.8658, interval_samples_per_second: 46.197, interval_steps_per_second: 5.775, epoch: 10.0963\r\n",
      "loss: 0.01545332, learning_rate: 1.484e-05, global_step: 6820, interval_runtime: 0.9216, interval_samples_per_second: 43.404, interval_steps_per_second: 5.425, epoch: 10.1037\r\n",
      "loss: 0.014491, learning_rate: 1.483e-05, global_step: 6825, interval_runtime: 0.825, interval_samples_per_second: 48.484, interval_steps_per_second: 6.061, epoch: 10.1111\r\n",
      "loss: 0.0201228, learning_rate: 1.482e-05, global_step: 6830, interval_runtime: 0.7386, interval_samples_per_second: 54.159, interval_steps_per_second: 6.77, epoch: 10.1185\r\n",
      "loss: 0.01968091, learning_rate: 1.481e-05, global_step: 6835, interval_runtime: 0.8124, interval_samples_per_second: 49.236, interval_steps_per_second: 6.155, epoch: 10.1259\r\n",
      "loss: 0.02354624, learning_rate: 1.48e-05, global_step: 6840, interval_runtime: 0.8123, interval_samples_per_second: 49.243, interval_steps_per_second: 6.155, epoch: 10.1333\r\n",
      "loss: 0.02876135, learning_rate: 1.479e-05, global_step: 6845, interval_runtime: 0.8632, interval_samples_per_second: 46.341, interval_steps_per_second: 5.793, epoch: 10.1407\r\n",
      "loss: 0.01964454, learning_rate: 1.478e-05, global_step: 6850, interval_runtime: 0.8692, interval_samples_per_second: 46.021, interval_steps_per_second: 5.753, epoch: 10.1481\r\n",
      "loss: 0.01635663, learning_rate: 1.477e-05, global_step: 6855, interval_runtime: 0.8567, interval_samples_per_second: 46.691, interval_steps_per_second: 5.836, epoch: 10.1556\r\n",
      "loss: 0.02143119, learning_rate: 1.476e-05, global_step: 6860, interval_runtime: 0.8467, interval_samples_per_second: 47.24, interval_steps_per_second: 5.905, epoch: 10.163\r\n",
      "loss: 0.03708793, learning_rate: 1.474e-05, global_step: 6865, interval_runtime: 0.9523, interval_samples_per_second: 42.006, interval_steps_per_second: 5.251, epoch: 10.1704\r\n",
      "loss: 0.03082174, learning_rate: 1.473e-05, global_step: 6870, interval_runtime: 0.8523, interval_samples_per_second: 46.933, interval_steps_per_second: 5.867, epoch: 10.1778\r\n",
      "loss: 0.02321626, learning_rate: 1.472e-05, global_step: 6875, interval_runtime: 0.775, interval_samples_per_second: 51.611, interval_steps_per_second: 6.451, epoch: 10.1852\r\n",
      "loss: 0.02022105, learning_rate: 1.471e-05, global_step: 6880, interval_runtime: 0.7813, interval_samples_per_second: 51.197, interval_steps_per_second: 6.4, epoch: 10.1926\r\n",
      "loss: 0.01038384, learning_rate: 1.47e-05, global_step: 6885, interval_runtime: 0.8839, interval_samples_per_second: 45.256, interval_steps_per_second: 5.657, epoch: 10.2\r\n",
      "loss: 0.01042656, learning_rate: 1.469e-05, global_step: 6890, interval_runtime: 1.0318, interval_samples_per_second: 38.769, interval_steps_per_second: 4.846, epoch: 10.2074\r\n",
      "loss: 0.02631626, learning_rate: 1.468e-05, global_step: 6895, interval_runtime: 0.8621, interval_samples_per_second: 46.4, interval_steps_per_second: 5.8, epoch: 10.2148\r\n",
      "loss: 0.03792507, learning_rate: 1.467e-05, global_step: 6900, interval_runtime: 0.8837, interval_samples_per_second: 45.264, interval_steps_per_second: 5.658, epoch: 10.2222\r\n",
      "loss: 0.02503475, learning_rate: 1.466e-05, global_step: 6905, interval_runtime: 0.7973, interval_samples_per_second: 50.167, interval_steps_per_second: 6.271, epoch: 10.2296\r\n",
      "loss: 0.0210285, learning_rate: 1.464e-05, global_step: 6910, interval_runtime: 0.9254, interval_samples_per_second: 43.226, interval_steps_per_second: 5.403, epoch: 10.237\r\n",
      "loss: 0.02779348, learning_rate: 1.463e-05, global_step: 6915, interval_runtime: 0.8881, interval_samples_per_second: 45.038, interval_steps_per_second: 5.63, epoch: 10.2444\r\n",
      "loss: 0.01946496, learning_rate: 1.462e-05, global_step: 6920, interval_runtime: 0.8735, interval_samples_per_second: 45.793, interval_steps_per_second: 5.724, epoch: 10.2519\r\n",
      "loss: 0.02688901, learning_rate: 1.461e-05, global_step: 6925, interval_runtime: 0.7712, interval_samples_per_second: 51.864, interval_steps_per_second: 6.483, epoch: 10.2593\r\n",
      "loss: 0.01131143, learning_rate: 1.46e-05, global_step: 6930, interval_runtime: 0.8748, interval_samples_per_second: 45.723, interval_steps_per_second: 5.715, epoch: 10.2667\r\n",
      "loss: 0.02101591, learning_rate: 1.459e-05, global_step: 6935, interval_runtime: 0.8217, interval_samples_per_second: 48.677, interval_steps_per_second: 6.085, epoch: 10.2741\r\n",
      "loss: 0.01301857, learning_rate: 1.458e-05, global_step: 6940, interval_runtime: 0.7616, interval_samples_per_second: 52.519, interval_steps_per_second: 6.565, epoch: 10.2815\r\n",
      "loss: 0.0243021, learning_rate: 1.457e-05, global_step: 6945, interval_runtime: 0.8746, interval_samples_per_second: 45.737, interval_steps_per_second: 5.717, epoch: 10.2889\r\n",
      "loss: 0.00659018, learning_rate: 1.456e-05, global_step: 6950, interval_runtime: 0.9096, interval_samples_per_second: 43.977, interval_steps_per_second: 5.497, epoch: 10.2963\r\n",
      "loss: 0.01377773, learning_rate: 1.454e-05, global_step: 6955, interval_runtime: 0.8266, interval_samples_per_second: 48.39, interval_steps_per_second: 6.049, epoch: 10.3037\r\n",
      "loss: 0.01459782, learning_rate: 1.453e-05, global_step: 6960, interval_runtime: 0.7501, interval_samples_per_second: 53.325, interval_steps_per_second: 6.666, epoch: 10.3111\r\n",
      "loss: 0.01668661, learning_rate: 1.452e-05, global_step: 6965, interval_runtime: 0.7036, interval_samples_per_second: 56.848, interval_steps_per_second: 7.106, epoch: 10.3185\r\n",
      "loss: 0.01306078, learning_rate: 1.451e-05, global_step: 6970, interval_runtime: 0.9093, interval_samples_per_second: 43.989, interval_steps_per_second: 5.499, epoch: 10.3259\r\n",
      "loss: 0.01660539, learning_rate: 1.45e-05, global_step: 6975, interval_runtime: 0.9604, interval_samples_per_second: 41.648, interval_steps_per_second: 5.206, epoch: 10.3333\r\n",
      "loss: 0.01702222, learning_rate: 1.449e-05, global_step: 6980, interval_runtime: 0.83, interval_samples_per_second: 48.195, interval_steps_per_second: 6.024, epoch: 10.3407\r\n",
      "loss: 0.02661469, learning_rate: 1.448e-05, global_step: 6985, interval_runtime: 0.8332, interval_samples_per_second: 48.007, interval_steps_per_second: 6.001, epoch: 10.3481\r\n",
      "loss: 0.01926259, learning_rate: 1.447e-05, global_step: 6990, interval_runtime: 0.9146, interval_samples_per_second: 43.734, interval_steps_per_second: 5.467, epoch: 10.3556\r\n",
      "loss: 0.012894, learning_rate: 1.446e-05, global_step: 6995, interval_runtime: 0.7531, interval_samples_per_second: 53.112, interval_steps_per_second: 6.639, epoch: 10.363\r\n",
      "loss: 0.00897315, learning_rate: 1.444e-05, global_step: 7000, interval_runtime: 0.7591, interval_samples_per_second: 52.696, interval_steps_per_second: 6.587, epoch: 10.3704\r\n",
      "loss: 0.01067571, learning_rate: 1.443e-05, global_step: 7005, interval_runtime: 1.0674, interval_samples_per_second: 37.474, interval_steps_per_second: 4.684, epoch: 10.3778\r\n",
      "loss: 0.01371118, learning_rate: 1.442e-05, global_step: 7010, interval_runtime: 0.7923, interval_samples_per_second: 50.487, interval_steps_per_second: 6.311, epoch: 10.3852\r\n",
      "loss: 0.00848347, learning_rate: 1.441e-05, global_step: 7015, interval_runtime: 0.9114, interval_samples_per_second: 43.887, interval_steps_per_second: 5.486, epoch: 10.3926\r\n",
      "loss: 0.03182693, learning_rate: 1.44e-05, global_step: 7020, interval_runtime: 0.8894, interval_samples_per_second: 44.972, interval_steps_per_second: 5.622, epoch: 10.4\r\n",
      "loss: 0.01394732, learning_rate: 1.439e-05, global_step: 7025, interval_runtime: 0.8195, interval_samples_per_second: 48.812, interval_steps_per_second: 6.102, epoch: 10.4074\r\n",
      "loss: 0.01039988, learning_rate: 1.438e-05, global_step: 7030, interval_runtime: 0.7782, interval_samples_per_second: 51.402, interval_steps_per_second: 6.425, epoch: 10.4148\r\n",
      "loss: 0.02425086, learning_rate: 1.437e-05, global_step: 7035, interval_runtime: 0.7779, interval_samples_per_second: 51.419, interval_steps_per_second: 6.427, epoch: 10.4222\r\n",
      "loss: 0.0278488, learning_rate: 1.436e-05, global_step: 7040, interval_runtime: 0.9802, interval_samples_per_second: 40.807, interval_steps_per_second: 5.101, epoch: 10.4296\r\n",
      "loss: 0.01519393, learning_rate: 1.434e-05, global_step: 7045, interval_runtime: 0.9414, interval_samples_per_second: 42.488, interval_steps_per_second: 5.311, epoch: 10.437\r\n",
      "loss: 0.01793859, learning_rate: 1.433e-05, global_step: 7050, interval_runtime: 0.8277, interval_samples_per_second: 48.328, interval_steps_per_second: 6.041, epoch: 10.4444\r\n",
      "loss: 0.0124306, learning_rate: 1.432e-05, global_step: 7055, interval_runtime: 0.7652, interval_samples_per_second: 52.273, interval_steps_per_second: 6.534, epoch: 10.4519\r\n",
      "loss: 0.00842691, learning_rate: 1.431e-05, global_step: 7060, interval_runtime: 0.8546, interval_samples_per_second: 46.808, interval_steps_per_second: 5.851, epoch: 10.4593\r\n",
      "loss: 0.02560987, learning_rate: 1.43e-05, global_step: 7065, interval_runtime: 0.8433, interval_samples_per_second: 47.433, interval_steps_per_second: 5.929, epoch: 10.4667\r\n",
      "loss: 0.02268954, learning_rate: 1.429e-05, global_step: 7070, interval_runtime: 0.8878, interval_samples_per_second: 45.055, interval_steps_per_second: 5.632, epoch: 10.4741\r\n",
      "loss: 0.01645363, learning_rate: 1.428e-05, global_step: 7075, interval_runtime: 0.7783, interval_samples_per_second: 51.397, interval_steps_per_second: 6.425, epoch: 10.4815\r\n",
      "loss: 0.0381215, learning_rate: 1.427e-05, global_step: 7080, interval_runtime: 0.8794, interval_samples_per_second: 45.487, interval_steps_per_second: 5.686, epoch: 10.4889\r\n",
      "loss: 0.0162863, learning_rate: 1.426e-05, global_step: 7085, interval_runtime: 0.8385, interval_samples_per_second: 47.705, interval_steps_per_second: 5.963, epoch: 10.4963\r\n",
      "loss: 0.01590834, learning_rate: 1.424e-05, global_step: 7090, interval_runtime: 1.0159, interval_samples_per_second: 39.373, interval_steps_per_second: 4.922, epoch: 10.5037\r\n",
      "loss: 0.01508817, learning_rate: 1.423e-05, global_step: 7095, interval_runtime: 0.9921, interval_samples_per_second: 40.318, interval_steps_per_second: 5.04, epoch: 10.5111\r\n",
      "loss: 0.02584394, learning_rate: 1.422e-05, global_step: 7100, interval_runtime: 0.7551, interval_samples_per_second: 52.971, interval_steps_per_second: 6.621, epoch: 10.5185\r\n",
      "loss: 0.01706211, learning_rate: 1.421e-05, global_step: 7105, interval_runtime: 0.9446, interval_samples_per_second: 42.347, interval_steps_per_second: 5.293, epoch: 10.5259\r\n",
      "loss: 0.02669859, learning_rate: 1.42e-05, global_step: 7110, interval_runtime: 0.7581, interval_samples_per_second: 52.761, interval_steps_per_second: 6.595, epoch: 10.5333\r\n",
      "loss: 0.01881535, learning_rate: 1.419e-05, global_step: 7115, interval_runtime: 0.9157, interval_samples_per_second: 43.682, interval_steps_per_second: 5.46, epoch: 10.5407\r\n",
      "loss: 0.01870716, learning_rate: 1.418e-05, global_step: 7120, interval_runtime: 0.8636, interval_samples_per_second: 46.317, interval_steps_per_second: 5.79, epoch: 10.5481\r\n",
      "loss: 0.01438043, learning_rate: 1.417e-05, global_step: 7125, interval_runtime: 0.7757, interval_samples_per_second: 51.569, interval_steps_per_second: 6.446, epoch: 10.5556\r\n",
      "loss: 0.01174509, learning_rate: 1.416e-05, global_step: 7130, interval_runtime: 0.9276, interval_samples_per_second: 43.12, interval_steps_per_second: 5.39, epoch: 10.563\r\n",
      "loss: 0.02252577, learning_rate: 1.414e-05, global_step: 7135, interval_runtime: 0.9147, interval_samples_per_second: 43.728, interval_steps_per_second: 5.466, epoch: 10.5704\r\n",
      "loss: 0.01553866, learning_rate: 1.413e-05, global_step: 7140, interval_runtime: 0.7817, interval_samples_per_second: 51.168, interval_steps_per_second: 6.396, epoch: 10.5778\r\n",
      "loss: 0.01827991, learning_rate: 1.412e-05, global_step: 7145, interval_runtime: 0.8319, interval_samples_per_second: 48.081, interval_steps_per_second: 6.01, epoch: 10.5852\r\n",
      "loss: 0.0179724, learning_rate: 1.411e-05, global_step: 7150, interval_runtime: 0.8179, interval_samples_per_second: 48.909, interval_steps_per_second: 6.114, epoch: 10.5926\r\n",
      "loss: 0.01191036, learning_rate: 1.41e-05, global_step: 7155, interval_runtime: 0.9725, interval_samples_per_second: 41.133, interval_steps_per_second: 5.142, epoch: 10.6\r\n",
      "loss: 0.02603488, learning_rate: 1.409e-05, global_step: 7160, interval_runtime: 0.9227, interval_samples_per_second: 43.351, interval_steps_per_second: 5.419, epoch: 10.6074\r\n",
      "loss: 0.0284738, learning_rate: 1.408e-05, global_step: 7165, interval_runtime: 0.8051, interval_samples_per_second: 49.68, interval_steps_per_second: 6.21, epoch: 10.6148\r\n",
      "loss: 0.01725462, learning_rate: 1.407e-05, global_step: 7170, interval_runtime: 0.7415, interval_samples_per_second: 53.948, interval_steps_per_second: 6.743, epoch: 10.6222\r\n",
      "loss: 0.02870401, learning_rate: 1.406e-05, global_step: 7175, interval_runtime: 0.7971, interval_samples_per_second: 50.179, interval_steps_per_second: 6.272, epoch: 10.6296\r\n",
      "loss: 0.0282115, learning_rate: 1.404e-05, global_step: 7180, interval_runtime: 0.7562, interval_samples_per_second: 52.894, interval_steps_per_second: 6.612, epoch: 10.637\r\n",
      "loss: 0.03470138, learning_rate: 1.403e-05, global_step: 7185, interval_runtime: 0.7429, interval_samples_per_second: 53.843, interval_steps_per_second: 6.73, epoch: 10.6444\r\n",
      "loss: 0.02227336, learning_rate: 1.402e-05, global_step: 7190, interval_runtime: 0.8284, interval_samples_per_second: 48.286, interval_steps_per_second: 6.036, epoch: 10.6519\r\n",
      "loss: 0.01849627, learning_rate: 1.401e-05, global_step: 7195, interval_runtime: 0.7356, interval_samples_per_second: 54.379, interval_steps_per_second: 6.797, epoch: 10.6593\r\n",
      "loss: 0.0189428, learning_rate: 1.4e-05, global_step: 7200, interval_runtime: 0.8084, interval_samples_per_second: 49.479, interval_steps_per_second: 6.185, epoch: 10.6667\r\n",
      "loss: 0.03802498, learning_rate: 1.399e-05, global_step: 7205, interval_runtime: 0.9885, interval_samples_per_second: 40.466, interval_steps_per_second: 5.058, epoch: 10.6741\r\n",
      "loss: 0.02772041, learning_rate: 1.398e-05, global_step: 7210, interval_runtime: 0.864, interval_samples_per_second: 46.294, interval_steps_per_second: 5.787, epoch: 10.6815\r\n",
      "loss: 0.02832517, learning_rate: 1.397e-05, global_step: 7215, interval_runtime: 0.9881, interval_samples_per_second: 40.481, interval_steps_per_second: 5.06, epoch: 10.6889\r\n",
      "loss: 0.02284376, learning_rate: 1.396e-05, global_step: 7220, interval_runtime: 0.7816, interval_samples_per_second: 51.179, interval_steps_per_second: 6.397, epoch: 10.6963\r\n",
      "loss: 0.02359863, learning_rate: 1.394e-05, global_step: 7225, interval_runtime: 0.8377, interval_samples_per_second: 47.75, interval_steps_per_second: 5.969, epoch: 10.7037\r\n",
      "loss: 0.01154502, learning_rate: 1.393e-05, global_step: 7230, interval_runtime: 0.784, interval_samples_per_second: 51.021, interval_steps_per_second: 6.378, epoch: 10.7111\r\n",
      "loss: 0.01742853, learning_rate: 1.392e-05, global_step: 7235, interval_runtime: 0.8519, interval_samples_per_second: 46.956, interval_steps_per_second: 5.87, epoch: 10.7185\r\n",
      "loss: 0.00878291, learning_rate: 1.391e-05, global_step: 7240, interval_runtime: 0.7908, interval_samples_per_second: 50.58, interval_steps_per_second: 6.322, epoch: 10.7259\r\n",
      "loss: 0.01023592, learning_rate: 1.39e-05, global_step: 7245, interval_runtime: 0.775, interval_samples_per_second: 51.615, interval_steps_per_second: 6.452, epoch: 10.7333\r\n",
      "loss: 0.02952001, learning_rate: 1.389e-05, global_step: 7250, interval_runtime: 1.0698, interval_samples_per_second: 37.39, interval_steps_per_second: 4.674, epoch: 10.7407\r\n",
      "loss: 0.02028455, learning_rate: 1.388e-05, global_step: 7255, interval_runtime: 0.9233, interval_samples_per_second: 43.324, interval_steps_per_second: 5.416, epoch: 10.7481\r\n",
      "loss: 0.01289292, learning_rate: 1.387e-05, global_step: 7260, interval_runtime: 1.007, interval_samples_per_second: 39.721, interval_steps_per_second: 4.965, epoch: 10.7556\r\n",
      "loss: 0.0299511, learning_rate: 1.386e-05, global_step: 7265, interval_runtime: 0.7356, interval_samples_per_second: 54.379, interval_steps_per_second: 6.797, epoch: 10.763\r\n",
      "loss: 0.02810048, learning_rate: 1.384e-05, global_step: 7270, interval_runtime: 0.8261, interval_samples_per_second: 48.423, interval_steps_per_second: 6.053, epoch: 10.7704\r\n",
      "loss: 0.03841354, learning_rate: 1.383e-05, global_step: 7275, interval_runtime: 0.8975, interval_samples_per_second: 44.57, interval_steps_per_second: 5.571, epoch: 10.7778\r\n",
      "loss: 0.00696478, learning_rate: 1.382e-05, global_step: 7280, interval_runtime: 0.8365, interval_samples_per_second: 47.818, interval_steps_per_second: 5.977, epoch: 10.7852\r\n",
      "loss: 0.01493317, learning_rate: 1.381e-05, global_step: 7285, interval_runtime: 0.8209, interval_samples_per_second: 48.725, interval_steps_per_second: 6.091, epoch: 10.7926\r\n",
      "loss: 0.02104052, learning_rate: 1.38e-05, global_step: 7290, interval_runtime: 0.7536, interval_samples_per_second: 53.081, interval_steps_per_second: 6.635, epoch: 10.8\r\n",
      "loss: 0.01507428, learning_rate: 1.379e-05, global_step: 7295, interval_runtime: 0.7831, interval_samples_per_second: 51.079, interval_steps_per_second: 6.385, epoch: 10.8074\r\n",
      "loss: 0.00930507, learning_rate: 1.378e-05, global_step: 7300, interval_runtime: 0.7812, interval_samples_per_second: 51.201, interval_steps_per_second: 6.4, epoch: 10.8148\r\n",
      "loss: 0.030221, learning_rate: 1.377e-05, global_step: 7305, interval_runtime: 0.8925, interval_samples_per_second: 44.817, interval_steps_per_second: 5.602, epoch: 10.8222\r\n",
      "loss: 0.0320908, learning_rate: 1.376e-05, global_step: 7310, interval_runtime: 0.845, interval_samples_per_second: 47.335, interval_steps_per_second: 5.917, epoch: 10.8296\r\n",
      "loss: 0.02548494, learning_rate: 1.374e-05, global_step: 7315, interval_runtime: 0.9061, interval_samples_per_second: 44.145, interval_steps_per_second: 5.518, epoch: 10.837\r\n",
      "loss: 0.03236257, learning_rate: 1.373e-05, global_step: 7320, interval_runtime: 0.88, interval_samples_per_second: 45.454, interval_steps_per_second: 5.682, epoch: 10.8444\r\n",
      "loss: 0.03532927, learning_rate: 1.372e-05, global_step: 7325, interval_runtime: 0.8331, interval_samples_per_second: 48.016, interval_steps_per_second: 6.002, epoch: 10.8519\r\n",
      "loss: 0.03001521, learning_rate: 1.371e-05, global_step: 7330, interval_runtime: 0.8911, interval_samples_per_second: 44.887, interval_steps_per_second: 5.611, epoch: 10.8593\r\n",
      "loss: 0.0129943, learning_rate: 1.37e-05, global_step: 7335, interval_runtime: 0.8229, interval_samples_per_second: 48.608, interval_steps_per_second: 6.076, epoch: 10.8667\r\n",
      "loss: 0.01546278, learning_rate: 1.369e-05, global_step: 7340, interval_runtime: 0.7915, interval_samples_per_second: 50.54, interval_steps_per_second: 6.317, epoch: 10.8741\r\n",
      "loss: 0.01412113, learning_rate: 1.368e-05, global_step: 7345, interval_runtime: 0.8173, interval_samples_per_second: 48.944, interval_steps_per_second: 6.118, epoch: 10.8815\r\n",
      "loss: 0.03409154, learning_rate: 1.367e-05, global_step: 7350, interval_runtime: 0.8418, interval_samples_per_second: 47.516, interval_steps_per_second: 5.94, epoch: 10.8889\r\n",
      "loss: 0.03094519, learning_rate: 1.366e-05, global_step: 7355, interval_runtime: 0.9062, interval_samples_per_second: 44.139, interval_steps_per_second: 5.517, epoch: 10.8963\r\n",
      "loss: 0.01336933, learning_rate: 1.364e-05, global_step: 7360, interval_runtime: 0.7564, interval_samples_per_second: 52.884, interval_steps_per_second: 6.61, epoch: 10.9037\r\n",
      "loss: 0.01652183, learning_rate: 1.363e-05, global_step: 7365, interval_runtime: 0.8603, interval_samples_per_second: 46.497, interval_steps_per_second: 5.812, epoch: 10.9111\r\n",
      "loss: 0.0098659, learning_rate: 1.362e-05, global_step: 7370, interval_runtime: 0.8579, interval_samples_per_second: 46.628, interval_steps_per_second: 5.829, epoch: 10.9185\r\n",
      "loss: 0.02534352, learning_rate: 1.361e-05, global_step: 7375, interval_runtime: 0.7626, interval_samples_per_second: 52.452, interval_steps_per_second: 6.556, epoch: 10.9259\r\n",
      "loss: 0.01345592, learning_rate: 1.36e-05, global_step: 7380, interval_runtime: 0.9129, interval_samples_per_second: 43.816, interval_steps_per_second: 5.477, epoch: 10.9333\r\n",
      "loss: 0.01828861, learning_rate: 1.359e-05, global_step: 7385, interval_runtime: 0.7472, interval_samples_per_second: 53.531, interval_steps_per_second: 6.691, epoch: 10.9407\r\n",
      "loss: 0.03852836, learning_rate: 1.358e-05, global_step: 7390, interval_runtime: 0.7656, interval_samples_per_second: 52.247, interval_steps_per_second: 6.531, epoch: 10.9481\r\n",
      "loss: 0.02227748, learning_rate: 1.357e-05, global_step: 7395, interval_runtime: 0.8162, interval_samples_per_second: 49.006, interval_steps_per_second: 6.126, epoch: 10.9556\r\n",
      "loss: 0.02679481, learning_rate: 1.356e-05, global_step: 7400, interval_runtime: 0.7287, interval_samples_per_second: 54.893, interval_steps_per_second: 6.862, epoch: 10.963\r\n",
      "loss: 0.02833477, learning_rate: 1.354e-05, global_step: 7405, interval_runtime: 0.8049, interval_samples_per_second: 49.693, interval_steps_per_second: 6.212, epoch: 10.9704\r\n",
      "loss: 0.02695405, learning_rate: 1.353e-05, global_step: 7410, interval_runtime: 0.8576, interval_samples_per_second: 46.641, interval_steps_per_second: 5.83, epoch: 10.9778\r\n",
      "loss: 0.01898717, learning_rate: 1.352e-05, global_step: 7415, interval_runtime: 0.8149, interval_samples_per_second: 49.088, interval_steps_per_second: 6.136, epoch: 10.9852\r\n",
      "loss: 0.0094436, learning_rate: 1.351e-05, global_step: 7420, interval_runtime: 0.7898, interval_samples_per_second: 50.648, interval_steps_per_second: 6.331, epoch: 10.9926\r\n",
      "loss: 0.00740301, learning_rate: 1.35e-05, global_step: 7425, interval_runtime: 0.6775, interval_samples_per_second: 59.042, interval_steps_per_second: 7.38, epoch: 11.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:03:21,764] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:03:21,769] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:03:21,773] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:03:21,777] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:03:21,781] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.6619330048561096, eval_micro_f1_score: 0.549982998979939, eval_macro_f1_score: 0.43657601838601645, eval_runtime: 13.278, eval_samples_per_second: 142.793, eval_steps_per_second: 17.849, epoch: 11.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:03:35,047] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-7425\r\n",
      "[2023-01-10 11:03:35,050] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:03:38,386] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-7425/tokenizer_config.json\r\n",
      "[2023-01-10 11:03:38,390] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-7425/special_tokens_map.json\r\n",
      "[2023-01-10 11:03:45,034] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-6075] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.02477298, learning_rate: 1.349e-05, global_step: 7430, interval_runtime: 24.8043, interval_samples_per_second: 1.613, interval_steps_per_second: 0.202, epoch: 11.0074\r\n",
      "loss: 0.01316519, learning_rate: 1.348e-05, global_step: 7435, interval_runtime: 0.8623, interval_samples_per_second: 46.387, interval_steps_per_second: 5.798, epoch: 11.0148\r\n",
      "loss: 0.01845261, learning_rate: 1.347e-05, global_step: 7440, interval_runtime: 0.8035, interval_samples_per_second: 49.784, interval_steps_per_second: 6.223, epoch: 11.0222\r\n",
      "loss: 0.01352524, learning_rate: 1.346e-05, global_step: 7445, interval_runtime: 0.9057, interval_samples_per_second: 44.163, interval_steps_per_second: 5.52, epoch: 11.0296\r\n",
      "loss: 0.01586065, learning_rate: 1.344e-05, global_step: 7450, interval_runtime: 0.7192, interval_samples_per_second: 55.614, interval_steps_per_second: 6.952, epoch: 11.037\r\n",
      "loss: 0.01100204, learning_rate: 1.343e-05, global_step: 7455, interval_runtime: 0.7649, interval_samples_per_second: 52.295, interval_steps_per_second: 6.537, epoch: 11.0444\r\n",
      "loss: 0.0102681, learning_rate: 1.342e-05, global_step: 7460, interval_runtime: 0.8558, interval_samples_per_second: 46.739, interval_steps_per_second: 5.842, epoch: 11.0519\r\n",
      "loss: 0.00867819, learning_rate: 1.341e-05, global_step: 7465, interval_runtime: 0.8897, interval_samples_per_second: 44.959, interval_steps_per_second: 5.62, epoch: 11.0593\r\n",
      "loss: 0.0210481, learning_rate: 1.34e-05, global_step: 7470, interval_runtime: 0.8216, interval_samples_per_second: 48.685, interval_steps_per_second: 6.086, epoch: 11.0667\r\n",
      "loss: 0.01100505, learning_rate: 1.339e-05, global_step: 7475, interval_runtime: 0.902, interval_samples_per_second: 44.346, interval_steps_per_second: 5.543, epoch: 11.0741\r\n",
      "loss: 0.00767698, learning_rate: 1.338e-05, global_step: 7480, interval_runtime: 0.7626, interval_samples_per_second: 52.453, interval_steps_per_second: 6.557, epoch: 11.0815\r\n",
      "loss: 0.01089765, learning_rate: 1.337e-05, global_step: 7485, interval_runtime: 0.8295, interval_samples_per_second: 48.22, interval_steps_per_second: 6.027, epoch: 11.0889\r\n",
      "loss: 0.00713847, learning_rate: 1.336e-05, global_step: 7490, interval_runtime: 0.9121, interval_samples_per_second: 43.856, interval_steps_per_second: 5.482, epoch: 11.0963\r\n",
      "loss: 0.00682857, learning_rate: 1.334e-05, global_step: 7495, interval_runtime: 0.7794, interval_samples_per_second: 51.322, interval_steps_per_second: 6.415, epoch: 11.1037\r\n",
      "loss: 0.01784789, learning_rate: 1.333e-05, global_step: 7500, interval_runtime: 0.8609, interval_samples_per_second: 46.46, interval_steps_per_second: 5.808, epoch: 11.1111\r\n",
      "loss: 0.02272889, learning_rate: 1.332e-05, global_step: 7505, interval_runtime: 0.862, interval_samples_per_second: 46.406, interval_steps_per_second: 5.801, epoch: 11.1185\r\n",
      "loss: 0.0188572, learning_rate: 1.331e-05, global_step: 7510, interval_runtime: 0.7571, interval_samples_per_second: 52.831, interval_steps_per_second: 6.604, epoch: 11.1259\r\n",
      "loss: 0.01950369, learning_rate: 1.33e-05, global_step: 7515, interval_runtime: 0.98, interval_samples_per_second: 40.817, interval_steps_per_second: 5.102, epoch: 11.1333\r\n",
      "loss: 0.02317802, learning_rate: 1.329e-05, global_step: 7520, interval_runtime: 0.7391, interval_samples_per_second: 54.119, interval_steps_per_second: 6.765, epoch: 11.1407\r\n",
      "loss: 0.00944961, learning_rate: 1.328e-05, global_step: 7525, interval_runtime: 0.8328, interval_samples_per_second: 48.029, interval_steps_per_second: 6.004, epoch: 11.1481\r\n",
      "loss: 0.02862676, learning_rate: 1.327e-05, global_step: 7530, interval_runtime: 0.8084, interval_samples_per_second: 49.478, interval_steps_per_second: 6.185, epoch: 11.1556\r\n",
      "loss: 0.01441967, learning_rate: 1.326e-05, global_step: 7535, interval_runtime: 0.8722, interval_samples_per_second: 45.862, interval_steps_per_second: 5.733, epoch: 11.163\r\n",
      "loss: 0.02062138, learning_rate: 1.324e-05, global_step: 7540, interval_runtime: 0.8375, interval_samples_per_second: 47.763, interval_steps_per_second: 5.97, epoch: 11.1704\r\n",
      "loss: 0.01879754, learning_rate: 1.323e-05, global_step: 7545, interval_runtime: 0.847, interval_samples_per_second: 47.224, interval_steps_per_second: 5.903, epoch: 11.1778\r\n",
      "loss: 0.03372519, learning_rate: 1.322e-05, global_step: 7550, interval_runtime: 0.95, interval_samples_per_second: 42.105, interval_steps_per_second: 5.263, epoch: 11.1852\r\n",
      "loss: 0.01348834, learning_rate: 1.321e-05, global_step: 7555, interval_runtime: 0.9855, interval_samples_per_second: 40.588, interval_steps_per_second: 5.073, epoch: 11.1926\r\n",
      "loss: 0.01113257, learning_rate: 1.32e-05, global_step: 7560, interval_runtime: 0.852, interval_samples_per_second: 46.95, interval_steps_per_second: 5.869, epoch: 11.2\r\n",
      "loss: 0.01130849, learning_rate: 1.319e-05, global_step: 7565, interval_runtime: 0.8782, interval_samples_per_second: 45.548, interval_steps_per_second: 5.693, epoch: 11.2074\r\n",
      "loss: 0.02671392, learning_rate: 1.318e-05, global_step: 7570, interval_runtime: 0.8777, interval_samples_per_second: 45.572, interval_steps_per_second: 5.696, epoch: 11.2148\r\n",
      "loss: 0.01138669, learning_rate: 1.317e-05, global_step: 7575, interval_runtime: 0.9231, interval_samples_per_second: 43.332, interval_steps_per_second: 5.417, epoch: 11.2222\r\n",
      "loss: 0.0118893, learning_rate: 1.316e-05, global_step: 7580, interval_runtime: 0.7085, interval_samples_per_second: 56.454, interval_steps_per_second: 7.057, epoch: 11.2296\r\n",
      "loss: 0.01471997, learning_rate: 1.314e-05, global_step: 7585, interval_runtime: 0.7952, interval_samples_per_second: 50.302, interval_steps_per_second: 6.288, epoch: 11.237\r\n",
      "loss: 0.01245046, learning_rate: 1.313e-05, global_step: 7590, interval_runtime: 0.7337, interval_samples_per_second: 54.521, interval_steps_per_second: 6.815, epoch: 11.2444\r\n",
      "loss: 0.01601192, learning_rate: 1.312e-05, global_step: 7595, interval_runtime: 0.7806, interval_samples_per_second: 51.243, interval_steps_per_second: 6.405, epoch: 11.2519\r\n",
      "loss: 0.01680662, learning_rate: 1.311e-05, global_step: 7600, interval_runtime: 0.7801, interval_samples_per_second: 51.275, interval_steps_per_second: 6.409, epoch: 11.2593\r\n",
      "loss: 0.02424515, learning_rate: 1.31e-05, global_step: 7605, interval_runtime: 0.8636, interval_samples_per_second: 46.318, interval_steps_per_second: 5.79, epoch: 11.2667\r\n",
      "loss: 0.0211294, learning_rate: 1.309e-05, global_step: 7610, interval_runtime: 0.9784, interval_samples_per_second: 40.881, interval_steps_per_second: 5.11, epoch: 11.2741\r\n",
      "loss: 0.00971064, learning_rate: 1.308e-05, global_step: 7615, interval_runtime: 0.8598, interval_samples_per_second: 46.524, interval_steps_per_second: 5.816, epoch: 11.2815\r\n",
      "loss: 0.00539456, learning_rate: 1.307e-05, global_step: 7620, interval_runtime: 1.0252, interval_samples_per_second: 39.016, interval_steps_per_second: 4.877, epoch: 11.2889\r\n",
      "loss: 0.0114228, learning_rate: 1.306e-05, global_step: 7625, interval_runtime: 0.8632, interval_samples_per_second: 46.338, interval_steps_per_second: 5.792, epoch: 11.2963\r\n",
      "loss: 0.00732693, learning_rate: 1.304e-05, global_step: 7630, interval_runtime: 0.8041, interval_samples_per_second: 49.745, interval_steps_per_second: 6.218, epoch: 11.3037\r\n",
      "loss: 0.03603005, learning_rate: 1.303e-05, global_step: 7635, interval_runtime: 0.8677, interval_samples_per_second: 46.097, interval_steps_per_second: 5.762, epoch: 11.3111\r\n",
      "loss: 0.01963973, learning_rate: 1.302e-05, global_step: 7640, interval_runtime: 0.8689, interval_samples_per_second: 46.033, interval_steps_per_second: 5.754, epoch: 11.3185\r\n",
      "loss: 0.03491111, learning_rate: 1.301e-05, global_step: 7645, interval_runtime: 0.9771, interval_samples_per_second: 40.939, interval_steps_per_second: 5.117, epoch: 11.3259\r\n",
      "loss: 0.03771833, learning_rate: 1.3e-05, global_step: 7650, interval_runtime: 0.8619, interval_samples_per_second: 46.407, interval_steps_per_second: 5.801, epoch: 11.3333\r\n",
      "loss: 0.00653834, learning_rate: 1.299e-05, global_step: 7655, interval_runtime: 0.8134, interval_samples_per_second: 49.175, interval_steps_per_second: 6.147, epoch: 11.3407\r\n",
      "loss: 0.01112342, learning_rate: 1.298e-05, global_step: 7660, interval_runtime: 0.9222, interval_samples_per_second: 43.377, interval_steps_per_second: 5.422, epoch: 11.3481\r\n",
      "loss: 0.01277025, learning_rate: 1.297e-05, global_step: 7665, interval_runtime: 0.8193, interval_samples_per_second: 48.824, interval_steps_per_second: 6.103, epoch: 11.3556\r\n",
      "loss: 0.01319244, learning_rate: 1.296e-05, global_step: 7670, interval_runtime: 0.8184, interval_samples_per_second: 48.877, interval_steps_per_second: 6.11, epoch: 11.363\r\n",
      "loss: 0.01141695, learning_rate: 1.294e-05, global_step: 7675, interval_runtime: 0.7834, interval_samples_per_second: 51.06, interval_steps_per_second: 6.383, epoch: 11.3704\r\n",
      "loss: 0.00781368, learning_rate: 1.293e-05, global_step: 7680, interval_runtime: 0.8534, interval_samples_per_second: 46.869, interval_steps_per_second: 5.859, epoch: 11.3778\r\n",
      "loss: 0.01596301, learning_rate: 1.292e-05, global_step: 7685, interval_runtime: 0.9243, interval_samples_per_second: 43.277, interval_steps_per_second: 5.41, epoch: 11.3852\r\n",
      "loss: 0.008538, learning_rate: 1.291e-05, global_step: 7690, interval_runtime: 0.7647, interval_samples_per_second: 52.311, interval_steps_per_second: 6.539, epoch: 11.3926\r\n",
      "loss: 0.00570972, learning_rate: 1.29e-05, global_step: 7695, interval_runtime: 0.7397, interval_samples_per_second: 54.074, interval_steps_per_second: 6.759, epoch: 11.4\r\n",
      "loss: 0.01855865, learning_rate: 1.289e-05, global_step: 7700, interval_runtime: 0.7486, interval_samples_per_second: 53.431, interval_steps_per_second: 6.679, epoch: 11.4074\r\n",
      "loss: 0.00874128, learning_rate: 1.288e-05, global_step: 7705, interval_runtime: 0.8563, interval_samples_per_second: 46.713, interval_steps_per_second: 5.839, epoch: 11.4148\r\n",
      "loss: 0.02458456, learning_rate: 1.287e-05, global_step: 7710, interval_runtime: 0.8782, interval_samples_per_second: 45.546, interval_steps_per_second: 5.693, epoch: 11.4222\r\n",
      "loss: 0.00745621, learning_rate: 1.286e-05, global_step: 7715, interval_runtime: 0.7795, interval_samples_per_second: 51.318, interval_steps_per_second: 6.415, epoch: 11.4296\r\n",
      "loss: 0.01426616, learning_rate: 1.284e-05, global_step: 7720, interval_runtime: 0.8432, interval_samples_per_second: 47.437, interval_steps_per_second: 5.93, epoch: 11.437\r\n",
      "loss: 0.01326076, learning_rate: 1.283e-05, global_step: 7725, interval_runtime: 0.7644, interval_samples_per_second: 52.332, interval_steps_per_second: 6.541, epoch: 11.4444\r\n",
      "loss: 0.01093247, learning_rate: 1.282e-05, global_step: 7730, interval_runtime: 0.7954, interval_samples_per_second: 50.292, interval_steps_per_second: 6.286, epoch: 11.4519\r\n",
      "loss: 0.01120077, learning_rate: 1.281e-05, global_step: 7735, interval_runtime: 0.8234, interval_samples_per_second: 48.578, interval_steps_per_second: 6.072, epoch: 11.4593\r\n",
      "loss: 0.01214078, learning_rate: 1.28e-05, global_step: 7740, interval_runtime: 0.8317, interval_samples_per_second: 48.095, interval_steps_per_second: 6.012, epoch: 11.4667\r\n",
      "loss: 0.01855295, learning_rate: 1.279e-05, global_step: 7745, interval_runtime: 0.8205, interval_samples_per_second: 48.749, interval_steps_per_second: 6.094, epoch: 11.4741\r\n",
      "loss: 0.00717338, learning_rate: 1.278e-05, global_step: 7750, interval_runtime: 0.9303, interval_samples_per_second: 42.996, interval_steps_per_second: 5.374, epoch: 11.4815\r\n",
      "loss: 0.00775271, learning_rate: 1.277e-05, global_step: 7755, interval_runtime: 0.9832, interval_samples_per_second: 40.683, interval_steps_per_second: 5.085, epoch: 11.4889\r\n",
      "loss: 0.00368569, learning_rate: 1.276e-05, global_step: 7760, interval_runtime: 0.8262, interval_samples_per_second: 48.413, interval_steps_per_second: 6.052, epoch: 11.4963\r\n",
      "loss: 0.00693503, learning_rate: 1.274e-05, global_step: 7765, interval_runtime: 0.9495, interval_samples_per_second: 42.13, interval_steps_per_second: 5.266, epoch: 11.5037\r\n",
      "loss: 0.00598461, learning_rate: 1.273e-05, global_step: 7770, interval_runtime: 0.8284, interval_samples_per_second: 48.286, interval_steps_per_second: 6.036, epoch: 11.5111\r\n",
      "loss: 0.01984666, learning_rate: 1.272e-05, global_step: 7775, interval_runtime: 0.9482, interval_samples_per_second: 42.185, interval_steps_per_second: 5.273, epoch: 11.5185\r\n",
      "loss: 0.01468179, learning_rate: 1.271e-05, global_step: 7780, interval_runtime: 0.7794, interval_samples_per_second: 51.321, interval_steps_per_second: 6.415, epoch: 11.5259\r\n",
      "loss: 0.02016234, learning_rate: 1.27e-05, global_step: 7785, interval_runtime: 0.9062, interval_samples_per_second: 44.14, interval_steps_per_second: 5.518, epoch: 11.5333\r\n",
      "loss: 0.01849363, learning_rate: 1.269e-05, global_step: 7790, interval_runtime: 0.8781, interval_samples_per_second: 45.554, interval_steps_per_second: 5.694, epoch: 11.5407\r\n",
      "loss: 0.02062111, learning_rate: 1.268e-05, global_step: 7795, interval_runtime: 0.7729, interval_samples_per_second: 51.753, interval_steps_per_second: 6.469, epoch: 11.5481\r\n",
      "loss: 0.02405185, learning_rate: 1.267e-05, global_step: 7800, interval_runtime: 0.8211, interval_samples_per_second: 48.714, interval_steps_per_second: 6.089, epoch: 11.5556\r\n",
      "loss: 0.00699756, learning_rate: 1.266e-05, global_step: 7805, interval_runtime: 0.8639, interval_samples_per_second: 46.3, interval_steps_per_second: 5.787, epoch: 11.563\r\n",
      "loss: 0.00657707, learning_rate: 1.264e-05, global_step: 7810, interval_runtime: 0.8749, interval_samples_per_second: 45.721, interval_steps_per_second: 5.715, epoch: 11.5704\r\n",
      "loss: 0.03196758, learning_rate: 1.263e-05, global_step: 7815, interval_runtime: 0.8203, interval_samples_per_second: 48.765, interval_steps_per_second: 6.096, epoch: 11.5778\r\n",
      "loss: 0.00922886, learning_rate: 1.262e-05, global_step: 7820, interval_runtime: 0.7536, interval_samples_per_second: 53.08, interval_steps_per_second: 6.635, epoch: 11.5852\r\n",
      "loss: 0.00430952, learning_rate: 1.261e-05, global_step: 7825, interval_runtime: 0.7891, interval_samples_per_second: 50.688, interval_steps_per_second: 6.336, epoch: 11.5926\r\n",
      "loss: 0.01102356, learning_rate: 1.26e-05, global_step: 7830, interval_runtime: 0.9318, interval_samples_per_second: 42.929, interval_steps_per_second: 5.366, epoch: 11.6\r\n",
      "loss: 0.01194042, learning_rate: 1.259e-05, global_step: 7835, interval_runtime: 0.9153, interval_samples_per_second: 43.7, interval_steps_per_second: 5.463, epoch: 11.6074\r\n",
      "loss: 0.01699389, learning_rate: 1.258e-05, global_step: 7840, interval_runtime: 0.744, interval_samples_per_second: 53.764, interval_steps_per_second: 6.721, epoch: 11.6148\r\n",
      "loss: 0.01100174, learning_rate: 1.257e-05, global_step: 7845, interval_runtime: 0.8581, interval_samples_per_second: 46.616, interval_steps_per_second: 5.827, epoch: 11.6222\r\n",
      "loss: 0.023797, learning_rate: 1.256e-05, global_step: 7850, interval_runtime: 0.7596, interval_samples_per_second: 52.659, interval_steps_per_second: 6.582, epoch: 11.6296\r\n",
      "loss: 0.01316571, learning_rate: 1.254e-05, global_step: 7855, interval_runtime: 1.0359, interval_samples_per_second: 38.614, interval_steps_per_second: 4.827, epoch: 11.637\r\n",
      "loss: 0.0052962, learning_rate: 1.253e-05, global_step: 7860, interval_runtime: 0.9768, interval_samples_per_second: 40.952, interval_steps_per_second: 5.119, epoch: 11.6444\r\n",
      "loss: 0.00569856, learning_rate: 1.252e-05, global_step: 7865, interval_runtime: 0.8347, interval_samples_per_second: 47.92, interval_steps_per_second: 5.99, epoch: 11.6519\r\n",
      "loss: 0.01203662, learning_rate: 1.251e-05, global_step: 7870, interval_runtime: 0.8607, interval_samples_per_second: 46.475, interval_steps_per_second: 5.809, epoch: 11.6593\r\n",
      "loss: 0.02278025, learning_rate: 1.25e-05, global_step: 7875, interval_runtime: 0.8871, interval_samples_per_second: 45.09, interval_steps_per_second: 5.636, epoch: 11.6667\r\n",
      "loss: 0.02540814, learning_rate: 1.249e-05, global_step: 7880, interval_runtime: 0.764, interval_samples_per_second: 52.355, interval_steps_per_second: 6.544, epoch: 11.6741\r\n",
      "loss: 0.01943599, learning_rate: 1.248e-05, global_step: 7885, interval_runtime: 0.8773, interval_samples_per_second: 45.597, interval_steps_per_second: 5.7, epoch: 11.6815\r\n",
      "loss: 0.01463579, learning_rate: 1.247e-05, global_step: 7890, interval_runtime: 0.8764, interval_samples_per_second: 45.642, interval_steps_per_second: 5.705, epoch: 11.6889\r\n",
      "loss: 0.02901782, learning_rate: 1.246e-05, global_step: 7895, interval_runtime: 0.9442, interval_samples_per_second: 42.365, interval_steps_per_second: 5.296, epoch: 11.6963\r\n",
      "loss: 0.01141643, learning_rate: 1.244e-05, global_step: 7900, interval_runtime: 0.9914, interval_samples_per_second: 40.346, interval_steps_per_second: 5.043, epoch: 11.7037\r\n",
      "loss: 0.01414383, learning_rate: 1.243e-05, global_step: 7905, interval_runtime: 0.7801, interval_samples_per_second: 51.276, interval_steps_per_second: 6.41, epoch: 11.7111\r\n",
      "loss: 0.01577667, learning_rate: 1.242e-05, global_step: 7910, interval_runtime: 0.8339, interval_samples_per_second: 47.966, interval_steps_per_second: 5.996, epoch: 11.7185\r\n",
      "loss: 0.01693627, learning_rate: 1.241e-05, global_step: 7915, interval_runtime: 0.7799, interval_samples_per_second: 51.288, interval_steps_per_second: 6.411, epoch: 11.7259\r\n",
      "loss: 0.0127063, learning_rate: 1.24e-05, global_step: 7920, interval_runtime: 0.9003, interval_samples_per_second: 44.429, interval_steps_per_second: 5.554, epoch: 11.7333\r\n",
      "loss: 0.02703009, learning_rate: 1.239e-05, global_step: 7925, interval_runtime: 0.8474, interval_samples_per_second: 47.203, interval_steps_per_second: 5.9, epoch: 11.7407\r\n",
      "loss: 0.02457332, learning_rate: 1.238e-05, global_step: 7930, interval_runtime: 0.7826, interval_samples_per_second: 51.109, interval_steps_per_second: 6.389, epoch: 11.7481\r\n",
      "loss: 0.03535313, learning_rate: 1.237e-05, global_step: 7935, interval_runtime: 0.8442, interval_samples_per_second: 47.384, interval_steps_per_second: 5.923, epoch: 11.7556\r\n",
      "loss: 0.00745303, learning_rate: 1.236e-05, global_step: 7940, interval_runtime: 0.8683, interval_samples_per_second: 46.069, interval_steps_per_second: 5.759, epoch: 11.763\r\n",
      "loss: 0.00917277, learning_rate: 1.234e-05, global_step: 7945, interval_runtime: 0.9643, interval_samples_per_second: 41.483, interval_steps_per_second: 5.185, epoch: 11.7704\r\n",
      "loss: 0.00756133, learning_rate: 1.233e-05, global_step: 7950, interval_runtime: 0.9946, interval_samples_per_second: 40.216, interval_steps_per_second: 5.027, epoch: 11.7778\r\n",
      "loss: 0.03455378, learning_rate: 1.232e-05, global_step: 7955, interval_runtime: 0.8286, interval_samples_per_second: 48.273, interval_steps_per_second: 6.034, epoch: 11.7852\r\n",
      "loss: 0.02563789, learning_rate: 1.231e-05, global_step: 7960, interval_runtime: 0.7917, interval_samples_per_second: 50.525, interval_steps_per_second: 6.316, epoch: 11.7926\r\n",
      "loss: 0.00561674, learning_rate: 1.23e-05, global_step: 7965, interval_runtime: 0.9278, interval_samples_per_second: 43.114, interval_steps_per_second: 5.389, epoch: 11.8\r\n",
      "loss: 0.03107764, learning_rate: 1.229e-05, global_step: 7970, interval_runtime: 0.8537, interval_samples_per_second: 46.855, interval_steps_per_second: 5.857, epoch: 11.8074\r\n",
      "loss: 0.01501271, learning_rate: 1.228e-05, global_step: 7975, interval_runtime: 0.8521, interval_samples_per_second: 46.944, interval_steps_per_second: 5.868, epoch: 11.8148\r\n",
      "loss: 0.01193595, learning_rate: 1.227e-05, global_step: 7980, interval_runtime: 0.9988, interval_samples_per_second: 40.047, interval_steps_per_second: 5.006, epoch: 11.8222\r\n",
      "loss: 0.03514719, learning_rate: 1.226e-05, global_step: 7985, interval_runtime: 0.9947, interval_samples_per_second: 40.215, interval_steps_per_second: 5.027, epoch: 11.8296\r\n",
      "loss: 0.0269537, learning_rate: 1.224e-05, global_step: 7990, interval_runtime: 0.9441, interval_samples_per_second: 42.367, interval_steps_per_second: 5.296, epoch: 11.837\r\n",
      "loss: 0.02359995, learning_rate: 1.223e-05, global_step: 7995, interval_runtime: 0.917, interval_samples_per_second: 43.62, interval_steps_per_second: 5.452, epoch: 11.8444\r\n",
      "loss: 0.02065819, learning_rate: 1.222e-05, global_step: 8000, interval_runtime: 0.8035, interval_samples_per_second: 49.779, interval_steps_per_second: 6.222, epoch: 11.8519\r\n",
      "loss: 0.00926391, learning_rate: 1.221e-05, global_step: 8005, interval_runtime: 0.7901, interval_samples_per_second: 50.63, interval_steps_per_second: 6.329, epoch: 11.8593\r\n",
      "loss: 0.02444472, learning_rate: 1.22e-05, global_step: 8010, interval_runtime: 0.7968, interval_samples_per_second: 50.199, interval_steps_per_second: 6.275, epoch: 11.8667\r\n",
      "loss: 0.01034265, learning_rate: 1.219e-05, global_step: 8015, interval_runtime: 0.8035, interval_samples_per_second: 49.782, interval_steps_per_second: 6.223, epoch: 11.8741\r\n",
      "loss: 0.01747909, learning_rate: 1.218e-05, global_step: 8020, interval_runtime: 0.9232, interval_samples_per_second: 43.327, interval_steps_per_second: 5.416, epoch: 11.8815\r\n",
      "loss: 0.0110861, learning_rate: 1.217e-05, global_step: 8025, interval_runtime: 0.9107, interval_samples_per_second: 43.921, interval_steps_per_second: 5.49, epoch: 11.8889\r\n",
      "loss: 0.01897869, learning_rate: 1.216e-05, global_step: 8030, interval_runtime: 0.934, interval_samples_per_second: 42.827, interval_steps_per_second: 5.353, epoch: 11.8963\r\n",
      "loss: 0.01128321, learning_rate: 1.214e-05, global_step: 8035, interval_runtime: 0.7263, interval_samples_per_second: 55.077, interval_steps_per_second: 6.885, epoch: 11.9037\r\n",
      "loss: 0.01426774, learning_rate: 1.213e-05, global_step: 8040, interval_runtime: 0.7787, interval_samples_per_second: 51.369, interval_steps_per_second: 6.421, epoch: 11.9111\r\n",
      "loss: 0.03150999, learning_rate: 1.212e-05, global_step: 8045, interval_runtime: 0.8226, interval_samples_per_second: 48.628, interval_steps_per_second: 6.079, epoch: 11.9185\r\n",
      "loss: 0.00633699, learning_rate: 1.211e-05, global_step: 8050, interval_runtime: 1.0041, interval_samples_per_second: 39.837, interval_steps_per_second: 4.98, epoch: 11.9259\r\n",
      "loss: 0.01401923, learning_rate: 1.21e-05, global_step: 8055, interval_runtime: 0.7737, interval_samples_per_second: 51.698, interval_steps_per_second: 6.462, epoch: 11.9333\r\n",
      "loss: 0.02471017, learning_rate: 1.209e-05, global_step: 8060, interval_runtime: 0.8967, interval_samples_per_second: 44.608, interval_steps_per_second: 5.576, epoch: 11.9407\r\n",
      "loss: 0.0267939, learning_rate: 1.208e-05, global_step: 8065, interval_runtime: 0.7826, interval_samples_per_second: 51.109, interval_steps_per_second: 6.389, epoch: 11.9481\r\n",
      "loss: 0.01236731, learning_rate: 1.207e-05, global_step: 8070, interval_runtime: 0.7722, interval_samples_per_second: 51.797, interval_steps_per_second: 6.475, epoch: 11.9556\r\n",
      "loss: 0.0193704, learning_rate: 1.206e-05, global_step: 8075, interval_runtime: 0.7837, interval_samples_per_second: 51.038, interval_steps_per_second: 6.38, epoch: 11.963\r\n",
      "loss: 0.03555561, learning_rate: 1.204e-05, global_step: 8080, interval_runtime: 0.7877, interval_samples_per_second: 50.78, interval_steps_per_second: 6.347, epoch: 11.9704\r\n",
      "loss: 0.01919952, learning_rate: 1.203e-05, global_step: 8085, interval_runtime: 0.757, interval_samples_per_second: 52.838, interval_steps_per_second: 6.605, epoch: 11.9778\r\n",
      "loss: 0.00627107, learning_rate: 1.202e-05, global_step: 8090, interval_runtime: 0.7633, interval_samples_per_second: 52.405, interval_steps_per_second: 6.551, epoch: 11.9852\r\n",
      "loss: 0.00953338, learning_rate: 1.201e-05, global_step: 8095, interval_runtime: 0.7965, interval_samples_per_second: 50.22, interval_steps_per_second: 6.277, epoch: 11.9926\r\n",
      "loss: 0.028011, learning_rate: 1.2e-05, global_step: 8100, interval_runtime: 0.6781, interval_samples_per_second: 58.988, interval_steps_per_second: 7.374, epoch: 12.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:05:40,360] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:05:40,363] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:05:40,365] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:05:40,367] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:05:40,369] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.6796460151672363, eval_micro_f1_score: 0.5660251603765725, eval_macro_f1_score: 0.45951226867697414, eval_runtime: 13.6074, eval_samples_per_second: 139.336, eval_steps_per_second: 17.417, epoch: 12.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:05:53,973] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-8100\r\n",
      "[2023-01-10 11:05:53,975] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:05:57,409] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-8100/tokenizer_config.json\r\n",
      "[2023-01-10 11:05:57,413] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-8100/special_tokens_map.json\r\n",
      "[2023-01-10 11:06:04,207] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-7425] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00792149, learning_rate: 1.199e-05, global_step: 8105, interval_runtime: 25.459, interval_samples_per_second: 1.571, interval_steps_per_second: 0.196, epoch: 12.0074\r\n",
      "loss: 0.00544044, learning_rate: 1.198e-05, global_step: 8110, interval_runtime: 0.8067, interval_samples_per_second: 49.584, interval_steps_per_second: 6.198, epoch: 12.0148\r\n",
      "loss: 0.01193316, learning_rate: 1.197e-05, global_step: 8115, interval_runtime: 0.8028, interval_samples_per_second: 49.826, interval_steps_per_second: 6.228, epoch: 12.0222\r\n",
      "loss: 0.01998717, learning_rate: 1.196e-05, global_step: 8120, interval_runtime: 0.809, interval_samples_per_second: 49.442, interval_steps_per_second: 6.18, epoch: 12.0296\r\n",
      "loss: 0.0207031, learning_rate: 1.194e-05, global_step: 8125, interval_runtime: 0.9329, interval_samples_per_second: 42.879, interval_steps_per_second: 5.36, epoch: 12.037\r\n",
      "loss: 0.01712724, learning_rate: 1.193e-05, global_step: 8130, interval_runtime: 0.8027, interval_samples_per_second: 49.834, interval_steps_per_second: 6.229, epoch: 12.0444\r\n",
      "loss: 0.01551845, learning_rate: 1.192e-05, global_step: 8135, interval_runtime: 0.829, interval_samples_per_second: 48.248, interval_steps_per_second: 6.031, epoch: 12.0519\r\n",
      "loss: 0.00689285, learning_rate: 1.191e-05, global_step: 8140, interval_runtime: 0.8462, interval_samples_per_second: 47.268, interval_steps_per_second: 5.909, epoch: 12.0593\r\n",
      "loss: 0.0374145, learning_rate: 1.19e-05, global_step: 8145, interval_runtime: 0.8219, interval_samples_per_second: 48.665, interval_steps_per_second: 6.083, epoch: 12.0667\r\n",
      "loss: 0.01221735, learning_rate: 1.189e-05, global_step: 8150, interval_runtime: 0.7918, interval_samples_per_second: 50.517, interval_steps_per_second: 6.315, epoch: 12.0741\r\n",
      "loss: 0.00216241, learning_rate: 1.188e-05, global_step: 8155, interval_runtime: 0.8066, interval_samples_per_second: 49.593, interval_steps_per_second: 6.199, epoch: 12.0815\r\n",
      "loss: 0.0061443, learning_rate: 1.187e-05, global_step: 8160, interval_runtime: 0.7587, interval_samples_per_second: 52.725, interval_steps_per_second: 6.591, epoch: 12.0889\r\n",
      "loss: 0.00674917, learning_rate: 1.186e-05, global_step: 8165, interval_runtime: 0.9195, interval_samples_per_second: 43.503, interval_steps_per_second: 5.438, epoch: 12.0963\r\n",
      "loss: 0.00937254, learning_rate: 1.184e-05, global_step: 8170, interval_runtime: 0.7556, interval_samples_per_second: 52.938, interval_steps_per_second: 6.617, epoch: 12.1037\r\n",
      "loss: 0.01035084, learning_rate: 1.183e-05, global_step: 8175, interval_runtime: 0.8081, interval_samples_per_second: 49.498, interval_steps_per_second: 6.187, epoch: 12.1111\r\n",
      "loss: 0.01566423, learning_rate: 1.182e-05, global_step: 8180, interval_runtime: 0.8332, interval_samples_per_second: 48.01, interval_steps_per_second: 6.001, epoch: 12.1185\r\n",
      "loss: 0.0062387, learning_rate: 1.181e-05, global_step: 8185, interval_runtime: 0.8088, interval_samples_per_second: 49.458, interval_steps_per_second: 6.182, epoch: 12.1259\r\n",
      "loss: 0.00786625, learning_rate: 1.18e-05, global_step: 8190, interval_runtime: 0.786, interval_samples_per_second: 50.893, interval_steps_per_second: 6.362, epoch: 12.1333\r\n",
      "loss: 0.00998877, learning_rate: 1.179e-05, global_step: 8195, interval_runtime: 0.8122, interval_samples_per_second: 49.248, interval_steps_per_second: 6.156, epoch: 12.1407\r\n",
      "loss: 0.01249434, learning_rate: 1.178e-05, global_step: 8200, interval_runtime: 0.8868, interval_samples_per_second: 45.107, interval_steps_per_second: 5.638, epoch: 12.1481\r\n",
      "loss: 0.01322258, learning_rate: 1.177e-05, global_step: 8205, interval_runtime: 0.6897, interval_samples_per_second: 58.0, interval_steps_per_second: 7.25, epoch: 12.1556\r\n",
      "loss: 0.00485518, learning_rate: 1.176e-05, global_step: 8210, interval_runtime: 0.8959, interval_samples_per_second: 44.649, interval_steps_per_second: 5.581, epoch: 12.163\r\n",
      "loss: 0.00682676, learning_rate: 1.174e-05, global_step: 8215, interval_runtime: 0.8424, interval_samples_per_second: 47.485, interval_steps_per_second: 5.936, epoch: 12.1704\r\n",
      "loss: 0.00783233, learning_rate: 1.173e-05, global_step: 8220, interval_runtime: 0.7409, interval_samples_per_second: 53.991, interval_steps_per_second: 6.749, epoch: 12.1778\r\n",
      "loss: 0.00401615, learning_rate: 1.172e-05, global_step: 8225, interval_runtime: 0.8238, interval_samples_per_second: 48.555, interval_steps_per_second: 6.069, epoch: 12.1852\r\n",
      "loss: 0.02101181, learning_rate: 1.171e-05, global_step: 8230, interval_runtime: 0.9272, interval_samples_per_second: 43.141, interval_steps_per_second: 5.393, epoch: 12.1926\r\n",
      "loss: 0.0057255, learning_rate: 1.17e-05, global_step: 8235, interval_runtime: 0.8794, interval_samples_per_second: 45.487, interval_steps_per_second: 5.686, epoch: 12.2\r\n",
      "loss: 0.0115497, learning_rate: 1.169e-05, global_step: 8240, interval_runtime: 0.8041, interval_samples_per_second: 49.746, interval_steps_per_second: 6.218, epoch: 12.2074\r\n",
      "loss: 0.00650239, learning_rate: 1.168e-05, global_step: 8245, interval_runtime: 0.902, interval_samples_per_second: 44.345, interval_steps_per_second: 5.543, epoch: 12.2148\r\n",
      "loss: 0.00964846, learning_rate: 1.167e-05, global_step: 8250, interval_runtime: 0.7293, interval_samples_per_second: 54.844, interval_steps_per_second: 6.855, epoch: 12.2222\r\n",
      "loss: 0.00693538, learning_rate: 1.166e-05, global_step: 8255, interval_runtime: 0.8081, interval_samples_per_second: 49.501, interval_steps_per_second: 6.188, epoch: 12.2296\r\n",
      "loss: 0.01006007, learning_rate: 1.164e-05, global_step: 8260, interval_runtime: 0.743, interval_samples_per_second: 53.835, interval_steps_per_second: 6.729, epoch: 12.237\r\n",
      "loss: 0.00375333, learning_rate: 1.163e-05, global_step: 8265, interval_runtime: 0.8123, interval_samples_per_second: 49.241, interval_steps_per_second: 6.155, epoch: 12.2444\r\n",
      "loss: 0.00864364, learning_rate: 1.162e-05, global_step: 8270, interval_runtime: 0.739, interval_samples_per_second: 54.127, interval_steps_per_second: 6.766, epoch: 12.2519\r\n",
      "loss: 0.03132497, learning_rate: 1.161e-05, global_step: 8275, interval_runtime: 0.9121, interval_samples_per_second: 43.856, interval_steps_per_second: 5.482, epoch: 12.2593\r\n",
      "loss: 0.00724008, learning_rate: 1.16e-05, global_step: 8280, interval_runtime: 0.8703, interval_samples_per_second: 45.963, interval_steps_per_second: 5.745, epoch: 12.2667\r\n",
      "loss: 0.00835088, learning_rate: 1.159e-05, global_step: 8285, interval_runtime: 0.7681, interval_samples_per_second: 52.076, interval_steps_per_second: 6.51, epoch: 12.2741\r\n",
      "loss: 0.01829751, learning_rate: 1.158e-05, global_step: 8290, interval_runtime: 0.7828, interval_samples_per_second: 51.097, interval_steps_per_second: 6.387, epoch: 12.2815\r\n",
      "loss: 0.00668865, learning_rate: 1.157e-05, global_step: 8295, interval_runtime: 0.8121, interval_samples_per_second: 49.254, interval_steps_per_second: 6.157, epoch: 12.2889\r\n",
      "loss: 0.01105149, learning_rate: 1.156e-05, global_step: 8300, interval_runtime: 0.8281, interval_samples_per_second: 48.302, interval_steps_per_second: 6.038, epoch: 12.2963\r\n",
      "loss: 0.00413216, learning_rate: 1.154e-05, global_step: 8305, interval_runtime: 0.9483, interval_samples_per_second: 42.181, interval_steps_per_second: 5.273, epoch: 12.3037\r\n",
      "loss: 0.01764227, learning_rate: 1.153e-05, global_step: 8310, interval_runtime: 0.8269, interval_samples_per_second: 48.375, interval_steps_per_second: 6.047, epoch: 12.3111\r\n",
      "loss: 0.00500924, learning_rate: 1.152e-05, global_step: 8315, interval_runtime: 0.8531, interval_samples_per_second: 46.885, interval_steps_per_second: 5.861, epoch: 12.3185\r\n",
      "loss: 0.00564913, learning_rate: 1.151e-05, global_step: 8320, interval_runtime: 0.9309, interval_samples_per_second: 42.967, interval_steps_per_second: 5.371, epoch: 12.3259\r\n",
      "loss: 0.00770438, learning_rate: 1.15e-05, global_step: 8325, interval_runtime: 0.8623, interval_samples_per_second: 46.389, interval_steps_per_second: 5.799, epoch: 12.3333\r\n",
      "loss: 0.00339422, learning_rate: 1.149e-05, global_step: 8330, interval_runtime: 0.8122, interval_samples_per_second: 49.247, interval_steps_per_second: 6.156, epoch: 12.3407\r\n",
      "loss: 0.00989066, learning_rate: 1.148e-05, global_step: 8335, interval_runtime: 0.7681, interval_samples_per_second: 52.078, interval_steps_per_second: 6.51, epoch: 12.3481\r\n",
      "loss: 0.02047807, learning_rate: 1.147e-05, global_step: 8340, interval_runtime: 0.7672, interval_samples_per_second: 52.139, interval_steps_per_second: 6.517, epoch: 12.3556\r\n",
      "loss: 0.01348007, learning_rate: 1.146e-05, global_step: 8345, interval_runtime: 0.862, interval_samples_per_second: 46.404, interval_steps_per_second: 5.801, epoch: 12.363\r\n",
      "loss: 0.01182692, learning_rate: 1.144e-05, global_step: 8350, interval_runtime: 0.8502, interval_samples_per_second: 47.045, interval_steps_per_second: 5.881, epoch: 12.3704\r\n",
      "loss: 0.00656859, learning_rate: 1.143e-05, global_step: 8355, interval_runtime: 0.7643, interval_samples_per_second: 52.334, interval_steps_per_second: 6.542, epoch: 12.3778\r\n",
      "loss: 0.01702199, learning_rate: 1.142e-05, global_step: 8360, interval_runtime: 0.7811, interval_samples_per_second: 51.207, interval_steps_per_second: 6.401, epoch: 12.3852\r\n",
      "loss: 0.01185092, learning_rate: 1.141e-05, global_step: 8365, interval_runtime: 0.8474, interval_samples_per_second: 47.203, interval_steps_per_second: 5.9, epoch: 12.3926\r\n",
      "loss: 0.00838601, learning_rate: 1.14e-05, global_step: 8370, interval_runtime: 0.9833, interval_samples_per_second: 40.68, interval_steps_per_second: 5.085, epoch: 12.4\r\n",
      "loss: 0.02271049, learning_rate: 1.139e-05, global_step: 8375, interval_runtime: 0.918, interval_samples_per_second: 43.574, interval_steps_per_second: 5.447, epoch: 12.4074\r\n",
      "loss: 0.00598508, learning_rate: 1.138e-05, global_step: 8380, interval_runtime: 0.8749, interval_samples_per_second: 45.719, interval_steps_per_second: 5.715, epoch: 12.4148\r\n",
      "loss: 0.01631326, learning_rate: 1.137e-05, global_step: 8385, interval_runtime: 0.8295, interval_samples_per_second: 48.223, interval_steps_per_second: 6.028, epoch: 12.4222\r\n",
      "loss: 0.00687318, learning_rate: 1.136e-05, global_step: 8390, interval_runtime: 0.7686, interval_samples_per_second: 52.042, interval_steps_per_second: 6.505, epoch: 12.4296\r\n",
      "loss: 0.00686115, learning_rate: 1.134e-05, global_step: 8395, interval_runtime: 0.7507, interval_samples_per_second: 53.28, interval_steps_per_second: 6.66, epoch: 12.437\r\n",
      "loss: 0.00658261, learning_rate: 1.133e-05, global_step: 8400, interval_runtime: 0.7946, interval_samples_per_second: 50.339, interval_steps_per_second: 6.292, epoch: 12.4444\r\n",
      "loss: 0.01185799, learning_rate: 1.132e-05, global_step: 8405, interval_runtime: 0.8711, interval_samples_per_second: 45.919, interval_steps_per_second: 5.74, epoch: 12.4519\r\n",
      "loss: 0.02740438, learning_rate: 1.131e-05, global_step: 8410, interval_runtime: 0.7773, interval_samples_per_second: 51.457, interval_steps_per_second: 6.432, epoch: 12.4593\r\n",
      "loss: 0.01961164, learning_rate: 1.13e-05, global_step: 8415, interval_runtime: 0.8241, interval_samples_per_second: 48.54, interval_steps_per_second: 6.067, epoch: 12.4667\r\n",
      "loss: 0.00817828, learning_rate: 1.129e-05, global_step: 8420, interval_runtime: 0.7982, interval_samples_per_second: 50.114, interval_steps_per_second: 6.264, epoch: 12.4741\r\n",
      "loss: 0.00448722, learning_rate: 1.128e-05, global_step: 8425, interval_runtime: 0.7197, interval_samples_per_second: 55.582, interval_steps_per_second: 6.948, epoch: 12.4815\r\n",
      "loss: 0.01318999, learning_rate: 1.127e-05, global_step: 8430, interval_runtime: 0.7498, interval_samples_per_second: 53.344, interval_steps_per_second: 6.668, epoch: 12.4889\r\n",
      "loss: 0.01331066, learning_rate: 1.126e-05, global_step: 8435, interval_runtime: 0.7129, interval_samples_per_second: 56.106, interval_steps_per_second: 7.013, epoch: 12.4963\r\n",
      "loss: 0.01468114, learning_rate: 1.124e-05, global_step: 8440, interval_runtime: 0.8901, interval_samples_per_second: 44.939, interval_steps_per_second: 5.617, epoch: 12.5037\r\n",
      "loss: 0.00875635, learning_rate: 1.123e-05, global_step: 8445, interval_runtime: 1.0551, interval_samples_per_second: 37.91, interval_steps_per_second: 4.739, epoch: 12.5111\r\n",
      "loss: 0.01565898, learning_rate: 1.122e-05, global_step: 8450, interval_runtime: 0.8581, interval_samples_per_second: 46.614, interval_steps_per_second: 5.827, epoch: 12.5185\r\n",
      "loss: 0.03451383, learning_rate: 1.121e-05, global_step: 8455, interval_runtime: 0.9075, interval_samples_per_second: 44.078, interval_steps_per_second: 5.51, epoch: 12.5259\r\n",
      "loss: 0.00759499, learning_rate: 1.12e-05, global_step: 8460, interval_runtime: 0.7814, interval_samples_per_second: 51.19, interval_steps_per_second: 6.399, epoch: 12.5333\r\n",
      "loss: 0.0142395, learning_rate: 1.119e-05, global_step: 8465, interval_runtime: 0.8693, interval_samples_per_second: 46.015, interval_steps_per_second: 5.752, epoch: 12.5407\r\n",
      "loss: 0.02305273, learning_rate: 1.118e-05, global_step: 8470, interval_runtime: 0.967, interval_samples_per_second: 41.364, interval_steps_per_second: 5.17, epoch: 12.5481\r\n",
      "loss: 0.0359333, learning_rate: 1.117e-05, global_step: 8475, interval_runtime: 0.8951, interval_samples_per_second: 44.685, interval_steps_per_second: 5.586, epoch: 12.5556\r\n",
      "loss: 0.00544962, learning_rate: 1.116e-05, global_step: 8480, interval_runtime: 0.84, interval_samples_per_second: 47.616, interval_steps_per_second: 5.952, epoch: 12.563\r\n",
      "loss: 0.0044765, learning_rate: 1.114e-05, global_step: 8485, interval_runtime: 1.0019, interval_samples_per_second: 39.923, interval_steps_per_second: 4.99, epoch: 12.5704\r\n",
      "loss: 0.00291319, learning_rate: 1.113e-05, global_step: 8490, interval_runtime: 0.9006, interval_samples_per_second: 44.413, interval_steps_per_second: 5.552, epoch: 12.5778\r\n",
      "loss: 0.00495397, learning_rate: 1.112e-05, global_step: 8495, interval_runtime: 0.7857, interval_samples_per_second: 50.912, interval_steps_per_second: 6.364, epoch: 12.5852\r\n",
      "loss: 0.01745389, learning_rate: 1.111e-05, global_step: 8500, interval_runtime: 0.9581, interval_samples_per_second: 41.75, interval_steps_per_second: 5.219, epoch: 12.5926\r\n",
      "loss: 0.00910983, learning_rate: 1.11e-05, global_step: 8505, interval_runtime: 0.7857, interval_samples_per_second: 50.907, interval_steps_per_second: 6.363, epoch: 12.6\r\n",
      "loss: 0.01912054, learning_rate: 1.109e-05, global_step: 8510, interval_runtime: 0.8338, interval_samples_per_second: 47.973, interval_steps_per_second: 5.997, epoch: 12.6074\r\n",
      "loss: 0.01622121, learning_rate: 1.108e-05, global_step: 8515, interval_runtime: 0.9043, interval_samples_per_second: 44.235, interval_steps_per_second: 5.529, epoch: 12.6148\r\n",
      "loss: 0.01939718, learning_rate: 1.107e-05, global_step: 8520, interval_runtime: 0.7662, interval_samples_per_second: 52.208, interval_steps_per_second: 6.526, epoch: 12.6222\r\n",
      "loss: 0.01373421, learning_rate: 1.106e-05, global_step: 8525, interval_runtime: 1.0469, interval_samples_per_second: 38.209, interval_steps_per_second: 4.776, epoch: 12.6296\r\n",
      "loss: 0.02862827, learning_rate: 1.104e-05, global_step: 8530, interval_runtime: 0.8337, interval_samples_per_second: 47.978, interval_steps_per_second: 5.997, epoch: 12.637\r\n",
      "loss: 0.02327657, learning_rate: 1.103e-05, global_step: 8535, interval_runtime: 0.7945, interval_samples_per_second: 50.345, interval_steps_per_second: 6.293, epoch: 12.6444\r\n",
      "loss: 0.00918387, learning_rate: 1.102e-05, global_step: 8540, interval_runtime: 0.9049, interval_samples_per_second: 44.205, interval_steps_per_second: 5.526, epoch: 12.6519\r\n",
      "loss: 0.02562834, learning_rate: 1.101e-05, global_step: 8545, interval_runtime: 1.0112, interval_samples_per_second: 39.556, interval_steps_per_second: 4.944, epoch: 12.6593\r\n",
      "loss: 0.02150257, learning_rate: 1.1e-05, global_step: 8550, interval_runtime: 0.7235, interval_samples_per_second: 55.286, interval_steps_per_second: 6.911, epoch: 12.6667\r\n",
      "loss: 0.02209142, learning_rate: 1.099e-05, global_step: 8555, interval_runtime: 0.7739, interval_samples_per_second: 51.685, interval_steps_per_second: 6.461, epoch: 12.6741\r\n",
      "loss: 0.03186971, learning_rate: 1.098e-05, global_step: 8560, interval_runtime: 0.888, interval_samples_per_second: 45.046, interval_steps_per_second: 5.631, epoch: 12.6815\r\n",
      "loss: 0.02476199, learning_rate: 1.097e-05, global_step: 8565, interval_runtime: 0.9058, interval_samples_per_second: 44.162, interval_steps_per_second: 5.52, epoch: 12.6889\r\n",
      "loss: 0.00944079, learning_rate: 1.096e-05, global_step: 8570, interval_runtime: 0.9113, interval_samples_per_second: 43.892, interval_steps_per_second: 5.487, epoch: 12.6963\r\n",
      "loss: 0.02357663, learning_rate: 1.094e-05, global_step: 8575, interval_runtime: 0.9003, interval_samples_per_second: 44.429, interval_steps_per_second: 5.554, epoch: 12.7037\r\n",
      "loss: 0.01532593, learning_rate: 1.093e-05, global_step: 8580, interval_runtime: 0.8294, interval_samples_per_second: 48.227, interval_steps_per_second: 6.028, epoch: 12.7111\r\n",
      "loss: 0.01239164, learning_rate: 1.092e-05, global_step: 8585, interval_runtime: 0.8686, interval_samples_per_second: 46.053, interval_steps_per_second: 5.757, epoch: 12.7185\r\n",
      "loss: 0.0174577, learning_rate: 1.091e-05, global_step: 8590, interval_runtime: 0.7873, interval_samples_per_second: 50.807, interval_steps_per_second: 6.351, epoch: 12.7259\r\n",
      "loss: 0.00651226, learning_rate: 1.09e-05, global_step: 8595, interval_runtime: 0.8069, interval_samples_per_second: 49.572, interval_steps_per_second: 6.197, epoch: 12.7333\r\n",
      "loss: 0.01062063, learning_rate: 1.089e-05, global_step: 8600, interval_runtime: 0.7265, interval_samples_per_second: 55.058, interval_steps_per_second: 6.882, epoch: 12.7407\r\n",
      "loss: 0.00434518, learning_rate: 1.088e-05, global_step: 8605, interval_runtime: 0.804, interval_samples_per_second: 49.749, interval_steps_per_second: 6.219, epoch: 12.7481\r\n",
      "loss: 0.01572283, learning_rate: 1.087e-05, global_step: 8610, interval_runtime: 0.7883, interval_samples_per_second: 50.742, interval_steps_per_second: 6.343, epoch: 12.7556\r\n",
      "loss: 0.02935771, learning_rate: 1.086e-05, global_step: 8615, interval_runtime: 0.7787, interval_samples_per_second: 51.365, interval_steps_per_second: 6.421, epoch: 12.763\r\n",
      "loss: 0.0229332, learning_rate: 1.084e-05, global_step: 8620, interval_runtime: 0.783, interval_samples_per_second: 51.086, interval_steps_per_second: 6.386, epoch: 12.7704\r\n",
      "loss: 0.01858573, learning_rate: 1.083e-05, global_step: 8625, interval_runtime: 0.9282, interval_samples_per_second: 43.094, interval_steps_per_second: 5.387, epoch: 12.7778\r\n",
      "loss: 0.02155752, learning_rate: 1.082e-05, global_step: 8630, interval_runtime: 0.855, interval_samples_per_second: 46.782, interval_steps_per_second: 5.848, epoch: 12.7852\r\n",
      "loss: 0.00492865, learning_rate: 1.081e-05, global_step: 8635, interval_runtime: 1.0142, interval_samples_per_second: 39.442, interval_steps_per_second: 4.93, epoch: 12.7926\r\n",
      "loss: 0.02388844, learning_rate: 1.08e-05, global_step: 8640, interval_runtime: 0.8122, interval_samples_per_second: 49.246, interval_steps_per_second: 6.156, epoch: 12.8\r\n",
      "loss: 0.02324088, learning_rate: 1.079e-05, global_step: 8645, interval_runtime: 0.8087, interval_samples_per_second: 49.463, interval_steps_per_second: 6.183, epoch: 12.8074\r\n",
      "loss: 0.02150356, learning_rate: 1.078e-05, global_step: 8650, interval_runtime: 0.7635, interval_samples_per_second: 52.393, interval_steps_per_second: 6.549, epoch: 12.8148\r\n",
      "loss: 0.01171686, learning_rate: 1.077e-05, global_step: 8655, interval_runtime: 0.7617, interval_samples_per_second: 52.511, interval_steps_per_second: 6.564, epoch: 12.8222\r\n",
      "loss: 0.00810571, learning_rate: 1.076e-05, global_step: 8660, interval_runtime: 0.7704, interval_samples_per_second: 51.92, interval_steps_per_second: 6.49, epoch: 12.8296\r\n",
      "loss: 0.01365257, learning_rate: 1.074e-05, global_step: 8665, interval_runtime: 0.7635, interval_samples_per_second: 52.391, interval_steps_per_second: 6.549, epoch: 12.837\r\n",
      "loss: 0.00717216, learning_rate: 1.073e-05, global_step: 8670, interval_runtime: 0.7112, interval_samples_per_second: 56.241, interval_steps_per_second: 7.03, epoch: 12.8444\r\n",
      "loss: 0.01900492, learning_rate: 1.072e-05, global_step: 8675, interval_runtime: 0.8609, interval_samples_per_second: 46.461, interval_steps_per_second: 5.808, epoch: 12.8519\r\n",
      "loss: 0.00633903, learning_rate: 1.071e-05, global_step: 8680, interval_runtime: 0.8954, interval_samples_per_second: 44.672, interval_steps_per_second: 5.584, epoch: 12.8593\r\n",
      "loss: 0.01322224, learning_rate: 1.07e-05, global_step: 8685, interval_runtime: 0.9169, interval_samples_per_second: 43.623, interval_steps_per_second: 5.453, epoch: 12.8667\r\n",
      "loss: 0.01052472, learning_rate: 1.069e-05, global_step: 8690, interval_runtime: 0.8963, interval_samples_per_second: 44.629, interval_steps_per_second: 5.579, epoch: 12.8741\r\n",
      "loss: 0.01838521, learning_rate: 1.068e-05, global_step: 8695, interval_runtime: 0.8956, interval_samples_per_second: 44.661, interval_steps_per_second: 5.583, epoch: 12.8815\r\n",
      "loss: 0.00955724, learning_rate: 1.067e-05, global_step: 8700, interval_runtime: 0.9657, interval_samples_per_second: 41.422, interval_steps_per_second: 5.178, epoch: 12.8889\r\n",
      "loss: 0.00546305, learning_rate: 1.066e-05, global_step: 8705, interval_runtime: 0.7626, interval_samples_per_second: 52.45, interval_steps_per_second: 6.556, epoch: 12.8963\r\n",
      "loss: 0.01494962, learning_rate: 1.064e-05, global_step: 8710, interval_runtime: 0.8244, interval_samples_per_second: 48.517, interval_steps_per_second: 6.065, epoch: 12.9037\r\n",
      "loss: 0.00497199, learning_rate: 1.063e-05, global_step: 8715, interval_runtime: 0.7832, interval_samples_per_second: 51.074, interval_steps_per_second: 6.384, epoch: 12.9111\r\n",
      "loss: 0.01389553, learning_rate: 1.062e-05, global_step: 8720, interval_runtime: 0.8499, interval_samples_per_second: 47.065, interval_steps_per_second: 5.883, epoch: 12.9185\r\n",
      "loss: 0.0197002, learning_rate: 1.061e-05, global_step: 8725, interval_runtime: 0.8055, interval_samples_per_second: 49.656, interval_steps_per_second: 6.207, epoch: 12.9259\r\n",
      "loss: 0.0049658, learning_rate: 1.06e-05, global_step: 8730, interval_runtime: 0.8171, interval_samples_per_second: 48.955, interval_steps_per_second: 6.119, epoch: 12.9333\r\n",
      "loss: 0.0230322, learning_rate: 1.059e-05, global_step: 8735, interval_runtime: 0.8233, interval_samples_per_second: 48.586, interval_steps_per_second: 6.073, epoch: 12.9407\r\n",
      "loss: 0.01480162, learning_rate: 1.058e-05, global_step: 8740, interval_runtime: 0.8261, interval_samples_per_second: 48.422, interval_steps_per_second: 6.053, epoch: 12.9481\r\n",
      "loss: 0.03242209, learning_rate: 1.057e-05, global_step: 8745, interval_runtime: 0.8229, interval_samples_per_second: 48.607, interval_steps_per_second: 6.076, epoch: 12.9556\r\n",
      "loss: 0.0060809, learning_rate: 1.056e-05, global_step: 8750, interval_runtime: 0.9114, interval_samples_per_second: 43.888, interval_steps_per_second: 5.486, epoch: 12.963\r\n",
      "loss: 0.01639584, learning_rate: 1.054e-05, global_step: 8755, interval_runtime: 0.9451, interval_samples_per_second: 42.324, interval_steps_per_second: 5.291, epoch: 12.9704\r\n",
      "loss: 0.01090575, learning_rate: 1.053e-05, global_step: 8760, interval_runtime: 0.944, interval_samples_per_second: 42.374, interval_steps_per_second: 5.297, epoch: 12.9778\r\n",
      "loss: 0.01182129, learning_rate: 1.052e-05, global_step: 8765, interval_runtime: 0.864, interval_samples_per_second: 46.295, interval_steps_per_second: 5.787, epoch: 12.9852\r\n",
      "loss: 0.02274233, learning_rate: 1.051e-05, global_step: 8770, interval_runtime: 0.9103, interval_samples_per_second: 43.942, interval_steps_per_second: 5.493, epoch: 12.9926\r\n",
      "loss: 0.01179178, learning_rate: 1.05e-05, global_step: 8775, interval_runtime: 0.8687, interval_samples_per_second: 46.045, interval_steps_per_second: 5.756, epoch: 13.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:07:58,241] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:07:58,243] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:07:58,245] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:07:58,247] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:07:58,249] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.7149218320846558, eval_micro_f1_score: 0.5639771801140994, eval_macro_f1_score: 0.4595367956940957, eval_runtime: 13.4716, eval_samples_per_second: 140.74, eval_steps_per_second: 17.593, epoch: 13.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:08:11,721] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-8775\r\n",
      "[2023-01-10 11:08:11,724] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:08:15,108] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-8775/tokenizer_config.json\r\n",
      "[2023-01-10 11:08:15,112] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-8775/special_tokens_map.json\r\n",
      "[2023-01-10 11:08:21,795] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-8100] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0137075, learning_rate: 1.049e-05, global_step: 8780, interval_runtime: 24.9505, interval_samples_per_second: 1.603, interval_steps_per_second: 0.2, epoch: 13.0074\r\n",
      "loss: 0.00764922, learning_rate: 1.048e-05, global_step: 8785, interval_runtime: 0.7916, interval_samples_per_second: 50.534, interval_steps_per_second: 6.317, epoch: 13.0148\r\n",
      "loss: 0.01768946, learning_rate: 1.047e-05, global_step: 8790, interval_runtime: 0.8513, interval_samples_per_second: 46.989, interval_steps_per_second: 5.874, epoch: 13.0222\r\n",
      "loss: 0.00667291, learning_rate: 1.046e-05, global_step: 8795, interval_runtime: 0.6923, interval_samples_per_second: 57.782, interval_steps_per_second: 7.223, epoch: 13.0296\r\n",
      "loss: 0.02210855, learning_rate: 1.044e-05, global_step: 8800, interval_runtime: 0.8965, interval_samples_per_second: 44.617, interval_steps_per_second: 5.577, epoch: 13.037\r\n",
      "loss: 0.00367394, learning_rate: 1.043e-05, global_step: 8805, interval_runtime: 0.8536, interval_samples_per_second: 46.859, interval_steps_per_second: 5.857, epoch: 13.0444\r\n",
      "loss: 0.00724585, learning_rate: 1.042e-05, global_step: 8810, interval_runtime: 0.8602, interval_samples_per_second: 46.499, interval_steps_per_second: 5.812, epoch: 13.0519\r\n",
      "loss: 0.00438435, learning_rate: 1.041e-05, global_step: 8815, interval_runtime: 0.7509, interval_samples_per_second: 53.269, interval_steps_per_second: 6.659, epoch: 13.0593\r\n",
      "loss: 0.00744382, learning_rate: 1.04e-05, global_step: 8820, interval_runtime: 0.8528, interval_samples_per_second: 46.902, interval_steps_per_second: 5.863, epoch: 13.0667\r\n",
      "loss: 0.02237241, learning_rate: 1.039e-05, global_step: 8825, interval_runtime: 0.881, interval_samples_per_second: 45.401, interval_steps_per_second: 5.675, epoch: 13.0741\r\n",
      "loss: 0.00215487, learning_rate: 1.038e-05, global_step: 8830, interval_runtime: 0.8277, interval_samples_per_second: 48.326, interval_steps_per_second: 6.041, epoch: 13.0815\r\n",
      "loss: 0.0108958, learning_rate: 1.037e-05, global_step: 8835, interval_runtime: 0.7479, interval_samples_per_second: 53.486, interval_steps_per_second: 6.686, epoch: 13.0889\r\n",
      "loss: 0.00802145, learning_rate: 1.036e-05, global_step: 8840, interval_runtime: 0.7735, interval_samples_per_second: 51.715, interval_steps_per_second: 6.464, epoch: 13.0963\r\n",
      "loss: 0.01697156, learning_rate: 1.034e-05, global_step: 8845, interval_runtime: 0.7625, interval_samples_per_second: 52.461, interval_steps_per_second: 6.558, epoch: 13.1037\r\n",
      "loss: 0.01069396, learning_rate: 1.033e-05, global_step: 8850, interval_runtime: 0.8876, interval_samples_per_second: 45.067, interval_steps_per_second: 5.633, epoch: 13.1111\r\n",
      "loss: 0.01169579, learning_rate: 1.032e-05, global_step: 8855, interval_runtime: 0.8187, interval_samples_per_second: 48.856, interval_steps_per_second: 6.107, epoch: 13.1185\r\n",
      "loss: 0.0172688, learning_rate: 1.031e-05, global_step: 8860, interval_runtime: 0.9099, interval_samples_per_second: 43.96, interval_steps_per_second: 5.495, epoch: 13.1259\r\n",
      "loss: 0.00313626, learning_rate: 1.03e-05, global_step: 8865, interval_runtime: 1.098, interval_samples_per_second: 36.43, interval_steps_per_second: 4.554, epoch: 13.1333\r\n",
      "loss: 0.01499721, learning_rate: 1.029e-05, global_step: 8870, interval_runtime: 0.867, interval_samples_per_second: 46.137, interval_steps_per_second: 5.767, epoch: 13.1407\r\n",
      "loss: 0.00532768, learning_rate: 1.028e-05, global_step: 8875, interval_runtime: 0.8946, interval_samples_per_second: 44.715, interval_steps_per_second: 5.589, epoch: 13.1481\r\n",
      "loss: 0.01793639, learning_rate: 1.027e-05, global_step: 8880, interval_runtime: 0.8116, interval_samples_per_second: 49.283, interval_steps_per_second: 6.16, epoch: 13.1556\r\n",
      "loss: 0.00442107, learning_rate: 1.026e-05, global_step: 8885, interval_runtime: 0.7629, interval_samples_per_second: 52.433, interval_steps_per_second: 6.554, epoch: 13.163\r\n",
      "loss: 0.01215733, learning_rate: 1.024e-05, global_step: 8890, interval_runtime: 0.9563, interval_samples_per_second: 41.829, interval_steps_per_second: 5.229, epoch: 13.1704\r\n",
      "loss: 0.01727909, learning_rate: 1.023e-05, global_step: 8895, interval_runtime: 0.925, interval_samples_per_second: 43.245, interval_steps_per_second: 5.406, epoch: 13.1778\r\n",
      "loss: 0.00527327, learning_rate: 1.022e-05, global_step: 8900, interval_runtime: 0.7257, interval_samples_per_second: 55.12, interval_steps_per_second: 6.89, epoch: 13.1852\r\n",
      "loss: 0.00606973, learning_rate: 1.021e-05, global_step: 8905, interval_runtime: 0.8371, interval_samples_per_second: 47.783, interval_steps_per_second: 5.973, epoch: 13.1926\r\n",
      "loss: 0.00315598, learning_rate: 1.02e-05, global_step: 8910, interval_runtime: 0.7539, interval_samples_per_second: 53.054, interval_steps_per_second: 6.632, epoch: 13.2\r\n",
      "loss: 0.01423151, learning_rate: 1.019e-05, global_step: 8915, interval_runtime: 0.7936, interval_samples_per_second: 50.404, interval_steps_per_second: 6.301, epoch: 13.2074\r\n",
      "loss: 0.01309577, learning_rate: 1.018e-05, global_step: 8920, interval_runtime: 0.7566, interval_samples_per_second: 52.87, interval_steps_per_second: 6.609, epoch: 13.2148\r\n",
      "loss: 0.00547954, learning_rate: 1.017e-05, global_step: 8925, interval_runtime: 0.7908, interval_samples_per_second: 50.582, interval_steps_per_second: 6.323, epoch: 13.2222\r\n",
      "loss: 0.00846454, learning_rate: 1.016e-05, global_step: 8930, interval_runtime: 0.8996, interval_samples_per_second: 44.464, interval_steps_per_second: 5.558, epoch: 13.2296\r\n",
      "loss: 0.00506582, learning_rate: 1.014e-05, global_step: 8935, interval_runtime: 0.8318, interval_samples_per_second: 48.089, interval_steps_per_second: 6.011, epoch: 13.237\r\n",
      "loss: 0.0117531, learning_rate: 1.013e-05, global_step: 8940, interval_runtime: 0.7881, interval_samples_per_second: 50.755, interval_steps_per_second: 6.344, epoch: 13.2444\r\n",
      "loss: 0.01503665, learning_rate: 1.012e-05, global_step: 8945, interval_runtime: 0.8765, interval_samples_per_second: 45.636, interval_steps_per_second: 5.705, epoch: 13.2519\r\n",
      "loss: 0.00830064, learning_rate: 1.011e-05, global_step: 8950, interval_runtime: 0.8022, interval_samples_per_second: 49.864, interval_steps_per_second: 6.233, epoch: 13.2593\r\n",
      "loss: 0.0070034, learning_rate: 1.01e-05, global_step: 8955, interval_runtime: 0.8918, interval_samples_per_second: 44.854, interval_steps_per_second: 5.607, epoch: 13.2667\r\n",
      "loss: 0.02778056, learning_rate: 1.009e-05, global_step: 8960, interval_runtime: 0.8601, interval_samples_per_second: 46.504, interval_steps_per_second: 5.813, epoch: 13.2741\r\n",
      "loss: 0.00772159, learning_rate: 1.008e-05, global_step: 8965, interval_runtime: 0.9018, interval_samples_per_second: 44.355, interval_steps_per_second: 5.544, epoch: 13.2815\r\n",
      "loss: 0.00421567, learning_rate: 1.007e-05, global_step: 8970, interval_runtime: 0.7354, interval_samples_per_second: 54.392, interval_steps_per_second: 6.799, epoch: 13.2889\r\n",
      "loss: 0.01256181, learning_rate: 1.006e-05, global_step: 8975, interval_runtime: 0.9178, interval_samples_per_second: 43.584, interval_steps_per_second: 5.448, epoch: 13.2963\r\n",
      "loss: 0.01018374, learning_rate: 1.004e-05, global_step: 8980, interval_runtime: 0.8264, interval_samples_per_second: 48.402, interval_steps_per_second: 6.05, epoch: 13.3037\r\n",
      "loss: 0.00290166, learning_rate: 1.003e-05, global_step: 8985, interval_runtime: 0.8878, interval_samples_per_second: 45.055, interval_steps_per_second: 5.632, epoch: 13.3111\r\n",
      "loss: 0.01606413, learning_rate: 1.002e-05, global_step: 8990, interval_runtime: 0.8294, interval_samples_per_second: 48.229, interval_steps_per_second: 6.029, epoch: 13.3185\r\n",
      "loss: 0.00941977, learning_rate: 1.001e-05, global_step: 8995, interval_runtime: 0.9001, interval_samples_per_second: 44.439, interval_steps_per_second: 5.555, epoch: 13.3259\r\n",
      "loss: 0.01293597, learning_rate: 1e-05, global_step: 9000, interval_runtime: 0.8664, interval_samples_per_second: 46.171, interval_steps_per_second: 5.771, epoch: 13.3333\r\n",
      "loss: 0.01692603, learning_rate: 9.989e-06, global_step: 9005, interval_runtime: 1.0833, interval_samples_per_second: 36.923, interval_steps_per_second: 4.615, epoch: 13.3407\r\n",
      "loss: 0.03255106, learning_rate: 9.978e-06, global_step: 9010, interval_runtime: 0.8167, interval_samples_per_second: 48.978, interval_steps_per_second: 6.122, epoch: 13.3481\r\n",
      "loss: 0.00427482, learning_rate: 9.967e-06, global_step: 9015, interval_runtime: 0.7863, interval_samples_per_second: 50.87, interval_steps_per_second: 6.359, epoch: 13.3556\r\n",
      "loss: 0.01402776, learning_rate: 9.956e-06, global_step: 9020, interval_runtime: 0.7816, interval_samples_per_second: 51.178, interval_steps_per_second: 6.397, epoch: 13.363\r\n",
      "loss: 0.0080281, learning_rate: 9.944e-06, global_step: 9025, interval_runtime: 0.7866, interval_samples_per_second: 50.85, interval_steps_per_second: 6.356, epoch: 13.3704\r\n",
      "loss: 0.00423968, learning_rate: 9.933e-06, global_step: 9030, interval_runtime: 0.7865, interval_samples_per_second: 50.856, interval_steps_per_second: 6.357, epoch: 13.3778\r\n",
      "loss: 0.01003306, learning_rate: 9.922e-06, global_step: 9035, interval_runtime: 0.8494, interval_samples_per_second: 47.091, interval_steps_per_second: 5.886, epoch: 13.3852\r\n",
      "loss: 0.01712182, learning_rate: 9.911e-06, global_step: 9040, interval_runtime: 0.9327, interval_samples_per_second: 42.886, interval_steps_per_second: 5.361, epoch: 13.3926\r\n",
      "loss: 0.0088461, learning_rate: 9.9e-06, global_step: 9045, interval_runtime: 0.8134, interval_samples_per_second: 49.177, interval_steps_per_second: 6.147, epoch: 13.4\r\n",
      "loss: 0.00309038, learning_rate: 9.889e-06, global_step: 9050, interval_runtime: 1.0371, interval_samples_per_second: 38.568, interval_steps_per_second: 4.821, epoch: 13.4074\r\n",
      "loss: 0.01515824, learning_rate: 9.878e-06, global_step: 9055, interval_runtime: 0.7846, interval_samples_per_second: 50.98, interval_steps_per_second: 6.372, epoch: 13.4148\r\n",
      "loss: 0.01124398, learning_rate: 9.867e-06, global_step: 9060, interval_runtime: 0.805, interval_samples_per_second: 49.689, interval_steps_per_second: 6.211, epoch: 13.4222\r\n",
      "loss: 0.01867439, learning_rate: 9.856e-06, global_step: 9065, interval_runtime: 1.0203, interval_samples_per_second: 39.206, interval_steps_per_second: 4.901, epoch: 13.4296\r\n",
      "loss: 0.01296552, learning_rate: 9.844e-06, global_step: 9070, interval_runtime: 0.7724, interval_samples_per_second: 51.784, interval_steps_per_second: 6.473, epoch: 13.437\r\n",
      "loss: 0.00291113, learning_rate: 9.833e-06, global_step: 9075, interval_runtime: 0.9106, interval_samples_per_second: 43.928, interval_steps_per_second: 5.491, epoch: 13.4444\r\n",
      "loss: 0.00516108, learning_rate: 9.822e-06, global_step: 9080, interval_runtime: 0.8966, interval_samples_per_second: 44.615, interval_steps_per_second: 5.577, epoch: 13.4519\r\n",
      "loss: 0.00466079, learning_rate: 9.811e-06, global_step: 9085, interval_runtime: 0.7159, interval_samples_per_second: 55.877, interval_steps_per_second: 6.985, epoch: 13.4593\r\n",
      "loss: 0.02079905, learning_rate: 9.8e-06, global_step: 9090, interval_runtime: 0.9108, interval_samples_per_second: 43.918, interval_steps_per_second: 5.49, epoch: 13.4667\r\n",
      "loss: 0.01918361, learning_rate: 9.789e-06, global_step: 9095, interval_runtime: 0.9102, interval_samples_per_second: 43.946, interval_steps_per_second: 5.493, epoch: 13.4741\r\n",
      "loss: 0.00357505, learning_rate: 9.778e-06, global_step: 9100, interval_runtime: 0.8086, interval_samples_per_second: 49.471, interval_steps_per_second: 6.184, epoch: 13.4815\r\n",
      "loss: 0.01616616, learning_rate: 9.767e-06, global_step: 9105, interval_runtime: 0.7954, interval_samples_per_second: 50.288, interval_steps_per_second: 6.286, epoch: 13.4889\r\n",
      "loss: 0.01278577, learning_rate: 9.756e-06, global_step: 9110, interval_runtime: 0.878, interval_samples_per_second: 45.556, interval_steps_per_second: 5.694, epoch: 13.4963\r\n",
      "loss: 0.0169062, learning_rate: 9.744e-06, global_step: 9115, interval_runtime: 0.8634, interval_samples_per_second: 46.33, interval_steps_per_second: 5.791, epoch: 13.5037\r\n",
      "loss: 0.00760173, learning_rate: 9.733e-06, global_step: 9120, interval_runtime: 0.7823, interval_samples_per_second: 51.131, interval_steps_per_second: 6.391, epoch: 13.5111\r\n",
      "loss: 0.00256697, learning_rate: 9.722e-06, global_step: 9125, interval_runtime: 0.719, interval_samples_per_second: 55.634, interval_steps_per_second: 6.954, epoch: 13.5185\r\n",
      "loss: 0.00586355, learning_rate: 9.711e-06, global_step: 9130, interval_runtime: 0.7092, interval_samples_per_second: 56.401, interval_steps_per_second: 7.05, epoch: 13.5259\r\n",
      "loss: 0.02028291, learning_rate: 9.7e-06, global_step: 9135, interval_runtime: 0.7667, interval_samples_per_second: 52.171, interval_steps_per_second: 6.521, epoch: 13.5333\r\n",
      "loss: 0.00298724, learning_rate: 9.689e-06, global_step: 9140, interval_runtime: 0.8547, interval_samples_per_second: 46.802, interval_steps_per_second: 5.85, epoch: 13.5407\r\n",
      "loss: 0.00959101, learning_rate: 9.678e-06, global_step: 9145, interval_runtime: 0.7807, interval_samples_per_second: 51.238, interval_steps_per_second: 6.405, epoch: 13.5481\r\n",
      "loss: 0.00988622, learning_rate: 9.667e-06, global_step: 9150, interval_runtime: 1.0158, interval_samples_per_second: 39.376, interval_steps_per_second: 4.922, epoch: 13.5556\r\n",
      "loss: 0.00587722, learning_rate: 9.656e-06, global_step: 9155, interval_runtime: 0.7097, interval_samples_per_second: 56.364, interval_steps_per_second: 7.046, epoch: 13.563\r\n",
      "loss: 0.00577837, learning_rate: 9.644e-06, global_step: 9160, interval_runtime: 0.7308, interval_samples_per_second: 54.734, interval_steps_per_second: 6.842, epoch: 13.5704\r\n",
      "loss: 0.0056138, learning_rate: 9.633e-06, global_step: 9165, interval_runtime: 0.7962, interval_samples_per_second: 50.239, interval_steps_per_second: 6.28, epoch: 13.5778\r\n",
      "loss: 0.0329637, learning_rate: 9.622e-06, global_step: 9170, interval_runtime: 0.8129, interval_samples_per_second: 49.205, interval_steps_per_second: 6.151, epoch: 13.5852\r\n",
      "loss: 0.00729382, learning_rate: 9.611e-06, global_step: 9175, interval_runtime: 0.8153, interval_samples_per_second: 49.064, interval_steps_per_second: 6.133, epoch: 13.5926\r\n",
      "loss: 0.01112248, learning_rate: 9.6e-06, global_step: 9180, interval_runtime: 0.9168, interval_samples_per_second: 43.631, interval_steps_per_second: 5.454, epoch: 13.6\r\n",
      "loss: 0.03017797, learning_rate: 9.589e-06, global_step: 9185, interval_runtime: 0.8991, interval_samples_per_second: 44.491, interval_steps_per_second: 5.561, epoch: 13.6074\r\n",
      "loss: 0.0137141, learning_rate: 9.578e-06, global_step: 9190, interval_runtime: 0.9528, interval_samples_per_second: 41.982, interval_steps_per_second: 5.248, epoch: 13.6148\r\n",
      "loss: 0.01844337, learning_rate: 9.567e-06, global_step: 9195, interval_runtime: 0.8027, interval_samples_per_second: 49.833, interval_steps_per_second: 6.229, epoch: 13.6222\r\n",
      "loss: 0.00584693, learning_rate: 9.556e-06, global_step: 9200, interval_runtime: 0.7797, interval_samples_per_second: 51.304, interval_steps_per_second: 6.413, epoch: 13.6296\r\n",
      "loss: 0.00501653, learning_rate: 9.544e-06, global_step: 9205, interval_runtime: 0.8806, interval_samples_per_second: 45.424, interval_steps_per_second: 5.678, epoch: 13.637\r\n",
      "loss: 0.01300769, learning_rate: 9.533e-06, global_step: 9210, interval_runtime: 0.7267, interval_samples_per_second: 55.046, interval_steps_per_second: 6.881, epoch: 13.6444\r\n",
      "loss: 0.02265168, learning_rate: 9.522e-06, global_step: 9215, interval_runtime: 0.8164, interval_samples_per_second: 48.997, interval_steps_per_second: 6.125, epoch: 13.6519\r\n",
      "loss: 0.00335776, learning_rate: 9.511e-06, global_step: 9220, interval_runtime: 0.9021, interval_samples_per_second: 44.343, interval_steps_per_second: 5.543, epoch: 13.6593\r\n",
      "loss: 0.00407682, learning_rate: 9.5e-06, global_step: 9225, interval_runtime: 0.9304, interval_samples_per_second: 42.99, interval_steps_per_second: 5.374, epoch: 13.6667\r\n",
      "loss: 0.00472636, learning_rate: 9.489e-06, global_step: 9230, interval_runtime: 0.9382, interval_samples_per_second: 42.636, interval_steps_per_second: 5.33, epoch: 13.6741\r\n",
      "loss: 0.00308794, learning_rate: 9.478e-06, global_step: 9235, interval_runtime: 0.9265, interval_samples_per_second: 43.173, interval_steps_per_second: 5.397, epoch: 13.6815\r\n",
      "loss: 0.01223981, learning_rate: 9.467e-06, global_step: 9240, interval_runtime: 0.7519, interval_samples_per_second: 53.197, interval_steps_per_second: 6.65, epoch: 13.6889\r\n",
      "loss: 0.01917373, learning_rate: 9.456e-06, global_step: 9245, interval_runtime: 0.8784, interval_samples_per_second: 45.537, interval_steps_per_second: 5.692, epoch: 13.6963\r\n",
      "loss: 0.00348468, learning_rate: 9.444e-06, global_step: 9250, interval_runtime: 0.7483, interval_samples_per_second: 53.451, interval_steps_per_second: 6.681, epoch: 13.7037\r\n",
      "loss: 0.00433337, learning_rate: 9.433e-06, global_step: 9255, interval_runtime: 0.7646, interval_samples_per_second: 52.312, interval_steps_per_second: 6.539, epoch: 13.7111\r\n",
      "loss: 0.01263591, learning_rate: 9.422e-06, global_step: 9260, interval_runtime: 0.8876, interval_samples_per_second: 45.068, interval_steps_per_second: 5.633, epoch: 13.7185\r\n",
      "loss: 0.0232525, learning_rate: 9.411e-06, global_step: 9265, interval_runtime: 0.7649, interval_samples_per_second: 52.297, interval_steps_per_second: 6.537, epoch: 13.7259\r\n",
      "loss: 0.00809937, learning_rate: 9.4e-06, global_step: 9270, interval_runtime: 0.9665, interval_samples_per_second: 41.388, interval_steps_per_second: 5.174, epoch: 13.7333\r\n",
      "loss: 0.01405455, learning_rate: 9.389e-06, global_step: 9275, interval_runtime: 0.9198, interval_samples_per_second: 43.489, interval_steps_per_second: 5.436, epoch: 13.7407\r\n",
      "loss: 0.02143081, learning_rate: 9.378e-06, global_step: 9280, interval_runtime: 0.8667, interval_samples_per_second: 46.154, interval_steps_per_second: 5.769, epoch: 13.7481\r\n",
      "loss: 0.00743154, learning_rate: 9.367e-06, global_step: 9285, interval_runtime: 0.896, interval_samples_per_second: 44.642, interval_steps_per_second: 5.58, epoch: 13.7556\r\n",
      "loss: 0.01222734, learning_rate: 9.356e-06, global_step: 9290, interval_runtime: 0.8479, interval_samples_per_second: 47.173, interval_steps_per_second: 5.897, epoch: 13.763\r\n",
      "loss: 0.00968108, learning_rate: 9.344e-06, global_step: 9295, interval_runtime: 0.8507, interval_samples_per_second: 47.019, interval_steps_per_second: 5.877, epoch: 13.7704\r\n",
      "loss: 0.03929841, learning_rate: 9.333e-06, global_step: 9300, interval_runtime: 0.9827, interval_samples_per_second: 40.703, interval_steps_per_second: 5.088, epoch: 13.7778\r\n",
      "loss: 0.00662955, learning_rate: 9.322e-06, global_step: 9305, interval_runtime: 0.6877, interval_samples_per_second: 58.165, interval_steps_per_second: 7.271, epoch: 13.7852\r\n",
      "loss: 0.00324047, learning_rate: 9.311e-06, global_step: 9310, interval_runtime: 0.8904, interval_samples_per_second: 44.925, interval_steps_per_second: 5.616, epoch: 13.7926\r\n",
      "loss: 0.00961694, learning_rate: 9.3e-06, global_step: 9315, interval_runtime: 0.7654, interval_samples_per_second: 52.26, interval_steps_per_second: 6.533, epoch: 13.8\r\n",
      "loss: 0.01857434, learning_rate: 9.289e-06, global_step: 9320, interval_runtime: 0.8969, interval_samples_per_second: 44.598, interval_steps_per_second: 5.575, epoch: 13.8074\r\n",
      "loss: 0.01035646, learning_rate: 9.278e-06, global_step: 9325, interval_runtime: 0.8301, interval_samples_per_second: 48.189, interval_steps_per_second: 6.024, epoch: 13.8148\r\n",
      "loss: 0.01040036, learning_rate: 9.267e-06, global_step: 9330, interval_runtime: 0.9531, interval_samples_per_second: 41.969, interval_steps_per_second: 5.246, epoch: 13.8222\r\n",
      "loss: 0.01460953, learning_rate: 9.256e-06, global_step: 9335, interval_runtime: 0.8192, interval_samples_per_second: 48.828, interval_steps_per_second: 6.103, epoch: 13.8296\r\n",
      "loss: 0.00999079, learning_rate: 9.244e-06, global_step: 9340, interval_runtime: 0.8773, interval_samples_per_second: 45.594, interval_steps_per_second: 5.699, epoch: 13.837\r\n",
      "loss: 0.00642018, learning_rate: 9.233e-06, global_step: 9345, interval_runtime: 0.8738, interval_samples_per_second: 45.775, interval_steps_per_second: 5.722, epoch: 13.8444\r\n",
      "loss: 0.00970306, learning_rate: 9.222e-06, global_step: 9350, interval_runtime: 0.7736, interval_samples_per_second: 51.704, interval_steps_per_second: 6.463, epoch: 13.8519\r\n",
      "loss: 0.01635261, learning_rate: 9.211e-06, global_step: 9355, interval_runtime: 0.8814, interval_samples_per_second: 45.385, interval_steps_per_second: 5.673, epoch: 13.8593\r\n",
      "loss: 0.00322126, learning_rate: 9.2e-06, global_step: 9360, interval_runtime: 0.7974, interval_samples_per_second: 50.16, interval_steps_per_second: 6.27, epoch: 13.8667\r\n",
      "loss: 0.0154654, learning_rate: 9.189e-06, global_step: 9365, interval_runtime: 0.7698, interval_samples_per_second: 51.96, interval_steps_per_second: 6.495, epoch: 13.8741\r\n",
      "loss: 0.00654789, learning_rate: 9.178e-06, global_step: 9370, interval_runtime: 0.8422, interval_samples_per_second: 47.494, interval_steps_per_second: 5.937, epoch: 13.8815\r\n",
      "loss: 0.01300182, learning_rate: 9.167e-06, global_step: 9375, interval_runtime: 0.8978, interval_samples_per_second: 44.554, interval_steps_per_second: 5.569, epoch: 13.8889\r\n",
      "loss: 0.01651385, learning_rate: 9.156e-06, global_step: 9380, interval_runtime: 0.8823, interval_samples_per_second: 45.334, interval_steps_per_second: 5.667, epoch: 13.8963\r\n",
      "loss: 0.01788197, learning_rate: 9.144e-06, global_step: 9385, interval_runtime: 0.8709, interval_samples_per_second: 45.931, interval_steps_per_second: 5.741, epoch: 13.9037\r\n",
      "loss: 0.0194269, learning_rate: 9.133e-06, global_step: 9390, interval_runtime: 0.8623, interval_samples_per_second: 46.388, interval_steps_per_second: 5.798, epoch: 13.9111\r\n",
      "loss: 0.01451586, learning_rate: 9.122e-06, global_step: 9395, interval_runtime: 0.7247, interval_samples_per_second: 55.194, interval_steps_per_second: 6.899, epoch: 13.9185\r\n",
      "loss: 0.00276295, learning_rate: 9.111e-06, global_step: 9400, interval_runtime: 0.8557, interval_samples_per_second: 46.743, interval_steps_per_second: 5.843, epoch: 13.9259\r\n",
      "loss: 0.01145097, learning_rate: 9.1e-06, global_step: 9405, interval_runtime: 0.8141, interval_samples_per_second: 49.137, interval_steps_per_second: 6.142, epoch: 13.9333\r\n",
      "loss: 0.01135967, learning_rate: 9.089e-06, global_step: 9410, interval_runtime: 0.8475, interval_samples_per_second: 47.196, interval_steps_per_second: 5.9, epoch: 13.9407\r\n",
      "loss: 0.00515419, learning_rate: 9.078e-06, global_step: 9415, interval_runtime: 0.7411, interval_samples_per_second: 53.973, interval_steps_per_second: 6.747, epoch: 13.9481\r\n",
      "loss: 0.01161871, learning_rate: 9.067e-06, global_step: 9420, interval_runtime: 0.8705, interval_samples_per_second: 45.95, interval_steps_per_second: 5.744, epoch: 13.9556\r\n",
      "loss: 0.00854034, learning_rate: 9.056e-06, global_step: 9425, interval_runtime: 0.7328, interval_samples_per_second: 54.585, interval_steps_per_second: 6.823, epoch: 13.963\r\n",
      "loss: 0.00326882, learning_rate: 9.044e-06, global_step: 9430, interval_runtime: 0.7143, interval_samples_per_second: 55.995, interval_steps_per_second: 6.999, epoch: 13.9704\r\n",
      "loss: 0.00717876, learning_rate: 9.033e-06, global_step: 9435, interval_runtime: 0.7731, interval_samples_per_second: 51.739, interval_steps_per_second: 6.467, epoch: 13.9778\r\n",
      "loss: 0.00429189, learning_rate: 9.022e-06, global_step: 9440, interval_runtime: 0.8181, interval_samples_per_second: 48.894, interval_steps_per_second: 6.112, epoch: 13.9852\r\n",
      "loss: 0.00964494, learning_rate: 9.011e-06, global_step: 9445, interval_runtime: 0.7381, interval_samples_per_second: 54.19, interval_steps_per_second: 6.774, epoch: 13.9926\r\n",
      "loss: 0.01827969, learning_rate: 9e-06, global_step: 9450, interval_runtime: 0.6864, interval_samples_per_second: 58.277, interval_steps_per_second: 7.285, epoch: 14.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:10:15,464] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:10:15,466] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:10:15,468] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:10:15,470] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:10:15,472] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.7363009452819824, eval_micro_f1_score: 0.5621248252610805, eval_macro_f1_score: 0.460433537097982, eval_runtime: 13.3743, eval_samples_per_second: 141.765, eval_steps_per_second: 17.721, epoch: 14.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:10:28,843] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-9450\r\n",
      "[2023-01-10 11:10:28,846] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:10:32,218] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-9450/tokenizer_config.json\r\n",
      "[2023-01-10 11:10:32,222] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-9450/special_tokens_map.json\r\n",
      "[2023-01-10 11:10:38,916] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-8775] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00262453, learning_rate: 8.989e-06, global_step: 9455, interval_runtime: 24.9328, interval_samples_per_second: 1.604, interval_steps_per_second: 0.201, epoch: 14.0074\r\n",
      "loss: 0.01605539, learning_rate: 8.978e-06, global_step: 9460, interval_runtime: 0.8235, interval_samples_per_second: 48.57, interval_steps_per_second: 6.071, epoch: 14.0148\r\n",
      "loss: 0.00173435, learning_rate: 8.967e-06, global_step: 9465, interval_runtime: 0.7098, interval_samples_per_second: 56.358, interval_steps_per_second: 7.045, epoch: 14.0222\r\n",
      "loss: 0.0030364, learning_rate: 8.956e-06, global_step: 9470, interval_runtime: 0.7123, interval_samples_per_second: 56.157, interval_steps_per_second: 7.02, epoch: 14.0296\r\n",
      "loss: 0.00449459, learning_rate: 8.944e-06, global_step: 9475, interval_runtime: 0.821, interval_samples_per_second: 48.72, interval_steps_per_second: 6.09, epoch: 14.037\r\n",
      "loss: 0.00249942, learning_rate: 8.933e-06, global_step: 9480, interval_runtime: 0.7883, interval_samples_per_second: 50.741, interval_steps_per_second: 6.343, epoch: 14.0444\r\n",
      "loss: 0.01363101, learning_rate: 8.922e-06, global_step: 9485, interval_runtime: 0.8567, interval_samples_per_second: 46.689, interval_steps_per_second: 5.836, epoch: 14.0519\r\n",
      "loss: 0.01454871, learning_rate: 8.911e-06, global_step: 9490, interval_runtime: 0.8583, interval_samples_per_second: 46.602, interval_steps_per_second: 5.825, epoch: 14.0593\r\n",
      "loss: 0.01490818, learning_rate: 8.9e-06, global_step: 9495, interval_runtime: 0.759, interval_samples_per_second: 52.698, interval_steps_per_second: 6.587, epoch: 14.0667\r\n",
      "loss: 0.01319945, learning_rate: 8.889e-06, global_step: 9500, interval_runtime: 0.7297, interval_samples_per_second: 54.816, interval_steps_per_second: 6.852, epoch: 14.0741\r\n",
      "loss: 0.00293083, learning_rate: 8.878e-06, global_step: 9505, interval_runtime: 0.8707, interval_samples_per_second: 45.942, interval_steps_per_second: 5.743, epoch: 14.0815\r\n",
      "loss: 0.00471917, learning_rate: 8.867e-06, global_step: 9510, interval_runtime: 0.8191, interval_samples_per_second: 48.831, interval_steps_per_second: 6.104, epoch: 14.0889\r\n",
      "loss: 0.01079291, learning_rate: 8.856e-06, global_step: 9515, interval_runtime: 0.8273, interval_samples_per_second: 48.348, interval_steps_per_second: 6.044, epoch: 14.0963\r\n",
      "loss: 0.01200205, learning_rate: 8.844e-06, global_step: 9520, interval_runtime: 0.9463, interval_samples_per_second: 42.269, interval_steps_per_second: 5.284, epoch: 14.1037\r\n",
      "loss: 0.00685736, learning_rate: 8.833e-06, global_step: 9525, interval_runtime: 0.8063, interval_samples_per_second: 49.611, interval_steps_per_second: 6.201, epoch: 14.1111\r\n",
      "loss: 0.0101461, learning_rate: 8.822e-06, global_step: 9530, interval_runtime: 0.8542, interval_samples_per_second: 46.828, interval_steps_per_second: 5.853, epoch: 14.1185\r\n",
      "loss: 0.0019919, learning_rate: 8.811e-06, global_step: 9535, interval_runtime: 0.8597, interval_samples_per_second: 46.525, interval_steps_per_second: 5.816, epoch: 14.1259\r\n",
      "loss: 0.00661494, learning_rate: 8.8e-06, global_step: 9540, interval_runtime: 0.9082, interval_samples_per_second: 44.041, interval_steps_per_second: 5.505, epoch: 14.1333\r\n",
      "loss: 0.01303418, learning_rate: 8.789e-06, global_step: 9545, interval_runtime: 0.9207, interval_samples_per_second: 43.444, interval_steps_per_second: 5.431, epoch: 14.1407\r\n",
      "loss: 0.01192428, learning_rate: 8.778e-06, global_step: 9550, interval_runtime: 0.741, interval_samples_per_second: 53.983, interval_steps_per_second: 6.748, epoch: 14.1481\r\n",
      "loss: 0.00329459, learning_rate: 8.767e-06, global_step: 9555, interval_runtime: 0.8009, interval_samples_per_second: 49.945, interval_steps_per_second: 6.243, epoch: 14.1556\r\n",
      "loss: 0.00174695, learning_rate: 8.756e-06, global_step: 9560, interval_runtime: 0.7141, interval_samples_per_second: 56.017, interval_steps_per_second: 7.002, epoch: 14.163\r\n",
      "loss: 0.00667544, learning_rate: 8.744e-06, global_step: 9565, interval_runtime: 0.8295, interval_samples_per_second: 48.223, interval_steps_per_second: 6.028, epoch: 14.1704\r\n",
      "loss: 0.00406164, learning_rate: 8.733e-06, global_step: 9570, interval_runtime: 0.7643, interval_samples_per_second: 52.337, interval_steps_per_second: 6.542, epoch: 14.1778\r\n",
      "loss: 0.01439772, learning_rate: 8.722e-06, global_step: 9575, interval_runtime: 0.8831, interval_samples_per_second: 45.294, interval_steps_per_second: 5.662, epoch: 14.1852\r\n",
      "loss: 0.00189385, learning_rate: 8.711e-06, global_step: 9580, interval_runtime: 0.7981, interval_samples_per_second: 50.118, interval_steps_per_second: 6.265, epoch: 14.1926\r\n",
      "loss: 0.00300209, learning_rate: 8.7e-06, global_step: 9585, interval_runtime: 0.7935, interval_samples_per_second: 50.408, interval_steps_per_second: 6.301, epoch: 14.2\r\n",
      "loss: 0.00922409, learning_rate: 8.689e-06, global_step: 9590, interval_runtime: 0.7832, interval_samples_per_second: 51.073, interval_steps_per_second: 6.384, epoch: 14.2074\r\n",
      "loss: 0.00740267, learning_rate: 8.678e-06, global_step: 9595, interval_runtime: 0.8157, interval_samples_per_second: 49.039, interval_steps_per_second: 6.13, epoch: 14.2148\r\n",
      "loss: 0.00448548, learning_rate: 8.667e-06, global_step: 9600, interval_runtime: 0.8433, interval_samples_per_second: 47.434, interval_steps_per_second: 5.929, epoch: 14.2222\r\n",
      "loss: 0.0098923, learning_rate: 8.656e-06, global_step: 9605, interval_runtime: 0.7861, interval_samples_per_second: 50.882, interval_steps_per_second: 6.36, epoch: 14.2296\r\n",
      "loss: 0.00352644, learning_rate: 8.644e-06, global_step: 9610, interval_runtime: 0.9918, interval_samples_per_second: 40.33, interval_steps_per_second: 5.041, epoch: 14.237\r\n",
      "loss: 0.00217277, learning_rate: 8.633e-06, global_step: 9615, interval_runtime: 0.876, interval_samples_per_second: 45.662, interval_steps_per_second: 5.708, epoch: 14.2444\r\n",
      "loss: 0.01453037, learning_rate: 8.622e-06, global_step: 9620, interval_runtime: 0.9919, interval_samples_per_second: 40.325, interval_steps_per_second: 5.041, epoch: 14.2519\r\n",
      "loss: 0.00914052, learning_rate: 8.611e-06, global_step: 9625, interval_runtime: 0.87, interval_samples_per_second: 45.975, interval_steps_per_second: 5.747, epoch: 14.2593\r\n",
      "loss: 0.01123505, learning_rate: 8.6e-06, global_step: 9630, interval_runtime: 0.8299, interval_samples_per_second: 48.201, interval_steps_per_second: 6.025, epoch: 14.2667\r\n",
      "loss: 0.0089045, learning_rate: 8.589e-06, global_step: 9635, interval_runtime: 0.8176, interval_samples_per_second: 48.923, interval_steps_per_second: 6.115, epoch: 14.2741\r\n",
      "loss: 0.01735042, learning_rate: 8.578e-06, global_step: 9640, interval_runtime: 0.935, interval_samples_per_second: 42.781, interval_steps_per_second: 5.348, epoch: 14.2815\r\n",
      "loss: 0.00216356, learning_rate: 8.567e-06, global_step: 9645, interval_runtime: 0.7401, interval_samples_per_second: 54.046, interval_steps_per_second: 6.756, epoch: 14.2889\r\n",
      "loss: 0.00525225, learning_rate: 8.556e-06, global_step: 9650, interval_runtime: 0.9841, interval_samples_per_second: 40.648, interval_steps_per_second: 5.081, epoch: 14.2963\r\n",
      "loss: 0.00280528, learning_rate: 8.544e-06, global_step: 9655, interval_runtime: 0.8128, interval_samples_per_second: 49.215, interval_steps_per_second: 6.152, epoch: 14.3037\r\n",
      "loss: 0.02072235, learning_rate: 8.533e-06, global_step: 9660, interval_runtime: 0.7975, interval_samples_per_second: 50.154, interval_steps_per_second: 6.269, epoch: 14.3111\r\n",
      "loss: 0.00994317, learning_rate: 8.522e-06, global_step: 9665, interval_runtime: 0.7689, interval_samples_per_second: 52.02, interval_steps_per_second: 6.503, epoch: 14.3185\r\n",
      "loss: 0.00155491, learning_rate: 8.511e-06, global_step: 9670, interval_runtime: 0.7877, interval_samples_per_second: 50.781, interval_steps_per_second: 6.348, epoch: 14.3259\r\n",
      "loss: 0.01186635, learning_rate: 8.5e-06, global_step: 9675, interval_runtime: 0.9327, interval_samples_per_second: 42.885, interval_steps_per_second: 5.361, epoch: 14.3333\r\n",
      "loss: 0.00602966, learning_rate: 8.489e-06, global_step: 9680, interval_runtime: 0.8814, interval_samples_per_second: 45.382, interval_steps_per_second: 5.673, epoch: 14.3407\r\n",
      "loss: 0.00601149, learning_rate: 8.478e-06, global_step: 9685, interval_runtime: 0.8662, interval_samples_per_second: 46.181, interval_steps_per_second: 5.773, epoch: 14.3481\r\n",
      "loss: 0.00610192, learning_rate: 8.467e-06, global_step: 9690, interval_runtime: 0.7919, interval_samples_per_second: 50.509, interval_steps_per_second: 6.314, epoch: 14.3556\r\n",
      "loss: 0.02220666, learning_rate: 8.456e-06, global_step: 9695, interval_runtime: 0.8149, interval_samples_per_second: 49.085, interval_steps_per_second: 6.136, epoch: 14.363\r\n",
      "loss: 0.0073956, learning_rate: 8.444e-06, global_step: 9700, interval_runtime: 0.8887, interval_samples_per_second: 45.01, interval_steps_per_second: 5.626, epoch: 14.3704\r\n",
      "loss: 0.0104296, learning_rate: 8.433e-06, global_step: 9705, interval_runtime: 0.8181, interval_samples_per_second: 48.891, interval_steps_per_second: 6.111, epoch: 14.3778\r\n",
      "loss: 0.00798396, learning_rate: 8.422e-06, global_step: 9710, interval_runtime: 0.8718, interval_samples_per_second: 45.881, interval_steps_per_second: 5.735, epoch: 14.3852\r\n",
      "loss: 0.01441643, learning_rate: 8.411e-06, global_step: 9715, interval_runtime: 0.8572, interval_samples_per_second: 46.663, interval_steps_per_second: 5.833, epoch: 14.3926\r\n",
      "loss: 0.00322293, learning_rate: 8.4e-06, global_step: 9720, interval_runtime: 0.9853, interval_samples_per_second: 40.596, interval_steps_per_second: 5.075, epoch: 14.4\r\n",
      "loss: 0.00234913, learning_rate: 8.389e-06, global_step: 9725, interval_runtime: 0.8829, interval_samples_per_second: 45.306, interval_steps_per_second: 5.663, epoch: 14.4074\r\n",
      "loss: 0.02090344, learning_rate: 8.378e-06, global_step: 9730, interval_runtime: 0.9586, interval_samples_per_second: 41.727, interval_steps_per_second: 5.216, epoch: 14.4148\r\n",
      "loss: 0.00740875, learning_rate: 8.367e-06, global_step: 9735, interval_runtime: 0.7527, interval_samples_per_second: 53.142, interval_steps_per_second: 6.643, epoch: 14.4222\r\n",
      "loss: 0.01388358, learning_rate: 8.356e-06, global_step: 9740, interval_runtime: 0.868, interval_samples_per_second: 46.085, interval_steps_per_second: 5.761, epoch: 14.4296\r\n",
      "loss: 0.01405805, learning_rate: 8.344e-06, global_step: 9745, interval_runtime: 0.8282, interval_samples_per_second: 48.3, interval_steps_per_second: 6.037, epoch: 14.437\r\n",
      "loss: 0.00192266, learning_rate: 8.333e-06, global_step: 9750, interval_runtime: 0.7568, interval_samples_per_second: 52.856, interval_steps_per_second: 6.607, epoch: 14.4444\r\n",
      "loss: 0.00217191, learning_rate: 8.322e-06, global_step: 9755, interval_runtime: 0.8054, interval_samples_per_second: 49.668, interval_steps_per_second: 6.208, epoch: 14.4519\r\n",
      "loss: 0.01002773, learning_rate: 8.311e-06, global_step: 9760, interval_runtime: 0.8094, interval_samples_per_second: 49.421, interval_steps_per_second: 6.178, epoch: 14.4593\r\n",
      "loss: 0.01801495, learning_rate: 8.3e-06, global_step: 9765, interval_runtime: 0.7729, interval_samples_per_second: 51.755, interval_steps_per_second: 6.469, epoch: 14.4667\r\n",
      "loss: 0.01087337, learning_rate: 8.289e-06, global_step: 9770, interval_runtime: 0.9225, interval_samples_per_second: 43.359, interval_steps_per_second: 5.42, epoch: 14.4741\r\n",
      "loss: 0.00351918, learning_rate: 8.278e-06, global_step: 9775, interval_runtime: 0.8272, interval_samples_per_second: 48.354, interval_steps_per_second: 6.044, epoch: 14.4815\r\n",
      "loss: 0.00331002, learning_rate: 8.267e-06, global_step: 9780, interval_runtime: 1.0019, interval_samples_per_second: 39.923, interval_steps_per_second: 4.99, epoch: 14.4889\r\n",
      "loss: 0.01518051, learning_rate: 8.256e-06, global_step: 9785, interval_runtime: 0.7597, interval_samples_per_second: 52.65, interval_steps_per_second: 6.581, epoch: 14.4963\r\n",
      "loss: 0.00180893, learning_rate: 8.244e-06, global_step: 9790, interval_runtime: 0.7565, interval_samples_per_second: 52.875, interval_steps_per_second: 6.609, epoch: 14.5037\r\n",
      "loss: 0.01281444, learning_rate: 8.233e-06, global_step: 9795, interval_runtime: 0.925, interval_samples_per_second: 43.244, interval_steps_per_second: 5.405, epoch: 14.5111\r\n",
      "loss: 0.00561449, learning_rate: 8.222e-06, global_step: 9800, interval_runtime: 0.9344, interval_samples_per_second: 42.808, interval_steps_per_second: 5.351, epoch: 14.5185\r\n",
      "loss: 0.02821012, learning_rate: 8.211e-06, global_step: 9805, interval_runtime: 0.7017, interval_samples_per_second: 57.0, interval_steps_per_second: 7.125, epoch: 14.5259\r\n",
      "loss: 0.00266305, learning_rate: 8.2e-06, global_step: 9810, interval_runtime: 0.6721, interval_samples_per_second: 59.513, interval_steps_per_second: 7.439, epoch: 14.5333\r\n",
      "loss: 0.01196999, learning_rate: 8.189e-06, global_step: 9815, interval_runtime: 0.8537, interval_samples_per_second: 46.854, interval_steps_per_second: 5.857, epoch: 14.5407\r\n",
      "loss: 0.00879579, learning_rate: 8.178e-06, global_step: 9820, interval_runtime: 0.7349, interval_samples_per_second: 54.433, interval_steps_per_second: 6.804, epoch: 14.5481\r\n",
      "loss: 0.01882474, learning_rate: 8.167e-06, global_step: 9825, interval_runtime: 0.8881, interval_samples_per_second: 45.042, interval_steps_per_second: 5.63, epoch: 14.5556\r\n",
      "loss: 0.00322928, learning_rate: 8.156e-06, global_step: 9830, interval_runtime: 0.8129, interval_samples_per_second: 49.209, interval_steps_per_second: 6.151, epoch: 14.563\r\n",
      "loss: 0.01444923, learning_rate: 8.144e-06, global_step: 9835, interval_runtime: 0.9259, interval_samples_per_second: 43.203, interval_steps_per_second: 5.4, epoch: 14.5704\r\n",
      "loss: 0.00638734, learning_rate: 8.133e-06, global_step: 9840, interval_runtime: 0.7671, interval_samples_per_second: 52.144, interval_steps_per_second: 6.518, epoch: 14.5778\r\n",
      "loss: 0.00185792, learning_rate: 8.122e-06, global_step: 9845, interval_runtime: 0.6716, interval_samples_per_second: 59.556, interval_steps_per_second: 7.445, epoch: 14.5852\r\n",
      "loss: 0.00764406, learning_rate: 8.111e-06, global_step: 9850, interval_runtime: 0.774, interval_samples_per_second: 51.678, interval_steps_per_second: 6.46, epoch: 14.5926\r\n",
      "loss: 0.0077825, learning_rate: 8.1e-06, global_step: 9855, interval_runtime: 1.0079, interval_samples_per_second: 39.686, interval_steps_per_second: 4.961, epoch: 14.6\r\n",
      "loss: 0.00619207, learning_rate: 8.089e-06, global_step: 9860, interval_runtime: 0.9295, interval_samples_per_second: 43.036, interval_steps_per_second: 5.38, epoch: 14.6074\r\n",
      "loss: 0.00903098, learning_rate: 8.078e-06, global_step: 9865, interval_runtime: 0.738, interval_samples_per_second: 54.202, interval_steps_per_second: 6.775, epoch: 14.6148\r\n",
      "loss: 0.00187481, learning_rate: 8.067e-06, global_step: 9870, interval_runtime: 0.8192, interval_samples_per_second: 48.829, interval_steps_per_second: 6.104, epoch: 14.6222\r\n",
      "loss: 0.01208312, learning_rate: 8.056e-06, global_step: 9875, interval_runtime: 0.8088, interval_samples_per_second: 49.456, interval_steps_per_second: 6.182, epoch: 14.6296\r\n",
      "loss: 0.00758397, learning_rate: 8.044e-06, global_step: 9880, interval_runtime: 0.9344, interval_samples_per_second: 42.806, interval_steps_per_second: 5.351, epoch: 14.637\r\n",
      "loss: 0.01415365, learning_rate: 8.033e-06, global_step: 9885, interval_runtime: 0.9975, interval_samples_per_second: 40.099, interval_steps_per_second: 5.012, epoch: 14.6444\r\n",
      "loss: 0.02157919, learning_rate: 8.022e-06, global_step: 9890, interval_runtime: 0.8197, interval_samples_per_second: 48.801, interval_steps_per_second: 6.1, epoch: 14.6519\r\n",
      "loss: 0.0028657, learning_rate: 8.011e-06, global_step: 9895, interval_runtime: 0.8914, interval_samples_per_second: 44.873, interval_steps_per_second: 5.609, epoch: 14.6593\r\n",
      "loss: 0.00959351, learning_rate: 8e-06, global_step: 9900, interval_runtime: 0.8519, interval_samples_per_second: 46.956, interval_steps_per_second: 5.87, epoch: 14.6667\r\n",
      "loss: 0.01548205, learning_rate: 7.989e-06, global_step: 9905, interval_runtime: 0.8371, interval_samples_per_second: 47.785, interval_steps_per_second: 5.973, epoch: 14.6741\r\n",
      "loss: 0.00263801, learning_rate: 7.978e-06, global_step: 9910, interval_runtime: 0.7414, interval_samples_per_second: 53.953, interval_steps_per_second: 6.744, epoch: 14.6815\r\n",
      "loss: 0.00226649, learning_rate: 7.967e-06, global_step: 9915, interval_runtime: 0.763, interval_samples_per_second: 52.427, interval_steps_per_second: 6.553, epoch: 14.6889\r\n",
      "loss: 0.02319047, learning_rate: 7.956e-06, global_step: 9920, interval_runtime: 0.7932, interval_samples_per_second: 50.43, interval_steps_per_second: 6.304, epoch: 14.6963\r\n",
      "loss: 0.03236535, learning_rate: 7.944e-06, global_step: 9925, interval_runtime: 0.9006, interval_samples_per_second: 44.416, interval_steps_per_second: 5.552, epoch: 14.7037\r\n",
      "loss: 0.00474797, learning_rate: 7.933e-06, global_step: 9930, interval_runtime: 0.8405, interval_samples_per_second: 47.593, interval_steps_per_second: 5.949, epoch: 14.7111\r\n",
      "loss: 0.00883768, learning_rate: 7.922e-06, global_step: 9935, interval_runtime: 0.8976, interval_samples_per_second: 44.566, interval_steps_per_second: 5.571, epoch: 14.7185\r\n",
      "loss: 0.00271869, learning_rate: 7.911e-06, global_step: 9940, interval_runtime: 0.9531, interval_samples_per_second: 41.968, interval_steps_per_second: 5.246, epoch: 14.7259\r\n",
      "loss: 0.00893924, learning_rate: 7.9e-06, global_step: 9945, interval_runtime: 0.8362, interval_samples_per_second: 47.836, interval_steps_per_second: 5.979, epoch: 14.7333\r\n",
      "loss: 0.00424991, learning_rate: 7.889e-06, global_step: 9950, interval_runtime: 0.8464, interval_samples_per_second: 47.256, interval_steps_per_second: 5.907, epoch: 14.7407\r\n",
      "loss: 0.00225142, learning_rate: 7.878e-06, global_step: 9955, interval_runtime: 0.8484, interval_samples_per_second: 47.147, interval_steps_per_second: 5.893, epoch: 14.7481\r\n",
      "loss: 0.01214909, learning_rate: 7.867e-06, global_step: 9960, interval_runtime: 0.8174, interval_samples_per_second: 48.937, interval_steps_per_second: 6.117, epoch: 14.7556\r\n",
      "loss: 0.00170396, learning_rate: 7.856e-06, global_step: 9965, interval_runtime: 0.7735, interval_samples_per_second: 51.711, interval_steps_per_second: 6.464, epoch: 14.763\r\n",
      "loss: 0.00270874, learning_rate: 7.844e-06, global_step: 9970, interval_runtime: 0.7231, interval_samples_per_second: 55.317, interval_steps_per_second: 6.915, epoch: 14.7704\r\n",
      "loss: 0.00603411, learning_rate: 7.833e-06, global_step: 9975, interval_runtime: 0.8527, interval_samples_per_second: 46.908, interval_steps_per_second: 5.864, epoch: 14.7778\r\n",
      "loss: 0.00992553, learning_rate: 7.822e-06, global_step: 9980, interval_runtime: 0.8634, interval_samples_per_second: 46.329, interval_steps_per_second: 5.791, epoch: 14.7852\r\n",
      "loss: 0.00473589, learning_rate: 7.811e-06, global_step: 9985, interval_runtime: 0.7641, interval_samples_per_second: 52.35, interval_steps_per_second: 6.544, epoch: 14.7926\r\n",
      "loss: 0.00964502, learning_rate: 7.8e-06, global_step: 9990, interval_runtime: 0.9679, interval_samples_per_second: 41.326, interval_steps_per_second: 5.166, epoch: 14.8\r\n",
      "loss: 0.00273633, learning_rate: 7.789e-06, global_step: 9995, interval_runtime: 0.7371, interval_samples_per_second: 54.269, interval_steps_per_second: 6.784, epoch: 14.8074\r\n",
      "loss: 0.01804546, learning_rate: 7.778e-06, global_step: 10000, interval_runtime: 0.8091, interval_samples_per_second: 49.436, interval_steps_per_second: 6.18, epoch: 14.8148\r\n",
      "loss: 0.01243624, learning_rate: 7.767e-06, global_step: 10005, interval_runtime: 0.8088, interval_samples_per_second: 49.458, interval_steps_per_second: 6.182, epoch: 14.8222\r\n",
      "loss: 0.02349031, learning_rate: 7.756e-06, global_step: 10010, interval_runtime: 0.7737, interval_samples_per_second: 51.702, interval_steps_per_second: 6.463, epoch: 14.8296\r\n",
      "loss: 0.00142151, learning_rate: 7.744e-06, global_step: 10015, interval_runtime: 0.812, interval_samples_per_second: 49.263, interval_steps_per_second: 6.158, epoch: 14.837\r\n",
      "loss: 0.00998153, learning_rate: 7.733e-06, global_step: 10020, interval_runtime: 0.8204, interval_samples_per_second: 48.756, interval_steps_per_second: 6.095, epoch: 14.8444\r\n",
      "loss: 0.0181794, learning_rate: 7.722e-06, global_step: 10025, interval_runtime: 0.9299, interval_samples_per_second: 43.015, interval_steps_per_second: 5.377, epoch: 14.8519\r\n",
      "loss: 0.01698524, learning_rate: 7.711e-06, global_step: 10030, interval_runtime: 0.889, interval_samples_per_second: 44.997, interval_steps_per_second: 5.625, epoch: 14.8593\r\n",
      "loss: 0.00265484, learning_rate: 7.7e-06, global_step: 10035, interval_runtime: 0.9044, interval_samples_per_second: 44.229, interval_steps_per_second: 5.529, epoch: 14.8667\r\n",
      "loss: 0.00216226, learning_rate: 7.689e-06, global_step: 10040, interval_runtime: 0.8398, interval_samples_per_second: 47.63, interval_steps_per_second: 5.954, epoch: 14.8741\r\n",
      "loss: 0.02301062, learning_rate: 7.678e-06, global_step: 10045, interval_runtime: 0.7627, interval_samples_per_second: 52.444, interval_steps_per_second: 6.555, epoch: 14.8815\r\n",
      "loss: 0.01496681, learning_rate: 7.667e-06, global_step: 10050, interval_runtime: 0.7634, interval_samples_per_second: 52.396, interval_steps_per_second: 6.55, epoch: 14.8889\r\n",
      "loss: 0.01664148, learning_rate: 7.656e-06, global_step: 10055, interval_runtime: 0.8076, interval_samples_per_second: 49.531, interval_steps_per_second: 6.191, epoch: 14.8963\r\n",
      "loss: 0.01339644, learning_rate: 7.644e-06, global_step: 10060, interval_runtime: 0.8343, interval_samples_per_second: 47.943, interval_steps_per_second: 5.993, epoch: 14.9037\r\n",
      "loss: 0.00909973, learning_rate: 7.633e-06, global_step: 10065, interval_runtime: 0.7869, interval_samples_per_second: 50.831, interval_steps_per_second: 6.354, epoch: 14.9111\r\n",
      "loss: 0.00881567, learning_rate: 7.622e-06, global_step: 10070, interval_runtime: 0.8735, interval_samples_per_second: 45.795, interval_steps_per_second: 5.724, epoch: 14.9185\r\n",
      "loss: 0.0016194, learning_rate: 7.611e-06, global_step: 10075, interval_runtime: 0.766, interval_samples_per_second: 52.219, interval_steps_per_second: 6.527, epoch: 14.9259\r\n",
      "loss: 0.00842628, learning_rate: 7.6e-06, global_step: 10080, interval_runtime: 0.9108, interval_samples_per_second: 43.918, interval_steps_per_second: 5.49, epoch: 14.9333\r\n",
      "loss: 0.01401903, learning_rate: 7.589e-06, global_step: 10085, interval_runtime: 0.7936, interval_samples_per_second: 50.401, interval_steps_per_second: 6.3, epoch: 14.9407\r\n",
      "loss: 0.03313612, learning_rate: 7.578e-06, global_step: 10090, interval_runtime: 0.9648, interval_samples_per_second: 41.459, interval_steps_per_second: 5.182, epoch: 14.9481\r\n",
      "loss: 0.02574978, learning_rate: 7.567e-06, global_step: 10095, interval_runtime: 0.8584, interval_samples_per_second: 46.598, interval_steps_per_second: 5.825, epoch: 14.9556\r\n",
      "loss: 0.01886568, learning_rate: 7.556e-06, global_step: 10100, interval_runtime: 0.9322, interval_samples_per_second: 42.911, interval_steps_per_second: 5.364, epoch: 14.963\r\n",
      "loss: 0.00632566, learning_rate: 7.544e-06, global_step: 10105, interval_runtime: 0.7387, interval_samples_per_second: 54.149, interval_steps_per_second: 6.769, epoch: 14.9704\r\n",
      "loss: 0.00428533, learning_rate: 7.533e-06, global_step: 10110, interval_runtime: 0.758, interval_samples_per_second: 52.769, interval_steps_per_second: 6.596, epoch: 14.9778\r\n",
      "loss: 0.01232752, learning_rate: 7.522e-06, global_step: 10115, interval_runtime: 0.7795, interval_samples_per_second: 51.316, interval_steps_per_second: 6.414, epoch: 14.9852\r\n",
      "loss: 0.00322267, learning_rate: 7.511e-06, global_step: 10120, interval_runtime: 0.7673, interval_samples_per_second: 52.129, interval_steps_per_second: 6.516, epoch: 14.9926\r\n",
      "loss: 0.00997844, learning_rate: 7.5e-06, global_step: 10125, interval_runtime: 0.7282, interval_samples_per_second: 54.934, interval_steps_per_second: 6.867, epoch: 15.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:12:32,066] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:12:32,068] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:12:32,070] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:12:32,072] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:12:32,074] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.7272669076919556, eval_micro_f1_score: 0.568191216607394, eval_macro_f1_score: 0.46464642618054175, eval_runtime: 13.4499, eval_samples_per_second: 140.967, eval_steps_per_second: 17.621, epoch: 15.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:12:45,521] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-10125\r\n",
      "[2023-01-10 11:12:45,524] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:12:48,903] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-10125/tokenizer_config.json\r\n",
      "[2023-01-10 11:12:48,907] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-10125/special_tokens_map.json\r\n",
      "[2023-01-10 11:12:55,553] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-6750] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00321779, learning_rate: 7.489e-06, global_step: 10130, interval_runtime: 25.073, interval_samples_per_second: 1.595, interval_steps_per_second: 0.199, epoch: 15.0074\r\n",
      "loss: 0.01209731, learning_rate: 7.478e-06, global_step: 10135, interval_runtime: 0.8141, interval_samples_per_second: 49.132, interval_steps_per_second: 6.141, epoch: 15.0148\r\n",
      "loss: 0.00391338, learning_rate: 7.467e-06, global_step: 10140, interval_runtime: 0.8359, interval_samples_per_second: 47.85, interval_steps_per_second: 5.981, epoch: 15.0222\r\n",
      "loss: 0.00219373, learning_rate: 7.456e-06, global_step: 10145, interval_runtime: 0.713, interval_samples_per_second: 56.101, interval_steps_per_second: 7.013, epoch: 15.0296\r\n",
      "loss: 0.00922036, learning_rate: 7.444e-06, global_step: 10150, interval_runtime: 0.8179, interval_samples_per_second: 48.906, interval_steps_per_second: 6.113, epoch: 15.037\r\n",
      "loss: 0.00409429, learning_rate: 7.433e-06, global_step: 10155, interval_runtime: 0.6847, interval_samples_per_second: 58.419, interval_steps_per_second: 7.302, epoch: 15.0444\r\n",
      "loss: 0.00551504, learning_rate: 7.422e-06, global_step: 10160, interval_runtime: 0.7624, interval_samples_per_second: 52.465, interval_steps_per_second: 6.558, epoch: 15.0519\r\n",
      "loss: 0.00160371, learning_rate: 7.411e-06, global_step: 10165, interval_runtime: 0.7824, interval_samples_per_second: 51.125, interval_steps_per_second: 6.391, epoch: 15.0593\r\n",
      "loss: 0.0085702, learning_rate: 7.4e-06, global_step: 10170, interval_runtime: 0.8167, interval_samples_per_second: 48.979, interval_steps_per_second: 6.122, epoch: 15.0667\r\n",
      "loss: 0.01758427, learning_rate: 7.389e-06, global_step: 10175, interval_runtime: 0.8403, interval_samples_per_second: 47.603, interval_steps_per_second: 5.95, epoch: 15.0741\r\n",
      "loss: 0.00704211, learning_rate: 7.378e-06, global_step: 10180, interval_runtime: 0.7821, interval_samples_per_second: 51.146, interval_steps_per_second: 6.393, epoch: 15.0815\r\n",
      "loss: 0.00199641, learning_rate: 7.367e-06, global_step: 10185, interval_runtime: 0.7873, interval_samples_per_second: 50.809, interval_steps_per_second: 6.351, epoch: 15.0889\r\n",
      "loss: 0.00696806, learning_rate: 7.356e-06, global_step: 10190, interval_runtime: 0.7512, interval_samples_per_second: 53.247, interval_steps_per_second: 6.656, epoch: 15.0963\r\n",
      "loss: 0.00608289, learning_rate: 7.344e-06, global_step: 10195, interval_runtime: 0.83, interval_samples_per_second: 48.194, interval_steps_per_second: 6.024, epoch: 15.1037\r\n",
      "loss: 0.00414986, learning_rate: 7.333e-06, global_step: 10200, interval_runtime: 0.8171, interval_samples_per_second: 48.956, interval_steps_per_second: 6.12, epoch: 15.1111\r\n",
      "loss: 0.00119829, learning_rate: 7.322e-06, global_step: 10205, interval_runtime: 0.7206, interval_samples_per_second: 55.51, interval_steps_per_second: 6.939, epoch: 15.1185\r\n",
      "loss: 0.00183993, learning_rate: 7.311e-06, global_step: 10210, interval_runtime: 0.9173, interval_samples_per_second: 43.607, interval_steps_per_second: 5.451, epoch: 15.1259\r\n",
      "loss: 0.00572175, learning_rate: 7.3e-06, global_step: 10215, interval_runtime: 0.7784, interval_samples_per_second: 51.388, interval_steps_per_second: 6.423, epoch: 15.1333\r\n",
      "loss: 0.00742614, learning_rate: 7.289e-06, global_step: 10220, interval_runtime: 0.931, interval_samples_per_second: 42.963, interval_steps_per_second: 5.37, epoch: 15.1407\r\n",
      "loss: 0.01796212, learning_rate: 7.278e-06, global_step: 10225, interval_runtime: 0.8947, interval_samples_per_second: 44.707, interval_steps_per_second: 5.588, epoch: 15.1481\r\n",
      "loss: 0.00294636, learning_rate: 7.267e-06, global_step: 10230, interval_runtime: 0.7559, interval_samples_per_second: 52.915, interval_steps_per_second: 6.614, epoch: 15.1556\r\n",
      "loss: 0.00515895, learning_rate: 7.256e-06, global_step: 10235, interval_runtime: 0.6643, interval_samples_per_second: 60.215, interval_steps_per_second: 7.527, epoch: 15.163\r\n",
      "loss: 0.00180208, learning_rate: 7.244e-06, global_step: 10240, interval_runtime: 0.7355, interval_samples_per_second: 54.385, interval_steps_per_second: 6.798, epoch: 15.1704\r\n",
      "loss: 0.00570304, learning_rate: 7.233e-06, global_step: 10245, interval_runtime: 0.9191, interval_samples_per_second: 43.52, interval_steps_per_second: 5.44, epoch: 15.1778\r\n",
      "loss: 0.00181526, learning_rate: 7.222e-06, global_step: 10250, interval_runtime: 0.8355, interval_samples_per_second: 47.875, interval_steps_per_second: 5.984, epoch: 15.1852\r\n",
      "loss: 0.00668786, learning_rate: 7.211e-06, global_step: 10255, interval_runtime: 0.8641, interval_samples_per_second: 46.289, interval_steps_per_second: 5.786, epoch: 15.1926\r\n",
      "loss: 0.00194861, learning_rate: 7.2e-06, global_step: 10260, interval_runtime: 0.8885, interval_samples_per_second: 45.019, interval_steps_per_second: 5.627, epoch: 15.2\r\n",
      "loss: 0.01220838, learning_rate: 7.189e-06, global_step: 10265, interval_runtime: 0.8635, interval_samples_per_second: 46.322, interval_steps_per_second: 5.79, epoch: 15.2074\r\n",
      "loss: 0.01777759, learning_rate: 7.178e-06, global_step: 10270, interval_runtime: 0.7797, interval_samples_per_second: 51.3, interval_steps_per_second: 6.412, epoch: 15.2148\r\n",
      "loss: 0.0132032, learning_rate: 7.167e-06, global_step: 10275, interval_runtime: 0.9371, interval_samples_per_second: 42.686, interval_steps_per_second: 5.336, epoch: 15.2222\r\n",
      "loss: 0.01152438, learning_rate: 7.156e-06, global_step: 10280, interval_runtime: 0.9491, interval_samples_per_second: 42.146, interval_steps_per_second: 5.268, epoch: 15.2296\r\n",
      "loss: 0.0059619, learning_rate: 7.144e-06, global_step: 10285, interval_runtime: 1.0175, interval_samples_per_second: 39.312, interval_steps_per_second: 4.914, epoch: 15.237\r\n",
      "loss: 0.00216068, learning_rate: 7.133e-06, global_step: 10290, interval_runtime: 0.9377, interval_samples_per_second: 42.658, interval_steps_per_second: 5.332, epoch: 15.2444\r\n",
      "loss: 0.00203038, learning_rate: 7.122e-06, global_step: 10295, interval_runtime: 0.8593, interval_samples_per_second: 46.548, interval_steps_per_second: 5.818, epoch: 15.2519\r\n",
      "loss: 0.01954758, learning_rate: 7.111e-06, global_step: 10300, interval_runtime: 0.9514, interval_samples_per_second: 42.043, interval_steps_per_second: 5.255, epoch: 15.2593\r\n",
      "loss: 0.01042334, learning_rate: 7.1e-06, global_step: 10305, interval_runtime: 0.8941, interval_samples_per_second: 44.74, interval_steps_per_second: 5.592, epoch: 15.2667\r\n",
      "loss: 0.00575058, learning_rate: 7.089e-06, global_step: 10310, interval_runtime: 0.8206, interval_samples_per_second: 48.747, interval_steps_per_second: 6.093, epoch: 15.2741\r\n",
      "loss: 0.00314289, learning_rate: 7.078e-06, global_step: 10315, interval_runtime: 0.913, interval_samples_per_second: 43.809, interval_steps_per_second: 5.476, epoch: 15.2815\r\n",
      "loss: 0.00154941, learning_rate: 7.067e-06, global_step: 10320, interval_runtime: 0.751, interval_samples_per_second: 53.259, interval_steps_per_second: 6.657, epoch: 15.2889\r\n",
      "loss: 0.00219419, learning_rate: 7.056e-06, global_step: 10325, interval_runtime: 0.937, interval_samples_per_second: 42.688, interval_steps_per_second: 5.336, epoch: 15.2963\r\n",
      "loss: 0.01028082, learning_rate: 7.044e-06, global_step: 10330, interval_runtime: 0.8988, interval_samples_per_second: 44.505, interval_steps_per_second: 5.563, epoch: 15.3037\r\n",
      "loss: 0.00399401, learning_rate: 7.033e-06, global_step: 10335, interval_runtime: 0.9174, interval_samples_per_second: 43.603, interval_steps_per_second: 5.45, epoch: 15.3111\r\n",
      "loss: 0.01069651, learning_rate: 7.022e-06, global_step: 10340, interval_runtime: 0.7883, interval_samples_per_second: 50.74, interval_steps_per_second: 6.343, epoch: 15.3185\r\n",
      "loss: 0.01062321, learning_rate: 7.011e-06, global_step: 10345, interval_runtime: 0.803, interval_samples_per_second: 49.814, interval_steps_per_second: 6.227, epoch: 15.3259\r\n",
      "loss: 0.00970568, learning_rate: 7e-06, global_step: 10350, interval_runtime: 0.8588, interval_samples_per_second: 46.575, interval_steps_per_second: 5.822, epoch: 15.3333\r\n",
      "loss: 0.00396275, learning_rate: 6.989e-06, global_step: 10355, interval_runtime: 0.8528, interval_samples_per_second: 46.903, interval_steps_per_second: 5.863, epoch: 15.3407\r\n",
      "loss: 0.01058005, learning_rate: 6.978e-06, global_step: 10360, interval_runtime: 0.8579, interval_samples_per_second: 46.624, interval_steps_per_second: 5.828, epoch: 15.3481\r\n",
      "loss: 0.02155385, learning_rate: 6.967e-06, global_step: 10365, interval_runtime: 0.8362, interval_samples_per_second: 47.836, interval_steps_per_second: 5.979, epoch: 15.3556\r\n",
      "loss: 0.01152508, learning_rate: 6.956e-06, global_step: 10370, interval_runtime: 0.9195, interval_samples_per_second: 43.5, interval_steps_per_second: 5.437, epoch: 15.363\r\n",
      "loss: 0.00184806, learning_rate: 6.944e-06, global_step: 10375, interval_runtime: 0.9143, interval_samples_per_second: 43.751, interval_steps_per_second: 5.469, epoch: 15.3704\r\n",
      "loss: 0.00714565, learning_rate: 6.933e-06, global_step: 10380, interval_runtime: 0.9206, interval_samples_per_second: 43.449, interval_steps_per_second: 5.431, epoch: 15.3778\r\n",
      "loss: 0.00544395, learning_rate: 6.922e-06, global_step: 10385, interval_runtime: 0.8181, interval_samples_per_second: 48.895, interval_steps_per_second: 6.112, epoch: 15.3852\r\n",
      "loss: 0.0111765, learning_rate: 6.911e-06, global_step: 10390, interval_runtime: 0.8965, interval_samples_per_second: 44.618, interval_steps_per_second: 5.577, epoch: 15.3926\r\n",
      "loss: 0.0037896, learning_rate: 6.9e-06, global_step: 10395, interval_runtime: 0.8289, interval_samples_per_second: 48.259, interval_steps_per_second: 6.032, epoch: 15.4\r\n",
      "loss: 0.01026378, learning_rate: 6.889e-06, global_step: 10400, interval_runtime: 0.8814, interval_samples_per_second: 45.382, interval_steps_per_second: 5.673, epoch: 15.4074\r\n",
      "loss: 0.00354033, learning_rate: 6.878e-06, global_step: 10405, interval_runtime: 0.7335, interval_samples_per_second: 54.529, interval_steps_per_second: 6.816, epoch: 15.4148\r\n",
      "loss: 0.01034648, learning_rate: 6.867e-06, global_step: 10410, interval_runtime: 0.9411, interval_samples_per_second: 42.504, interval_steps_per_second: 5.313, epoch: 15.4222\r\n",
      "loss: 0.00725097, learning_rate: 6.856e-06, global_step: 10415, interval_runtime: 0.8247, interval_samples_per_second: 48.504, interval_steps_per_second: 6.063, epoch: 15.4296\r\n",
      "loss: 0.00749621, learning_rate: 6.844e-06, global_step: 10420, interval_runtime: 0.7516, interval_samples_per_second: 53.222, interval_steps_per_second: 6.653, epoch: 15.437\r\n",
      "loss: 0.016989, learning_rate: 6.833e-06, global_step: 10425, interval_runtime: 0.868, interval_samples_per_second: 46.083, interval_steps_per_second: 5.76, epoch: 15.4444\r\n",
      "loss: 0.01245574, learning_rate: 6.822e-06, global_step: 10430, interval_runtime: 0.9011, interval_samples_per_second: 44.388, interval_steps_per_second: 5.549, epoch: 15.4519\r\n",
      "loss: 0.00172106, learning_rate: 6.811e-06, global_step: 10435, interval_runtime: 0.8195, interval_samples_per_second: 48.808, interval_steps_per_second: 6.101, epoch: 15.4593\r\n",
      "loss: 0.00152657, learning_rate: 6.8e-06, global_step: 10440, interval_runtime: 0.963, interval_samples_per_second: 41.535, interval_steps_per_second: 5.192, epoch: 15.4667\r\n",
      "loss: 0.00481713, learning_rate: 6.789e-06, global_step: 10445, interval_runtime: 0.7842, interval_samples_per_second: 51.007, interval_steps_per_second: 6.376, epoch: 15.4741\r\n",
      "loss: 0.00245556, learning_rate: 6.778e-06, global_step: 10450, interval_runtime: 0.9202, interval_samples_per_second: 43.468, interval_steps_per_second: 5.433, epoch: 15.4815\r\n",
      "loss: 0.00353619, learning_rate: 6.767e-06, global_step: 10455, interval_runtime: 0.8407, interval_samples_per_second: 47.581, interval_steps_per_second: 5.948, epoch: 15.4889\r\n",
      "loss: 0.01706222, learning_rate: 6.756e-06, global_step: 10460, interval_runtime: 0.864, interval_samples_per_second: 46.298, interval_steps_per_second: 5.787, epoch: 15.4963\r\n",
      "loss: 0.0100667, learning_rate: 6.744e-06, global_step: 10465, interval_runtime: 0.8342, interval_samples_per_second: 47.949, interval_steps_per_second: 5.994, epoch: 15.5037\r\n",
      "loss: 0.00434907, learning_rate: 6.733e-06, global_step: 10470, interval_runtime: 0.7829, interval_samples_per_second: 51.092, interval_steps_per_second: 6.386, epoch: 15.5111\r\n",
      "loss: 0.01912765, learning_rate: 6.722e-06, global_step: 10475, interval_runtime: 0.814, interval_samples_per_second: 49.14, interval_steps_per_second: 6.143, epoch: 15.5185\r\n",
      "loss: 0.01500041, learning_rate: 6.711e-06, global_step: 10480, interval_runtime: 0.7761, interval_samples_per_second: 51.54, interval_steps_per_second: 6.442, epoch: 15.5259\r\n",
      "loss: 0.00890531, learning_rate: 6.7e-06, global_step: 10485, interval_runtime: 0.9361, interval_samples_per_second: 42.728, interval_steps_per_second: 5.341, epoch: 15.5333\r\n",
      "loss: 0.01890146, learning_rate: 6.689e-06, global_step: 10490, interval_runtime: 0.7841, interval_samples_per_second: 51.015, interval_steps_per_second: 6.377, epoch: 15.5407\r\n",
      "loss: 0.00832866, learning_rate: 6.678e-06, global_step: 10495, interval_runtime: 0.8138, interval_samples_per_second: 49.154, interval_steps_per_second: 6.144, epoch: 15.5481\r\n",
      "loss: 0.00164368, learning_rate: 6.667e-06, global_step: 10500, interval_runtime: 0.8455, interval_samples_per_second: 47.309, interval_steps_per_second: 5.914, epoch: 15.5556\r\n",
      "loss: 0.00660434, learning_rate: 6.656e-06, global_step: 10505, interval_runtime: 0.8018, interval_samples_per_second: 49.89, interval_steps_per_second: 6.236, epoch: 15.563\r\n",
      "loss: 0.00719431, learning_rate: 6.644e-06, global_step: 10510, interval_runtime: 0.9376, interval_samples_per_second: 42.663, interval_steps_per_second: 5.333, epoch: 15.5704\r\n",
      "loss: 0.00527515, learning_rate: 6.633e-06, global_step: 10515, interval_runtime: 0.9919, interval_samples_per_second: 40.328, interval_steps_per_second: 5.041, epoch: 15.5778\r\n",
      "loss: 0.00500615, learning_rate: 6.622e-06, global_step: 10520, interval_runtime: 0.7549, interval_samples_per_second: 52.985, interval_steps_per_second: 6.623, epoch: 15.5852\r\n",
      "loss: 0.00476903, learning_rate: 6.611e-06, global_step: 10525, interval_runtime: 0.8376, interval_samples_per_second: 47.757, interval_steps_per_second: 5.97, epoch: 15.5926\r\n",
      "loss: 0.00221126, learning_rate: 6.6e-06, global_step: 10530, interval_runtime: 0.7617, interval_samples_per_second: 52.517, interval_steps_per_second: 6.565, epoch: 15.6\r\n",
      "loss: 0.01233198, learning_rate: 6.589e-06, global_step: 10535, interval_runtime: 0.7395, interval_samples_per_second: 54.092, interval_steps_per_second: 6.762, epoch: 15.6074\r\n",
      "loss: 0.02154436, learning_rate: 6.578e-06, global_step: 10540, interval_runtime: 0.8967, interval_samples_per_second: 44.608, interval_steps_per_second: 5.576, epoch: 15.6148\r\n",
      "loss: 0.01009658, learning_rate: 6.567e-06, global_step: 10545, interval_runtime: 0.9196, interval_samples_per_second: 43.496, interval_steps_per_second: 5.437, epoch: 15.6222\r\n",
      "loss: 0.0054032, learning_rate: 6.556e-06, global_step: 10550, interval_runtime: 0.9784, interval_samples_per_second: 40.883, interval_steps_per_second: 5.11, epoch: 15.6296\r\n",
      "loss: 0.02218047, learning_rate: 6.544e-06, global_step: 10555, interval_runtime: 0.7776, interval_samples_per_second: 51.44, interval_steps_per_second: 6.43, epoch: 15.637\r\n",
      "loss: 0.02290657, learning_rate: 6.533e-06, global_step: 10560, interval_runtime: 0.822, interval_samples_per_second: 48.661, interval_steps_per_second: 6.083, epoch: 15.6444\r\n",
      "loss: 0.01429548, learning_rate: 6.522e-06, global_step: 10565, interval_runtime: 0.7553, interval_samples_per_second: 52.957, interval_steps_per_second: 6.62, epoch: 15.6519\r\n",
      "loss: 0.00230874, learning_rate: 6.511e-06, global_step: 10570, interval_runtime: 0.7861, interval_samples_per_second: 50.887, interval_steps_per_second: 6.361, epoch: 15.6593\r\n",
      "loss: 0.00750715, learning_rate: 6.5e-06, global_step: 10575, interval_runtime: 0.7903, interval_samples_per_second: 50.614, interval_steps_per_second: 6.327, epoch: 15.6667\r\n",
      "loss: 0.00641393, learning_rate: 6.489e-06, global_step: 10580, interval_runtime: 0.804, interval_samples_per_second: 49.752, interval_steps_per_second: 6.219, epoch: 15.6741\r\n",
      "loss: 0.01556952, learning_rate: 6.478e-06, global_step: 10585, interval_runtime: 0.8223, interval_samples_per_second: 48.644, interval_steps_per_second: 6.081, epoch: 15.6815\r\n",
      "loss: 0.00301467, learning_rate: 6.467e-06, global_step: 10590, interval_runtime: 0.7811, interval_samples_per_second: 51.211, interval_steps_per_second: 6.401, epoch: 15.6889\r\n",
      "loss: 0.00830326, learning_rate: 6.456e-06, global_step: 10595, interval_runtime: 0.9212, interval_samples_per_second: 43.419, interval_steps_per_second: 5.427, epoch: 15.6963\r\n",
      "loss: 0.00334989, learning_rate: 6.444e-06, global_step: 10600, interval_runtime: 0.7681, interval_samples_per_second: 52.075, interval_steps_per_second: 6.509, epoch: 15.7037\r\n",
      "loss: 0.01414666, learning_rate: 6.433e-06, global_step: 10605, interval_runtime: 0.8434, interval_samples_per_second: 47.426, interval_steps_per_second: 5.928, epoch: 15.7111\r\n",
      "loss: 0.01371149, learning_rate: 6.422e-06, global_step: 10610, interval_runtime: 0.7319, interval_samples_per_second: 54.651, interval_steps_per_second: 6.831, epoch: 15.7185\r\n",
      "loss: 0.00665105, learning_rate: 6.411e-06, global_step: 10615, interval_runtime: 0.9385, interval_samples_per_second: 42.619, interval_steps_per_second: 5.327, epoch: 15.7259\r\n",
      "loss: 0.00497583, learning_rate: 6.4e-06, global_step: 10620, interval_runtime: 0.8129, interval_samples_per_second: 49.208, interval_steps_per_second: 6.151, epoch: 15.7333\r\n",
      "loss: 0.00177932, learning_rate: 6.389e-06, global_step: 10625, interval_runtime: 0.8439, interval_samples_per_second: 47.4, interval_steps_per_second: 5.925, epoch: 15.7407\r\n",
      "loss: 0.00573106, learning_rate: 6.378e-06, global_step: 10630, interval_runtime: 0.769, interval_samples_per_second: 52.017, interval_steps_per_second: 6.502, epoch: 15.7481\r\n",
      "loss: 0.01201831, learning_rate: 6.367e-06, global_step: 10635, interval_runtime: 0.9224, interval_samples_per_second: 43.365, interval_steps_per_second: 5.421, epoch: 15.7556\r\n",
      "loss: 0.01031892, learning_rate: 6.356e-06, global_step: 10640, interval_runtime: 0.8373, interval_samples_per_second: 47.771, interval_steps_per_second: 5.971, epoch: 15.763\r\n",
      "loss: 0.00165848, learning_rate: 6.344e-06, global_step: 10645, interval_runtime: 0.8223, interval_samples_per_second: 48.641, interval_steps_per_second: 6.08, epoch: 15.7704\r\n",
      "loss: 0.00136981, learning_rate: 6.333e-06, global_step: 10650, interval_runtime: 0.8553, interval_samples_per_second: 46.768, interval_steps_per_second: 5.846, epoch: 15.7778\r\n",
      "loss: 0.02470238, learning_rate: 6.322e-06, global_step: 10655, interval_runtime: 0.7166, interval_samples_per_second: 55.818, interval_steps_per_second: 6.977, epoch: 15.7852\r\n",
      "loss: 0.00384743, learning_rate: 6.311e-06, global_step: 10660, interval_runtime: 0.8031, interval_samples_per_second: 49.807, interval_steps_per_second: 6.226, epoch: 15.7926\r\n",
      "loss: 0.00286466, learning_rate: 6.3e-06, global_step: 10665, interval_runtime: 0.7653, interval_samples_per_second: 52.266, interval_steps_per_second: 6.533, epoch: 15.8\r\n",
      "loss: 0.00419926, learning_rate: 6.289e-06, global_step: 10670, interval_runtime: 0.8216, interval_samples_per_second: 48.687, interval_steps_per_second: 6.086, epoch: 15.8074\r\n",
      "loss: 0.00230164, learning_rate: 6.278e-06, global_step: 10675, interval_runtime: 0.7326, interval_samples_per_second: 54.602, interval_steps_per_second: 6.825, epoch: 15.8148\r\n",
      "loss: 0.02434713, learning_rate: 6.267e-06, global_step: 10680, interval_runtime: 0.8241, interval_samples_per_second: 48.539, interval_steps_per_second: 6.067, epoch: 15.8222\r\n",
      "loss: 0.00542933, learning_rate: 6.256e-06, global_step: 10685, interval_runtime: 0.8067, interval_samples_per_second: 49.585, interval_steps_per_second: 6.198, epoch: 15.8296\r\n",
      "loss: 0.01919692, learning_rate: 6.244e-06, global_step: 10690, interval_runtime: 0.9007, interval_samples_per_second: 44.412, interval_steps_per_second: 5.552, epoch: 15.837\r\n",
      "loss: 0.00642709, learning_rate: 6.233e-06, global_step: 10695, interval_runtime: 0.8447, interval_samples_per_second: 47.356, interval_steps_per_second: 5.919, epoch: 15.8444\r\n",
      "loss: 0.00765883, learning_rate: 6.222e-06, global_step: 10700, interval_runtime: 0.8162, interval_samples_per_second: 49.009, interval_steps_per_second: 6.126, epoch: 15.8519\r\n",
      "loss: 0.01366279, learning_rate: 6.211e-06, global_step: 10705, interval_runtime: 0.8051, interval_samples_per_second: 49.681, interval_steps_per_second: 6.21, epoch: 15.8593\r\n",
      "loss: 0.0078911, learning_rate: 6.2e-06, global_step: 10710, interval_runtime: 0.8305, interval_samples_per_second: 48.165, interval_steps_per_second: 6.021, epoch: 15.8667\r\n",
      "loss: 0.0145024, learning_rate: 6.189e-06, global_step: 10715, interval_runtime: 0.7402, interval_samples_per_second: 54.042, interval_steps_per_second: 6.755, epoch: 15.8741\r\n",
      "loss: 0.00212517, learning_rate: 6.178e-06, global_step: 10720, interval_runtime: 0.7019, interval_samples_per_second: 56.987, interval_steps_per_second: 7.123, epoch: 15.8815\r\n",
      "loss: 0.00129503, learning_rate: 6.167e-06, global_step: 10725, interval_runtime: 0.6971, interval_samples_per_second: 57.383, interval_steps_per_second: 7.173, epoch: 15.8889\r\n",
      "loss: 0.00141406, learning_rate: 6.156e-06, global_step: 10730, interval_runtime: 0.7964, interval_samples_per_second: 50.227, interval_steps_per_second: 6.278, epoch: 15.8963\r\n",
      "loss: 0.00988387, learning_rate: 6.144e-06, global_step: 10735, interval_runtime: 0.7564, interval_samples_per_second: 52.883, interval_steps_per_second: 6.61, epoch: 15.9037\r\n",
      "loss: 0.01073679, learning_rate: 6.133e-06, global_step: 10740, interval_runtime: 0.8499, interval_samples_per_second: 47.063, interval_steps_per_second: 5.883, epoch: 15.9111\r\n",
      "loss: 0.01035741, learning_rate: 6.122e-06, global_step: 10745, interval_runtime: 0.7493, interval_samples_per_second: 53.38, interval_steps_per_second: 6.672, epoch: 15.9185\r\n",
      "loss: 0.00400329, learning_rate: 6.111e-06, global_step: 10750, interval_runtime: 0.7602, interval_samples_per_second: 52.616, interval_steps_per_second: 6.577, epoch: 15.9259\r\n",
      "loss: 0.00677482, learning_rate: 6.1e-06, global_step: 10755, interval_runtime: 1.0058, interval_samples_per_second: 39.768, interval_steps_per_second: 4.971, epoch: 15.9333\r\n",
      "loss: 0.02203976, learning_rate: 6.089e-06, global_step: 10760, interval_runtime: 0.7921, interval_samples_per_second: 50.496, interval_steps_per_second: 6.312, epoch: 15.9407\r\n",
      "loss: 0.00927287, learning_rate: 6.078e-06, global_step: 10765, interval_runtime: 0.9751, interval_samples_per_second: 41.022, interval_steps_per_second: 5.128, epoch: 15.9481\r\n",
      "loss: 0.01003053, learning_rate: 6.067e-06, global_step: 10770, interval_runtime: 0.9032, interval_samples_per_second: 44.285, interval_steps_per_second: 5.536, epoch: 15.9556\r\n",
      "loss: 0.01115619, learning_rate: 6.056e-06, global_step: 10775, interval_runtime: 0.8832, interval_samples_per_second: 45.289, interval_steps_per_second: 5.661, epoch: 15.963\r\n",
      "loss: 0.01234475, learning_rate: 6.044e-06, global_step: 10780, interval_runtime: 0.7834, interval_samples_per_second: 51.061, interval_steps_per_second: 6.383, epoch: 15.9704\r\n",
      "loss: 0.00775839, learning_rate: 6.033e-06, global_step: 10785, interval_runtime: 0.7296, interval_samples_per_second: 54.825, interval_steps_per_second: 6.853, epoch: 15.9778\r\n",
      "loss: 0.01090558, learning_rate: 6.022e-06, global_step: 10790, interval_runtime: 0.9238, interval_samples_per_second: 43.3, interval_steps_per_second: 5.412, epoch: 15.9852\r\n",
      "loss: 0.0094121, learning_rate: 6.011e-06, global_step: 10795, interval_runtime: 0.9618, interval_samples_per_second: 41.589, interval_steps_per_second: 5.199, epoch: 15.9926\r\n",
      "loss: 0.00078792, learning_rate: 6e-06, global_step: 10800, interval_runtime: 0.589, interval_samples_per_second: 67.913, interval_steps_per_second: 8.489, epoch: 16.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:14:48,772] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:14:48,775] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:14:48,777] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:14:48,779] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:14:48,781] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.7428695559501648, eval_micro_f1_score: 0.5600137174211248, eval_macro_f1_score: 0.4584515464083866, eval_runtime: 13.2053, eval_samples_per_second: 143.579, eval_steps_per_second: 17.947, epoch: 16.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:15:01,982] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-10800\r\n",
      "[2023-01-10 11:15:01,986] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:15:05,405] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-10800/tokenizer_config.json\r\n",
      "[2023-01-10 11:15:05,409] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-10800/special_tokens_map.json\r\n",
      "[2023-01-10 11:15:12,175] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-9450] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0092145, learning_rate: 5.989e-06, global_step: 10805, interval_runtime: 24.9248, interval_samples_per_second: 1.605, interval_steps_per_second: 0.201, epoch: 16.0074\r\n",
      "loss: 0.0070822, learning_rate: 5.978e-06, global_step: 10810, interval_runtime: 0.8697, interval_samples_per_second: 45.994, interval_steps_per_second: 5.749, epoch: 16.0148\r\n",
      "loss: 0.01198479, learning_rate: 5.967e-06, global_step: 10815, interval_runtime: 0.8172, interval_samples_per_second: 48.949, interval_steps_per_second: 6.119, epoch: 16.0222\r\n",
      "loss: 0.00337225, learning_rate: 5.956e-06, global_step: 10820, interval_runtime: 0.8272, interval_samples_per_second: 48.357, interval_steps_per_second: 6.045, epoch: 16.0296\r\n",
      "loss: 0.00471758, learning_rate: 5.944e-06, global_step: 10825, interval_runtime: 0.8487, interval_samples_per_second: 47.131, interval_steps_per_second: 5.891, epoch: 16.037\r\n",
      "loss: 0.01429155, learning_rate: 5.933e-06, global_step: 10830, interval_runtime: 0.9278, interval_samples_per_second: 43.115, interval_steps_per_second: 5.389, epoch: 16.0444\r\n",
      "loss: 0.00413472, learning_rate: 5.922e-06, global_step: 10835, interval_runtime: 0.7271, interval_samples_per_second: 55.016, interval_steps_per_second: 6.877, epoch: 16.0519\r\n",
      "loss: 0.00429687, learning_rate: 5.911e-06, global_step: 10840, interval_runtime: 0.7454, interval_samples_per_second: 53.663, interval_steps_per_second: 6.708, epoch: 16.0593\r\n",
      "loss: 0.00415084, learning_rate: 5.9e-06, global_step: 10845, interval_runtime: 0.7554, interval_samples_per_second: 52.954, interval_steps_per_second: 6.619, epoch: 16.0667\r\n",
      "loss: 0.00120974, learning_rate: 5.889e-06, global_step: 10850, interval_runtime: 0.8038, interval_samples_per_second: 49.765, interval_steps_per_second: 6.221, epoch: 16.0741\r\n",
      "loss: 0.01850487, learning_rate: 5.878e-06, global_step: 10855, interval_runtime: 0.9356, interval_samples_per_second: 42.753, interval_steps_per_second: 5.344, epoch: 16.0815\r\n",
      "loss: 0.00898903, learning_rate: 5.867e-06, global_step: 10860, interval_runtime: 0.9497, interval_samples_per_second: 42.119, interval_steps_per_second: 5.265, epoch: 16.0889\r\n",
      "loss: 0.00185269, learning_rate: 5.856e-06, global_step: 10865, interval_runtime: 0.7505, interval_samples_per_second: 53.297, interval_steps_per_second: 6.662, epoch: 16.0963\r\n",
      "loss: 0.00108145, learning_rate: 5.844e-06, global_step: 10870, interval_runtime: 0.8422, interval_samples_per_second: 47.493, interval_steps_per_second: 5.937, epoch: 16.1037\r\n",
      "loss: 0.00124584, learning_rate: 5.833e-06, global_step: 10875, interval_runtime: 0.9035, interval_samples_per_second: 44.275, interval_steps_per_second: 5.534, epoch: 16.1111\r\n",
      "loss: 0.00562784, learning_rate: 5.822e-06, global_step: 10880, interval_runtime: 0.8555, interval_samples_per_second: 46.755, interval_steps_per_second: 5.844, epoch: 16.1185\r\n",
      "loss: 0.00175317, learning_rate: 5.811e-06, global_step: 10885, interval_runtime: 0.9328, interval_samples_per_second: 42.883, interval_steps_per_second: 5.36, epoch: 16.1259\r\n",
      "loss: 0.01032435, learning_rate: 5.8e-06, global_step: 10890, interval_runtime: 0.7266, interval_samples_per_second: 55.053, interval_steps_per_second: 6.882, epoch: 16.1333\r\n",
      "loss: 0.00486236, learning_rate: 5.789e-06, global_step: 10895, interval_runtime: 0.7997, interval_samples_per_second: 50.021, interval_steps_per_second: 6.253, epoch: 16.1407\r\n",
      "loss: 0.00108096, learning_rate: 5.778e-06, global_step: 10900, interval_runtime: 0.8231, interval_samples_per_second: 48.599, interval_steps_per_second: 6.075, epoch: 16.1481\r\n",
      "loss: 0.01177182, learning_rate: 5.767e-06, global_step: 10905, interval_runtime: 0.8973, interval_samples_per_second: 44.577, interval_steps_per_second: 5.572, epoch: 16.1556\r\n",
      "loss: 0.00669467, learning_rate: 5.756e-06, global_step: 10910, interval_runtime: 0.7093, interval_samples_per_second: 56.395, interval_steps_per_second: 7.049, epoch: 16.163\r\n",
      "loss: 0.00258341, learning_rate: 5.744e-06, global_step: 10915, interval_runtime: 0.9289, interval_samples_per_second: 43.064, interval_steps_per_second: 5.383, epoch: 16.1704\r\n",
      "loss: 0.00736141, learning_rate: 5.733e-06, global_step: 10920, interval_runtime: 0.7357, interval_samples_per_second: 54.366, interval_steps_per_second: 6.796, epoch: 16.1778\r\n",
      "loss: 0.0125922, learning_rate: 5.722e-06, global_step: 10925, interval_runtime: 0.8141, interval_samples_per_second: 49.136, interval_steps_per_second: 6.142, epoch: 16.1852\r\n",
      "loss: 0.00146844, learning_rate: 5.711e-06, global_step: 10930, interval_runtime: 0.9154, interval_samples_per_second: 43.697, interval_steps_per_second: 5.462, epoch: 16.1926\r\n",
      "loss: 0.00534943, learning_rate: 5.7e-06, global_step: 10935, interval_runtime: 0.8753, interval_samples_per_second: 45.698, interval_steps_per_second: 5.712, epoch: 16.2\r\n",
      "loss: 0.01056733, learning_rate: 5.689e-06, global_step: 10940, interval_runtime: 0.8122, interval_samples_per_second: 49.249, interval_steps_per_second: 6.156, epoch: 16.2074\r\n",
      "loss: 0.00483198, learning_rate: 5.678e-06, global_step: 10945, interval_runtime: 0.7423, interval_samples_per_second: 53.89, interval_steps_per_second: 6.736, epoch: 16.2148\r\n",
      "loss: 0.00124543, learning_rate: 5.667e-06, global_step: 10950, interval_runtime: 0.8346, interval_samples_per_second: 47.928, interval_steps_per_second: 5.991, epoch: 16.2222\r\n",
      "loss: 0.00552947, learning_rate: 5.656e-06, global_step: 10955, interval_runtime: 0.7764, interval_samples_per_second: 51.522, interval_steps_per_second: 6.44, epoch: 16.2296\r\n",
      "loss: 0.00961195, learning_rate: 5.644e-06, global_step: 10960, interval_runtime: 0.8093, interval_samples_per_second: 49.426, interval_steps_per_second: 6.178, epoch: 16.237\r\n",
      "loss: 0.00386097, learning_rate: 5.633e-06, global_step: 10965, interval_runtime: 0.7386, interval_samples_per_second: 54.16, interval_steps_per_second: 6.77, epoch: 16.2444\r\n",
      "loss: 0.00108021, learning_rate: 5.622e-06, global_step: 10970, interval_runtime: 1.0311, interval_samples_per_second: 38.795, interval_steps_per_second: 4.849, epoch: 16.2519\r\n",
      "loss: 0.00628532, learning_rate: 5.611e-06, global_step: 10975, interval_runtime: 0.7767, interval_samples_per_second: 51.497, interval_steps_per_second: 6.437, epoch: 16.2593\r\n",
      "loss: 0.00667348, learning_rate: 5.6e-06, global_step: 10980, interval_runtime: 0.764, interval_samples_per_second: 52.355, interval_steps_per_second: 6.544, epoch: 16.2667\r\n",
      "loss: 0.01005115, learning_rate: 5.589e-06, global_step: 10985, interval_runtime: 0.9881, interval_samples_per_second: 40.482, interval_steps_per_second: 5.06, epoch: 16.2741\r\n",
      "loss: 0.01159729, learning_rate: 5.578e-06, global_step: 10990, interval_runtime: 0.9895, interval_samples_per_second: 40.425, interval_steps_per_second: 5.053, epoch: 16.2815\r\n",
      "loss: 0.00102435, learning_rate: 5.567e-06, global_step: 10995, interval_runtime: 1.1016, interval_samples_per_second: 36.311, interval_steps_per_second: 4.539, epoch: 16.2889\r\n",
      "loss: 0.00605676, learning_rate: 5.556e-06, global_step: 11000, interval_runtime: 0.8724, interval_samples_per_second: 45.852, interval_steps_per_second: 5.731, epoch: 16.2963\r\n",
      "loss: 0.00523736, learning_rate: 5.544e-06, global_step: 11005, interval_runtime: 0.9979, interval_samples_per_second: 40.082, interval_steps_per_second: 5.01, epoch: 16.3037\r\n",
      "loss: 0.00108303, learning_rate: 5.533e-06, global_step: 11010, interval_runtime: 0.7936, interval_samples_per_second: 50.401, interval_steps_per_second: 6.3, epoch: 16.3111\r\n",
      "loss: 0.00517682, learning_rate: 5.522e-06, global_step: 11015, interval_runtime: 0.8104, interval_samples_per_second: 49.361, interval_steps_per_second: 6.17, epoch: 16.3185\r\n",
      "loss: 0.01100175, learning_rate: 5.511e-06, global_step: 11020, interval_runtime: 0.8263, interval_samples_per_second: 48.41, interval_steps_per_second: 6.051, epoch: 16.3259\r\n",
      "loss: 0.00987131, learning_rate: 5.5e-06, global_step: 11025, interval_runtime: 0.8129, interval_samples_per_second: 49.205, interval_steps_per_second: 6.151, epoch: 16.3333\r\n",
      "loss: 0.0071507, learning_rate: 5.489e-06, global_step: 11030, interval_runtime: 0.8137, interval_samples_per_second: 49.161, interval_steps_per_second: 6.145, epoch: 16.3407\r\n",
      "loss: 0.00616378, learning_rate: 5.478e-06, global_step: 11035, interval_runtime: 0.7301, interval_samples_per_second: 54.788, interval_steps_per_second: 6.848, epoch: 16.3481\r\n",
      "loss: 0.01961063, learning_rate: 5.467e-06, global_step: 11040, interval_runtime: 0.8208, interval_samples_per_second: 48.735, interval_steps_per_second: 6.092, epoch: 16.3556\r\n",
      "loss: 0.00568432, learning_rate: 5.456e-06, global_step: 11045, interval_runtime: 0.7686, interval_samples_per_second: 52.045, interval_steps_per_second: 6.506, epoch: 16.363\r\n",
      "loss: 0.0058305, learning_rate: 5.444e-06, global_step: 11050, interval_runtime: 0.8966, interval_samples_per_second: 44.615, interval_steps_per_second: 5.577, epoch: 16.3704\r\n",
      "loss: 0.00378657, learning_rate: 5.433e-06, global_step: 11055, interval_runtime: 1.0098, interval_samples_per_second: 39.611, interval_steps_per_second: 4.951, epoch: 16.3778\r\n",
      "loss: 0.0014979, learning_rate: 5.422e-06, global_step: 11060, interval_runtime: 1.1101, interval_samples_per_second: 36.032, interval_steps_per_second: 4.504, epoch: 16.3852\r\n",
      "loss: 0.00844035, learning_rate: 5.411e-06, global_step: 11065, interval_runtime: 0.8007, interval_samples_per_second: 49.954, interval_steps_per_second: 6.244, epoch: 16.3926\r\n",
      "loss: 0.0075311, learning_rate: 5.4e-06, global_step: 11070, interval_runtime: 0.8924, interval_samples_per_second: 44.823, interval_steps_per_second: 5.603, epoch: 16.4\r\n",
      "loss: 0.00106585, learning_rate: 5.389e-06, global_step: 11075, interval_runtime: 0.744, interval_samples_per_second: 53.765, interval_steps_per_second: 6.721, epoch: 16.4074\r\n",
      "loss: 0.01438769, learning_rate: 5.378e-06, global_step: 11080, interval_runtime: 0.7516, interval_samples_per_second: 53.218, interval_steps_per_second: 6.652, epoch: 16.4148\r\n",
      "loss: 0.01163944, learning_rate: 5.367e-06, global_step: 11085, interval_runtime: 0.7994, interval_samples_per_second: 50.036, interval_steps_per_second: 6.255, epoch: 16.4222\r\n",
      "loss: 0.00553395, learning_rate: 5.356e-06, global_step: 11090, interval_runtime: 0.8049, interval_samples_per_second: 49.695, interval_steps_per_second: 6.212, epoch: 16.4296\r\n",
      "loss: 0.00182257, learning_rate: 5.344e-06, global_step: 11095, interval_runtime: 0.8078, interval_samples_per_second: 49.516, interval_steps_per_second: 6.189, epoch: 16.437\r\n",
      "loss: 0.00648928, learning_rate: 5.333e-06, global_step: 11100, interval_runtime: 0.7132, interval_samples_per_second: 56.084, interval_steps_per_second: 7.011, epoch: 16.4444\r\n",
      "loss: 0.00828765, learning_rate: 5.322e-06, global_step: 11105, interval_runtime: 0.9033, interval_samples_per_second: 44.284, interval_steps_per_second: 5.535, epoch: 16.4519\r\n",
      "loss: 0.0027441, learning_rate: 5.311e-06, global_step: 11110, interval_runtime: 0.8548, interval_samples_per_second: 46.796, interval_steps_per_second: 5.85, epoch: 16.4593\r\n",
      "loss: 0.00216833, learning_rate: 5.3e-06, global_step: 11115, interval_runtime: 0.8077, interval_samples_per_second: 49.526, interval_steps_per_second: 6.191, epoch: 16.4667\r\n",
      "loss: 0.00349282, learning_rate: 5.289e-06, global_step: 11120, interval_runtime: 0.7703, interval_samples_per_second: 51.929, interval_steps_per_second: 6.491, epoch: 16.4741\r\n",
      "loss: 0.00157141, learning_rate: 5.278e-06, global_step: 11125, interval_runtime: 0.79, interval_samples_per_second: 50.633, interval_steps_per_second: 6.329, epoch: 16.4815\r\n",
      "loss: 0.0080044, learning_rate: 5.267e-06, global_step: 11130, interval_runtime: 0.7746, interval_samples_per_second: 51.638, interval_steps_per_second: 6.455, epoch: 16.4889\r\n",
      "loss: 0.01562857, learning_rate: 5.256e-06, global_step: 11135, interval_runtime: 0.8722, interval_samples_per_second: 45.859, interval_steps_per_second: 5.732, epoch: 16.4963\r\n",
      "loss: 0.01536885, learning_rate: 5.244e-06, global_step: 11140, interval_runtime: 0.8132, interval_samples_per_second: 49.189, interval_steps_per_second: 6.149, epoch: 16.5037\r\n",
      "loss: 0.00993285, learning_rate: 5.233e-06, global_step: 11145, interval_runtime: 0.7579, interval_samples_per_second: 52.781, interval_steps_per_second: 6.598, epoch: 16.5111\r\n",
      "loss: 0.00742945, learning_rate: 5.222e-06, global_step: 11150, interval_runtime: 0.8404, interval_samples_per_second: 47.598, interval_steps_per_second: 5.95, epoch: 16.5185\r\n",
      "loss: 0.01089608, learning_rate: 5.211e-06, global_step: 11155, interval_runtime: 0.9484, interval_samples_per_second: 42.174, interval_steps_per_second: 5.272, epoch: 16.5259\r\n",
      "loss: 0.00175605, learning_rate: 5.2e-06, global_step: 11160, interval_runtime: 0.8438, interval_samples_per_second: 47.403, interval_steps_per_second: 5.925, epoch: 16.5333\r\n",
      "loss: 0.0159878, learning_rate: 5.189e-06, global_step: 11165, interval_runtime: 0.8856, interval_samples_per_second: 45.166, interval_steps_per_second: 5.646, epoch: 16.5407\r\n",
      "loss: 0.00664433, learning_rate: 5.178e-06, global_step: 11170, interval_runtime: 1.0245, interval_samples_per_second: 39.043, interval_steps_per_second: 4.88, epoch: 16.5481\r\n",
      "loss: 0.0044682, learning_rate: 5.167e-06, global_step: 11175, interval_runtime: 0.7246, interval_samples_per_second: 55.205, interval_steps_per_second: 6.901, epoch: 16.5556\r\n",
      "loss: 0.01195918, learning_rate: 5.156e-06, global_step: 11180, interval_runtime: 0.8374, interval_samples_per_second: 47.766, interval_steps_per_second: 5.971, epoch: 16.563\r\n",
      "loss: 0.01414086, learning_rate: 5.144e-06, global_step: 11185, interval_runtime: 1.0863, interval_samples_per_second: 36.822, interval_steps_per_second: 4.603, epoch: 16.5704\r\n",
      "loss: 0.01618891, learning_rate: 5.133e-06, global_step: 11190, interval_runtime: 0.9084, interval_samples_per_second: 44.035, interval_steps_per_second: 5.504, epoch: 16.5778\r\n",
      "loss: 0.0212056, learning_rate: 5.122e-06, global_step: 11195, interval_runtime: 0.8661, interval_samples_per_second: 46.185, interval_steps_per_second: 5.773, epoch: 16.5852\r\n",
      "loss: 0.01345679, learning_rate: 5.111e-06, global_step: 11200, interval_runtime: 0.8527, interval_samples_per_second: 46.912, interval_steps_per_second: 5.864, epoch: 16.5926\r\n",
      "loss: 0.01062877, learning_rate: 5.1e-06, global_step: 11205, interval_runtime: 0.9522, interval_samples_per_second: 42.008, interval_steps_per_second: 5.251, epoch: 16.6\r\n",
      "loss: 0.01624593, learning_rate: 5.089e-06, global_step: 11210, interval_runtime: 0.9709, interval_samples_per_second: 41.201, interval_steps_per_second: 5.15, epoch: 16.6074\r\n",
      "loss: 0.00980252, learning_rate: 5.078e-06, global_step: 11215, interval_runtime: 0.9648, interval_samples_per_second: 41.459, interval_steps_per_second: 5.182, epoch: 16.6148\r\n",
      "loss: 0.00095208, learning_rate: 5.067e-06, global_step: 11220, interval_runtime: 0.8129, interval_samples_per_second: 49.207, interval_steps_per_second: 6.151, epoch: 16.6222\r\n",
      "loss: 0.0042704, learning_rate: 5.056e-06, global_step: 11225, interval_runtime: 0.8074, interval_samples_per_second: 49.542, interval_steps_per_second: 6.193, epoch: 16.6296\r\n",
      "loss: 0.00889669, learning_rate: 5.044e-06, global_step: 11230, interval_runtime: 0.9303, interval_samples_per_second: 42.999, interval_steps_per_second: 5.375, epoch: 16.637\r\n",
      "loss: 0.00174159, learning_rate: 5.033e-06, global_step: 11235, interval_runtime: 0.9017, interval_samples_per_second: 44.361, interval_steps_per_second: 5.545, epoch: 16.6444\r\n",
      "loss: 0.001019, learning_rate: 5.022e-06, global_step: 11240, interval_runtime: 0.7818, interval_samples_per_second: 51.164, interval_steps_per_second: 6.396, epoch: 16.6519\r\n",
      "loss: 0.00094796, learning_rate: 5.011e-06, global_step: 11245, interval_runtime: 0.8819, interval_samples_per_second: 45.359, interval_steps_per_second: 5.67, epoch: 16.6593\r\n",
      "loss: 0.01115349, learning_rate: 5e-06, global_step: 11250, interval_runtime: 0.8356, interval_samples_per_second: 47.869, interval_steps_per_second: 5.984, epoch: 16.6667\r\n",
      "loss: 0.00145169, learning_rate: 4.989e-06, global_step: 11255, interval_runtime: 0.7654, interval_samples_per_second: 52.261, interval_steps_per_second: 6.533, epoch: 16.6741\r\n",
      "loss: 0.00483961, learning_rate: 4.978e-06, global_step: 11260, interval_runtime: 0.9206, interval_samples_per_second: 43.45, interval_steps_per_second: 5.431, epoch: 16.6815\r\n",
      "loss: 0.01091664, learning_rate: 4.967e-06, global_step: 11265, interval_runtime: 0.7609, interval_samples_per_second: 52.566, interval_steps_per_second: 6.571, epoch: 16.6889\r\n",
      "loss: 0.0012924, learning_rate: 4.956e-06, global_step: 11270, interval_runtime: 0.9366, interval_samples_per_second: 42.708, interval_steps_per_second: 5.338, epoch: 16.6963\r\n",
      "loss: 0.00536141, learning_rate: 4.944e-06, global_step: 11275, interval_runtime: 0.7612, interval_samples_per_second: 52.551, interval_steps_per_second: 6.569, epoch: 16.7037\r\n",
      "loss: 0.01331719, learning_rate: 4.933e-06, global_step: 11280, interval_runtime: 0.8679, interval_samples_per_second: 46.089, interval_steps_per_second: 5.761, epoch: 16.7111\r\n",
      "loss: 0.02095087, learning_rate: 4.922e-06, global_step: 11285, interval_runtime: 0.7743, interval_samples_per_second: 51.656, interval_steps_per_second: 6.457, epoch: 16.7185\r\n",
      "loss: 0.00129366, learning_rate: 4.911e-06, global_step: 11290, interval_runtime: 0.8412, interval_samples_per_second: 47.548, interval_steps_per_second: 5.944, epoch: 16.7259\r\n",
      "loss: 0.00698035, learning_rate: 4.9e-06, global_step: 11295, interval_runtime: 0.8233, interval_samples_per_second: 48.583, interval_steps_per_second: 6.073, epoch: 16.7333\r\n",
      "loss: 0.01681714, learning_rate: 4.889e-06, global_step: 11300, interval_runtime: 0.8688, interval_samples_per_second: 46.04, interval_steps_per_second: 5.755, epoch: 16.7407\r\n",
      "loss: 0.00511946, learning_rate: 4.878e-06, global_step: 11305, interval_runtime: 0.8036, interval_samples_per_second: 49.778, interval_steps_per_second: 6.222, epoch: 16.7481\r\n",
      "loss: 0.00273195, learning_rate: 4.867e-06, global_step: 11310, interval_runtime: 0.7467, interval_samples_per_second: 53.57, interval_steps_per_second: 6.696, epoch: 16.7556\r\n",
      "loss: 0.00869829, learning_rate: 4.856e-06, global_step: 11315, interval_runtime: 0.8108, interval_samples_per_second: 49.334, interval_steps_per_second: 6.167, epoch: 16.763\r\n",
      "loss: 0.01393751, learning_rate: 4.844e-06, global_step: 11320, interval_runtime: 0.8171, interval_samples_per_second: 48.954, interval_steps_per_second: 6.119, epoch: 16.7704\r\n",
      "loss: 0.000978, learning_rate: 4.833e-06, global_step: 11325, interval_runtime: 0.7514, interval_samples_per_second: 53.236, interval_steps_per_second: 6.655, epoch: 16.7778\r\n",
      "loss: 0.00904114, learning_rate: 4.822e-06, global_step: 11330, interval_runtime: 0.7416, interval_samples_per_second: 53.939, interval_steps_per_second: 6.742, epoch: 16.7852\r\n",
      "loss: 0.00731248, learning_rate: 4.811e-06, global_step: 11335, interval_runtime: 0.7581, interval_samples_per_second: 52.764, interval_steps_per_second: 6.596, epoch: 16.7926\r\n",
      "loss: 0.00482404, learning_rate: 4.8e-06, global_step: 11340, interval_runtime: 0.8149, interval_samples_per_second: 49.087, interval_steps_per_second: 6.136, epoch: 16.8\r\n",
      "loss: 0.00092993, learning_rate: 4.789e-06, global_step: 11345, interval_runtime: 0.8469, interval_samples_per_second: 47.231, interval_steps_per_second: 5.904, epoch: 16.8074\r\n",
      "loss: 0.00082847, learning_rate: 4.778e-06, global_step: 11350, interval_runtime: 0.9903, interval_samples_per_second: 40.39, interval_steps_per_second: 5.049, epoch: 16.8148\r\n",
      "loss: 0.0083898, learning_rate: 4.767e-06, global_step: 11355, interval_runtime: 0.7738, interval_samples_per_second: 51.693, interval_steps_per_second: 6.462, epoch: 16.8222\r\n",
      "loss: 0.00335603, learning_rate: 4.756e-06, global_step: 11360, interval_runtime: 0.852, interval_samples_per_second: 46.95, interval_steps_per_second: 5.869, epoch: 16.8296\r\n",
      "loss: 0.00246338, learning_rate: 4.744e-06, global_step: 11365, interval_runtime: 0.9753, interval_samples_per_second: 41.014, interval_steps_per_second: 5.127, epoch: 16.837\r\n",
      "loss: 0.00885391, learning_rate: 4.733e-06, global_step: 11370, interval_runtime: 0.8363, interval_samples_per_second: 47.827, interval_steps_per_second: 5.978, epoch: 16.8444\r\n",
      "loss: 0.01911726, learning_rate: 4.722e-06, global_step: 11375, interval_runtime: 0.8645, interval_samples_per_second: 46.271, interval_steps_per_second: 5.784, epoch: 16.8519\r\n",
      "loss: 0.01267077, learning_rate: 4.711e-06, global_step: 11380, interval_runtime: 0.9178, interval_samples_per_second: 43.583, interval_steps_per_second: 5.448, epoch: 16.8593\r\n",
      "loss: 0.01067277, learning_rate: 4.7e-06, global_step: 11385, interval_runtime: 0.7839, interval_samples_per_second: 51.03, interval_steps_per_second: 6.379, epoch: 16.8667\r\n",
      "loss: 0.01483553, learning_rate: 4.689e-06, global_step: 11390, interval_runtime: 0.8398, interval_samples_per_second: 47.631, interval_steps_per_second: 5.954, epoch: 16.8741\r\n",
      "loss: 0.00088025, learning_rate: 4.678e-06, global_step: 11395, interval_runtime: 0.909, interval_samples_per_second: 44.005, interval_steps_per_second: 5.501, epoch: 16.8815\r\n",
      "loss: 0.00093437, learning_rate: 4.667e-06, global_step: 11400, interval_runtime: 0.7927, interval_samples_per_second: 50.462, interval_steps_per_second: 6.308, epoch: 16.8889\r\n",
      "loss: 0.00102255, learning_rate: 4.656e-06, global_step: 11405, interval_runtime: 0.7625, interval_samples_per_second: 52.456, interval_steps_per_second: 6.557, epoch: 16.8963\r\n",
      "loss: 0.01012729, learning_rate: 4.644e-06, global_step: 11410, interval_runtime: 0.8933, interval_samples_per_second: 44.776, interval_steps_per_second: 5.597, epoch: 16.9037\r\n",
      "loss: 0.00952536, learning_rate: 4.633e-06, global_step: 11415, interval_runtime: 0.794, interval_samples_per_second: 50.377, interval_steps_per_second: 6.297, epoch: 16.9111\r\n",
      "loss: 0.00999455, learning_rate: 4.622e-06, global_step: 11420, interval_runtime: 0.8349, interval_samples_per_second: 47.909, interval_steps_per_second: 5.989, epoch: 16.9185\r\n",
      "loss: 0.00111055, learning_rate: 4.611e-06, global_step: 11425, interval_runtime: 0.8338, interval_samples_per_second: 47.974, interval_steps_per_second: 5.997, epoch: 16.9259\r\n",
      "loss: 0.0140987, learning_rate: 4.6e-06, global_step: 11430, interval_runtime: 0.6994, interval_samples_per_second: 57.192, interval_steps_per_second: 7.149, epoch: 16.9333\r\n",
      "loss: 0.00435267, learning_rate: 4.589e-06, global_step: 11435, interval_runtime: 0.6855, interval_samples_per_second: 58.348, interval_steps_per_second: 7.293, epoch: 16.9407\r\n",
      "loss: 0.00822746, learning_rate: 4.578e-06, global_step: 11440, interval_runtime: 0.8781, interval_samples_per_second: 45.553, interval_steps_per_second: 5.694, epoch: 16.9481\r\n",
      "loss: 0.00096079, learning_rate: 4.567e-06, global_step: 11445, interval_runtime: 0.7699, interval_samples_per_second: 51.955, interval_steps_per_second: 6.494, epoch: 16.9556\r\n",
      "loss: 0.01335043, learning_rate: 4.556e-06, global_step: 11450, interval_runtime: 0.8968, interval_samples_per_second: 44.601, interval_steps_per_second: 5.575, epoch: 16.963\r\n",
      "loss: 0.0058968, learning_rate: 4.544e-06, global_step: 11455, interval_runtime: 0.7828, interval_samples_per_second: 51.101, interval_steps_per_second: 6.388, epoch: 16.9704\r\n",
      "loss: 0.00805319, learning_rate: 4.533e-06, global_step: 11460, interval_runtime: 0.9543, interval_samples_per_second: 41.915, interval_steps_per_second: 5.239, epoch: 16.9778\r\n",
      "loss: 0.01574675, learning_rate: 4.522e-06, global_step: 11465, interval_runtime: 0.8363, interval_samples_per_second: 47.828, interval_steps_per_second: 5.979, epoch: 16.9852\r\n",
      "loss: 0.00559362, learning_rate: 4.511e-06, global_step: 11470, interval_runtime: 0.7604, interval_samples_per_second: 52.607, interval_steps_per_second: 6.576, epoch: 16.9926\r\n",
      "loss: 0.0101263, learning_rate: 4.5e-06, global_step: 11475, interval_runtime: 0.7303, interval_samples_per_second: 54.769, interval_steps_per_second: 6.846, epoch: 17.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:17:06,418] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:17:06,422] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:17:06,424] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:17:06,427] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:17:06,430] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.7581160068511963, eval_micro_f1_score: 0.5704798273285737, eval_macro_f1_score: 0.46827143351220213, eval_runtime: 13.2355, eval_samples_per_second: 143.251, eval_steps_per_second: 17.906, epoch: 17.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:17:19,659] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-11475\r\n",
      "[2023-01-10 11:17:19,663] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:17:23,058] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-11475/tokenizer_config.json\r\n",
      "[2023-01-10 11:17:23,062] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-11475/special_tokens_map.json\r\n",
      "[2023-01-10 11:17:29,810] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-10125] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00704499, learning_rate: 4.489e-06, global_step: 11480, interval_runtime: 24.8527, interval_samples_per_second: 1.609, interval_steps_per_second: 0.201, epoch: 17.0074\r\n",
      "loss: 0.0102994, learning_rate: 4.478e-06, global_step: 11485, interval_runtime: 0.7615, interval_samples_per_second: 52.526, interval_steps_per_second: 6.566, epoch: 17.0148\r\n",
      "loss: 0.00736592, learning_rate: 4.467e-06, global_step: 11490, interval_runtime: 0.7277, interval_samples_per_second: 54.967, interval_steps_per_second: 6.871, epoch: 17.0222\r\n",
      "loss: 0.00110211, learning_rate: 4.456e-06, global_step: 11495, interval_runtime: 0.8375, interval_samples_per_second: 47.759, interval_steps_per_second: 5.97, epoch: 17.0296\r\n",
      "loss: 0.00478343, learning_rate: 4.444e-06, global_step: 11500, interval_runtime: 0.7668, interval_samples_per_second: 52.165, interval_steps_per_second: 6.521, epoch: 17.037\r\n",
      "loss: 0.0087641, learning_rate: 4.433e-06, global_step: 11505, interval_runtime: 1.0016, interval_samples_per_second: 39.935, interval_steps_per_second: 4.992, epoch: 17.0444\r\n",
      "loss: 0.01205331, learning_rate: 4.422e-06, global_step: 11510, interval_runtime: 0.8435, interval_samples_per_second: 47.419, interval_steps_per_second: 5.927, epoch: 17.0519\r\n",
      "loss: 0.00353221, learning_rate: 4.411e-06, global_step: 11515, interval_runtime: 0.9087, interval_samples_per_second: 44.017, interval_steps_per_second: 5.502, epoch: 17.0593\r\n",
      "loss: 0.00947182, learning_rate: 4.4e-06, global_step: 11520, interval_runtime: 0.7949, interval_samples_per_second: 50.321, interval_steps_per_second: 6.29, epoch: 17.0667\r\n",
      "loss: 0.00806948, learning_rate: 4.389e-06, global_step: 11525, interval_runtime: 0.8151, interval_samples_per_second: 49.073, interval_steps_per_second: 6.134, epoch: 17.0741\r\n",
      "loss: 0.01730566, learning_rate: 4.378e-06, global_step: 11530, interval_runtime: 0.756, interval_samples_per_second: 52.909, interval_steps_per_second: 6.614, epoch: 17.0815\r\n",
      "loss: 0.01443284, learning_rate: 4.367e-06, global_step: 11535, interval_runtime: 1.0544, interval_samples_per_second: 37.936, interval_steps_per_second: 4.742, epoch: 17.0889\r\n",
      "loss: 0.00070153, learning_rate: 4.356e-06, global_step: 11540, interval_runtime: 0.7649, interval_samples_per_second: 52.297, interval_steps_per_second: 6.537, epoch: 17.0963\r\n",
      "loss: 0.00570276, learning_rate: 4.344e-06, global_step: 11545, interval_runtime: 0.7594, interval_samples_per_second: 52.671, interval_steps_per_second: 6.584, epoch: 17.1037\r\n",
      "loss: 0.00487341, learning_rate: 4.333e-06, global_step: 11550, interval_runtime: 0.7626, interval_samples_per_second: 52.453, interval_steps_per_second: 6.557, epoch: 17.1111\r\n",
      "loss: 0.00091436, learning_rate: 4.322e-06, global_step: 11555, interval_runtime: 0.867, interval_samples_per_second: 46.136, interval_steps_per_second: 5.767, epoch: 17.1185\r\n",
      "loss: 0.01012397, learning_rate: 4.311e-06, global_step: 11560, interval_runtime: 0.8868, interval_samples_per_second: 45.105, interval_steps_per_second: 5.638, epoch: 17.1259\r\n",
      "loss: 0.00127531, learning_rate: 4.3e-06, global_step: 11565, interval_runtime: 0.8899, interval_samples_per_second: 44.947, interval_steps_per_second: 5.618, epoch: 17.1333\r\n",
      "loss: 0.00303879, learning_rate: 4.289e-06, global_step: 11570, interval_runtime: 0.899, interval_samples_per_second: 44.496, interval_steps_per_second: 5.562, epoch: 17.1407\r\n",
      "loss: 0.00096377, learning_rate: 4.278e-06, global_step: 11575, interval_runtime: 0.7606, interval_samples_per_second: 52.59, interval_steps_per_second: 6.574, epoch: 17.1481\r\n",
      "loss: 0.00905271, learning_rate: 4.267e-06, global_step: 11580, interval_runtime: 0.7451, interval_samples_per_second: 53.682, interval_steps_per_second: 6.71, epoch: 17.1556\r\n",
      "loss: 0.00062563, learning_rate: 4.256e-06, global_step: 11585, interval_runtime: 0.7477, interval_samples_per_second: 53.5, interval_steps_per_second: 6.688, epoch: 17.163\r\n",
      "loss: 0.00090807, learning_rate: 4.244e-06, global_step: 11590, interval_runtime: 0.746, interval_samples_per_second: 53.618, interval_steps_per_second: 6.702, epoch: 17.1704\r\n",
      "loss: 0.00312986, learning_rate: 4.233e-06, global_step: 11595, interval_runtime: 0.7895, interval_samples_per_second: 50.663, interval_steps_per_second: 6.333, epoch: 17.1778\r\n",
      "loss: 0.00587548, learning_rate: 4.222e-06, global_step: 11600, interval_runtime: 0.9817, interval_samples_per_second: 40.747, interval_steps_per_second: 5.093, epoch: 17.1852\r\n",
      "loss: 0.00092829, learning_rate: 4.211e-06, global_step: 11605, interval_runtime: 0.9383, interval_samples_per_second: 42.631, interval_steps_per_second: 5.329, epoch: 17.1926\r\n",
      "loss: 0.01447529, learning_rate: 4.2e-06, global_step: 11610, interval_runtime: 0.7939, interval_samples_per_second: 50.382, interval_steps_per_second: 6.298, epoch: 17.2\r\n",
      "loss: 0.00607622, learning_rate: 4.189e-06, global_step: 11615, interval_runtime: 0.7282, interval_samples_per_second: 54.932, interval_steps_per_second: 6.866, epoch: 17.2074\r\n",
      "loss: 0.00104119, learning_rate: 4.178e-06, global_step: 11620, interval_runtime: 0.8295, interval_samples_per_second: 48.222, interval_steps_per_second: 6.028, epoch: 17.2148\r\n",
      "loss: 0.00111507, learning_rate: 4.167e-06, global_step: 11625, interval_runtime: 0.7978, interval_samples_per_second: 50.136, interval_steps_per_second: 6.267, epoch: 17.2222\r\n",
      "loss: 0.00991455, learning_rate: 4.156e-06, global_step: 11630, interval_runtime: 0.9054, interval_samples_per_second: 44.178, interval_steps_per_second: 5.522, epoch: 17.2296\r\n",
      "loss: 0.0009244, learning_rate: 4.144e-06, global_step: 11635, interval_runtime: 0.922, interval_samples_per_second: 43.383, interval_steps_per_second: 5.423, epoch: 17.237\r\n",
      "loss: 0.00679449, learning_rate: 4.133e-06, global_step: 11640, interval_runtime: 0.8271, interval_samples_per_second: 48.361, interval_steps_per_second: 6.045, epoch: 17.2444\r\n",
      "loss: 0.01346846, learning_rate: 4.122e-06, global_step: 11645, interval_runtime: 0.9473, interval_samples_per_second: 42.224, interval_steps_per_second: 5.278, epoch: 17.2519\r\n",
      "loss: 0.00886035, learning_rate: 4.111e-06, global_step: 11650, interval_runtime: 0.8163, interval_samples_per_second: 49.003, interval_steps_per_second: 6.125, epoch: 17.2593\r\n",
      "loss: 0.00260343, learning_rate: 4.1e-06, global_step: 11655, interval_runtime: 0.8718, interval_samples_per_second: 45.88, interval_steps_per_second: 5.735, epoch: 17.2667\r\n",
      "loss: 0.00140809, learning_rate: 4.089e-06, global_step: 11660, interval_runtime: 0.8558, interval_samples_per_second: 46.738, interval_steps_per_second: 5.842, epoch: 17.2741\r\n",
      "loss: 0.00101351, learning_rate: 4.078e-06, global_step: 11665, interval_runtime: 1.0353, interval_samples_per_second: 38.637, interval_steps_per_second: 4.83, epoch: 17.2815\r\n",
      "loss: 0.00978895, learning_rate: 4.067e-06, global_step: 11670, interval_runtime: 0.8254, interval_samples_per_second: 48.463, interval_steps_per_second: 6.058, epoch: 17.2889\r\n",
      "loss: 0.01696958, learning_rate: 4.056e-06, global_step: 11675, interval_runtime: 0.8015, interval_samples_per_second: 49.908, interval_steps_per_second: 6.239, epoch: 17.2963\r\n",
      "loss: 0.01541605, learning_rate: 4.044e-06, global_step: 11680, interval_runtime: 0.8033, interval_samples_per_second: 49.794, interval_steps_per_second: 6.224, epoch: 17.3037\r\n",
      "loss: 0.00086827, learning_rate: 4.033e-06, global_step: 11685, interval_runtime: 0.8306, interval_samples_per_second: 48.16, interval_steps_per_second: 6.02, epoch: 17.3111\r\n",
      "loss: 0.01218089, learning_rate: 4.022e-06, global_step: 11690, interval_runtime: 0.8954, interval_samples_per_second: 44.675, interval_steps_per_second: 5.584, epoch: 17.3185\r\n",
      "loss: 0.01607479, learning_rate: 4.011e-06, global_step: 11695, interval_runtime: 0.796, interval_samples_per_second: 50.254, interval_steps_per_second: 6.282, epoch: 17.3259\r\n",
      "loss: 0.01786519, learning_rate: 4e-06, global_step: 11700, interval_runtime: 0.8672, interval_samples_per_second: 46.127, interval_steps_per_second: 5.766, epoch: 17.3333\r\n",
      "loss: 0.00523979, learning_rate: 3.989e-06, global_step: 11705, interval_runtime: 0.7831, interval_samples_per_second: 51.079, interval_steps_per_second: 6.385, epoch: 17.3407\r\n",
      "loss: 0.00125775, learning_rate: 3.978e-06, global_step: 11710, interval_runtime: 0.741, interval_samples_per_second: 53.983, interval_steps_per_second: 6.748, epoch: 17.3481\r\n",
      "loss: 0.00128488, learning_rate: 3.967e-06, global_step: 11715, interval_runtime: 0.7176, interval_samples_per_second: 55.743, interval_steps_per_second: 6.968, epoch: 17.3556\r\n",
      "loss: 0.00981221, learning_rate: 3.956e-06, global_step: 11720, interval_runtime: 0.9146, interval_samples_per_second: 43.734, interval_steps_per_second: 5.467, epoch: 17.363\r\n",
      "loss: 0.01238691, learning_rate: 3.944e-06, global_step: 11725, interval_runtime: 1.0455, interval_samples_per_second: 38.258, interval_steps_per_second: 4.782, epoch: 17.3704\r\n",
      "loss: 0.01502434, learning_rate: 3.933e-06, global_step: 11730, interval_runtime: 0.8108, interval_samples_per_second: 49.332, interval_steps_per_second: 6.167, epoch: 17.3778\r\n",
      "loss: 0.00091297, learning_rate: 3.922e-06, global_step: 11735, interval_runtime: 0.8365, interval_samples_per_second: 47.818, interval_steps_per_second: 5.977, epoch: 17.3852\r\n",
      "loss: 0.00780517, learning_rate: 3.911e-06, global_step: 11740, interval_runtime: 0.9088, interval_samples_per_second: 44.015, interval_steps_per_second: 5.502, epoch: 17.3926\r\n",
      "loss: 0.00059784, learning_rate: 3.9e-06, global_step: 11745, interval_runtime: 0.8767, interval_samples_per_second: 45.626, interval_steps_per_second: 5.703, epoch: 17.4\r\n",
      "loss: 0.01447653, learning_rate: 3.889e-06, global_step: 11750, interval_runtime: 0.7847, interval_samples_per_second: 50.976, interval_steps_per_second: 6.372, epoch: 17.4074\r\n",
      "loss: 0.00406673, learning_rate: 3.878e-06, global_step: 11755, interval_runtime: 0.8901, interval_samples_per_second: 44.939, interval_steps_per_second: 5.617, epoch: 17.4148\r\n",
      "loss: 0.00499976, learning_rate: 3.867e-06, global_step: 11760, interval_runtime: 1.0726, interval_samples_per_second: 37.292, interval_steps_per_second: 4.661, epoch: 17.4222\r\n",
      "loss: 0.00571434, learning_rate: 3.856e-06, global_step: 11765, interval_runtime: 0.8514, interval_samples_per_second: 46.982, interval_steps_per_second: 5.873, epoch: 17.4296\r\n",
      "loss: 0.01180582, learning_rate: 3.844e-06, global_step: 11770, interval_runtime: 0.7991, interval_samples_per_second: 50.057, interval_steps_per_second: 6.257, epoch: 17.437\r\n",
      "loss: 0.0120117, learning_rate: 3.833e-06, global_step: 11775, interval_runtime: 0.7211, interval_samples_per_second: 55.472, interval_steps_per_second: 6.934, epoch: 17.4444\r\n",
      "loss: 0.00438049, learning_rate: 3.822e-06, global_step: 11780, interval_runtime: 0.7253, interval_samples_per_second: 55.146, interval_steps_per_second: 6.893, epoch: 17.4519\r\n",
      "loss: 0.00200029, learning_rate: 3.811e-06, global_step: 11785, interval_runtime: 0.886, interval_samples_per_second: 45.147, interval_steps_per_second: 5.643, epoch: 17.4593\r\n",
      "loss: 0.00247911, learning_rate: 3.8e-06, global_step: 11790, interval_runtime: 0.8744, interval_samples_per_second: 45.745, interval_steps_per_second: 5.718, epoch: 17.4667\r\n",
      "loss: 0.00584167, learning_rate: 3.789e-06, global_step: 11795, interval_runtime: 0.7747, interval_samples_per_second: 51.635, interval_steps_per_second: 6.454, epoch: 17.4741\r\n",
      "loss: 0.00333627, learning_rate: 3.778e-06, global_step: 11800, interval_runtime: 0.8266, interval_samples_per_second: 48.391, interval_steps_per_second: 6.049, epoch: 17.4815\r\n",
      "loss: 0.01597366, learning_rate: 3.767e-06, global_step: 11805, interval_runtime: 0.7872, interval_samples_per_second: 50.812, interval_steps_per_second: 6.352, epoch: 17.4889\r\n",
      "loss: 0.00726583, learning_rate: 3.756e-06, global_step: 11810, interval_runtime: 0.783, interval_samples_per_second: 51.089, interval_steps_per_second: 6.386, epoch: 17.4963\r\n",
      "loss: 0.0067484, learning_rate: 3.744e-06, global_step: 11815, interval_runtime: 0.7534, interval_samples_per_second: 53.094, interval_steps_per_second: 6.637, epoch: 17.5037\r\n",
      "loss: 0.01452111, learning_rate: 3.733e-06, global_step: 11820, interval_runtime: 0.8193, interval_samples_per_second: 48.819, interval_steps_per_second: 6.102, epoch: 17.5111\r\n",
      "loss: 0.00679938, learning_rate: 3.722e-06, global_step: 11825, interval_runtime: 0.7833, interval_samples_per_second: 51.068, interval_steps_per_second: 6.383, epoch: 17.5185\r\n",
      "loss: 0.00099767, learning_rate: 3.711e-06, global_step: 11830, interval_runtime: 0.6992, interval_samples_per_second: 57.212, interval_steps_per_second: 7.152, epoch: 17.5259\r\n",
      "loss: 0.00895999, learning_rate: 3.7e-06, global_step: 11835, interval_runtime: 0.9743, interval_samples_per_second: 41.055, interval_steps_per_second: 5.132, epoch: 17.5333\r\n",
      "loss: 0.00870794, learning_rate: 3.689e-06, global_step: 11840, interval_runtime: 0.753, interval_samples_per_second: 53.12, interval_steps_per_second: 6.64, epoch: 17.5407\r\n",
      "loss: 0.01109603, learning_rate: 3.678e-06, global_step: 11845, interval_runtime: 1.0594, interval_samples_per_second: 37.756, interval_steps_per_second: 4.719, epoch: 17.5481\r\n",
      "loss: 0.00094677, learning_rate: 3.667e-06, global_step: 11850, interval_runtime: 0.7703, interval_samples_per_second: 51.931, interval_steps_per_second: 6.491, epoch: 17.5556\r\n",
      "loss: 0.00118533, learning_rate: 3.656e-06, global_step: 11855, interval_runtime: 0.9284, interval_samples_per_second: 43.084, interval_steps_per_second: 5.386, epoch: 17.563\r\n",
      "loss: 0.01540276, learning_rate: 3.644e-06, global_step: 11860, interval_runtime: 0.7997, interval_samples_per_second: 50.017, interval_steps_per_second: 6.252, epoch: 17.5704\r\n",
      "loss: 0.00072235, learning_rate: 3.633e-06, global_step: 11865, interval_runtime: 0.8008, interval_samples_per_second: 49.951, interval_steps_per_second: 6.244, epoch: 17.5778\r\n",
      "loss: 0.0045882, learning_rate: 3.622e-06, global_step: 11870, interval_runtime: 0.9257, interval_samples_per_second: 43.209, interval_steps_per_second: 5.401, epoch: 17.5852\r\n",
      "loss: 0.00894692, learning_rate: 3.611e-06, global_step: 11875, interval_runtime: 0.8497, interval_samples_per_second: 47.074, interval_steps_per_second: 5.884, epoch: 17.5926\r\n",
      "loss: 0.00061095, learning_rate: 3.6e-06, global_step: 11880, interval_runtime: 0.7274, interval_samples_per_second: 54.994, interval_steps_per_second: 6.874, epoch: 17.6\r\n",
      "loss: 0.00686392, learning_rate: 3.589e-06, global_step: 11885, interval_runtime: 0.727, interval_samples_per_second: 55.02, interval_steps_per_second: 6.878, epoch: 17.6074\r\n",
      "loss: 0.01778975, learning_rate: 3.578e-06, global_step: 11890, interval_runtime: 0.9621, interval_samples_per_second: 41.577, interval_steps_per_second: 5.197, epoch: 17.6148\r\n",
      "loss: 0.00276116, learning_rate: 3.567e-06, global_step: 11895, interval_runtime: 0.8857, interval_samples_per_second: 45.16, interval_steps_per_second: 5.645, epoch: 17.6222\r\n",
      "loss: 0.0095396, learning_rate: 3.556e-06, global_step: 11900, interval_runtime: 0.8699, interval_samples_per_second: 45.981, interval_steps_per_second: 5.748, epoch: 17.6296\r\n",
      "loss: 0.00330097, learning_rate: 3.544e-06, global_step: 11905, interval_runtime: 0.9506, interval_samples_per_second: 42.08, interval_steps_per_second: 5.26, epoch: 17.637\r\n",
      "loss: 0.00095822, learning_rate: 3.533e-06, global_step: 11910, interval_runtime: 0.8157, interval_samples_per_second: 49.035, interval_steps_per_second: 6.129, epoch: 17.6444\r\n",
      "loss: 0.00515119, learning_rate: 3.522e-06, global_step: 11915, interval_runtime: 0.8686, interval_samples_per_second: 46.052, interval_steps_per_second: 5.756, epoch: 17.6519\r\n",
      "loss: 0.00085695, learning_rate: 3.511e-06, global_step: 11920, interval_runtime: 0.7635, interval_samples_per_second: 52.387, interval_steps_per_second: 6.548, epoch: 17.6593\r\n",
      "loss: 0.00783832, learning_rate: 3.5e-06, global_step: 11925, interval_runtime: 0.8437, interval_samples_per_second: 47.413, interval_steps_per_second: 5.927, epoch: 17.6667\r\n",
      "loss: 0.00767098, learning_rate: 3.489e-06, global_step: 11930, interval_runtime: 0.7116, interval_samples_per_second: 56.214, interval_steps_per_second: 7.027, epoch: 17.6741\r\n",
      "loss: 0.01015942, learning_rate: 3.478e-06, global_step: 11935, interval_runtime: 0.8898, interval_samples_per_second: 44.953, interval_steps_per_second: 5.619, epoch: 17.6815\r\n",
      "loss: 0.00090628, learning_rate: 3.467e-06, global_step: 11940, interval_runtime: 0.7601, interval_samples_per_second: 52.626, interval_steps_per_second: 6.578, epoch: 17.6889\r\n",
      "loss: 0.00130672, learning_rate: 3.456e-06, global_step: 11945, interval_runtime: 0.7747, interval_samples_per_second: 51.63, interval_steps_per_second: 6.454, epoch: 17.6963\r\n",
      "loss: 0.00101883, learning_rate: 3.444e-06, global_step: 11950, interval_runtime: 0.9382, interval_samples_per_second: 42.633, interval_steps_per_second: 5.329, epoch: 17.7037\r\n",
      "loss: 0.00684212, learning_rate: 3.433e-06, global_step: 11955, interval_runtime: 0.8573, interval_samples_per_second: 46.657, interval_steps_per_second: 5.832, epoch: 17.7111\r\n",
      "loss: 0.01013782, learning_rate: 3.422e-06, global_step: 11960, interval_runtime: 0.8285, interval_samples_per_second: 48.281, interval_steps_per_second: 6.035, epoch: 17.7185\r\n",
      "loss: 0.00077433, learning_rate: 3.411e-06, global_step: 11965, interval_runtime: 0.7705, interval_samples_per_second: 51.912, interval_steps_per_second: 6.489, epoch: 17.7259\r\n",
      "loss: 0.00825802, learning_rate: 3.4e-06, global_step: 11970, interval_runtime: 0.7996, interval_samples_per_second: 50.024, interval_steps_per_second: 6.253, epoch: 17.7333\r\n",
      "loss: 0.00081777, learning_rate: 3.389e-06, global_step: 11975, interval_runtime: 0.9777, interval_samples_per_second: 40.911, interval_steps_per_second: 5.114, epoch: 17.7407\r\n",
      "loss: 0.01012642, learning_rate: 3.378e-06, global_step: 11980, interval_runtime: 0.7628, interval_samples_per_second: 52.435, interval_steps_per_second: 6.554, epoch: 17.7481\r\n",
      "loss: 0.00110899, learning_rate: 3.367e-06, global_step: 11985, interval_runtime: 0.8101, interval_samples_per_second: 49.376, interval_steps_per_second: 6.172, epoch: 17.7556\r\n",
      "loss: 0.00582178, learning_rate: 3.356e-06, global_step: 11990, interval_runtime: 0.875, interval_samples_per_second: 45.716, interval_steps_per_second: 5.714, epoch: 17.763\r\n",
      "loss: 0.00549554, learning_rate: 3.344e-06, global_step: 11995, interval_runtime: 0.7684, interval_samples_per_second: 52.059, interval_steps_per_second: 6.507, epoch: 17.7704\r\n",
      "loss: 0.00340767, learning_rate: 3.333e-06, global_step: 12000, interval_runtime: 0.7865, interval_samples_per_second: 50.855, interval_steps_per_second: 6.357, epoch: 17.7778\r\n",
      "loss: 0.0070794, learning_rate: 3.322e-06, global_step: 12005, interval_runtime: 0.7484, interval_samples_per_second: 53.449, interval_steps_per_second: 6.681, epoch: 17.7852\r\n",
      "loss: 0.00092801, learning_rate: 3.311e-06, global_step: 12010, interval_runtime: 0.9333, interval_samples_per_second: 42.857, interval_steps_per_second: 5.357, epoch: 17.7926\r\n",
      "loss: 0.01156015, learning_rate: 3.3e-06, global_step: 12015, interval_runtime: 0.9232, interval_samples_per_second: 43.326, interval_steps_per_second: 5.416, epoch: 17.8\r\n",
      "loss: 0.00516985, learning_rate: 3.289e-06, global_step: 12020, interval_runtime: 0.8878, interval_samples_per_second: 45.056, interval_steps_per_second: 5.632, epoch: 17.8074\r\n",
      "loss: 0.00425212, learning_rate: 3.278e-06, global_step: 12025, interval_runtime: 0.7934, interval_samples_per_second: 50.417, interval_steps_per_second: 6.302, epoch: 17.8148\r\n",
      "loss: 0.00784829, learning_rate: 3.267e-06, global_step: 12030, interval_runtime: 0.7936, interval_samples_per_second: 50.406, interval_steps_per_second: 6.301, epoch: 17.8222\r\n",
      "loss: 0.01012902, learning_rate: 3.256e-06, global_step: 12035, interval_runtime: 0.7892, interval_samples_per_second: 50.684, interval_steps_per_second: 6.336, epoch: 17.8296\r\n",
      "loss: 0.00075149, learning_rate: 3.244e-06, global_step: 12040, interval_runtime: 0.7407, interval_samples_per_second: 54.002, interval_steps_per_second: 6.75, epoch: 17.837\r\n",
      "loss: 0.00315331, learning_rate: 3.233e-06, global_step: 12045, interval_runtime: 0.8054, interval_samples_per_second: 49.664, interval_steps_per_second: 6.208, epoch: 17.8444\r\n",
      "loss: 0.0010497, learning_rate: 3.222e-06, global_step: 12050, interval_runtime: 0.9743, interval_samples_per_second: 41.057, interval_steps_per_second: 5.132, epoch: 17.8519\r\n",
      "loss: 0.00068107, learning_rate: 3.211e-06, global_step: 12055, interval_runtime: 0.7221, interval_samples_per_second: 55.397, interval_steps_per_second: 6.925, epoch: 17.8593\r\n",
      "loss: 0.00211371, learning_rate: 3.2e-06, global_step: 12060, interval_runtime: 0.7263, interval_samples_per_second: 55.073, interval_steps_per_second: 6.884, epoch: 17.8667\r\n",
      "loss: 0.01040544, learning_rate: 3.189e-06, global_step: 12065, interval_runtime: 0.7725, interval_samples_per_second: 51.778, interval_steps_per_second: 6.472, epoch: 17.8741\r\n",
      "loss: 0.00662449, learning_rate: 3.178e-06, global_step: 12070, interval_runtime: 0.9564, interval_samples_per_second: 41.822, interval_steps_per_second: 5.228, epoch: 17.8815\r\n",
      "loss: 0.00964703, learning_rate: 3.167e-06, global_step: 12075, interval_runtime: 0.8896, interval_samples_per_second: 44.964, interval_steps_per_second: 5.62, epoch: 17.8889\r\n",
      "loss: 0.00711588, learning_rate: 3.156e-06, global_step: 12080, interval_runtime: 0.78, interval_samples_per_second: 51.282, interval_steps_per_second: 6.41, epoch: 17.8963\r\n",
      "loss: 0.00753661, learning_rate: 3.144e-06, global_step: 12085, interval_runtime: 0.751, interval_samples_per_second: 53.266, interval_steps_per_second: 6.658, epoch: 17.9037\r\n",
      "loss: 0.00776474, learning_rate: 3.133e-06, global_step: 12090, interval_runtime: 0.9043, interval_samples_per_second: 44.231, interval_steps_per_second: 5.529, epoch: 17.9111\r\n",
      "loss: 0.01133104, learning_rate: 3.122e-06, global_step: 12095, interval_runtime: 0.8543, interval_samples_per_second: 46.82, interval_steps_per_second: 5.853, epoch: 17.9185\r\n",
      "loss: 0.01395592, learning_rate: 3.111e-06, global_step: 12100, interval_runtime: 0.7898, interval_samples_per_second: 50.648, interval_steps_per_second: 6.331, epoch: 17.9259\r\n",
      "loss: 0.02387225, learning_rate: 3.1e-06, global_step: 12105, interval_runtime: 0.8086, interval_samples_per_second: 49.47, interval_steps_per_second: 6.184, epoch: 17.9333\r\n",
      "loss: 0.00465536, learning_rate: 3.089e-06, global_step: 12110, interval_runtime: 0.7805, interval_samples_per_second: 51.252, interval_steps_per_second: 6.406, epoch: 17.9407\r\n",
      "loss: 0.00465972, learning_rate: 3.078e-06, global_step: 12115, interval_runtime: 0.8996, interval_samples_per_second: 44.464, interval_steps_per_second: 5.558, epoch: 17.9481\r\n",
      "loss: 0.00575981, learning_rate: 3.067e-06, global_step: 12120, interval_runtime: 0.8004, interval_samples_per_second: 49.974, interval_steps_per_second: 6.247, epoch: 17.9556\r\n",
      "loss: 0.00774599, learning_rate: 3.056e-06, global_step: 12125, interval_runtime: 0.8589, interval_samples_per_second: 46.57, interval_steps_per_second: 5.821, epoch: 17.963\r\n",
      "loss: 0.00709766, learning_rate: 3.044e-06, global_step: 12130, interval_runtime: 0.8543, interval_samples_per_second: 46.823, interval_steps_per_second: 5.853, epoch: 17.9704\r\n",
      "loss: 0.00777257, learning_rate: 3.033e-06, global_step: 12135, interval_runtime: 0.9784, interval_samples_per_second: 40.882, interval_steps_per_second: 5.11, epoch: 17.9778\r\n",
      "loss: 0.00129396, learning_rate: 3.022e-06, global_step: 12140, interval_runtime: 0.8546, interval_samples_per_second: 46.803, interval_steps_per_second: 5.85, epoch: 17.9852\r\n",
      "loss: 0.00878265, learning_rate: 3.011e-06, global_step: 12145, interval_runtime: 0.765, interval_samples_per_second: 52.289, interval_steps_per_second: 6.536, epoch: 17.9926\r\n",
      "loss: 0.00096236, learning_rate: 3e-06, global_step: 12150, interval_runtime: 0.721, interval_samples_per_second: 55.482, interval_steps_per_second: 6.935, epoch: 18.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:19:23,137] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:19:23,139] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:19:23,141] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:19:23,143] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:19:23,145] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.7695221304893494, eval_micro_f1_score: 0.5745628505443747, eval_macro_f1_score: 0.46770808329132973, eval_runtime: 13.3022, eval_samples_per_second: 142.532, eval_steps_per_second: 17.817, epoch: 18.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:19:36,444] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-12150\r\n",
      "[2023-01-10 11:19:36,446] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:19:39,811] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-12150/tokenizer_config.json\r\n",
      "[2023-01-10 11:19:39,815] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-12150/special_tokens_map.json\r\n",
      "[2023-01-10 11:19:46,521] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-10800] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00227365, learning_rate: 2.989e-06, global_step: 12155, interval_runtime: 24.8359, interval_samples_per_second: 1.611, interval_steps_per_second: 0.201, epoch: 18.0074\r\n",
      "loss: 0.01127937, learning_rate: 2.978e-06, global_step: 12160, interval_runtime: 0.7994, interval_samples_per_second: 50.036, interval_steps_per_second: 6.254, epoch: 18.0148\r\n",
      "loss: 0.01177429, learning_rate: 2.967e-06, global_step: 12165, interval_runtime: 0.8311, interval_samples_per_second: 48.13, interval_steps_per_second: 6.016, epoch: 18.0222\r\n",
      "loss: 0.0009459, learning_rate: 2.956e-06, global_step: 12170, interval_runtime: 0.8747, interval_samples_per_second: 45.729, interval_steps_per_second: 5.716, epoch: 18.0296\r\n",
      "loss: 0.00067603, learning_rate: 2.944e-06, global_step: 12175, interval_runtime: 0.7696, interval_samples_per_second: 51.974, interval_steps_per_second: 6.497, epoch: 18.037\r\n",
      "loss: 0.00234358, learning_rate: 2.933e-06, global_step: 12180, interval_runtime: 0.8304, interval_samples_per_second: 48.172, interval_steps_per_second: 6.022, epoch: 18.0444\r\n",
      "loss: 0.00923695, learning_rate: 2.922e-06, global_step: 12185, interval_runtime: 0.7098, interval_samples_per_second: 56.356, interval_steps_per_second: 7.044, epoch: 18.0519\r\n",
      "loss: 0.00521727, learning_rate: 2.911e-06, global_step: 12190, interval_runtime: 0.7647, interval_samples_per_second: 52.309, interval_steps_per_second: 6.539, epoch: 18.0593\r\n",
      "loss: 0.00446168, learning_rate: 2.9e-06, global_step: 12195, interval_runtime: 0.8719, interval_samples_per_second: 45.876, interval_steps_per_second: 5.735, epoch: 18.0667\r\n",
      "loss: 0.0033693, learning_rate: 2.889e-06, global_step: 12200, interval_runtime: 0.8504, interval_samples_per_second: 47.034, interval_steps_per_second: 5.879, epoch: 18.0741\r\n",
      "loss: 0.00300368, learning_rate: 2.878e-06, global_step: 12205, interval_runtime: 0.8607, interval_samples_per_second: 46.475, interval_steps_per_second: 5.809, epoch: 18.0815\r\n",
      "loss: 0.00080541, learning_rate: 2.867e-06, global_step: 12210, interval_runtime: 0.8071, interval_samples_per_second: 49.56, interval_steps_per_second: 6.195, epoch: 18.0889\r\n",
      "loss: 0.00920372, learning_rate: 2.856e-06, global_step: 12215, interval_runtime: 0.9019, interval_samples_per_second: 44.348, interval_steps_per_second: 5.544, epoch: 18.0963\r\n",
      "loss: 0.00091484, learning_rate: 2.844e-06, global_step: 12220, interval_runtime: 0.813, interval_samples_per_second: 49.198, interval_steps_per_second: 6.15, epoch: 18.1037\r\n",
      "loss: 0.00583019, learning_rate: 2.833e-06, global_step: 12225, interval_runtime: 0.8817, interval_samples_per_second: 45.367, interval_steps_per_second: 5.671, epoch: 18.1111\r\n",
      "loss: 0.00075148, learning_rate: 2.822e-06, global_step: 12230, interval_runtime: 0.7517, interval_samples_per_second: 53.215, interval_steps_per_second: 6.652, epoch: 18.1185\r\n",
      "loss: 0.00069745, learning_rate: 2.811e-06, global_step: 12235, interval_runtime: 0.8217, interval_samples_per_second: 48.682, interval_steps_per_second: 6.085, epoch: 18.1259\r\n",
      "loss: 0.00057763, learning_rate: 2.8e-06, global_step: 12240, interval_runtime: 0.9828, interval_samples_per_second: 40.699, interval_steps_per_second: 5.087, epoch: 18.1333\r\n",
      "loss: 0.00250974, learning_rate: 2.789e-06, global_step: 12245, interval_runtime: 0.8218, interval_samples_per_second: 48.677, interval_steps_per_second: 6.085, epoch: 18.1407\r\n",
      "loss: 0.01385065, learning_rate: 2.778e-06, global_step: 12250, interval_runtime: 0.7388, interval_samples_per_second: 54.14, interval_steps_per_second: 6.768, epoch: 18.1481\r\n",
      "loss: 0.00081004, learning_rate: 2.767e-06, global_step: 12255, interval_runtime: 0.7645, interval_samples_per_second: 52.322, interval_steps_per_second: 6.54, epoch: 18.1556\r\n",
      "loss: 0.01096976, learning_rate: 2.756e-06, global_step: 12260, interval_runtime: 0.7727, interval_samples_per_second: 51.767, interval_steps_per_second: 6.471, epoch: 18.163\r\n",
      "loss: 0.0007245, learning_rate: 2.744e-06, global_step: 12265, interval_runtime: 0.8792, interval_samples_per_second: 45.498, interval_steps_per_second: 5.687, epoch: 18.1704\r\n",
      "loss: 0.00095267, learning_rate: 2.733e-06, global_step: 12270, interval_runtime: 0.8593, interval_samples_per_second: 46.548, interval_steps_per_second: 5.818, epoch: 18.1778\r\n",
      "loss: 0.00083631, learning_rate: 2.722e-06, global_step: 12275, interval_runtime: 0.9241, interval_samples_per_second: 43.285, interval_steps_per_second: 5.411, epoch: 18.1852\r\n",
      "loss: 0.006397, learning_rate: 2.711e-06, global_step: 12280, interval_runtime: 0.8558, interval_samples_per_second: 46.74, interval_steps_per_second: 5.842, epoch: 18.1926\r\n",
      "loss: 0.01481181, learning_rate: 2.7e-06, global_step: 12285, interval_runtime: 0.8017, interval_samples_per_second: 49.892, interval_steps_per_second: 6.237, epoch: 18.2\r\n",
      "loss: 0.00408447, learning_rate: 2.689e-06, global_step: 12290, interval_runtime: 0.7328, interval_samples_per_second: 54.587, interval_steps_per_second: 6.823, epoch: 18.2074\r\n",
      "loss: 0.00518617, learning_rate: 2.678e-06, global_step: 12295, interval_runtime: 0.831, interval_samples_per_second: 48.134, interval_steps_per_second: 6.017, epoch: 18.2148\r\n",
      "loss: 0.00062221, learning_rate: 2.667e-06, global_step: 12300, interval_runtime: 0.7914, interval_samples_per_second: 50.544, interval_steps_per_second: 6.318, epoch: 18.2222\r\n",
      "loss: 0.00322495, learning_rate: 2.656e-06, global_step: 12305, interval_runtime: 0.82, interval_samples_per_second: 48.781, interval_steps_per_second: 6.098, epoch: 18.2296\r\n",
      "loss: 0.00919629, learning_rate: 2.644e-06, global_step: 12310, interval_runtime: 0.7785, interval_samples_per_second: 51.381, interval_steps_per_second: 6.423, epoch: 18.237\r\n",
      "loss: 0.00054915, learning_rate: 2.633e-06, global_step: 12315, interval_runtime: 0.8748, interval_samples_per_second: 45.722, interval_steps_per_second: 5.715, epoch: 18.2444\r\n",
      "loss: 0.01258282, learning_rate: 2.622e-06, global_step: 12320, interval_runtime: 1.014, interval_samples_per_second: 39.446, interval_steps_per_second: 4.931, epoch: 18.2519\r\n",
      "loss: 0.00363184, learning_rate: 2.611e-06, global_step: 12325, interval_runtime: 0.8778, interval_samples_per_second: 45.568, interval_steps_per_second: 5.696, epoch: 18.2593\r\n",
      "loss: 0.00375047, learning_rate: 2.6e-06, global_step: 12330, interval_runtime: 0.83, interval_samples_per_second: 48.194, interval_steps_per_second: 6.024, epoch: 18.2667\r\n",
      "loss: 0.00287163, learning_rate: 2.589e-06, global_step: 12335, interval_runtime: 0.9032, interval_samples_per_second: 44.289, interval_steps_per_second: 5.536, epoch: 18.2741\r\n",
      "loss: 0.00118417, learning_rate: 2.578e-06, global_step: 12340, interval_runtime: 0.9951, interval_samples_per_second: 40.196, interval_steps_per_second: 5.024, epoch: 18.2815\r\n",
      "loss: 0.00089875, learning_rate: 2.567e-06, global_step: 12345, interval_runtime: 0.9299, interval_samples_per_second: 43.017, interval_steps_per_second: 5.377, epoch: 18.2889\r\n",
      "loss: 0.01360787, learning_rate: 2.556e-06, global_step: 12350, interval_runtime: 0.936, interval_samples_per_second: 42.735, interval_steps_per_second: 5.342, epoch: 18.2963\r\n",
      "loss: 0.00645302, learning_rate: 2.544e-06, global_step: 12355, interval_runtime: 0.7536, interval_samples_per_second: 53.082, interval_steps_per_second: 6.635, epoch: 18.3037\r\n",
      "loss: 0.00399354, learning_rate: 2.533e-06, global_step: 12360, interval_runtime: 0.8198, interval_samples_per_second: 48.792, interval_steps_per_second: 6.099, epoch: 18.3111\r\n",
      "loss: 0.00078459, learning_rate: 2.522e-06, global_step: 12365, interval_runtime: 0.7734, interval_samples_per_second: 51.72, interval_steps_per_second: 6.465, epoch: 18.3185\r\n",
      "loss: 0.00103172, learning_rate: 2.511e-06, global_step: 12370, interval_runtime: 0.8083, interval_samples_per_second: 49.484, interval_steps_per_second: 6.186, epoch: 18.3259\r\n",
      "loss: 0.0006959, learning_rate: 2.5e-06, global_step: 12375, interval_runtime: 0.8029, interval_samples_per_second: 49.822, interval_steps_per_second: 6.228, epoch: 18.3333\r\n",
      "loss: 0.00666105, learning_rate: 2.489e-06, global_step: 12380, interval_runtime: 0.7912, interval_samples_per_second: 50.558, interval_steps_per_second: 6.32, epoch: 18.3407\r\n",
      "loss: 0.00397005, learning_rate: 2.478e-06, global_step: 12385, interval_runtime: 0.817, interval_samples_per_second: 48.957, interval_steps_per_second: 6.12, epoch: 18.3481\r\n",
      "loss: 0.00247292, learning_rate: 2.467e-06, global_step: 12390, interval_runtime: 0.8778, interval_samples_per_second: 45.568, interval_steps_per_second: 5.696, epoch: 18.3556\r\n",
      "loss: 0.00087828, learning_rate: 2.456e-06, global_step: 12395, interval_runtime: 0.9909, interval_samples_per_second: 40.365, interval_steps_per_second: 5.046, epoch: 18.363\r\n",
      "loss: 0.01387934, learning_rate: 2.444e-06, global_step: 12400, interval_runtime: 0.8722, interval_samples_per_second: 45.86, interval_steps_per_second: 5.732, epoch: 18.3704\r\n",
      "loss: 0.00220361, learning_rate: 2.433e-06, global_step: 12405, interval_runtime: 0.7394, interval_samples_per_second: 54.098, interval_steps_per_second: 6.762, epoch: 18.3778\r\n",
      "loss: 0.00580282, learning_rate: 2.422e-06, global_step: 12410, interval_runtime: 0.7871, interval_samples_per_second: 50.816, interval_steps_per_second: 6.352, epoch: 18.3852\r\n",
      "loss: 0.00671566, learning_rate: 2.411e-06, global_step: 12415, interval_runtime: 0.7287, interval_samples_per_second: 54.891, interval_steps_per_second: 6.861, epoch: 18.3926\r\n",
      "loss: 0.00641093, learning_rate: 2.4e-06, global_step: 12420, interval_runtime: 0.7812, interval_samples_per_second: 51.206, interval_steps_per_second: 6.401, epoch: 18.4\r\n",
      "loss: 0.0085171, learning_rate: 2.389e-06, global_step: 12425, interval_runtime: 0.897, interval_samples_per_second: 44.591, interval_steps_per_second: 5.574, epoch: 18.4074\r\n",
      "loss: 0.00528584, learning_rate: 2.378e-06, global_step: 12430, interval_runtime: 0.8769, interval_samples_per_second: 45.616, interval_steps_per_second: 5.702, epoch: 18.4148\r\n",
      "loss: 0.00745355, learning_rate: 2.367e-06, global_step: 12435, interval_runtime: 1.1309, interval_samples_per_second: 35.371, interval_steps_per_second: 4.421, epoch: 18.4222\r\n",
      "loss: 0.0081997, learning_rate: 2.356e-06, global_step: 12440, interval_runtime: 0.7833, interval_samples_per_second: 51.065, interval_steps_per_second: 6.383, epoch: 18.4296\r\n",
      "loss: 0.00065019, learning_rate: 2.344e-06, global_step: 12445, interval_runtime: 0.8327, interval_samples_per_second: 48.038, interval_steps_per_second: 6.005, epoch: 18.437\r\n",
      "loss: 0.0153758, learning_rate: 2.333e-06, global_step: 12450, interval_runtime: 0.9798, interval_samples_per_second: 40.823, interval_steps_per_second: 5.103, epoch: 18.4444\r\n",
      "loss: 0.0080171, learning_rate: 2.322e-06, global_step: 12455, interval_runtime: 0.8218, interval_samples_per_second: 48.672, interval_steps_per_second: 6.084, epoch: 18.4519\r\n",
      "loss: 0.02137358, learning_rate: 2.311e-06, global_step: 12460, interval_runtime: 0.7921, interval_samples_per_second: 50.5, interval_steps_per_second: 6.313, epoch: 18.4593\r\n",
      "loss: 0.00645132, learning_rate: 2.3e-06, global_step: 12465, interval_runtime: 0.717, interval_samples_per_second: 55.787, interval_steps_per_second: 6.973, epoch: 18.4667\r\n",
      "loss: 0.00377965, learning_rate: 2.289e-06, global_step: 12470, interval_runtime: 0.7737, interval_samples_per_second: 51.701, interval_steps_per_second: 6.463, epoch: 18.4741\r\n",
      "loss: 0.00231486, learning_rate: 2.278e-06, global_step: 12475, interval_runtime: 0.7452, interval_samples_per_second: 53.676, interval_steps_per_second: 6.71, epoch: 18.4815\r\n",
      "loss: 0.00371059, learning_rate: 2.267e-06, global_step: 12480, interval_runtime: 0.9007, interval_samples_per_second: 44.409, interval_steps_per_second: 5.551, epoch: 18.4889\r\n",
      "loss: 0.0086557, learning_rate: 2.256e-06, global_step: 12485, interval_runtime: 1.064, interval_samples_per_second: 37.593, interval_steps_per_second: 4.699, epoch: 18.4963\r\n",
      "loss: 0.00091595, learning_rate: 2.244e-06, global_step: 12490, interval_runtime: 0.8629, interval_samples_per_second: 46.353, interval_steps_per_second: 5.794, epoch: 18.5037\r\n",
      "loss: 0.00613038, learning_rate: 2.233e-06, global_step: 12495, interval_runtime: 0.7992, interval_samples_per_second: 50.051, interval_steps_per_second: 6.256, epoch: 18.5111\r\n",
      "loss: 0.0008945, learning_rate: 2.222e-06, global_step: 12500, interval_runtime: 0.9404, interval_samples_per_second: 42.536, interval_steps_per_second: 5.317, epoch: 18.5185\r\n",
      "loss: 0.00708864, learning_rate: 2.211e-06, global_step: 12505, interval_runtime: 0.9288, interval_samples_per_second: 43.066, interval_steps_per_second: 5.383, epoch: 18.5259\r\n",
      "loss: 0.00852526, learning_rate: 2.2e-06, global_step: 12510, interval_runtime: 0.7923, interval_samples_per_second: 50.489, interval_steps_per_second: 6.311, epoch: 18.5333\r\n",
      "loss: 0.00333727, learning_rate: 2.189e-06, global_step: 12515, interval_runtime: 0.7304, interval_samples_per_second: 54.763, interval_steps_per_second: 6.845, epoch: 18.5407\r\n",
      "loss: 0.01605009, learning_rate: 2.178e-06, global_step: 12520, interval_runtime: 0.785, interval_samples_per_second: 50.957, interval_steps_per_second: 6.37, epoch: 18.5481\r\n",
      "loss: 0.00233472, learning_rate: 2.167e-06, global_step: 12525, interval_runtime: 0.6879, interval_samples_per_second: 58.144, interval_steps_per_second: 7.268, epoch: 18.5556\r\n",
      "loss: 0.00573565, learning_rate: 2.156e-06, global_step: 12530, interval_runtime: 0.9264, interval_samples_per_second: 43.178, interval_steps_per_second: 5.397, epoch: 18.563\r\n",
      "loss: 0.00957173, learning_rate: 2.144e-06, global_step: 12535, interval_runtime: 0.8327, interval_samples_per_second: 48.039, interval_steps_per_second: 6.005, epoch: 18.5704\r\n",
      "loss: 0.00495205, learning_rate: 2.133e-06, global_step: 12540, interval_runtime: 0.7937, interval_samples_per_second: 50.394, interval_steps_per_second: 6.299, epoch: 18.5778\r\n",
      "loss: 0.0101828, learning_rate: 2.122e-06, global_step: 12545, interval_runtime: 0.9039, interval_samples_per_second: 44.253, interval_steps_per_second: 5.532, epoch: 18.5852\r\n",
      "loss: 0.00632779, learning_rate: 2.111e-06, global_step: 12550, interval_runtime: 0.8286, interval_samples_per_second: 48.276, interval_steps_per_second: 6.035, epoch: 18.5926\r\n",
      "loss: 0.0164753, learning_rate: 2.1e-06, global_step: 12555, interval_runtime: 0.8406, interval_samples_per_second: 47.586, interval_steps_per_second: 5.948, epoch: 18.6\r\n",
      "loss: 0.01075829, learning_rate: 2.089e-06, global_step: 12560, interval_runtime: 0.8862, interval_samples_per_second: 45.135, interval_steps_per_second: 5.642, epoch: 18.6074\r\n",
      "loss: 0.00795637, learning_rate: 2.078e-06, global_step: 12565, interval_runtime: 0.9263, interval_samples_per_second: 43.181, interval_steps_per_second: 5.398, epoch: 18.6148\r\n",
      "loss: 0.00363503, learning_rate: 2.067e-06, global_step: 12570, interval_runtime: 0.7923, interval_samples_per_second: 50.485, interval_steps_per_second: 6.311, epoch: 18.6222\r\n",
      "loss: 0.00077837, learning_rate: 2.056e-06, global_step: 12575, interval_runtime: 0.7993, interval_samples_per_second: 50.045, interval_steps_per_second: 6.256, epoch: 18.6296\r\n",
      "loss: 0.00103466, learning_rate: 2.044e-06, global_step: 12580, interval_runtime: 0.7155, interval_samples_per_second: 55.905, interval_steps_per_second: 6.988, epoch: 18.637\r\n",
      "loss: 0.01048354, learning_rate: 2.033e-06, global_step: 12585, interval_runtime: 0.8382, interval_samples_per_second: 47.723, interval_steps_per_second: 5.965, epoch: 18.6444\r\n",
      "loss: 0.00093558, learning_rate: 2.022e-06, global_step: 12590, interval_runtime: 0.6784, interval_samples_per_second: 58.966, interval_steps_per_second: 7.371, epoch: 18.6519\r\n",
      "loss: 0.00288107, learning_rate: 2.011e-06, global_step: 12595, interval_runtime: 0.809, interval_samples_per_second: 49.445, interval_steps_per_second: 6.181, epoch: 18.6593\r\n",
      "loss: 0.00066566, learning_rate: 2e-06, global_step: 12600, interval_runtime: 0.8588, interval_samples_per_second: 46.577, interval_steps_per_second: 5.822, epoch: 18.6667\r\n",
      "loss: 0.00736853, learning_rate: 1.989e-06, global_step: 12605, interval_runtime: 0.8544, interval_samples_per_second: 46.819, interval_steps_per_second: 5.852, epoch: 18.6741\r\n",
      "loss: 0.00561866, learning_rate: 1.978e-06, global_step: 12610, interval_runtime: 0.997, interval_samples_per_second: 40.121, interval_steps_per_second: 5.015, epoch: 18.6815\r\n",
      "loss: 0.00459767, learning_rate: 1.967e-06, global_step: 12615, interval_runtime: 0.7907, interval_samples_per_second: 50.589, interval_steps_per_second: 6.324, epoch: 18.6889\r\n",
      "loss: 0.01513697, learning_rate: 1.956e-06, global_step: 12620, interval_runtime: 0.8278, interval_samples_per_second: 48.323, interval_steps_per_second: 6.04, epoch: 18.6963\r\n",
      "loss: 0.00859883, learning_rate: 1.944e-06, global_step: 12625, interval_runtime: 0.8683, interval_samples_per_second: 46.07, interval_steps_per_second: 5.759, epoch: 18.7037\r\n",
      "loss: 0.01096728, learning_rate: 1.933e-06, global_step: 12630, interval_runtime: 0.7622, interval_samples_per_second: 52.479, interval_steps_per_second: 6.56, epoch: 18.7111\r\n",
      "loss: 0.000657, learning_rate: 1.922e-06, global_step: 12635, interval_runtime: 0.7168, interval_samples_per_second: 55.801, interval_steps_per_second: 6.975, epoch: 18.7185\r\n",
      "loss: 0.00360536, learning_rate: 1.911e-06, global_step: 12640, interval_runtime: 0.765, interval_samples_per_second: 52.285, interval_steps_per_second: 6.536, epoch: 18.7259\r\n",
      "loss: 0.00531677, learning_rate: 1.9e-06, global_step: 12645, interval_runtime: 0.8162, interval_samples_per_second: 49.005, interval_steps_per_second: 6.126, epoch: 18.7333\r\n",
      "loss: 0.01615861, learning_rate: 1.889e-06, global_step: 12650, interval_runtime: 0.7189, interval_samples_per_second: 55.643, interval_steps_per_second: 6.955, epoch: 18.7407\r\n",
      "loss: 0.01350152, learning_rate: 1.878e-06, global_step: 12655, interval_runtime: 1.0277, interval_samples_per_second: 38.922, interval_steps_per_second: 4.865, epoch: 18.7481\r\n",
      "loss: 0.01043752, learning_rate: 1.867e-06, global_step: 12660, interval_runtime: 0.6854, interval_samples_per_second: 58.361, interval_steps_per_second: 7.295, epoch: 18.7556\r\n",
      "loss: 0.00103069, learning_rate: 1.856e-06, global_step: 12665, interval_runtime: 0.7639, interval_samples_per_second: 52.365, interval_steps_per_second: 6.546, epoch: 18.763\r\n",
      "loss: 0.00501647, learning_rate: 1.844e-06, global_step: 12670, interval_runtime: 0.8949, interval_samples_per_second: 44.697, interval_steps_per_second: 5.587, epoch: 18.7704\r\n",
      "loss: 0.0042583, learning_rate: 1.833e-06, global_step: 12675, interval_runtime: 0.7697, interval_samples_per_second: 51.967, interval_steps_per_second: 6.496, epoch: 18.7778\r\n",
      "loss: 0.00261791, learning_rate: 1.822e-06, global_step: 12680, interval_runtime: 0.9123, interval_samples_per_second: 43.845, interval_steps_per_second: 5.481, epoch: 18.7852\r\n",
      "loss: 0.00655568, learning_rate: 1.811e-06, global_step: 12685, interval_runtime: 0.9656, interval_samples_per_second: 41.426, interval_steps_per_second: 5.178, epoch: 18.7926\r\n",
      "loss: 0.0080223, learning_rate: 1.8e-06, global_step: 12690, interval_runtime: 0.8154, interval_samples_per_second: 49.057, interval_steps_per_second: 6.132, epoch: 18.8\r\n",
      "loss: 0.00485766, learning_rate: 1.789e-06, global_step: 12695, interval_runtime: 0.9618, interval_samples_per_second: 41.589, interval_steps_per_second: 5.199, epoch: 18.8074\r\n",
      "loss: 0.00306381, learning_rate: 1.778e-06, global_step: 12700, interval_runtime: 0.9694, interval_samples_per_second: 41.264, interval_steps_per_second: 5.158, epoch: 18.8148\r\n",
      "loss: 0.01094112, learning_rate: 1.767e-06, global_step: 12705, interval_runtime: 0.8933, interval_samples_per_second: 44.78, interval_steps_per_second: 5.598, epoch: 18.8222\r\n",
      "loss: 0.0140211, learning_rate: 1.756e-06, global_step: 12710, interval_runtime: 0.7414, interval_samples_per_second: 53.953, interval_steps_per_second: 6.744, epoch: 18.8296\r\n",
      "loss: 0.00194707, learning_rate: 1.744e-06, global_step: 12715, interval_runtime: 0.8805, interval_samples_per_second: 45.428, interval_steps_per_second: 5.679, epoch: 18.837\r\n",
      "loss: 0.00843739, learning_rate: 1.733e-06, global_step: 12720, interval_runtime: 0.9172, interval_samples_per_second: 43.612, interval_steps_per_second: 5.451, epoch: 18.8444\r\n",
      "loss: 0.00249618, learning_rate: 1.722e-06, global_step: 12725, interval_runtime: 0.8469, interval_samples_per_second: 47.233, interval_steps_per_second: 5.904, epoch: 18.8519\r\n",
      "loss: 0.00628369, learning_rate: 1.711e-06, global_step: 12730, interval_runtime: 0.7444, interval_samples_per_second: 53.737, interval_steps_per_second: 6.717, epoch: 18.8593\r\n",
      "loss: 0.0066868, learning_rate: 1.7e-06, global_step: 12735, interval_runtime: 0.8863, interval_samples_per_second: 45.131, interval_steps_per_second: 5.641, epoch: 18.8667\r\n",
      "loss: 0.0011564, learning_rate: 1.689e-06, global_step: 12740, interval_runtime: 0.8606, interval_samples_per_second: 46.48, interval_steps_per_second: 5.81, epoch: 18.8741\r\n",
      "loss: 0.00548558, learning_rate: 1.678e-06, global_step: 12745, interval_runtime: 0.7043, interval_samples_per_second: 56.79, interval_steps_per_second: 7.099, epoch: 18.8815\r\n",
      "loss: 0.0053114, learning_rate: 1.667e-06, global_step: 12750, interval_runtime: 0.8239, interval_samples_per_second: 48.55, interval_steps_per_second: 6.069, epoch: 18.8889\r\n",
      "loss: 0.00716722, learning_rate: 1.656e-06, global_step: 12755, interval_runtime: 0.7679, interval_samples_per_second: 52.09, interval_steps_per_second: 6.511, epoch: 18.8963\r\n",
      "loss: 0.00574502, learning_rate: 1.644e-06, global_step: 12760, interval_runtime: 0.756, interval_samples_per_second: 52.909, interval_steps_per_second: 6.614, epoch: 18.9037\r\n",
      "loss: 0.00423035, learning_rate: 1.633e-06, global_step: 12765, interval_runtime: 0.8771, interval_samples_per_second: 45.603, interval_steps_per_second: 5.7, epoch: 18.9111\r\n",
      "loss: 0.00068898, learning_rate: 1.622e-06, global_step: 12770, interval_runtime: 0.8874, interval_samples_per_second: 45.078, interval_steps_per_second: 5.635, epoch: 18.9185\r\n",
      "loss: 0.00883854, learning_rate: 1.611e-06, global_step: 12775, interval_runtime: 0.7979, interval_samples_per_second: 50.129, interval_steps_per_second: 6.266, epoch: 18.9259\r\n",
      "loss: 0.00064445, learning_rate: 1.6e-06, global_step: 12780, interval_runtime: 0.8686, interval_samples_per_second: 46.051, interval_steps_per_second: 5.756, epoch: 18.9333\r\n",
      "loss: 0.02128275, learning_rate: 1.589e-06, global_step: 12785, interval_runtime: 0.8984, interval_samples_per_second: 44.524, interval_steps_per_second: 5.566, epoch: 18.9407\r\n",
      "loss: 0.00577702, learning_rate: 1.578e-06, global_step: 12790, interval_runtime: 0.7616, interval_samples_per_second: 52.524, interval_steps_per_second: 6.566, epoch: 18.9481\r\n",
      "loss: 0.00777109, learning_rate: 1.567e-06, global_step: 12795, interval_runtime: 0.7793, interval_samples_per_second: 51.329, interval_steps_per_second: 6.416, epoch: 18.9556\r\n",
      "loss: 0.00294424, learning_rate: 1.556e-06, global_step: 12800, interval_runtime: 0.7881, interval_samples_per_second: 50.752, interval_steps_per_second: 6.344, epoch: 18.963\r\n",
      "loss: 0.00970237, learning_rate: 1.544e-06, global_step: 12805, interval_runtime: 0.906, interval_samples_per_second: 44.149, interval_steps_per_second: 5.519, epoch: 18.9704\r\n",
      "loss: 0.00698876, learning_rate: 1.533e-06, global_step: 12810, interval_runtime: 0.8319, interval_samples_per_second: 48.085, interval_steps_per_second: 6.011, epoch: 18.9778\r\n",
      "loss: 0.0006333, learning_rate: 1.522e-06, global_step: 12815, interval_runtime: 0.9558, interval_samples_per_second: 41.848, interval_steps_per_second: 5.231, epoch: 18.9852\r\n",
      "loss: 0.00799115, learning_rate: 1.511e-06, global_step: 12820, interval_runtime: 0.8055, interval_samples_per_second: 49.659, interval_steps_per_second: 6.207, epoch: 18.9926\r\n",
      "loss: 0.01399286, learning_rate: 1.5e-06, global_step: 12825, interval_runtime: 0.7574, interval_samples_per_second: 52.812, interval_steps_per_second: 6.601, epoch: 19.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:21:40,065] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:21:40,067] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:21:40,070] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:21:40,072] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:21:40,074] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.7748196721076965, eval_micro_f1_score: 0.5715005458056932, eval_macro_f1_score: 0.46803429808673175, eval_runtime: 13.5146, eval_samples_per_second: 140.293, eval_steps_per_second: 17.537, epoch: 19.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:21:53,584] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-12825\r\n",
      "[2023-01-10 11:21:53,586] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:21:56,970] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-12825/tokenizer_config.json\r\n",
      "[2023-01-10 11:21:56,973] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-12825/special_tokens_map.json\r\n",
      "[2023-01-10 11:22:03,714] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-12150] due to args.save_total_limit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00597225, learning_rate: 1.489e-06, global_step: 12830, interval_runtime: 25.2274, interval_samples_per_second: 1.586, interval_steps_per_second: 0.198, epoch: 19.0074\r\n",
      "loss: 0.00520583, learning_rate: 1.478e-06, global_step: 12835, interval_runtime: 0.833, interval_samples_per_second: 48.019, interval_steps_per_second: 6.002, epoch: 19.0148\r\n",
      "loss: 0.00780163, learning_rate: 1.467e-06, global_step: 12840, interval_runtime: 0.866, interval_samples_per_second: 46.19, interval_steps_per_second: 5.774, epoch: 19.0222\r\n",
      "loss: 0.01672464, learning_rate: 1.456e-06, global_step: 12845, interval_runtime: 0.9278, interval_samples_per_second: 43.114, interval_steps_per_second: 5.389, epoch: 19.0296\r\n",
      "loss: 0.00233791, learning_rate: 1.444e-06, global_step: 12850, interval_runtime: 0.8085, interval_samples_per_second: 49.472, interval_steps_per_second: 6.184, epoch: 19.037\r\n",
      "loss: 0.00303548, learning_rate: 1.433e-06, global_step: 12855, interval_runtime: 0.8265, interval_samples_per_second: 48.396, interval_steps_per_second: 6.049, epoch: 19.0444\r\n",
      "loss: 0.00295787, learning_rate: 1.422e-06, global_step: 12860, interval_runtime: 0.7863, interval_samples_per_second: 50.869, interval_steps_per_second: 6.359, epoch: 19.0519\r\n",
      "loss: 0.00070122, learning_rate: 1.411e-06, global_step: 12865, interval_runtime: 0.8497, interval_samples_per_second: 47.074, interval_steps_per_second: 5.884, epoch: 19.0593\r\n",
      "loss: 0.00733049, learning_rate: 1.4e-06, global_step: 12870, interval_runtime: 0.8739, interval_samples_per_second: 45.771, interval_steps_per_second: 5.721, epoch: 19.0667\r\n",
      "loss: 0.00316984, learning_rate: 1.389e-06, global_step: 12875, interval_runtime: 0.7441, interval_samples_per_second: 53.759, interval_steps_per_second: 6.72, epoch: 19.0741\r\n",
      "loss: 0.0009285, learning_rate: 1.378e-06, global_step: 12880, interval_runtime: 0.76, interval_samples_per_second: 52.631, interval_steps_per_second: 6.579, epoch: 19.0815\r\n",
      "loss: 0.0035602, learning_rate: 1.367e-06, global_step: 12885, interval_runtime: 0.7701, interval_samples_per_second: 51.945, interval_steps_per_second: 6.493, epoch: 19.0889\r\n",
      "loss: 0.00064236, learning_rate: 1.356e-06, global_step: 12890, interval_runtime: 0.8205, interval_samples_per_second: 48.751, interval_steps_per_second: 6.094, epoch: 19.0963\r\n",
      "loss: 0.00470889, learning_rate: 1.344e-06, global_step: 12895, interval_runtime: 0.7738, interval_samples_per_second: 51.69, interval_steps_per_second: 6.461, epoch: 19.1037\r\n",
      "loss: 0.00065213, learning_rate: 1.333e-06, global_step: 12900, interval_runtime: 0.7825, interval_samples_per_second: 51.117, interval_steps_per_second: 6.39, epoch: 19.1111\r\n",
      "loss: 0.00336673, learning_rate: 1.322e-06, global_step: 12905, interval_runtime: 0.9422, interval_samples_per_second: 42.454, interval_steps_per_second: 5.307, epoch: 19.1185\r\n",
      "loss: 0.00087061, learning_rate: 1.311e-06, global_step: 12910, interval_runtime: 0.7567, interval_samples_per_second: 52.858, interval_steps_per_second: 6.607, epoch: 19.1259\r\n",
      "loss: 0.00086557, learning_rate: 1.3e-06, global_step: 12915, interval_runtime: 0.8673, interval_samples_per_second: 46.118, interval_steps_per_second: 5.765, epoch: 19.1333\r\n",
      "loss: 0.00717635, learning_rate: 1.289e-06, global_step: 12920, interval_runtime: 0.9278, interval_samples_per_second: 43.113, interval_steps_per_second: 5.389, epoch: 19.1407\r\n",
      "loss: 0.00548813, learning_rate: 1.278e-06, global_step: 12925, interval_runtime: 0.886, interval_samples_per_second: 45.149, interval_steps_per_second: 5.644, epoch: 19.1481\r\n",
      "loss: 0.00626111, learning_rate: 1.267e-06, global_step: 12930, interval_runtime: 0.9356, interval_samples_per_second: 42.754, interval_steps_per_second: 5.344, epoch: 19.1556\r\n",
      "loss: 0.00091988, learning_rate: 1.256e-06, global_step: 12935, interval_runtime: 0.7498, interval_samples_per_second: 53.345, interval_steps_per_second: 6.668, epoch: 19.163\r\n",
      "loss: 0.00059545, learning_rate: 1.244e-06, global_step: 12940, interval_runtime: 0.9576, interval_samples_per_second: 41.771, interval_steps_per_second: 5.221, epoch: 19.1704\r\n",
      "loss: 0.00428755, learning_rate: 1.233e-06, global_step: 12945, interval_runtime: 0.8067, interval_samples_per_second: 49.584, interval_steps_per_second: 6.198, epoch: 19.1778\r\n",
      "loss: 0.0005295, learning_rate: 1.222e-06, global_step: 12950, interval_runtime: 0.7187, interval_samples_per_second: 55.655, interval_steps_per_second: 6.957, epoch: 19.1852\r\n",
      "loss: 0.00490717, learning_rate: 1.211e-06, global_step: 12955, interval_runtime: 0.9102, interval_samples_per_second: 43.947, interval_steps_per_second: 5.493, epoch: 19.1926\r\n",
      "loss: 0.00359848, learning_rate: 1.2e-06, global_step: 12960, interval_runtime: 0.712, interval_samples_per_second: 56.18, interval_steps_per_second: 7.023, epoch: 19.2\r\n",
      "loss: 0.00636604, learning_rate: 1.189e-06, global_step: 12965, interval_runtime: 0.781, interval_samples_per_second: 51.219, interval_steps_per_second: 6.402, epoch: 19.2074\r\n",
      "loss: 0.00083641, learning_rate: 1.178e-06, global_step: 12970, interval_runtime: 0.7477, interval_samples_per_second: 53.497, interval_steps_per_second: 6.687, epoch: 19.2148\r\n",
      "loss: 0.00057512, learning_rate: 1.167e-06, global_step: 12975, interval_runtime: 0.8495, interval_samples_per_second: 47.086, interval_steps_per_second: 5.886, epoch: 19.2222\r\n",
      "loss: 0.00416485, learning_rate: 1.156e-06, global_step: 12980, interval_runtime: 0.8976, interval_samples_per_second: 44.565, interval_steps_per_second: 5.571, epoch: 19.2296\r\n",
      "loss: 0.00241659, learning_rate: 1.144e-06, global_step: 12985, interval_runtime: 0.8025, interval_samples_per_second: 49.845, interval_steps_per_second: 6.231, epoch: 19.237\r\n",
      "loss: 0.00213694, learning_rate: 1.133e-06, global_step: 12990, interval_runtime: 0.7973, interval_samples_per_second: 50.166, interval_steps_per_second: 6.271, epoch: 19.2444\r\n",
      "loss: 0.01079376, learning_rate: 1.122e-06, global_step: 12995, interval_runtime: 0.8908, interval_samples_per_second: 44.903, interval_steps_per_second: 5.613, epoch: 19.2519\r\n",
      "loss: 0.01295933, learning_rate: 1.111e-06, global_step: 13000, interval_runtime: 0.9209, interval_samples_per_second: 43.435, interval_steps_per_second: 5.429, epoch: 19.2593\r\n",
      "loss: 0.00063425, learning_rate: 1.1e-06, global_step: 13005, interval_runtime: 0.7869, interval_samples_per_second: 50.836, interval_steps_per_second: 6.354, epoch: 19.2667\r\n",
      "loss: 0.0081642, learning_rate: 1.089e-06, global_step: 13010, interval_runtime: 0.8872, interval_samples_per_second: 45.083, interval_steps_per_second: 5.635, epoch: 19.2741\r\n",
      "loss: 0.00716702, learning_rate: 1.078e-06, global_step: 13015, interval_runtime: 0.7939, interval_samples_per_second: 50.386, interval_steps_per_second: 6.298, epoch: 19.2815\r\n",
      "loss: 0.01119016, learning_rate: 1.067e-06, global_step: 13020, interval_runtime: 0.7696, interval_samples_per_second: 51.974, interval_steps_per_second: 6.497, epoch: 19.2889\r\n",
      "loss: 0.01257784, learning_rate: 1.056e-06, global_step: 13025, interval_runtime: 0.8058, interval_samples_per_second: 49.638, interval_steps_per_second: 6.205, epoch: 19.2963\r\n",
      "loss: 0.00696727, learning_rate: 1.044e-06, global_step: 13030, interval_runtime: 0.8357, interval_samples_per_second: 47.864, interval_steps_per_second: 5.983, epoch: 19.3037\r\n",
      "loss: 0.00335214, learning_rate: 1.033e-06, global_step: 13035, interval_runtime: 0.8221, interval_samples_per_second: 48.657, interval_steps_per_second: 6.082, epoch: 19.3111\r\n",
      "loss: 0.0027078, learning_rate: 1.022e-06, global_step: 13040, interval_runtime: 0.7655, interval_samples_per_second: 52.254, interval_steps_per_second: 6.532, epoch: 19.3185\r\n",
      "loss: 0.00879016, learning_rate: 1.011e-06, global_step: 13045, interval_runtime: 0.8274, interval_samples_per_second: 48.342, interval_steps_per_second: 6.043, epoch: 19.3259\r\n",
      "loss: 0.00100608, learning_rate: 1e-06, global_step: 13050, interval_runtime: 0.784, interval_samples_per_second: 51.017, interval_steps_per_second: 6.377, epoch: 19.3333\r\n",
      "loss: 0.00655455, learning_rate: 9.889e-07, global_step: 13055, interval_runtime: 0.8087, interval_samples_per_second: 49.464, interval_steps_per_second: 6.183, epoch: 19.3407\r\n",
      "loss: 0.00070038, learning_rate: 9.778e-07, global_step: 13060, interval_runtime: 0.8006, interval_samples_per_second: 49.965, interval_steps_per_second: 6.246, epoch: 19.3481\r\n",
      "loss: 0.00390399, learning_rate: 9.667e-07, global_step: 13065, interval_runtime: 0.8886, interval_samples_per_second: 45.015, interval_steps_per_second: 5.627, epoch: 19.3556\r\n",
      "loss: 0.00874001, learning_rate: 9.556e-07, global_step: 13070, interval_runtime: 0.8546, interval_samples_per_second: 46.805, interval_steps_per_second: 5.851, epoch: 19.363\r\n",
      "loss: 0.000516, learning_rate: 9.444e-07, global_step: 13075, interval_runtime: 0.7864, interval_samples_per_second: 50.863, interval_steps_per_second: 6.358, epoch: 19.3704\r\n",
      "loss: 0.01168379, learning_rate: 9.333e-07, global_step: 13080, interval_runtime: 0.8501, interval_samples_per_second: 47.053, interval_steps_per_second: 5.882, epoch: 19.3778\r\n",
      "loss: 0.00071144, learning_rate: 9.222e-07, global_step: 13085, interval_runtime: 0.8259, interval_samples_per_second: 48.434, interval_steps_per_second: 6.054, epoch: 19.3852\r\n",
      "loss: 0.00065285, learning_rate: 9.111e-07, global_step: 13090, interval_runtime: 0.7548, interval_samples_per_second: 52.997, interval_steps_per_second: 6.625, epoch: 19.3926\r\n",
      "loss: 0.00323922, learning_rate: 9e-07, global_step: 13095, interval_runtime: 0.8802, interval_samples_per_second: 45.445, interval_steps_per_second: 5.681, epoch: 19.4\r\n",
      "loss: 0.01417734, learning_rate: 8.889e-07, global_step: 13100, interval_runtime: 0.9115, interval_samples_per_second: 43.884, interval_steps_per_second: 5.485, epoch: 19.4074\r\n",
      "loss: 0.01483088, learning_rate: 8.778e-07, global_step: 13105, interval_runtime: 0.8141, interval_samples_per_second: 49.132, interval_steps_per_second: 6.142, epoch: 19.4148\r\n",
      "loss: 0.0080255, learning_rate: 8.667e-07, global_step: 13110, interval_runtime: 0.7605, interval_samples_per_second: 52.597, interval_steps_per_second: 6.575, epoch: 19.4222\r\n",
      "loss: 0.01058292, learning_rate: 8.556e-07, global_step: 13115, interval_runtime: 0.9935, interval_samples_per_second: 40.26, interval_steps_per_second: 5.033, epoch: 19.4296\r\n",
      "loss: 0.01321663, learning_rate: 8.444e-07, global_step: 13120, interval_runtime: 0.9133, interval_samples_per_second: 43.796, interval_steps_per_second: 5.474, epoch: 19.437\r\n",
      "loss: 0.00267364, learning_rate: 8.333e-07, global_step: 13125, interval_runtime: 0.8807, interval_samples_per_second: 45.418, interval_steps_per_second: 5.677, epoch: 19.4444\r\n",
      "loss: 0.00062233, learning_rate: 8.222e-07, global_step: 13130, interval_runtime: 0.7917, interval_samples_per_second: 50.523, interval_steps_per_second: 6.315, epoch: 19.4519\r\n",
      "loss: 0.00331106, learning_rate: 8.111e-07, global_step: 13135, interval_runtime: 0.9418, interval_samples_per_second: 42.47, interval_steps_per_second: 5.309, epoch: 19.4593\r\n",
      "loss: 0.0008335, learning_rate: 8e-07, global_step: 13140, interval_runtime: 1.004, interval_samples_per_second: 39.84, interval_steps_per_second: 4.98, epoch: 19.4667\r\n",
      "loss: 0.00086673, learning_rate: 7.889e-07, global_step: 13145, interval_runtime: 0.8166, interval_samples_per_second: 48.981, interval_steps_per_second: 6.123, epoch: 19.4741\r\n",
      "loss: 0.00107793, learning_rate: 7.778e-07, global_step: 13150, interval_runtime: 0.8134, interval_samples_per_second: 49.177, interval_steps_per_second: 6.147, epoch: 19.4815\r\n",
      "loss: 0.00074794, learning_rate: 7.667e-07, global_step: 13155, interval_runtime: 0.9377, interval_samples_per_second: 42.655, interval_steps_per_second: 5.332, epoch: 19.4889\r\n",
      "loss: 0.00052967, learning_rate: 7.556e-07, global_step: 13160, interval_runtime: 0.7621, interval_samples_per_second: 52.489, interval_steps_per_second: 6.561, epoch: 19.4963\r\n",
      "loss: 0.00406378, learning_rate: 7.444e-07, global_step: 13165, interval_runtime: 0.9963, interval_samples_per_second: 40.147, interval_steps_per_second: 5.018, epoch: 19.5037\r\n",
      "loss: 0.00211194, learning_rate: 7.333e-07, global_step: 13170, interval_runtime: 0.7838, interval_samples_per_second: 51.035, interval_steps_per_second: 6.379, epoch: 19.5111\r\n",
      "loss: 0.00062954, learning_rate: 7.222e-07, global_step: 13175, interval_runtime: 0.8789, interval_samples_per_second: 45.513, interval_steps_per_second: 5.689, epoch: 19.5185\r\n",
      "loss: 0.01208095, learning_rate: 7.111e-07, global_step: 13180, interval_runtime: 0.9079, interval_samples_per_second: 44.056, interval_steps_per_second: 5.507, epoch: 19.5259\r\n",
      "loss: 0.00495243, learning_rate: 7e-07, global_step: 13185, interval_runtime: 0.8484, interval_samples_per_second: 47.149, interval_steps_per_second: 5.894, epoch: 19.5333\r\n",
      "loss: 0.00475128, learning_rate: 6.889e-07, global_step: 13190, interval_runtime: 0.8788, interval_samples_per_second: 45.518, interval_steps_per_second: 5.69, epoch: 19.5407\r\n",
      "loss: 0.00964575, learning_rate: 6.778e-07, global_step: 13195, interval_runtime: 0.8005, interval_samples_per_second: 49.971, interval_steps_per_second: 6.246, epoch: 19.5481\r\n",
      "loss: 0.01927674, learning_rate: 6.667e-07, global_step: 13200, interval_runtime: 0.8204, interval_samples_per_second: 48.756, interval_steps_per_second: 6.094, epoch: 19.5556\r\n",
      "loss: 0.00086518, learning_rate: 6.556e-07, global_step: 13205, interval_runtime: 0.7734, interval_samples_per_second: 51.72, interval_steps_per_second: 6.465, epoch: 19.563\r\n",
      "loss: 0.0037023, learning_rate: 6.444e-07, global_step: 13210, interval_runtime: 0.8202, interval_samples_per_second: 48.767, interval_steps_per_second: 6.096, epoch: 19.5704\r\n",
      "loss: 0.00277273, learning_rate: 6.333e-07, global_step: 13215, interval_runtime: 0.762, interval_samples_per_second: 52.492, interval_steps_per_second: 6.562, epoch: 19.5778\r\n",
      "loss: 0.00078674, learning_rate: 6.222e-07, global_step: 13220, interval_runtime: 1.0671, interval_samples_per_second: 37.486, interval_steps_per_second: 4.686, epoch: 19.5852\r\n",
      "loss: 0.00272503, learning_rate: 6.111e-07, global_step: 13225, interval_runtime: 0.8679, interval_samples_per_second: 46.086, interval_steps_per_second: 5.761, epoch: 19.5926\r\n",
      "loss: 0.00362588, learning_rate: 6e-07, global_step: 13230, interval_runtime: 0.7513, interval_samples_per_second: 53.241, interval_steps_per_second: 6.655, epoch: 19.6\r\n",
      "loss: 0.00587065, learning_rate: 5.889e-07, global_step: 13235, interval_runtime: 0.7705, interval_samples_per_second: 51.918, interval_steps_per_second: 6.49, epoch: 19.6074\r\n",
      "loss: 0.00050608, learning_rate: 5.778e-07, global_step: 13240, interval_runtime: 0.8009, interval_samples_per_second: 49.943, interval_steps_per_second: 6.243, epoch: 19.6148\r\n",
      "loss: 0.00346435, learning_rate: 5.667e-07, global_step: 13245, interval_runtime: 0.8309, interval_samples_per_second: 48.142, interval_steps_per_second: 6.018, epoch: 19.6222\r\n",
      "loss: 0.00716114, learning_rate: 5.556e-07, global_step: 13250, interval_runtime: 0.7683, interval_samples_per_second: 52.063, interval_steps_per_second: 6.508, epoch: 19.6296\r\n",
      "loss: 0.0006102, learning_rate: 5.444e-07, global_step: 13255, interval_runtime: 0.6825, interval_samples_per_second: 58.605, interval_steps_per_second: 7.326, epoch: 19.637\r\n",
      "loss: 0.0077684, learning_rate: 5.333e-07, global_step: 13260, interval_runtime: 0.9211, interval_samples_per_second: 43.424, interval_steps_per_second: 5.428, epoch: 19.6444\r\n",
      "loss: 0.0167013, learning_rate: 5.222e-07, global_step: 13265, interval_runtime: 0.8108, interval_samples_per_second: 49.337, interval_steps_per_second: 6.167, epoch: 19.6519\r\n",
      "loss: 0.01263697, learning_rate: 5.111e-07, global_step: 13270, interval_runtime: 0.821, interval_samples_per_second: 48.724, interval_steps_per_second: 6.09, epoch: 19.6593\r\n",
      "loss: 0.00572376, learning_rate: 5e-07, global_step: 13275, interval_runtime: 0.79, interval_samples_per_second: 50.631, interval_steps_per_second: 6.329, epoch: 19.6667\r\n",
      "loss: 0.00802867, learning_rate: 4.889e-07, global_step: 13280, interval_runtime: 0.9007, interval_samples_per_second: 44.412, interval_steps_per_second: 5.551, epoch: 19.6741\r\n",
      "loss: 0.00945687, learning_rate: 4.778e-07, global_step: 13285, interval_runtime: 0.893, interval_samples_per_second: 44.792, interval_steps_per_second: 5.599, epoch: 19.6815\r\n",
      "loss: 0.00072375, learning_rate: 4.667e-07, global_step: 13290, interval_runtime: 0.8425, interval_samples_per_second: 47.478, interval_steps_per_second: 5.935, epoch: 19.6889\r\n",
      "loss: 0.006536, learning_rate: 4.556e-07, global_step: 13295, interval_runtime: 0.8114, interval_samples_per_second: 49.297, interval_steps_per_second: 6.162, epoch: 19.6963\r\n",
      "loss: 0.00055053, learning_rate: 4.444e-07, global_step: 13300, interval_runtime: 0.8359, interval_samples_per_second: 47.851, interval_steps_per_second: 5.981, epoch: 19.7037\r\n",
      "loss: 0.00484308, learning_rate: 4.333e-07, global_step: 13305, interval_runtime: 0.742, interval_samples_per_second: 53.91, interval_steps_per_second: 6.739, epoch: 19.7111\r\n",
      "loss: 0.00075269, learning_rate: 4.222e-07, global_step: 13310, interval_runtime: 0.8298, interval_samples_per_second: 48.204, interval_steps_per_second: 6.026, epoch: 19.7185\r\n",
      "loss: 0.00049398, learning_rate: 4.111e-07, global_step: 13315, interval_runtime: 0.797, interval_samples_per_second: 50.186, interval_steps_per_second: 6.273, epoch: 19.7259\r\n",
      "loss: 0.01223124, learning_rate: 4e-07, global_step: 13320, interval_runtime: 0.7525, interval_samples_per_second: 53.158, interval_steps_per_second: 6.645, epoch: 19.7333\r\n",
      "loss: 0.01218008, learning_rate: 3.889e-07, global_step: 13325, interval_runtime: 0.8938, interval_samples_per_second: 44.751, interval_steps_per_second: 5.594, epoch: 19.7407\r\n",
      "loss: 0.00052266, learning_rate: 3.778e-07, global_step: 13330, interval_runtime: 0.6995, interval_samples_per_second: 57.18, interval_steps_per_second: 7.148, epoch: 19.7481\r\n",
      "loss: 0.00778977, learning_rate: 3.667e-07, global_step: 13335, interval_runtime: 0.7221, interval_samples_per_second: 55.392, interval_steps_per_second: 6.924, epoch: 19.7556\r\n",
      "loss: 0.00970297, learning_rate: 3.556e-07, global_step: 13340, interval_runtime: 0.9009, interval_samples_per_second: 44.399, interval_steps_per_second: 5.55, epoch: 19.763\r\n",
      "loss: 0.00075983, learning_rate: 3.444e-07, global_step: 13345, interval_runtime: 0.8767, interval_samples_per_second: 45.628, interval_steps_per_second: 5.704, epoch: 19.7704\r\n",
      "loss: 0.02081501, learning_rate: 3.333e-07, global_step: 13350, interval_runtime: 0.8895, interval_samples_per_second: 44.97, interval_steps_per_second: 5.621, epoch: 19.7778\r\n",
      "loss: 0.00744159, learning_rate: 3.222e-07, global_step: 13355, interval_runtime: 0.8509, interval_samples_per_second: 47.011, interval_steps_per_second: 5.876, epoch: 19.7852\r\n",
      "loss: 0.00911935, learning_rate: 3.111e-07, global_step: 13360, interval_runtime: 0.7167, interval_samples_per_second: 55.813, interval_steps_per_second: 6.977, epoch: 19.7926\r\n",
      "loss: 0.00580568, learning_rate: 3e-07, global_step: 13365, interval_runtime: 0.8015, interval_samples_per_second: 49.903, interval_steps_per_second: 6.238, epoch: 19.8\r\n",
      "loss: 0.00066256, learning_rate: 2.889e-07, global_step: 13370, interval_runtime: 0.8405, interval_samples_per_second: 47.588, interval_steps_per_second: 5.949, epoch: 19.8074\r\n",
      "loss: 0.00078541, learning_rate: 2.778e-07, global_step: 13375, interval_runtime: 0.9046, interval_samples_per_second: 44.219, interval_steps_per_second: 5.527, epoch: 19.8148\r\n",
      "loss: 0.01012533, learning_rate: 2.667e-07, global_step: 13380, interval_runtime: 0.9458, interval_samples_per_second: 42.292, interval_steps_per_second: 5.286, epoch: 19.8222\r\n",
      "loss: 0.01105639, learning_rate: 2.556e-07, global_step: 13385, interval_runtime: 0.7835, interval_samples_per_second: 51.051, interval_steps_per_second: 6.381, epoch: 19.8296\r\n",
      "loss: 0.00062008, learning_rate: 2.444e-07, global_step: 13390, interval_runtime: 0.8721, interval_samples_per_second: 45.867, interval_steps_per_second: 5.733, epoch: 19.837\r\n",
      "loss: 0.00072865, learning_rate: 2.333e-07, global_step: 13395, interval_runtime: 0.7544, interval_samples_per_second: 53.019, interval_steps_per_second: 6.627, epoch: 19.8444\r\n",
      "loss: 0.01654588, learning_rate: 2.222e-07, global_step: 13400, interval_runtime: 0.7598, interval_samples_per_second: 52.644, interval_steps_per_second: 6.58, epoch: 19.8519\r\n",
      "loss: 0.00436762, learning_rate: 2.111e-07, global_step: 13405, interval_runtime: 0.8023, interval_samples_per_second: 49.854, interval_steps_per_second: 6.232, epoch: 19.8593\r\n",
      "loss: 0.00783651, learning_rate: 2e-07, global_step: 13410, interval_runtime: 0.8917, interval_samples_per_second: 44.857, interval_steps_per_second: 5.607, epoch: 19.8667\r\n",
      "loss: 0.0007513, learning_rate: 1.889e-07, global_step: 13415, interval_runtime: 0.7297, interval_samples_per_second: 54.817, interval_steps_per_second: 6.852, epoch: 19.8741\r\n",
      "loss: 0.00069686, learning_rate: 1.778e-07, global_step: 13420, interval_runtime: 0.7569, interval_samples_per_second: 52.848, interval_steps_per_second: 6.606, epoch: 19.8815\r\n",
      "loss: 0.0053458, learning_rate: 1.667e-07, global_step: 13425, interval_runtime: 0.891, interval_samples_per_second: 44.892, interval_steps_per_second: 5.611, epoch: 19.8889\r\n",
      "loss: 0.00059555, learning_rate: 1.556e-07, global_step: 13430, interval_runtime: 0.9925, interval_samples_per_second: 40.304, interval_steps_per_second: 5.038, epoch: 19.8963\r\n",
      "loss: 0.00214767, learning_rate: 1.444e-07, global_step: 13435, interval_runtime: 0.7661, interval_samples_per_second: 52.211, interval_steps_per_second: 6.526, epoch: 19.9037\r\n",
      "loss: 0.00882828, learning_rate: 1.333e-07, global_step: 13440, interval_runtime: 0.7694, interval_samples_per_second: 51.99, interval_steps_per_second: 6.499, epoch: 19.9111\r\n",
      "loss: 0.00107574, learning_rate: 1.222e-07, global_step: 13445, interval_runtime: 0.9011, interval_samples_per_second: 44.39, interval_steps_per_second: 5.549, epoch: 19.9185\r\n",
      "loss: 0.00848364, learning_rate: 1.111e-07, global_step: 13450, interval_runtime: 0.8307, interval_samples_per_second: 48.151, interval_steps_per_second: 6.019, epoch: 19.9259\r\n",
      "loss: 0.00472507, learning_rate: 1e-07, global_step: 13455, interval_runtime: 0.8181, interval_samples_per_second: 48.896, interval_steps_per_second: 6.112, epoch: 19.9333\r\n",
      "loss: 0.00779548, learning_rate: 8.889e-08, global_step: 13460, interval_runtime: 0.8178, interval_samples_per_second: 48.913, interval_steps_per_second: 6.114, epoch: 19.9407\r\n",
      "loss: 0.00818136, learning_rate: 7.778e-08, global_step: 13465, interval_runtime: 0.8495, interval_samples_per_second: 47.087, interval_steps_per_second: 5.886, epoch: 19.9481\r\n",
      "loss: 0.00055985, learning_rate: 6.667e-08, global_step: 13470, interval_runtime: 0.8266, interval_samples_per_second: 48.391, interval_steps_per_second: 6.049, epoch: 19.9556\r\n",
      "loss: 0.00775104, learning_rate: 5.556e-08, global_step: 13475, interval_runtime: 0.8824, interval_samples_per_second: 45.329, interval_steps_per_second: 5.666, epoch: 19.963\r\n",
      "loss: 0.0145721, learning_rate: 4.444e-08, global_step: 13480, interval_runtime: 0.9542, interval_samples_per_second: 41.922, interval_steps_per_second: 5.24, epoch: 19.9704\r\n",
      "loss: 0.00173961, learning_rate: 3.333e-08, global_step: 13485, interval_runtime: 0.8587, interval_samples_per_second: 46.583, interval_steps_per_second: 5.823, epoch: 19.9778\r\n",
      "loss: 0.00277615, learning_rate: 2.222e-08, global_step: 13490, interval_runtime: 0.8076, interval_samples_per_second: 49.531, interval_steps_per_second: 6.191, epoch: 19.9852\r\n",
      "loss: 0.000526, learning_rate: 1.111e-08, global_step: 13495, interval_runtime: 0.7849, interval_samples_per_second: 50.964, interval_steps_per_second: 6.37, epoch: 19.9926\r\n",
      "loss: 0.00993314, learning_rate: 0.0, global_step: 13500, interval_runtime: 0.8555, interval_samples_per_second: 46.758, interval_steps_per_second: 5.845, epoch: 20.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:23:57,001] [    INFO] - ***** Running Evaluation *****\r\n",
      "[2023-01-10 11:23:57,003] [    INFO] -   Num examples = 1896\r\n",
      "[2023-01-10 11:23:57,005] [    INFO] -   Total prediction steps = 237\r\n",
      "[2023-01-10 11:23:57,007] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 11:23:57,009] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.7842276096343994, eval_micro_f1_score: 0.5733422638981915, eval_macro_f1_score: 0.4692847521060946, eval_runtime: 13.5618, eval_samples_per_second: 139.804, eval_steps_per_second: 17.476, epoch: 20.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:24:10,568] [    INFO] - Saving model checkpoint to ./checkpoints/checkpoint-13500\r\n",
      "[2023-01-10 11:24:10,571] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:24:14,078] [    INFO] - tokenizer config file saved in ./checkpoints/checkpoint-13500/tokenizer_config.json\r\n",
      "[2023-01-10 11:24:14,082] [    INFO] - Special tokens file saved in ./checkpoints/checkpoint-13500/special_tokens_map.json\r\n",
      "[2023-01-10 11:24:20,905] [    INFO] - Deleting older checkpoint [checkpoints/checkpoint-11475] due to args.save_total_limit\r\n",
      "[2023-01-10 11:24:21,546] [    INFO] - \r\n",
      "Training completed. \r\n",
      "\r\n",
      "[2023-01-10 11:24:21,550] [    INFO] - Loading best model from ./checkpoints/checkpoint-13500 (score: 0.4692847521060946).\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_runtime: 2754.9119, train_samples_per_second: 39.152, train_steps_per_second: 4.9, train_loss: 0.08036288937715882, epoch: 20.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 11:24:23,622] [    INFO] - Saving model checkpoint to ./checkpoints/\r\n",
      "[2023-01-10 11:24:23,625] [    INFO] - Trainer.model is not a `PretrainedModel`, only saving its state dict.\r\n",
      "[2023-01-10 11:24:26,962] [    INFO] - tokenizer config file saved in ./checkpoints/tokenizer_config.json\r\n",
      "[2023-01-10 11:24:26,966] [    INFO] - Special tokens file saved in ./checkpoints/special_tokens_map.json\r\n",
      "[2023-01-10 11:24:26,977] [    INFO] - ***** train metrics *****\r\n",
      "[2023-01-10 11:24:26,980] [    INFO] -   epoch                    =       20.0\r\n",
      "[2023-01-10 11:24:26,982] [    INFO] -   train_loss               =     0.0804\r\n",
      "[2023-01-10 11:24:26,984] [    INFO] -   train_runtime            = 0:45:54.91\r\n",
      "[2023-01-10 11:24:26,987] [    INFO] -   train_samples_per_second =     39.152\r\n",
      "[2023-01-10 11:24:26,989] [    INFO] -   train_steps_per_second   =        4.9\r\n"
     ]
    }
   ],
   "source": [
    "# Training.\n",
    "train_result = trainer.train(resume_from_checkpoint=None)\n",
    "metrics = train_result.metrics\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec2497c-a7eb-4299-8721-3d9d84182e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T03:35:39.572699Z",
     "iopub.status.busy": "2023-01-10T03:35:39.572042Z",
     "iopub.status.idle": "2023-01-10T03:35:39.977944Z",
     "shell.execute_reply": "2023-01-10T03:35:39.976385Z",
     "shell.execute_reply.started": "2023-01-10T03:35:39.572646Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/             label.txt                prompt2.ipynb\r\n",
      "data/                    main.ipynb               prompt.ipynb\r\n",
      "dataprocess-1 (1).ipynb  model/                   train.tsv\r\n",
      "dataprocess (2).ipynb    multilossErnie2.0.ipynb  work/\r\n",
      "dataprocessprompt.ipynb  prompt/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e9de171-7a97-473b-8398-aaf8fd76b7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:38:45.228804Z",
     "iopub.status.busy": "2023-01-10T04:38:45.227372Z",
     "iopub.status.idle": "2023-01-10T04:38:47.171165Z",
     "shell.execute_reply": "2023-01-10T04:38:47.170189Z",
     "shell.execute_reply.started": "2023-01-10T04:38:45.228753Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_model.set_dict(paddle.load('checkpoints/model_state.pdparams'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcecf77b-7e59-49ba-b355-4162718823fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:38:51.860287Z",
     "iopub.status.busy": "2023-01-10T04:38:51.859532Z",
     "iopub.status.idle": "2023-01-10T04:38:52.600331Z",
     "shell.execute_reply": "2023-01-10T04:38:52.599257Z",
     "shell.execute_reply.started": "2023-01-10T04:38:51.860240Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " Tensor(shape=[30522, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00546739, -0.07279876, -0.00485531, ..., -0.05335438,\n",
       "           0.13600905, -0.20567332],\n",
       "         [-0.03285649, -0.04737137, -0.00188808, ...,  0.01321391,\n",
       "          -0.06982858, -0.06631948],\n",
       "         [-0.02384438, -0.01789385, -0.02179209, ..., -0.04086783,\n",
       "          -0.03336208, -0.08547164],\n",
       "         ...,\n",
       "         [ 0.00767266, -0.01697906, -0.01206527, ..., -0.00926016,\n",
       "           0.02441780, -0.08461355],\n",
       "         [-0.04005636, -0.01736297, -0.01372629, ..., -0.01628069,\n",
       "          -0.04072044, -0.11731133],\n",
       "         [ 0.01058857, -0.04614783, -0.01974028, ..., -0.03609759,\n",
       "          -0.06223337, -0.11604351]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[512, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00507997,  0.00187391, -0.01345916, ...,  0.00126663,\n",
       "          -0.00574510,  0.02086964],\n",
       "         [ 0.00292164,  0.00058186, -0.01195123, ...,  0.00351804,\n",
       "           0.01124866,  0.00287333],\n",
       "         [ 0.01181076, -0.01656369,  0.00427157, ...,  0.00434542,\n",
       "           0.02468900,  0.00723502],\n",
       "         ...,\n",
       "         [ 0.00702994, -0.00715088,  0.01145341, ..., -0.00003174,\n",
       "           0.00102580,  0.03143644],\n",
       "         [ 0.01968670,  0.00619306,  0.02487305, ..., -0.00513413,\n",
       "           0.00908471,  0.02814749],\n",
       "         [ 0.04055700,  0.01582482,  0.03196988, ...,  0.01533185,\n",
       "           0.01130116,  0.04628271]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00562339, -0.00902005,  0.00335708, ...,  0.00125806,\n",
       "           0.01050304,  0.02132046],\n",
       "         [-0.00033866, -0.00611977, -0.00980567, ...,  0.00252657,\n",
       "           0.00462465,  0.02257314],\n",
       "         [-0.01214475, -0.01347071,  0.00336370, ...,  0.01444779,\n",
       "           0.00906863,  0.01946940],\n",
       "         [-0.00529713, -0.00649051, -0.00009847, ...,  0.01121292,\n",
       "           0.00404791,  0.00556499]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[3, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00556043,  0.01207466, -0.05974247, ..., -0.00220376,\n",
       "           0.00053524,  0.01290023],\n",
       "         [-0.01766550, -0.02588688,  0.00750925, ...,  0.00620871,\n",
       "          -0.01174253, -0.00087369],\n",
       "         [ 0.00711616,  0.00082270, -0.01791317, ..., -0.01124782,\n",
       "          -0.01423857, -0.02957504]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.86570227, 0.87068999, 0.83374381, ..., 0.91927922, 0.89081973,\n",
       "         0.78663528]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02061026,  0.01057680,  0.02097345, ...,  0.01197484,\n",
       "          0.02429084,  0.08365896]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02165245,  0.01962121,  0.01430346, ..., -0.00230435,\n",
       "           0.04210546,  0.01765760],\n",
       "         [-0.03425077,  0.01871881, -0.01664569, ..., -0.01189850,\n",
       "          -0.00521408, -0.01579156],\n",
       "         [-0.05979552, -0.02007616, -0.03779425, ..., -0.01165872,\n",
       "           0.05649451, -0.00527014],\n",
       "         ...,\n",
       "         [ 0.01942109, -0.03110511,  0.03265965, ...,  0.03688818,\n",
       "          -0.01226761,  0.00433018],\n",
       "         [-0.01016609, -0.03582525,  0.00147209, ...,  0.03677451,\n",
       "          -0.01827369,  0.02352894],\n",
       "         [ 0.01772570, -0.01415499, -0.05572314, ...,  0.05526742,\n",
       "          -0.02089711,  0.02663185]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02542322,  0.20874120, -0.07034953, ..., -0.30008370,\n",
       "         -0.16278210,  0.13531761]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04844436, -0.02803303,  0.02447791, ...,  0.02649010,\n",
       "          -0.00308817,  0.00897467],\n",
       "         [ 0.04895176,  0.01249367, -0.00054956, ...,  0.01216429,\n",
       "           0.03598249, -0.00718619],\n",
       "         [-0.03661693,  0.00599952,  0.04517999, ...,  0.00405003,\n",
       "           0.00084686, -0.01294104],\n",
       "         ...,\n",
       "         [-0.03337665, -0.08218561,  0.02016096, ..., -0.02105017,\n",
       "           0.00806285,  0.00366512],\n",
       "         [ 0.06537340, -0.00860789,  0.04969020, ...,  0.06219239,\n",
       "          -0.04595096,  0.00966856],\n",
       "         [ 0.06969538,  0.01430999, -0.00746905, ...,  0.04257790,\n",
       "          -0.01162383,  0.00517727]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01875185, -0.03835705,  0.00663958, ...,  0.00386064,\n",
       "          0.02953196, -0.02359953]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01033662, -0.02179039, -0.00497147, ...,  0.02598202,\n",
       "          -0.01167515,  0.00564915],\n",
       "         [-0.00116191, -0.00146257, -0.00511527, ..., -0.00847754,\n",
       "           0.00729379, -0.00060772],\n",
       "         [-0.02963600,  0.00898237, -0.04023365, ...,  0.00477325,\n",
       "           0.02129426,  0.01641809],\n",
       "         ...,\n",
       "         [-0.00338870,  0.02051764, -0.03789696, ...,  0.00195613,\n",
       "          -0.00938758,  0.02400527],\n",
       "         [-0.06393202,  0.04914527,  0.02262706, ..., -0.00873399,\n",
       "          -0.00468901,  0.02234690],\n",
       "         [ 0.01461754,  0.02201836,  0.01110306, ..., -0.02330946,\n",
       "           0.01060808,  0.01422826]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00400644,  0.01754071, -0.01900113, ...,  0.00633497,\n",
       "          0.00191918, -0.03156042]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02621873,  0.00368805,  0.02841258, ..., -0.01556996,\n",
       "          -0.01134442, -0.03829392],\n",
       "         [-0.00777048,  0.00848474, -0.02965884, ..., -0.01691525,\n",
       "           0.02665857, -0.02585075],\n",
       "         [ 0.01652857,  0.05344447, -0.05279056, ..., -0.01853471,\n",
       "          -0.01565380,  0.00302158],\n",
       "         ...,\n",
       "         [ 0.00364930, -0.01000880,  0.02233331, ...,  0.02690089,\n",
       "           0.00325710, -0.02475746],\n",
       "         [-0.00095461, -0.02056030, -0.02109055, ..., -0.01350672,\n",
       "           0.01083132,  0.00907709],\n",
       "         [ 0.00524134,  0.00242417, -0.00171739, ..., -0.00413641,\n",
       "           0.01871274, -0.00721771]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03243011,  0.01921139,  0.00529409, ...,  0.00687134,\n",
       "          0.01170489,  0.01273240]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.09551344,  0.02521930, -0.01784329, ..., -0.00129528,\n",
       "           0.05789843, -0.01346657],\n",
       "         [-0.01448985,  0.03915878,  0.02124251, ..., -0.03387569,\n",
       "           0.02482050, -0.01462728],\n",
       "         [ 0.04040029,  0.02384592, -0.00888610, ..., -0.00302552,\n",
       "          -0.01827061,  0.00611765],\n",
       "         ...,\n",
       "         [ 0.05597835,  0.01895947,  0.04660091, ...,  0.01373478,\n",
       "          -0.00613690, -0.00124358],\n",
       "         [ 0.01932138, -0.00144440, -0.05377527, ..., -0.03028912,\n",
       "           0.08129494, -0.00171711],\n",
       "         [ 0.01906828,  0.00938510, -0.00710095, ..., -0.00337167,\n",
       "           0.05463964, -0.02433835]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.17491718, -0.07536733, -0.11202170, ..., -0.08807229,\n",
       "         -0.08983501, -0.05355591]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.06103866,  0.02414988,  0.02062188, ...,  0.03309232,\n",
       "          -0.01618136,  0.03889030],\n",
       "         [ 0.06439631,  0.01331663, -0.04194381, ..., -0.01601036,\n",
       "           0.02189787, -0.01762216],\n",
       "         [ 0.00159075, -0.00493440,  0.02056648, ...,  0.02668635,\n",
       "          -0.05351550, -0.01802632],\n",
       "         ...,\n",
       "         [-0.02118632, -0.03084333, -0.00357996, ...,  0.00452367,\n",
       "          -0.04288596, -0.00936652],\n",
       "         [ 0.03585682, -0.03002897, -0.02926642, ..., -0.04680423,\n",
       "           0.03261744, -0.04046116],\n",
       "         [ 0.03927838,  0.00310966,  0.00667719, ..., -0.00598648,\n",
       "           0.00330476,  0.00238648]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03800587, -0.00374643, -0.02657506, ...,  0.02238671,\n",
       "         -0.00462150,  0.01956801]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.99798673, 0.99116522, 0.99790424, ..., 1.03521132, 1.02945662,\n",
       "         1.00259316]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07245085,  0.07100190,  0.24703194, ..., -0.37113339,\n",
       "          0.31827593, -0.09715804]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90282136, 0.90011883, 0.87407351, ..., 0.88658857, 0.92085463,\n",
       "         0.86814106]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01253934,  0.01949977, -0.02989252, ...,  0.12062980,\n",
       "         -0.04499102,  0.06897105]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02154309,  0.03190599, -0.08757252, ..., -0.00134260,\n",
       "           0.00618432,  0.00707078],\n",
       "         [ 0.02182343, -0.03194952,  0.01743666, ...,  0.02420074,\n",
       "          -0.00206225, -0.03453589],\n",
       "         [-0.04914932, -0.01346543, -0.00552094, ...,  0.02001883,\n",
       "          -0.01056975, -0.02700518],\n",
       "         ...,\n",
       "         [ 0.03695894, -0.00901623,  0.00716919, ...,  0.04646511,\n",
       "          -0.01470129, -0.08644851],\n",
       "         [ 0.01755749, -0.04666661, -0.03593117, ..., -0.00303438,\n",
       "           0.01302075,  0.01753821],\n",
       "         [-0.02612897, -0.00387278,  0.06455828, ..., -0.03401105,\n",
       "           0.01652087, -0.03235384]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03384410, -0.02156361,  0.03866598, ..., -0.01099471,\n",
       "          0.07206319,  0.03021944]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00941576, -0.07384894,  0.00616098, ..., -0.00536570,\n",
       "           0.00444870, -0.02830235],\n",
       "         [ 0.00362398, -0.00350955,  0.00513141, ..., -0.04629123,\n",
       "          -0.00732370,  0.04995700],\n",
       "         [ 0.04416887, -0.00692058,  0.03782831, ...,  0.02833038,\n",
       "           0.00598005, -0.01226150],\n",
       "         ...,\n",
       "         [-0.01155730, -0.02872580, -0.03814134, ...,  0.01128108,\n",
       "          -0.04602158,  0.06626476],\n",
       "         [ 0.01047505, -0.01564571, -0.00693010, ..., -0.00622827,\n",
       "           0.01436899,  0.02368557],\n",
       "         [ 0.02521737, -0.01206553,  0.04228716, ...,  0.03169850,\n",
       "          -0.03626365,  0.04271752]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11305520,  0.02457824,  0.13670282, ...,  0.01204466,\n",
       "          0.02290571,  0.02541137]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02718382,  0.01082707, -0.01253162, ..., -0.02618417,\n",
       "          -0.02578423, -0.02676863],\n",
       "         [ 0.01534780, -0.02756925, -0.00300965, ...,  0.00271410,\n",
       "           0.00006806,  0.04656863],\n",
       "         [ 0.00499224, -0.04073225,  0.00086020, ...,  0.01447308,\n",
       "          -0.03157840, -0.00523639],\n",
       "         ...,\n",
       "         [ 0.03660113, -0.02194548,  0.02412545, ...,  0.01616369,\n",
       "           0.01634970,  0.00487118],\n",
       "         [-0.01420516, -0.04323233,  0.03074152, ..., -0.04000682,\n",
       "          -0.00857711,  0.01077608],\n",
       "         [ 0.06545540,  0.01408258,  0.02558282, ...,  0.00856049,\n",
       "          -0.00725661, -0.02173029]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00456013, -0.01741426, -0.01252179, ..., -0.01094165,\n",
       "         -0.00270965,  0.00184975]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00058088,  0.00973884,  0.03355338, ...,  0.02225498,\n",
       "          -0.00621057,  0.01763900],\n",
       "         [-0.00948755, -0.01129056,  0.03735543, ..., -0.00936331,\n",
       "          -0.01940664,  0.03551307],\n",
       "         [ 0.05118655, -0.03641982,  0.02014386, ..., -0.00973406,\n",
       "          -0.00700663,  0.02455928],\n",
       "         ...,\n",
       "         [ 0.05703275,  0.01904500,  0.00771489, ...,  0.00563726,\n",
       "           0.05299850, -0.00692609],\n",
       "         [ 0.01914904, -0.01172930,  0.00929820, ...,  0.00848367,\n",
       "           0.00066756, -0.01513171],\n",
       "         [-0.01188048, -0.03232439,  0.00781176, ..., -0.00068546,\n",
       "          -0.02298286, -0.00414053]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03031881, -0.00535547, -0.00167732, ...,  0.00315669,\n",
       "          0.02229424,  0.04434390]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01077013,  0.02916615, -0.07644665, ...,  0.08704734,\n",
       "          -0.04035007,  0.02655316],\n",
       "         [ 0.03327730,  0.00596931, -0.05741483, ..., -0.05065294,\n",
       "          -0.04293575, -0.03549986],\n",
       "         [-0.02018435, -0.06968486, -0.01512017, ..., -0.02514503,\n",
       "           0.04013383, -0.03291339],\n",
       "         ...,\n",
       "         [ 0.01527223,  0.02122314,  0.03708855, ..., -0.00555952,\n",
       "          -0.05866667, -0.01176534],\n",
       "         [-0.00294262, -0.07811566, -0.00358336, ...,  0.02932653,\n",
       "          -0.00567969, -0.02645823],\n",
       "         [ 0.01155640, -0.00353146, -0.04803866, ..., -0.02351953,\n",
       "           0.01430042, -0.00217569]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07261106, -0.08898391, -0.05689410, ..., -0.06246220,\n",
       "         -0.07401095, -0.07229283]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04780799, -0.01762321, -0.00699412, ...,  0.02068176,\n",
       "           0.02211725,  0.00943086],\n",
       "         [-0.02567902, -0.02564304, -0.00266114, ...,  0.02305603,\n",
       "          -0.00437081,  0.04152414],\n",
       "         [-0.02864391, -0.00578361, -0.01885343, ..., -0.03112473,\n",
       "          -0.00933424, -0.01714028],\n",
       "         ...,\n",
       "         [-0.01464074, -0.04180218, -0.00957387, ...,  0.02452425,\n",
       "           0.00530743,  0.03045905],\n",
       "         [-0.02847682,  0.02620400,  0.01142524, ...,  0.00097001,\n",
       "           0.02351801,  0.02545865],\n",
       "         [ 0.00504775, -0.03037585,  0.06141156, ...,  0.01618577,\n",
       "          -0.00094245,  0.01539848]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01372548,  0.01298664, -0.06168745, ...,  0.05964814,\n",
       "         -0.01751787, -0.00429494]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.99401480, 0.96494097, 0.98234493, ..., 1.00187516, 1.00430441,\n",
       "         0.98268753]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.12272438,  0.12252688,  0.09972298, ..., -0.21528834,\n",
       "          0.23244694, -0.00734201]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.93493503, 0.94117892, 0.93905395, ..., 0.92537439, 0.95446283,\n",
       "         0.92375511]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.08949640, -0.03592343,  0.00649307, ...,  0.11906743,\n",
       "         -0.08476302,  0.01887068]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00187264,  0.03664690, -0.07480329, ...,  0.00853819,\n",
       "           0.01785471,  0.03004906],\n",
       "         [-0.03120578,  0.04112335, -0.04363067, ..., -0.00244692,\n",
       "          -0.01342712,  0.02926392],\n",
       "         [-0.03969974, -0.01911366,  0.03674633, ..., -0.00063313,\n",
       "           0.02253249,  0.01838413],\n",
       "         ...,\n",
       "         [ 0.03319034,  0.01970395, -0.00325449, ...,  0.00408467,\n",
       "          -0.05736190, -0.03466770],\n",
       "         [ 0.02899564, -0.00671087,  0.01334862, ...,  0.02368167,\n",
       "          -0.04502670, -0.05679351],\n",
       "         [ 0.03549600, -0.01527241, -0.03217169, ..., -0.10398378,\n",
       "          -0.00355348,  0.02888017]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01107056,  0.07019701,  0.00223872, ..., -0.04540491,\n",
       "         -0.02341057, -0.01720056]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03010446, -0.03934263, -0.02948866, ...,  0.03090297,\n",
       "           0.03577599, -0.03602628],\n",
       "         [ 0.02586341,  0.01812079,  0.03825855, ...,  0.06579248,\n",
       "          -0.00825371,  0.01732639],\n",
       "         [-0.02337473,  0.00736421, -0.03712850, ...,  0.01651330,\n",
       "           0.00196081,  0.00831748],\n",
       "         ...,\n",
       "         [ 0.00029857, -0.05367414,  0.02828052, ..., -0.00679220,\n",
       "           0.02612982,  0.03743557],\n",
       "         [-0.01828360,  0.02882275, -0.07718309, ..., -0.03667499,\n",
       "           0.00525916, -0.04131386],\n",
       "         [-0.00268564, -0.00920135, -0.05722724, ...,  0.02526876,\n",
       "          -0.03519429,  0.07673659]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00083275,  0.07093410,  0.03901595, ..., -0.02240705,\n",
       "         -0.00767333, -0.06235615]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01523952, -0.00668102,  0.01625089, ..., -0.02025274,\n",
       "          -0.00861877,  0.00398694],\n",
       "         [ 0.01555767,  0.00056461, -0.02073646, ..., -0.00369188,\n",
       "          -0.03241087, -0.00664653],\n",
       "         [-0.00556967, -0.01767230, -0.01998700, ..., -0.00189256,\n",
       "           0.01083030,  0.02962894],\n",
       "         ...,\n",
       "         [ 0.00577600, -0.00091703, -0.04174646, ...,  0.03438747,\n",
       "           0.02222401,  0.00833589],\n",
       "         [-0.00471703, -0.00233638, -0.01592196, ...,  0.01168905,\n",
       "          -0.06525059,  0.02456177],\n",
       "         [-0.05034782,  0.00899318,  0.00329698, ..., -0.01281319,\n",
       "           0.00655066, -0.01299746]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00903887, -0.09171849, -0.01007821, ...,  0.02145014,\n",
       "          0.00223950,  0.00464470]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03380707, -0.02585695, -0.00164727, ..., -0.03032255,\n",
       "           0.02247412, -0.02902056],\n",
       "         [ 0.04501200, -0.01216291,  0.02577172, ..., -0.00168877,\n",
       "           0.00649749,  0.01537591],\n",
       "         [-0.01815041,  0.03196091, -0.06142617, ...,  0.02431093,\n",
       "          -0.01008292, -0.02308192],\n",
       "         ...,\n",
       "         [ 0.01441480, -0.00569054,  0.03525589, ..., -0.01252164,\n",
       "           0.00119713, -0.01213438],\n",
       "         [ 0.00702174, -0.01719729,  0.00019624, ..., -0.01220347,\n",
       "           0.05371847,  0.01703353],\n",
       "         [-0.01532890, -0.00562424, -0.00955719, ...,  0.00330495,\n",
       "          -0.01040510,  0.00341298]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02859519, -0.02938941, -0.00034968, ...,  0.01019300,\n",
       "         -0.02082036,  0.04858099]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00679939, -0.01256576, -0.00687045, ..., -0.00623931,\n",
       "           0.01218855, -0.01246139],\n",
       "         [ 0.05805406, -0.00307528,  0.00146839, ...,  0.05998588,\n",
       "          -0.01963969,  0.05309044],\n",
       "         [-0.09028150, -0.03650155, -0.01992772, ..., -0.02507983,\n",
       "           0.00012071, -0.01250919],\n",
       "         ...,\n",
       "         [ 0.01258776, -0.05904996,  0.02692041, ..., -0.00712835,\n",
       "           0.01661376,  0.02992825],\n",
       "         [ 0.02550282, -0.02386601,  0.03473059, ...,  0.02110808,\n",
       "           0.04082729,  0.06493478],\n",
       "         [ 0.00265130, -0.01601810,  0.04657507, ...,  0.03768580,\n",
       "          -0.06328547,  0.02608122]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06845414, -0.07368025, -0.04708447, ..., -0.03683836,\n",
       "         -0.07963219, -0.06683056]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.05431368,  0.02822990, -0.07565643, ...,  0.01565950,\n",
       "           0.04072224,  0.00865093],\n",
       "         [ 0.02540101, -0.02250307,  0.06017384, ..., -0.05258779,\n",
       "           0.02049353, -0.01783587],\n",
       "         [-0.00529703,  0.01758843,  0.04587194, ..., -0.00393205,\n",
       "           0.04465622,  0.03558236],\n",
       "         ...,\n",
       "         [-0.03817849,  0.02453324, -0.03119223, ...,  0.00151211,\n",
       "           0.04095440,  0.03231252],\n",
       "         [ 0.01465193, -0.04145223,  0.03117827, ..., -0.02160681,\n",
       "           0.02820252, -0.05742065],\n",
       "         [ 0.03285373,  0.01132218, -0.00171476, ...,  0.02001699,\n",
       "          -0.02100491,  0.03745595]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02098511,  0.00174295, -0.06190158, ...,  0.06962232,\n",
       "         -0.03900337, -0.00557880]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.96750849, 0.96198136, 0.99594635, ..., 0.97195476, 0.97673094,\n",
       "         0.93950188]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.10059139,  0.05345498,  0.20486343, ..., -0.13092649,\n",
       "          0.12834695, -0.02823232]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.93530500, 0.94601852, 0.91840184, ..., 0.92090803, 0.95994431,\n",
       "         0.89796305]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.08219226, -0.01976293, -0.07364026, ...,  0.11643357,\n",
       "         -0.05698409,  0.05195755]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.06997801,  0.03403695,  0.00801056, ..., -0.02036118,\n",
       "          -0.06785335, -0.02775296],\n",
       "         [ 0.02833418, -0.07958113,  0.00475356, ...,  0.01299560,\n",
       "          -0.01935024, -0.09614071],\n",
       "         [-0.00780280,  0.04042844, -0.00223793, ...,  0.03651365,\n",
       "           0.02833192,  0.02024033],\n",
       "         ...,\n",
       "         [-0.00209291, -0.00778890,  0.01572090, ...,  0.02165994,\n",
       "           0.05858569,  0.06132914],\n",
       "         [ 0.02443486, -0.04433451,  0.02128468, ..., -0.02124860,\n",
       "           0.05574485,  0.01170642],\n",
       "         [-0.07583261,  0.02089794,  0.03768731, ..., -0.02214307,\n",
       "           0.01177406, -0.01868921]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03499555,  0.01317501, -0.01954166, ..., -0.08677704,\n",
       "          0.02696713, -0.03937043]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.08577783, -0.03691950, -0.00576206, ...,  0.01532165,\n",
       "          -0.00048969, -0.03629885],\n",
       "         [-0.03039857,  0.05517736, -0.04979338, ...,  0.02226881,\n",
       "          -0.02124177, -0.00883540],\n",
       "         [ 0.05136275,  0.01417528, -0.00405279, ...,  0.00373357,\n",
       "          -0.00638491,  0.00085403],\n",
       "         ...,\n",
       "         [ 0.01661459,  0.02054391, -0.04933106, ..., -0.04079137,\n",
       "          -0.01123635, -0.02121757],\n",
       "         [-0.04180251,  0.02900794,  0.03635546, ...,  0.07041787,\n",
       "          -0.06371767, -0.05400907],\n",
       "         [-0.01798524,  0.04321076,  0.03616852, ...,  0.01083319,\n",
       "          -0.02116370, -0.04840666]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08373445, -0.00674625, -0.03055264, ..., -0.04085879,\n",
       "          0.00467196,  0.05222342]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00860242,  0.00299433, -0.00706796, ..., -0.01752977,\n",
       "          -0.02995522,  0.01674199],\n",
       "         [ 0.01701836, -0.02070845,  0.01477405, ...,  0.00805709,\n",
       "          -0.01092794,  0.00291236],\n",
       "         [-0.00363786, -0.00790362,  0.00909607, ..., -0.00439328,\n",
       "          -0.01526376, -0.02811198],\n",
       "         ...,\n",
       "         [ 0.06688646,  0.01193139,  0.04387220, ...,  0.02017850,\n",
       "           0.00646342, -0.02445910],\n",
       "         [-0.01343123, -0.03595743, -0.05103635, ..., -0.02585508,\n",
       "          -0.02041663,  0.00611049],\n",
       "         [-0.07655270,  0.00498827, -0.02575369, ..., -0.00418888,\n",
       "           0.03366595,  0.04145950]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00323314, -0.01217277, -0.01824006, ...,  0.01489943,\n",
       "         -0.01382563, -0.01431349]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02481145, -0.00204798, -0.00142929, ..., -0.03199236,\n",
       "          -0.00750615,  0.03314051],\n",
       "         [ 0.02667348,  0.00785610,  0.01867200, ..., -0.01153093,\n",
       "          -0.01400335, -0.00270230],\n",
       "         [ 0.00676689, -0.00546261, -0.04497155, ..., -0.01621365,\n",
       "           0.00660690,  0.01392223],\n",
       "         ...,\n",
       "         [-0.00013623, -0.02386822,  0.00430103, ..., -0.01840207,\n",
       "          -0.00975583, -0.02659154],\n",
       "         [ 0.00455912,  0.01981742,  0.00468709, ...,  0.00045966,\n",
       "           0.04549692, -0.00874993],\n",
       "         [ 0.01300030, -0.01487291, -0.02228289, ..., -0.00466248,\n",
       "           0.00946354, -0.01044399]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01113462,  0.07466472, -0.04647900, ...,  0.07520027,\n",
       "         -0.01815445,  0.02151146]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04626199,  0.02776363,  0.00199827, ...,  0.06784222,\n",
       "           0.00284590,  0.04270079],\n",
       "         [ 0.07302646, -0.05109327, -0.02547820, ...,  0.05750188,\n",
       "           0.02391753, -0.02378814],\n",
       "         [-0.01706478, -0.01367129, -0.07364381, ...,  0.02295348,\n",
       "          -0.04835924, -0.03520579],\n",
       "         ...,\n",
       "         [-0.00519177,  0.02273732, -0.00511212, ..., -0.00120540,\n",
       "          -0.00152330,  0.03417980],\n",
       "         [-0.06002333,  0.02506504, -0.01521083, ..., -0.00523602,\n",
       "           0.01008906, -0.01268393],\n",
       "         [-0.00987081,  0.07563142,  0.05039502, ...,  0.03034586,\n",
       "           0.01644229,  0.05555295]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07262418, -0.08076896, -0.07034615, ..., -0.07157809,\n",
       "         -0.06958293, -0.06831679]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03513527, -0.01159589,  0.01723501, ...,  0.00817777,\n",
       "          -0.00846626, -0.03822545],\n",
       "         [ 0.04117040, -0.03057771,  0.01741926, ..., -0.03891749,\n",
       "           0.01293027,  0.01624038],\n",
       "         [ 0.00273368, -0.01850114, -0.05195282, ...,  0.00437952,\n",
       "          -0.00481177, -0.03284320],\n",
       "         ...,\n",
       "         [ 0.02136684,  0.01275694,  0.00518470, ...,  0.02138918,\n",
       "          -0.04577834, -0.02127735],\n",
       "         [ 0.00761283, -0.01051725, -0.02619000, ..., -0.03392064,\n",
       "          -0.01217809,  0.01324927],\n",
       "         [-0.01311408,  0.06564178,  0.01153758, ...,  0.03449515,\n",
       "          -0.01438150, -0.06021000]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00146070,  0.01736160, -0.08845048, ...,  0.08512256,\n",
       "         -0.02943513, -0.02852380]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.97375715, 0.95534366, 0.99075872, ..., 0.96978706, 0.97134066,\n",
       "         0.93294019]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.15137358, -0.00185832,  0.22996755, ..., -0.06628359,\n",
       "          0.07091097,  0.02100921]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91615254, 0.93026501, 0.88591069, ..., 0.92984647, 0.95838410,\n",
       "         0.91024971]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.11008775,  0.01852817, -0.08447688, ...,  0.10112366,\n",
       "         -0.04002447,  0.01738966]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03399576,  0.02031573, -0.02786278, ..., -0.06836528,\n",
       "          -0.00591919,  0.01927357],\n",
       "         [-0.00593707, -0.04995826,  0.01392644, ...,  0.01490348,\n",
       "           0.00457600, -0.03664094],\n",
       "         [-0.04786201,  0.03231987,  0.00176772, ...,  0.06850375,\n",
       "           0.04279979, -0.00562250],\n",
       "         ...,\n",
       "         [ 0.00333498,  0.00163899, -0.02413108, ...,  0.00001026,\n",
       "           0.02035522, -0.04706169],\n",
       "         [-0.00387916,  0.00540464,  0.00191450, ...,  0.00479433,\n",
       "          -0.01436276, -0.02318076],\n",
       "         [-0.00591922, -0.00231971, -0.02099684, ..., -0.04298626,\n",
       "           0.03773485,  0.00231735]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01398670, -0.07123644,  0.07056879, ..., -0.01165437,\n",
       "         -0.00990477, -0.03876054]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.07808722, -0.04582607,  0.02169892, ...,  0.00510287,\n",
       "           0.00518550,  0.04320298],\n",
       "         [-0.02191243,  0.00421963,  0.03616475, ..., -0.02048114,\n",
       "           0.01053840, -0.00270772],\n",
       "         [ 0.02650898,  0.02639083, -0.04454264, ..., -0.04748500,\n",
       "          -0.03878909,  0.01734771],\n",
       "         ...,\n",
       "         [-0.02798215,  0.03657450, -0.04368250, ..., -0.01626463,\n",
       "           0.05824459,  0.04391992],\n",
       "         [ 0.01663339,  0.02996370, -0.00047135, ...,  0.02375348,\n",
       "           0.01040109,  0.00699306],\n",
       "         [-0.01814311, -0.05210248,  0.00367074, ...,  0.00615942,\n",
       "          -0.05360638, -0.05220679]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02196125, -0.25898373,  0.05722695, ...,  0.03923904,\n",
       "          0.01339656, -0.07149100]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01271745,  0.00932912, -0.00615469, ..., -0.00646952,\n",
       "           0.03720864,  0.05690637],\n",
       "         [ 0.00101497,  0.02227123, -0.04033122, ..., -0.01666568,\n",
       "          -0.02169786,  0.03382464],\n",
       "         [-0.02899723, -0.03611388, -0.01335074, ...,  0.00435250,\n",
       "          -0.03514659, -0.02195653],\n",
       "         ...,\n",
       "         [ 0.01083036, -0.01976180,  0.02129534, ..., -0.07126440,\n",
       "           0.01925775, -0.00844972],\n",
       "         [ 0.02286791, -0.01578311,  0.03902663, ...,  0.03612215,\n",
       "           0.01647159,  0.05462509],\n",
       "         [ 0.04522009, -0.01536091,  0.02590648, ...,  0.00809051,\n",
       "           0.01112818, -0.01647949]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01778710,  0.00416464, -0.00879775, ...,  0.00846842,\n",
       "          0.02127063,  0.00743342]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02183276,  0.03952023,  0.02365866, ..., -0.00951446,\n",
       "           0.01460638, -0.02132472],\n",
       "         [ 0.02341023, -0.05352094, -0.03196145, ...,  0.00172341,\n",
       "           0.00827760,  0.01806271],\n",
       "         [-0.00804600,  0.01007959, -0.04418446, ...,  0.00539618,\n",
       "          -0.01504476,  0.02132842],\n",
       "         ...,\n",
       "         [ 0.01624353, -0.01906842, -0.00886712, ..., -0.01457822,\n",
       "          -0.00217499, -0.01645518],\n",
       "         [-0.01582659, -0.00218876, -0.03744259, ..., -0.02248649,\n",
       "          -0.02424905,  0.03065636],\n",
       "         [ 0.00576605, -0.01345295,  0.02023068, ..., -0.00536284,\n",
       "          -0.00263893, -0.00827601]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03605250, -0.00289547, -0.00867259, ...,  0.02189634,\n",
       "          0.01296984,  0.03481429]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01562904,  0.02145915, -0.01037889, ..., -0.02132313,\n",
       "          -0.00687824,  0.04524128],\n",
       "         [-0.01257884,  0.00875120,  0.01045327, ..., -0.02285296,\n",
       "          -0.03066341, -0.02895666],\n",
       "         [ 0.03857575,  0.04216749,  0.00175718, ...,  0.04982113,\n",
       "          -0.00719159,  0.02707681],\n",
       "         ...,\n",
       "         [ 0.05156654, -0.03927720,  0.00137980, ..., -0.00655430,\n",
       "           0.02536841, -0.02673415],\n",
       "         [ 0.02349286, -0.01141057,  0.01382044, ...,  0.07115067,\n",
       "          -0.07281448, -0.00436265],\n",
       "         [ 0.06701785, -0.05514511, -0.01476882, ...,  0.00715050,\n",
       "           0.00359965,  0.03703189]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06330173, -0.08061309, -0.04132523, ..., -0.06171605,\n",
       "         -0.05903632, -0.03813280]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04038624, -0.03153719, -0.04486884, ...,  0.06937268,\n",
       "           0.00238660,  0.00462633],\n",
       "         [ 0.02697231, -0.07810778, -0.00530461, ...,  0.04892191,\n",
       "           0.01588615, -0.02809144],\n",
       "         [ 0.00620475, -0.02849613, -0.00488872, ..., -0.02944085,\n",
       "          -0.00421954, -0.00485915],\n",
       "         ...,\n",
       "         [-0.00222333, -0.03824960,  0.01656340, ..., -0.01359879,\n",
       "          -0.00316814,  0.04244627],\n",
       "         [ 0.01576062,  0.00117676,  0.03465547, ...,  0.00534002,\n",
       "          -0.00957956, -0.03543746],\n",
       "         [-0.03922075,  0.03528069,  0.04698691, ..., -0.02224552,\n",
       "          -0.01909704, -0.04533674]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02582171,  0.02858391, -0.02822003, ...,  0.08706655,\n",
       "         -0.01310323, -0.03085333]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.94602960, 0.93560201, 0.96940273, ..., 0.94384950, 0.95495099,\n",
       "         0.93721116]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.13666452,  0.06740961,  0.24714744, ...,  0.05493936,\n",
       "         -0.02943347,  0.05127873]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90467948, 0.93292862, 0.89632362, ..., 0.93428445, 0.96053994,\n",
       "         0.90887111]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.12613788, -0.02219705, -0.08584443, ...,  0.03465523,\n",
       "          0.00280716,  0.03019924]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02525022,  0.00997348,  0.02523055, ...,  0.01821265,\n",
       "           0.01927893, -0.02804378],\n",
       "         [ 0.00934064, -0.04756892,  0.01212151, ...,  0.05868220,\n",
       "           0.01743174, -0.04522275],\n",
       "         [-0.05335831,  0.02909278, -0.06018190, ..., -0.03175811,\n",
       "          -0.03409074,  0.02075919],\n",
       "         ...,\n",
       "         [-0.03246259,  0.03841541, -0.01159173, ..., -0.02544440,\n",
       "           0.02857324, -0.01477203],\n",
       "         [ 0.00069601, -0.00401515, -0.03121210, ...,  0.02699045,\n",
       "          -0.02644004, -0.03625650],\n",
       "         [ 0.01160645, -0.03046928,  0.04724977, ..., -0.01449508,\n",
       "           0.00447905, -0.03618418]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02486702,  0.00483830, -0.06196487, ..., -0.04950723,\n",
       "          0.00318141, -0.04628885]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01416538, -0.03613395,  0.02513991, ..., -0.02550254,\n",
       "           0.01536174,  0.01046561],\n",
       "         [ 0.00128976, -0.05321799, -0.00094758, ..., -0.02073003,\n",
       "           0.00385165,  0.01623077],\n",
       "         [-0.02344026,  0.06371332, -0.06331708, ...,  0.04763788,\n",
       "           0.00674263, -0.02445254],\n",
       "         ...,\n",
       "         [ 0.00379134, -0.02320586,  0.04097822, ...,  0.01700498,\n",
       "           0.00540856,  0.02748981],\n",
       "         [ 0.03022332,  0.00477480, -0.00118433, ...,  0.00658933,\n",
       "           0.02425473,  0.03914327],\n",
       "         [ 0.03268294,  0.03934529,  0.03580631, ..., -0.01468153,\n",
       "          -0.01619741,  0.02285166]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04470081,  0.07882296, -0.03312239, ..., -0.10481687,\n",
       "          0.17904553, -0.04678589]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02653860, -0.03695584,  0.02951830, ..., -0.05569368,\n",
       "          -0.05203701, -0.03448588],\n",
       "         [-0.02997836, -0.00208910, -0.01807279, ...,  0.02056126,\n",
       "          -0.00092571,  0.03345111],\n",
       "         [ 0.01940504, -0.01829948,  0.01312496, ..., -0.02723535,\n",
       "           0.00999050, -0.04778604],\n",
       "         ...,\n",
       "         [ 0.01868661, -0.01043159,  0.00705879, ..., -0.02021288,\n",
       "           0.00527732,  0.00475293],\n",
       "         [ 0.03974094, -0.02216908,  0.02411203, ..., -0.00396745,\n",
       "          -0.01381885,  0.00722956],\n",
       "         [ 0.04243631,  0.05131752,  0.01866504, ...,  0.02894462,\n",
       "          -0.00974737, -0.02251608]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00682494,  0.00718065,  0.00943569, ...,  0.00033061,\n",
       "          0.00380077, -0.01242587]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02560347,  0.04603404,  0.01466966, ..., -0.00779442,\n",
       "           0.03974799, -0.02575745],\n",
       "         [ 0.01130180,  0.01611723, -0.01469338, ...,  0.01351758,\n",
       "          -0.00127165,  0.01787735],\n",
       "         [-0.01964834,  0.05565464,  0.00488812, ...,  0.00077507,\n",
       "           0.02594108,  0.00857124],\n",
       "         ...,\n",
       "         [-0.02171527,  0.01764359, -0.01899547, ..., -0.00528950,\n",
       "           0.00270175,  0.04352304],\n",
       "         [-0.03526631,  0.03889945,  0.02359073, ...,  0.00800707,\n",
       "          -0.00693048,  0.03869750],\n",
       "         [ 0.00830131,  0.01082669, -0.01485202, ..., -0.04391113,\n",
       "           0.01789385,  0.00428850]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00321774,  0.01726199, -0.01119922, ...,  0.01594228,\n",
       "         -0.01356950,  0.02232339]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03664876,  0.08299423, -0.06810175, ...,  0.07155086,\n",
       "          -0.09021421, -0.02725267],\n",
       "         [ 0.00262020,  0.00953993, -0.01420933, ...,  0.01448051,\n",
       "          -0.00942457,  0.03747421],\n",
       "         [-0.01820736, -0.01777867, -0.02203698, ..., -0.05482380,\n",
       "          -0.02306272,  0.02269444],\n",
       "         ...,\n",
       "         [-0.01073818, -0.03439542, -0.03698038, ...,  0.03860046,\n",
       "           0.05953967,  0.00223158],\n",
       "         [-0.00494312, -0.02413690, -0.02241136, ...,  0.02070382,\n",
       "          -0.03459295,  0.02698510],\n",
       "         [-0.04337554, -0.00535397,  0.00926846, ..., -0.02016128,\n",
       "          -0.03217474,  0.05075156]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06642429, -0.07170234, -0.06812643, ..., -0.06019281,\n",
       "         -0.06323732, -0.08247820]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00773696, -0.00268321,  0.00632421, ...,  0.02429743,\n",
       "          -0.03457936,  0.04395073],\n",
       "         [ 0.03000369,  0.07178819, -0.00085886, ...,  0.02108173,\n",
       "           0.00012996, -0.04602132],\n",
       "         [-0.02257089, -0.01024841,  0.00287991, ..., -0.05408838,\n",
       "          -0.01149133,  0.01250494],\n",
       "         ...,\n",
       "         [-0.01869779,  0.01188279,  0.03368482, ..., -0.01765426,\n",
       "          -0.01429471, -0.00004435],\n",
       "         [-0.06735814, -0.00319236,  0.01050527, ...,  0.02841277,\n",
       "          -0.00733645, -0.00004277],\n",
       "         [-0.00074823, -0.03630643, -0.03597883, ...,  0.01190000,\n",
       "          -0.00577988,  0.01168995]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01862134, -0.00123157, -0.04569997, ...,  0.08507542,\n",
       "         -0.03216169,  0.00412705]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91890645, 0.90861154, 0.96628189, ..., 0.90526855, 0.94455820,\n",
       "         0.90617388]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.14411294,  0.06834798,  0.32178283, ...,  0.06243030,\n",
       "         -0.13738292,  0.14233761]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.85965973, 0.87435591, 0.82767040, ..., 0.89870644, 0.92101437,\n",
       "         0.86852270]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.12108129, -0.01575522, -0.09179127, ...,  0.04193841,\n",
       "          0.06296698, -0.02184233]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03380688,  0.04807649,  0.04148862, ...,  0.05621969,\n",
       "           0.01171872,  0.03739688],\n",
       "         [ 0.07536146,  0.00653215, -0.02172311, ...,  0.02080826,\n",
       "          -0.01734737,  0.04328398],\n",
       "         [-0.05615536, -0.00042504, -0.01416247, ..., -0.03495732,\n",
       "          -0.02041923,  0.03040441],\n",
       "         ...,\n",
       "         [-0.02851023,  0.00765766,  0.01112484, ...,  0.03089748,\n",
       "          -0.06270738,  0.03116149],\n",
       "         [ 0.01518233, -0.06055611, -0.08245116, ..., -0.06616655,\n",
       "          -0.01163218,  0.04284002],\n",
       "         [ 0.02861210,  0.06570279,  0.04717163, ...,  0.00120340,\n",
       "           0.01602398,  0.02459500]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02102922, -0.01445383, -0.03973243, ..., -0.05126784,\n",
       "         -0.03156053,  0.12396812]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02074802,  0.03802306, -0.00619604, ...,  0.06308566,\n",
       "          -0.00179902, -0.00632568],\n",
       "         [ 0.08615767,  0.01834288,  0.09253167, ...,  0.01334955,\n",
       "          -0.02464014, -0.00754465],\n",
       "         [ 0.00678109, -0.00632559, -0.03880756, ..., -0.07309668,\n",
       "           0.01825923, -0.02109207],\n",
       "         ...,\n",
       "         [-0.02538165,  0.03672335,  0.02449776, ..., -0.01942535,\n",
       "          -0.00113297, -0.02699711],\n",
       "         [ 0.07481990, -0.06120639, -0.07407296, ..., -0.13676056,\n",
       "          -0.02633959,  0.02001500],\n",
       "         [-0.03734317,  0.04944125,  0.02821858, ...,  0.01803591,\n",
       "           0.01387187, -0.00678328]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02535092,  0.00548275, -0.15597941, ..., -0.12344711,\n",
       "          0.04813453,  0.27004531]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00220596, -0.01619888,  0.00891397, ..., -0.01591601,\n",
       "          -0.03957880,  0.00046248],\n",
       "         [ 0.00317477,  0.02434142, -0.01682072, ..., -0.02396681,\n",
       "           0.02878522, -0.00931409],\n",
       "         [-0.01929663, -0.00972308, -0.02580839, ..., -0.02033661,\n",
       "          -0.03743759, -0.01160448],\n",
       "         ...,\n",
       "         [-0.02119110,  0.02721196,  0.03750570, ..., -0.05701033,\n",
       "           0.00604475, -0.04325784],\n",
       "         [ 0.02502355, -0.01110600,  0.00858043, ...,  0.02455712,\n",
       "           0.01548600,  0.02395849],\n",
       "         [ 0.01977784,  0.00230351,  0.00692518, ...,  0.00814558,\n",
       "           0.04576024,  0.00600056]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00145850, -0.00712285, -0.00073849, ...,  0.00663410,\n",
       "         -0.01109444, -0.01883978]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02222846, -0.00798066,  0.00630193, ...,  0.00146071,\n",
       "           0.01792075, -0.01550902],\n",
       "         [-0.00102717,  0.03915637,  0.00784601, ..., -0.00188191,\n",
       "           0.02245667,  0.05441244],\n",
       "         [ 0.01516188, -0.02673530, -0.06162628, ...,  0.02227389,\n",
       "           0.02187549, -0.02095728],\n",
       "         ...,\n",
       "         [-0.02286393,  0.05479193,  0.00865503, ...,  0.01455222,\n",
       "          -0.00759577,  0.02493307],\n",
       "         [ 0.01192001,  0.02076586, -0.03559021, ...,  0.01484361,\n",
       "          -0.00735056, -0.00929084],\n",
       "         [-0.01330237, -0.00333852,  0.01253251, ..., -0.00818697,\n",
       "           0.00905386, -0.03564806]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01331706, -0.01806567,  0.04605639, ...,  0.03244816,\n",
       "          0.00688528,  0.02974099]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00351270,  0.06981730,  0.00840263, ...,  0.02688709,\n",
       "           0.03053258,  0.08022568],\n",
       "         [-0.01497860, -0.01637135,  0.00722808, ..., -0.01411810,\n",
       "           0.00841993,  0.02292982],\n",
       "         [ 0.02392921, -0.06798774,  0.02454544, ..., -0.05106210,\n",
       "          -0.01425696,  0.03684787],\n",
       "         ...,\n",
       "         [ 0.03891969,  0.02768730,  0.04378244, ..., -0.00315902,\n",
       "           0.03664970,  0.01162622],\n",
       "         [-0.03390056, -0.06430257, -0.05577923, ..., -0.02697617,\n",
       "           0.02932780, -0.00053024],\n",
       "         [-0.04626441, -0.06141810, -0.04065566, ...,  0.00679405,\n",
       "           0.05760367,  0.01822959]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04625672, -0.09395215, -0.08552275, ...,  0.04141880,\n",
       "         -0.06599099, -0.08756623]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02121027,  0.00564026, -0.02963905, ...,  0.03943757,\n",
       "          -0.02763688, -0.00351428],\n",
       "         [ 0.00060014, -0.05157558,  0.03829021, ...,  0.00472567,\n",
       "           0.00383415, -0.00779823],\n",
       "         [-0.02437482, -0.02154900, -0.01676604, ...,  0.00017879,\n",
       "           0.01883107,  0.01978232],\n",
       "         ...,\n",
       "         [ 0.00364480,  0.04354706,  0.03758147, ...,  0.05241120,\n",
       "           0.03699256,  0.03405575],\n",
       "         [-0.03659790,  0.00801808,  0.00856293, ..., -0.03715747,\n",
       "           0.01856254, -0.00424565],\n",
       "         [ 0.04506321,  0.01111323,  0.03985028, ...,  0.01545806,\n",
       "           0.01365146, -0.02114736]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01423036,  0.04239644, -0.08600166, ...,  0.04143820,\n",
       "         -0.02112536, -0.00802210]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90010315, 0.91333568, 0.96468753, ..., 0.93274367, 0.94403005,\n",
       "         0.88995260]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00299480, -0.07702731,  0.30153364, ...,  0.13064542,\n",
       "         -0.14004233,  0.08640503]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.86856043, 0.86847001, 0.83318448, ..., 0.87944847, 0.88818556,\n",
       "         0.85346061]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.05180473,  0.02044404, -0.08346247, ..., -0.00960106,\n",
       "          0.08872372, -0.02259345]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01620971, -0.04560905,  0.03098615, ..., -0.00316686,\n",
       "          -0.01452449,  0.02478106],\n",
       "         [-0.04655116,  0.03137535, -0.03469355, ...,  0.00143017,\n",
       "          -0.00126999,  0.03925989],\n",
       "         [ 0.02541699,  0.00557904,  0.03699346, ...,  0.00542887,\n",
       "           0.01671376,  0.01225940],\n",
       "         ...,\n",
       "         [ 0.02343452, -0.03034202,  0.01583553, ...,  0.03642708,\n",
       "          -0.01698065, -0.04479694],\n",
       "         [-0.01259650,  0.05086679,  0.00403232, ...,  0.01624980,\n",
       "          -0.02007879,  0.00388376],\n",
       "         [-0.04312905, -0.03940958, -0.01197221, ...,  0.05321453,\n",
       "          -0.07952879,  0.05440563]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11712433,  0.06164765, -0.06698811, ...,  0.07491819,\n",
       "          0.07970842,  0.02759364]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01552467, -0.04890681,  0.05097117, ..., -0.01452721,\n",
       "          -0.02148134,  0.01617034],\n",
       "         [-0.00151417,  0.03504990, -0.03182294, ..., -0.06408381,\n",
       "           0.03554454, -0.02170342],\n",
       "         [-0.03568732,  0.01647079,  0.02755890, ..., -0.00720741,\n",
       "          -0.00100646,  0.00420907],\n",
       "         ...,\n",
       "         [-0.00313648, -0.00401388,  0.02978494, ...,  0.02710993,\n",
       "           0.00356990, -0.01775824],\n",
       "         [ 0.08011670,  0.04924062,  0.02638360, ..., -0.05846804,\n",
       "           0.03310552, -0.02365278],\n",
       "         [ 0.02099767,  0.05622954, -0.04962448, ...,  0.03714712,\n",
       "           0.04623958, -0.01611714]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02970341, -0.03920527, -0.02026020, ...,  0.02826411,\n",
       "         -0.01053408, -0.02425720]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00368040, -0.01163165, -0.05885848, ..., -0.00316089,\n",
       "          -0.04646534, -0.06630393],\n",
       "         [-0.02675333, -0.01044844,  0.01629238, ..., -0.02259798,\n",
       "          -0.00790832, -0.05486739],\n",
       "         [ 0.01214706,  0.02954725,  0.02558301, ...,  0.02377497,\n",
       "           0.00849482,  0.01912230],\n",
       "         ...,\n",
       "         [-0.02115771,  0.02560355,  0.01364876, ..., -0.01437963,\n",
       "           0.01070235, -0.02626784],\n",
       "         [-0.03823279, -0.01658314, -0.03770531, ..., -0.00202341,\n",
       "          -0.01240054,  0.01952831],\n",
       "         [-0.05002473, -0.02236416, -0.00600924, ...,  0.04451240,\n",
       "          -0.00663294, -0.03250650]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02776493, -0.01159485,  0.01236673, ...,  0.01444550,\n",
       "         -0.00486983,  0.00622440]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01846154, -0.00933932, -0.00018446, ...,  0.00239128,\n",
       "          -0.01921554, -0.02111529],\n",
       "         [ 0.02620279, -0.05159651, -0.00737029, ..., -0.04215209,\n",
       "           0.00029756,  0.02641732],\n",
       "         [ 0.04876318, -0.03095562,  0.01008690, ..., -0.00549633,\n",
       "          -0.03008938,  0.00908185],\n",
       "         ...,\n",
       "         [-0.03375439,  0.03316411, -0.01192684, ..., -0.00072493,\n",
       "          -0.01412632,  0.00021574],\n",
       "         [ 0.00228417,  0.03305425,  0.00174955, ..., -0.02817081,\n",
       "          -0.00398868,  0.01020736],\n",
       "         [ 0.02662574,  0.05463562, -0.00532984, ...,  0.01511543,\n",
       "          -0.00239537, -0.00018984]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.00540265, 0.00797991, 0.01923662, ..., 0.00891241, 0.00023567,\n",
       "         0.01341840]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.06274951,  0.07945332,  0.01841965, ...,  0.00071781,\n",
       "          -0.01624047,  0.01519056],\n",
       "         [ 0.01946210,  0.04991865,  0.01342262, ..., -0.00150899,\n",
       "          -0.01514412, -0.05370376],\n",
       "         [-0.08389179, -0.00409128,  0.02583046, ..., -0.00630115,\n",
       "           0.01170153, -0.04897782],\n",
       "         ...,\n",
       "         [-0.01145833, -0.03542885, -0.02991717, ..., -0.06116323,\n",
       "          -0.00308339, -0.00709347],\n",
       "         [ 0.06712300, -0.01133221, -0.00466776, ...,  0.01848467,\n",
       "          -0.02978520,  0.04790524],\n",
       "         [-0.01879886,  0.00273317, -0.00546179, ..., -0.02453848,\n",
       "           0.03832638, -0.00988463]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07938340, -0.06882890, -0.07691643, ..., -0.08104044,\n",
       "         -0.08440261, -0.08572096]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03470201, -0.05260455, -0.04447336, ..., -0.03178011,\n",
       "           0.03011216, -0.03662116],\n",
       "         [-0.05368047, -0.03558556,  0.03997234, ..., -0.00015956,\n",
       "          -0.02064098, -0.02471938],\n",
       "         [ 0.02492116,  0.02381684,  0.00684353, ...,  0.02712832,\n",
       "          -0.01779800, -0.02172330],\n",
       "         ...,\n",
       "         [ 0.05024826,  0.04659495,  0.06002700, ...,  0.00340735,\n",
       "           0.06516857,  0.01262121],\n",
       "         [-0.02835732, -0.02864577, -0.03120079, ...,  0.00182518,\n",
       "          -0.00962498,  0.03676590],\n",
       "         [ 0.01314224, -0.04077450,  0.03353657, ...,  0.01628619,\n",
       "           0.06126010,  0.03370872]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01547550,  0.05088839, -0.09637531, ...,  0.02647132,\n",
       "          0.02451104,  0.00769149]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91191322, 0.93411732, 0.99803013, ..., 0.94340795, 0.97544813,\n",
       "         0.90677744]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01603062, -0.16368960,  0.30049410, ...,  0.19713347,\n",
       "         -0.11984175,  0.08528440]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.88125497, 0.87915331, 0.85574061, ..., 0.88464046, 0.93392831,\n",
       "         0.86438161]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01618820,  0.05847332, -0.15155785, ..., -0.08062353,\n",
       "          0.08913953, -0.07354490]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00157293, -0.00919670,  0.02316195, ..., -0.02586107,\n",
       "           0.00221984, -0.02844881],\n",
       "         [ 0.07217497,  0.00399537,  0.00198101, ...,  0.01955234,\n",
       "          -0.02509576,  0.01195180],\n",
       "         [-0.04352979, -0.03020961, -0.04771511, ...,  0.00941115,\n",
       "           0.03678621,  0.02204640],\n",
       "         ...,\n",
       "         [-0.02108434,  0.03036138, -0.08341632, ...,  0.00337365,\n",
       "          -0.02927054,  0.00612737],\n",
       "         [-0.03147095, -0.01484789, -0.00764524, ...,  0.00569905,\n",
       "           0.03656472,  0.03373765],\n",
       "         [ 0.01699593,  0.05646973,  0.02555868, ..., -0.01874749,\n",
       "          -0.04172605, -0.00816155]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.15114419,  0.02228342,  0.38863695, ..., -0.02933374,\n",
       "          0.02248969, -0.07453002]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03970274,  0.03941768, -0.04736079, ...,  0.01707669,\n",
       "           0.02941790, -0.02698554],\n",
       "         [-0.03640243,  0.02217175,  0.00356769, ...,  0.03189336,\n",
       "          -0.00551184,  0.01844998],\n",
       "         [-0.00642844,  0.05800490,  0.00376029, ...,  0.00035130,\n",
       "           0.01985555,  0.04970741],\n",
       "         ...,\n",
       "         [-0.03453929, -0.01418229,  0.02443701, ..., -0.01154108,\n",
       "           0.04819652, -0.00380773],\n",
       "         [-0.03035449,  0.03613230, -0.03852251, ...,  0.00947247,\n",
       "           0.04085252,  0.03174260],\n",
       "         [-0.02383949, -0.01903046,  0.00943120, ...,  0.00541140,\n",
       "          -0.03444140,  0.01285043]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03306497, -0.04503963, -0.14246160, ...,  0.08947761,\n",
       "         -0.24728721,  0.06221331]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00273741,  0.01057714, -0.00033084, ...,  0.01444882,\n",
       "           0.01278752, -0.05431376],\n",
       "         [-0.06865352, -0.00734325,  0.01103945, ...,  0.01643217,\n",
       "          -0.07316630,  0.01969923],\n",
       "         [-0.00029593, -0.02500195, -0.01467490, ..., -0.02106159,\n",
       "           0.03492881, -0.00821112],\n",
       "         ...,\n",
       "         [-0.01294938,  0.02351945, -0.04695211, ...,  0.00275432,\n",
       "           0.02176201, -0.01409444],\n",
       "         [-0.02640696,  0.02415003, -0.00350878, ..., -0.01196201,\n",
       "           0.03261710, -0.00854834],\n",
       "         [ 0.00806285,  0.05429538,  0.02819853, ...,  0.01115885,\n",
       "           0.00243138,  0.03154756]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00671151,  0.00962553, -0.01803264, ...,  0.00024183,\n",
       "          0.01726011, -0.00309892]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03057409,  0.00288410,  0.05503271, ..., -0.05259801,\n",
       "           0.00897779,  0.04371420],\n",
       "         [ 0.02426711, -0.03052107,  0.03813267, ...,  0.03410167,\n",
       "          -0.03283604,  0.02833686],\n",
       "         [ 0.00581202, -0.03689761,  0.00679113, ...,  0.05074934,\n",
       "           0.02037095, -0.01019448],\n",
       "         ...,\n",
       "         [-0.01529931, -0.01230513, -0.02368005, ..., -0.00295667,\n",
       "           0.01251606, -0.02217311],\n",
       "         [ 0.02589613,  0.05019986, -0.02822282, ..., -0.01683327,\n",
       "          -0.02610164, -0.02757811],\n",
       "         [ 0.03259980, -0.01032188, -0.01849872, ...,  0.04238397,\n",
       "          -0.02228330,  0.00832932]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02026185,  0.02259838, -0.03171751, ...,  0.00101787,\n",
       "          0.00326002, -0.00759901]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01967999, -0.01924593,  0.02115881, ..., -0.06213649,\n",
       "          -0.01357924, -0.01102766],\n",
       "         [ 0.03137554,  0.00847778, -0.00023171, ...,  0.05535764,\n",
       "          -0.01340695,  0.10149105],\n",
       "         [ 0.05144629,  0.03077440, -0.01189708, ..., -0.01683447,\n",
       "           0.00008508, -0.00787574],\n",
       "         ...,\n",
       "         [-0.00706644, -0.03313646, -0.00958033, ...,  0.05701672,\n",
       "           0.01072607, -0.08097999],\n",
       "         [-0.00315071, -0.05312120,  0.02053762, ..., -0.01838971,\n",
       "           0.03492430,  0.09252689],\n",
       "         [-0.00336040, -0.01974069, -0.05228163, ..., -0.03990323,\n",
       "          -0.00152468, -0.00931251]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07401050, -0.07944326, -0.07633644, ..., -0.07434979,\n",
       "         -0.07115524, -0.07251805]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01071096, -0.02416724,  0.05032096, ..., -0.02705188,\n",
       "           0.01821935, -0.00250545],\n",
       "         [ 0.02228972,  0.00260459, -0.00322227, ...,  0.02111405,\n",
       "           0.04377576,  0.03020870],\n",
       "         [-0.01003814, -0.03121179,  0.00379972, ..., -0.07297442,\n",
       "          -0.04597769, -0.01309117],\n",
       "         ...,\n",
       "         [-0.00739180,  0.00699421, -0.00305540, ...,  0.09038488,\n",
       "           0.00807337,  0.03056293],\n",
       "         [ 0.01126506, -0.02593007, -0.03024018, ...,  0.01886912,\n",
       "          -0.02564907, -0.10041679],\n",
       "         [ 0.06130797,  0.10068315,  0.00156788, ..., -0.03887399,\n",
       "           0.00685058,  0.03200207]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00600650,  0.02959985, -0.07967660, ..., -0.00303168,\n",
       "         -0.00271580,  0.01661421]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90274310, 0.91616261, 0.96558905, ..., 0.92534983, 0.96804565,\n",
       "         0.88593072]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.07622778, -0.08663688,  0.27097580, ...,  0.16289634,\n",
       "         -0.04972670,  0.04509988]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.92892021, 0.94467449, 0.90503240, ..., 0.94718474, 1.00924659,\n",
       "         0.89064205]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06803160,  0.01651326, -0.16759479, ..., -0.12379067,\n",
       "          0.03936218, -0.06018992]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01645944, -0.00110132,  0.05721267, ...,  0.05670338,\n",
       "          -0.06143757,  0.02116298],\n",
       "         [ 0.05318939, -0.03424661,  0.09107473, ...,  0.00643509,\n",
       "           0.00739091, -0.03052291],\n",
       "         [ 0.00468693, -0.00649137,  0.01642319, ..., -0.03139646,\n",
       "           0.00863562,  0.03216072],\n",
       "         ...,\n",
       "         [-0.01039603,  0.06248394, -0.04222773, ...,  0.03824140,\n",
       "          -0.05030216,  0.00569024],\n",
       "         [-0.03975552, -0.07758250, -0.07925245, ..., -0.01805571,\n",
       "          -0.00660537, -0.01689503],\n",
       "         [-0.01594931,  0.02639727, -0.02701537, ..., -0.01993499,\n",
       "           0.03915585,  0.03943383]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04268955,  0.05650680,  0.05244983, ..., -0.19362609,\n",
       "          0.17445718, -0.35739923]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02392326,  0.03431656, -0.02542036, ..., -0.02779382,\n",
       "          -0.00686012,  0.00940440],\n",
       "         [-0.01772851, -0.04785739,  0.03712868, ..., -0.06415392,\n",
       "           0.00061310,  0.03076429],\n",
       "         [-0.00747574, -0.01553644, -0.07458159, ...,  0.04315230,\n",
       "          -0.05826787, -0.03647881],\n",
       "         ...,\n",
       "         [ 0.01411521,  0.02083189, -0.00797381, ...,  0.03179837,\n",
       "          -0.04297044, -0.00930720],\n",
       "         [-0.01045043, -0.04763203, -0.03988822, ...,  0.04822677,\n",
       "          -0.00701360,  0.00809740],\n",
       "         [-0.07130782,  0.01839141, -0.01913642, ..., -0.01396398,\n",
       "           0.02308682,  0.00611761]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.16321389, 0.18277295, 0.13306667, ..., 0.08990461, 0.00612404,\n",
       "         0.12486146]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02887514, -0.02687941,  0.04084717, ..., -0.01557303,\n",
       "           0.00383468,  0.00120676],\n",
       "         [-0.04774381, -0.01658677,  0.03232097, ...,  0.01392105,\n",
       "          -0.00183351,  0.01508192],\n",
       "         [-0.00093641,  0.00916918,  0.01638475, ..., -0.01464381,\n",
       "           0.02555167, -0.00514208],\n",
       "         ...,\n",
       "         [-0.00363764, -0.00256591,  0.04734938, ..., -0.00079785,\n",
       "           0.01646860,  0.02638915],\n",
       "         [-0.02575078,  0.00965003, -0.00521169, ...,  0.00611917,\n",
       "          -0.01035122, -0.00398822],\n",
       "         [-0.00520922,  0.00845477, -0.02362891, ..., -0.00916659,\n",
       "           0.03502503,  0.02816184]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.04719294,  0.02256671, -0.04648663, ..., -0.02889640,\n",
       "          0.01894476, -0.03040775]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00036346,  0.03867693, -0.00994973, ..., -0.00533597,\n",
       "           0.00503491, -0.00064666],\n",
       "         [ 0.01210742,  0.00440368, -0.04292953, ..., -0.02012360,\n",
       "          -0.03123745, -0.00246394],\n",
       "         [-0.01813881,  0.01176577, -0.03717897, ..., -0.03100852,\n",
       "           0.01185451,  0.00062346],\n",
       "         ...,\n",
       "         [ 0.01335914, -0.00541817,  0.02331955, ...,  0.00249005,\n",
       "           0.01920649, -0.00121260],\n",
       "         [ 0.01771336,  0.02870254, -0.03662108, ..., -0.02125874,\n",
       "          -0.00322677, -0.03666488],\n",
       "         [-0.01439105, -0.02305350,  0.00505187, ..., -0.03951306,\n",
       "          -0.00405833,  0.00889138]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00538653,  0.06317894, -0.03332582, ...,  0.07348315,\n",
       "         -0.04315170,  0.01434789]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01178819, -0.00858479, -0.00073724, ...,  0.00652279,\n",
       "           0.01677707, -0.07026646],\n",
       "         [ 0.04999716, -0.00432978, -0.00130038, ...,  0.03508716,\n",
       "           0.06152343, -0.04349520],\n",
       "         [-0.04266846,  0.01090301, -0.01094845, ..., -0.08525597,\n",
       "          -0.01653429, -0.05135628],\n",
       "         ...,\n",
       "         [ 0.04347723, -0.00037765, -0.01453897, ..., -0.02203736,\n",
       "          -0.01500141, -0.03166359],\n",
       "         [ 0.07192465,  0.00518894,  0.02059537, ...,  0.05330819,\n",
       "          -0.03862457, -0.02257478],\n",
       "         [-0.10213202, -0.03999119, -0.02616260, ...,  0.03343614,\n",
       "          -0.01168538, -0.00089295]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06283313, -0.02014690, -0.06207281, ..., -0.08467185,\n",
       "         -0.03116783, -0.07859302]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02341543, -0.00959854,  0.03718600, ..., -0.03377881,\n",
       "           0.00430652,  0.01227375],\n",
       "         [-0.02028036,  0.00512765,  0.04090320, ..., -0.00941237,\n",
       "          -0.01393618, -0.04612345],\n",
       "         [ 0.01890693,  0.00277378, -0.01164173, ..., -0.00900125,\n",
       "          -0.00750561, -0.03741794],\n",
       "         ...,\n",
       "         [-0.02670656,  0.01047785,  0.00077236, ...,  0.02052538,\n",
       "          -0.03162083, -0.05138053],\n",
       "         [-0.04544141, -0.03254434, -0.01646158, ...,  0.04742010,\n",
       "           0.01332909, -0.00703640],\n",
       "         [ 0.05472232, -0.00991647, -0.06255425, ...,  0.03295298,\n",
       "          -0.01430349,  0.06298971]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00768524, -0.00194863, -0.08029662, ..., -0.02544526,\n",
       "         -0.02473851,  0.05475409]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91041684, 0.92900145, 0.97243261, ..., 0.93199694, 0.95929790,\n",
       "         0.89136618]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03303102, -0.11742736,  0.23878746, ...,  0.11082016,\n",
       "          0.01158008, -0.01431019]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.94030493, 0.92569721, 0.88540763, ..., 0.93776667, 1.01090598,\n",
       "         0.88787633]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01157150,  0.03227582, -0.15525828, ..., -0.09141754,\n",
       "          0.02257527, -0.04913119]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04914455,  0.02481384, -0.04185954, ..., -0.01431483,\n",
       "           0.00240387, -0.02987926],\n",
       "         [ 0.00895251,  0.02411813, -0.00380282, ..., -0.01308491,\n",
       "          -0.00476777,  0.03696501],\n",
       "         [-0.03081588,  0.00990691, -0.00067603, ...,  0.00895613,\n",
       "           0.02553022, -0.00123565],\n",
       "         ...,\n",
       "         [-0.03426886, -0.02877931, -0.02318949, ...,  0.01261354,\n",
       "          -0.04045613,  0.02592612],\n",
       "         [ 0.02864576,  0.00667046,  0.03126473, ..., -0.00059500,\n",
       "           0.02955478,  0.02852032],\n",
       "         [ 0.02361967, -0.01802609,  0.00233899, ...,  0.05236093,\n",
       "           0.00091933,  0.00729866]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00427256,  0.01770321,  0.02901169, ..., -0.00696510,\n",
       "         -0.06042413, -0.05172079]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03230345, -0.04086738, -0.00520857, ..., -0.01386861,\n",
       "           0.00085905, -0.01966209],\n",
       "         [ 0.01500539, -0.00582238, -0.02343191, ..., -0.02277756,\n",
       "          -0.01935237, -0.02127424],\n",
       "         [-0.02275254,  0.01338232,  0.00258984, ...,  0.00481220,\n",
       "           0.04196810, -0.04703217],\n",
       "         ...,\n",
       "         [ 0.06220374,  0.04789198,  0.00203325, ...,  0.03317720,\n",
       "           0.05502317, -0.02984311],\n",
       "         [ 0.00805228, -0.01488882,  0.01130398, ..., -0.01035870,\n",
       "           0.05179714,  0.01815714],\n",
       "         [ 0.05637969, -0.01174146, -0.02351759, ..., -0.03319816,\n",
       "          -0.00134980,  0.02490211]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.10861035,  0.24191169,  0.34863511, ..., -0.07710074,\n",
       "         -0.06742996, -0.49149805]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01764765,  0.05311744,  0.01238860, ...,  0.00053928,\n",
       "           0.00791885, -0.00777203],\n",
       "         [ 0.01126399,  0.00358806, -0.01449637, ...,  0.06234708,\n",
       "           0.06112702,  0.03390437],\n",
       "         [ 0.00884905,  0.00032051, -0.01748706, ..., -0.04366452,\n",
       "           0.02947392,  0.01879255],\n",
       "         ...,\n",
       "         [-0.01807507,  0.00551250, -0.02997680, ..., -0.01501716,\n",
       "           0.00036944, -0.01395639],\n",
       "         [ 0.00267371,  0.01363740,  0.02186996, ...,  0.01158929,\n",
       "          -0.00226137, -0.00498831],\n",
       "         [ 0.01768754, -0.00601523,  0.02679238, ...,  0.04205087,\n",
       "          -0.01140830,  0.01933147]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00694902, -0.01260735,  0.03413962, ...,  0.01206533,\n",
       "          0.00436168, -0.01765770]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00891095,  0.00343766, -0.01430287, ..., -0.00437912,\n",
       "           0.02044433,  0.02046243],\n",
       "         [-0.01300011,  0.03379876,  0.01729446, ..., -0.03567056,\n",
       "           0.01702907,  0.00110346],\n",
       "         [ 0.02335511, -0.03785004,  0.03499012, ..., -0.00932552,\n",
       "           0.01169709, -0.01187002],\n",
       "         ...,\n",
       "         [-0.03080001,  0.00407373,  0.00275953, ...,  0.00471949,\n",
       "          -0.01792369,  0.01248472],\n",
       "         [ 0.00991338, -0.01064032,  0.00841515, ...,  0.02605110,\n",
       "          -0.02267374,  0.03234264],\n",
       "         [-0.00398178, -0.04027536, -0.00800358, ..., -0.05718777,\n",
       "           0.01945242,  0.00638092]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00466047, -0.00325754,  0.01552474, ..., -0.00622418,\n",
       "          0.00892059,  0.10920756]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05477000, -0.02088392, -0.05706711, ...,  0.01369629,\n",
       "          -0.00624509, -0.06516023],\n",
       "         [-0.00585976,  0.04927057, -0.00126941, ...,  0.01173862,\n",
       "           0.01623367,  0.03284916],\n",
       "         [-0.03101115,  0.01946129,  0.02731403, ...,  0.00911041,\n",
       "          -0.04180754,  0.02981427],\n",
       "         ...,\n",
       "         [ 0.02838359,  0.01379003, -0.07243607, ...,  0.04156595,\n",
       "          -0.02366978,  0.01026506],\n",
       "         [-0.02429375,  0.01146780, -0.02320224, ...,  0.04603010,\n",
       "           0.01249264, -0.05262753],\n",
       "         [-0.01341172, -0.00363162,  0.04133292, ...,  0.03193299,\n",
       "          -0.01942892, -0.04265017]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.09110897, -0.08223435, -0.07207403, ...,  0.00938086,\n",
       "          0.03468283, -0.02931571]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05986182,  0.02804859, -0.04116379, ...,  0.01490304,\n",
       "           0.00311553, -0.04326749],\n",
       "         [-0.01836013,  0.05751385,  0.02399960, ...,  0.01852573,\n",
       "          -0.02068319,  0.03313210],\n",
       "         [ 0.00957355,  0.02570712,  0.00239368, ...,  0.00440887,\n",
       "           0.03556174,  0.01934461],\n",
       "         ...,\n",
       "         [-0.03976499,  0.07409966,  0.01713257, ...,  0.02165014,\n",
       "           0.03369028,  0.06084331],\n",
       "         [-0.04402779,  0.00643101,  0.01413611, ...,  0.03178599,\n",
       "           0.02190585,  0.04666542],\n",
       "         [ 0.00986791, -0.06544518,  0.02017365, ...,  0.00849102,\n",
       "          -0.00582980,  0.03534719]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02279478,  0.03358344, -0.03583237, ...,  0.02508860,\n",
       "         -0.07104435,  0.06592368]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91363966, 0.90465671, 0.92790288, ..., 0.94004893, 0.94849735,\n",
       "         0.88802880]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02926966, -0.10560635,  0.17815672, ...,  0.15558781,\n",
       "          0.06121523, -0.06644358]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90946883, 0.91726625, 0.90760428, ..., 0.92126721, 0.98054278,\n",
       "         0.89457297]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00406428,  0.03929247, -0.06246166, ..., -0.05230488,\n",
       "          0.00197186,  0.01944300]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03538308,  0.01018057, -0.01251241, ...,  0.01073656,\n",
       "          -0.08388323, -0.01430826],\n",
       "         [ 0.01896496, -0.01782219, -0.02333739, ..., -0.00073895,\n",
       "           0.05531346,  0.03633278],\n",
       "         [-0.03783100, -0.01645574, -0.03033436, ...,  0.02219100,\n",
       "           0.01046022, -0.01295591],\n",
       "         ...,\n",
       "         [-0.00950601,  0.00143231, -0.03729945, ...,  0.01433766,\n",
       "          -0.02161212,  0.00798458],\n",
       "         [ 0.02040522, -0.00803297, -0.00770934, ...,  0.02340165,\n",
       "          -0.01210863, -0.01093119],\n",
       "         [-0.01261359, -0.01729089,  0.01467079, ..., -0.00609337,\n",
       "          -0.00367250,  0.04830111]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02688649, -0.14536770,  0.18096966, ...,  0.11206455,\n",
       "         -0.03406007,  0.02992524]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03197132, -0.04858785, -0.00798439, ...,  0.06775092,\n",
       "          -0.03077757, -0.01798019],\n",
       "         [ 0.02210682,  0.03439195,  0.03176307, ...,  0.00560363,\n",
       "           0.01271306, -0.01674884],\n",
       "         [-0.01796863,  0.02465871,  0.02027617, ..., -0.01325801,\n",
       "          -0.03810804,  0.04478473],\n",
       "         ...,\n",
       "         [ 0.04419782,  0.02703919,  0.03916579, ...,  0.00621506,\n",
       "          -0.01454278, -0.07832742],\n",
       "         [-0.03818258, -0.00868636,  0.03360559, ..., -0.04451760,\n",
       "          -0.07124975, -0.00262361],\n",
       "         [ 0.02086318,  0.02943123, -0.03169481, ..., -0.01251203,\n",
       "          -0.01960608,  0.04419363]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08861177,  0.02036802,  0.15411504, ...,  0.09790452,\n",
       "         -0.29928333,  0.00132499]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04805978,  0.01980548,  0.07689622, ...,  0.05275806,\n",
       "           0.01207626, -0.02179280],\n",
       "         [-0.00125577, -0.07469635, -0.06302358, ..., -0.05653621,\n",
       "           0.02765130,  0.02694579],\n",
       "         [ 0.00725264,  0.00693710,  0.00598896, ...,  0.00213343,\n",
       "           0.03544633,  0.01788708],\n",
       "         ...,\n",
       "         [ 0.00571834, -0.02812434,  0.01447497, ...,  0.04494910,\n",
       "          -0.02982744, -0.08320878],\n",
       "         [-0.02461279,  0.01824461,  0.02250403, ...,  0.02345819,\n",
       "           0.07024187,  0.04168170],\n",
       "         [ 0.02222569,  0.00048392, -0.01645726, ...,  0.02760743,\n",
       "          -0.03289435, -0.03795275]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00771586,  0.00304864, -0.01058285, ..., -0.00071838,\n",
       "          0.01253403,  0.00010490]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01362179, -0.01228201,  0.02945867, ...,  0.03951726,\n",
       "           0.06178520,  0.01086211],\n",
       "         [ 0.01601996,  0.00176369,  0.03269286, ..., -0.00513804,\n",
       "          -0.02994656,  0.00323572],\n",
       "         [-0.05944305,  0.05366262,  0.00678045, ...,  0.02546630,\n",
       "           0.01577497,  0.01398287],\n",
       "         ...,\n",
       "         [-0.00437649, -0.00169571, -0.06423540, ...,  0.01780980,\n",
       "           0.03987381, -0.02634483],\n",
       "         [ 0.01727470, -0.04313487,  0.04264866, ...,  0.01469304,\n",
       "          -0.01814170, -0.02711133],\n",
       "         [-0.02389555,  0.00805750,  0.02149708, ..., -0.00676353,\n",
       "           0.00285572,  0.06383098]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02662213, -0.08740468, -0.00331191, ...,  0.08682272,\n",
       "         -0.01374793,  0.03058601]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01915744, -0.00411907, -0.01125680, ...,  0.00833294,\n",
       "          -0.07426554, -0.02673411],\n",
       "         [ 0.02079125, -0.00414610,  0.03645442, ..., -0.00069318,\n",
       "          -0.00318838,  0.02645848],\n",
       "         [ 0.03058129, -0.03576641,  0.01357151, ...,  0.02692423,\n",
       "           0.05012881, -0.02250883],\n",
       "         ...,\n",
       "         [-0.01137183, -0.03744521,  0.04163112, ..., -0.00817413,\n",
       "          -0.00710329, -0.00221190],\n",
       "         [ 0.03925821,  0.02364125, -0.03110881, ...,  0.02774203,\n",
       "          -0.02100562,  0.00539468],\n",
       "         [-0.01228705, -0.02692647,  0.02303310, ...,  0.04659699,\n",
       "          -0.00763856, -0.02319642]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07777014, -0.02577599, -0.05460755, ..., -0.08819459,\n",
       "         -0.07305256, -0.09653366]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01427169,  0.01315905,  0.02187943, ...,  0.02795485,\n",
       "          -0.02512600,  0.00469289],\n",
       "         [ 0.04137782,  0.02893962,  0.04644689, ..., -0.02909283,\n",
       "          -0.01957322,  0.01237540],\n",
       "         [-0.00958222,  0.01093161, -0.02297383, ...,  0.00152503,\n",
       "          -0.02026521, -0.01345396],\n",
       "         ...,\n",
       "         [-0.01778005,  0.05638054, -0.01815024, ...,  0.00076212,\n",
       "           0.00094645,  0.01440251],\n",
       "         [ 0.01670219,  0.02210589, -0.02048748, ..., -0.00623645,\n",
       "          -0.01684329, -0.06787483],\n",
       "         [-0.05446017, -0.05345682,  0.00473014, ..., -0.02658066,\n",
       "           0.01558983,  0.07064301]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02312165,  0.00322920, -0.00645101, ...,  0.03040004,\n",
       "         -0.05707321,  0.04406023]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90788680, 0.90355569, 0.91523618, ..., 0.92875504, 0.95141250,\n",
       "         0.87363231]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02602037, -0.07180270,  0.09320769, ...,  0.08954467,\n",
       "          0.06064738,  0.01407709]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.89134812, 0.89967889, 0.89376909, ..., 0.91330904, 0.96290195,\n",
       "         0.85717756]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01046764, -0.00377135, -0.02940233, ..., -0.04233900,\n",
       "         -0.02097282, -0.01970338]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00386459,  0.01617385, -0.02247608, ...,  0.01372136,\n",
       "          -0.08997398,  0.06247601],\n",
       "         [-0.01904178, -0.03591531,  0.03665331, ...,  0.00892878,\n",
       "           0.08186270,  0.10515185],\n",
       "         [ 0.00059213,  0.00878551, -0.08889096, ...,  0.07396272,\n",
       "          -0.09052765, -0.00277337],\n",
       "         ...,\n",
       "         [-0.00792000, -0.00528079,  0.00151087, ..., -0.05280887,\n",
       "           0.10651544, -0.03912970],\n",
       "         [-0.05079252, -0.04313026, -0.07054727, ..., -0.01825853,\n",
       "          -0.04112098,  0.02779458],\n",
       "         [ 0.02814453, -0.00452590,  0.07116905, ..., -0.02289633,\n",
       "           0.06878462, -0.01122809]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11378269,  0.03080056,  0.11700400, ..., -0.02067091,\n",
       "         -0.04918093,  0.00466941]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05513529, -0.01902248,  0.03439472, ..., -0.08734810,\n",
       "           0.01004401, -0.02954047],\n",
       "         [-0.04421583,  0.07797311, -0.02319006, ...,  0.00114298,\n",
       "          -0.00192046, -0.01077057],\n",
       "         [-0.00755303, -0.04602458,  0.02093693, ...,  0.00051806,\n",
       "          -0.02092226,  0.08345028],\n",
       "         ...,\n",
       "         [-0.03515130,  0.00670630, -0.04985934, ..., -0.02868390,\n",
       "           0.01072811,  0.03132531],\n",
       "         [-0.01074285,  0.08735020,  0.03146072, ..., -0.04457564,\n",
       "          -0.01583859,  0.02869688],\n",
       "         [-0.01723269, -0.00706636,  0.03469196, ...,  0.01455405,\n",
       "          -0.01904934, -0.00848046]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00032046, -0.01594060,  0.03150896, ...,  0.04255866,\n",
       "          0.07266828,  0.17110194]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02524042, -0.01156613, -0.03102603, ...,  0.00633657,\n",
       "          -0.00710327,  0.00088418],\n",
       "         [ 0.01891261, -0.02133663,  0.03108322, ...,  0.02220915,\n",
       "           0.01325203, -0.01371997],\n",
       "         [-0.05520946,  0.06507695,  0.00684695, ...,  0.00432709,\n",
       "           0.00943187,  0.03131051],\n",
       "         ...,\n",
       "         [ 0.01063357, -0.01432649, -0.04701619, ...,  0.00882386,\n",
       "          -0.02744542, -0.00031725],\n",
       "         [-0.01568667,  0.00701148, -0.00544578, ..., -0.02983680,\n",
       "           0.00541605,  0.00833206],\n",
       "         [-0.00256457,  0.00458861,  0.03443707, ..., -0.00973082,\n",
       "           0.04205228, -0.01484039]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01232762,  0.01992843,  0.00329195, ...,  0.00420778,\n",
       "         -0.00574968,  0.08667539]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04615640,  0.01281291, -0.03866822, ..., -0.06109206,\n",
       "           0.02434283, -0.07182746],\n",
       "         [ 0.04398469,  0.03055700, -0.00874852, ...,  0.00003953,\n",
       "           0.00802639,  0.01216986],\n",
       "         [ 0.05045652, -0.00559819, -0.00347532, ...,  0.00644745,\n",
       "          -0.00214704,  0.03320580],\n",
       "         ...,\n",
       "         [-0.00288285, -0.00761148, -0.00951443, ..., -0.00649285,\n",
       "          -0.02826624,  0.00905112],\n",
       "         [-0.03540911,  0.02118564,  0.01698185, ..., -0.02052954,\n",
       "           0.00487551, -0.00077992],\n",
       "         [-0.00681161,  0.00237399, -0.01225946, ...,  0.01300215,\n",
       "           0.00087761, -0.01145677]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01715026, -0.04203990,  0.00139860, ..., -0.05901207,\n",
       "         -0.02252339,  0.10716650]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02396782,  0.01451411, -0.05181728, ...,  0.04699504,\n",
       "          -0.02610783, -0.02769667],\n",
       "         [ 0.01398061,  0.03564427,  0.00419557, ..., -0.02287082,\n",
       "           0.01658864, -0.02360392],\n",
       "         [-0.05237678,  0.05923977, -0.06549666, ..., -0.00959357,\n",
       "          -0.12796871,  0.00248267],\n",
       "         ...,\n",
       "         [-0.01182477, -0.02209351,  0.05464987, ..., -0.02026761,\n",
       "           0.04737367,  0.02360628],\n",
       "         [ 0.01203627,  0.01551853,  0.01651492, ..., -0.01516623,\n",
       "           0.02038913, -0.06470333],\n",
       "         [ 0.04425601,  0.02097624,  0.02647918, ..., -0.01142650,\n",
       "           0.00844620,  0.02416505]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07613230, -0.05756746, -0.08893313, ..., -0.04608973,\n",
       "         -0.10790805, -0.04605167]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04900569,  0.00422795, -0.03068528, ..., -0.02181638,\n",
       "           0.01244559, -0.02348805],\n",
       "         [ 0.02022150,  0.03219492,  0.00608654, ..., -0.01228870,\n",
       "           0.01271608,  0.00065512],\n",
       "         [ 0.01565040, -0.04344282,  0.07864422, ..., -0.03911450,\n",
       "           0.04770081, -0.00248255],\n",
       "         ...,\n",
       "         [ 0.00340492,  0.01309512, -0.03801236, ..., -0.02992273,\n",
       "           0.00534698,  0.05892901],\n",
       "         [ 0.01059243,  0.00601713, -0.07151075, ...,  0.01695063,\n",
       "          -0.00467405,  0.05191450],\n",
       "         [ 0.01024429, -0.03597855,  0.02645372, ...,  0.03255892,\n",
       "          -0.04917452, -0.02181352]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03326367, -0.00964120, -0.00633800, ..., -0.04283603,\n",
       "         -0.11842811,  0.03111336]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.89756298, 0.89123082, 0.90314639, ..., 0.92543739, 0.97821075,\n",
       "         0.85351938]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00936892, -0.04785558,  0.09253957, ...,  0.20781167,\n",
       "         -0.04065345, -0.08334860]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.85630471, 0.88069838, 0.86673933, ..., 0.87348843, 0.92974913,\n",
       "         0.84571487]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00975297,  0.00476136, -0.02483401, ..., -0.10593291,\n",
       "          0.00928201,  0.01711968]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00965272, -0.04250776,  0.04286716, ..., -0.07035988,\n",
       "          -0.01544900,  0.01090079],\n",
       "         [ 0.03248251, -0.01258503, -0.00399783, ..., -0.00329400,\n",
       "           0.01618955,  0.00706371],\n",
       "         [-0.01602150, -0.08455168, -0.02101744, ..., -0.01097917,\n",
       "           0.01932612,  0.02802197],\n",
       "         ...,\n",
       "         [ 0.05307091, -0.05537638, -0.05845071, ...,  0.00446768,\n",
       "          -0.03727963, -0.02543362],\n",
       "         [ 0.01574416,  0.02872995,  0.01970221, ...,  0.04533172,\n",
       "           0.01399978, -0.01854716],\n",
       "         [-0.00702682,  0.06231867, -0.01865251, ..., -0.01434674,\n",
       "           0.09243033,  0.04206719]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.08696913,  0.05382522, -0.02537982, ...,  0.10459639,\n",
       "         -0.06339618, -0.00632953]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01257013, -0.01818248, -0.02468867, ..., -0.06160270,\n",
       "          -0.00039322,  0.04248675],\n",
       "         [ 0.04628785, -0.02676297,  0.00525550, ...,  0.03481279,\n",
       "           0.02233996,  0.01365132],\n",
       "         [-0.04735937, -0.00301722, -0.03536402, ..., -0.01636937,\n",
       "          -0.04443841, -0.03044484],\n",
       "         ...,\n",
       "         [-0.02960213,  0.03438141,  0.01024313, ...,  0.00830206,\n",
       "          -0.01563803, -0.00427836],\n",
       "         [ 0.01943152,  0.01222918, -0.00084774, ..., -0.01270372,\n",
       "          -0.01114109,  0.05384707],\n",
       "         [-0.00329314,  0.02841735,  0.01400429, ...,  0.01747740,\n",
       "          -0.06720136,  0.03999337]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.37845913, -0.26668978, -0.32822454, ...,  0.12004040,\n",
       "         -0.25263330,  0.00465063]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01152014,  0.05623285, -0.01599250, ...,  0.00000309,\n",
       "           0.01970500,  0.00738411],\n",
       "         [-0.00700328,  0.04575947,  0.01232667, ...,  0.05671566,\n",
       "          -0.02119248,  0.03244673],\n",
       "         [-0.01957578,  0.03281967,  0.03176875, ..., -0.00143266,\n",
       "          -0.01153245, -0.00737897],\n",
       "         ...,\n",
       "         [-0.02126837, -0.04057017, -0.03724524, ...,  0.03581547,\n",
       "           0.03658266, -0.00566942],\n",
       "         [-0.01508931, -0.03457372, -0.04755278, ...,  0.00773972,\n",
       "          -0.01030966,  0.02231431],\n",
       "         [-0.03183440,  0.01739812,  0.05626680, ...,  0.02733516,\n",
       "          -0.00018490,  0.02853000]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01104302,  0.02621641, -0.00137250, ..., -0.00036582,\n",
       "         -0.03519859, -0.08571228]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00603982, -0.03404764, -0.01310442, ..., -0.00299937,\n",
       "          -0.02052747,  0.01527405],\n",
       "         [ 0.01142874, -0.02904579,  0.02788821, ...,  0.02271727,\n",
       "          -0.01006074, -0.02793089],\n",
       "         [-0.04719558, -0.01797715,  0.06327135, ..., -0.03996994,\n",
       "          -0.04400016, -0.00539443],\n",
       "         ...,\n",
       "         [ 0.00740639,  0.03507692,  0.02254636, ..., -0.00246577,\n",
       "          -0.02470388,  0.05933399],\n",
       "         [ 0.03067776,  0.01469063, -0.00469437, ..., -0.02019646,\n",
       "          -0.01299332, -0.01346829],\n",
       "         [ 0.02048670,  0.03073333, -0.01075032, ...,  0.02551979,\n",
       "           0.00201940,  0.03929907]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04351561, -0.01120257, -0.00835043, ..., -0.01812008,\n",
       "         -0.00430295,  0.05558858]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00371333, -0.03507373, -0.02270810, ..., -0.01407082,\n",
       "           0.00471978,  0.01042539],\n",
       "         [-0.02431703, -0.02915119,  0.01552758, ...,  0.00817508,\n",
       "          -0.01193655,  0.02075509],\n",
       "         [-0.02207215,  0.02721941, -0.00363961, ...,  0.00712708,\n",
       "           0.03197444, -0.00978914],\n",
       "         ...,\n",
       "         [ 0.00985953, -0.02873943, -0.04195756, ..., -0.03799156,\n",
       "          -0.02831369, -0.04502012],\n",
       "         [-0.00140197,  0.01405528, -0.00758565, ...,  0.00203092,\n",
       "           0.02715702,  0.04274823],\n",
       "         [ 0.00588775, -0.01352227,  0.01854353, ...,  0.07924407,\n",
       "           0.00873893, -0.04269660]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08765444, -0.03520038, -0.09954143, ..., -0.09838357,\n",
       "         -0.03140571, -0.04797393]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01135853, -0.01125981, -0.02049443, ..., -0.02044005,\n",
       "          -0.02259785,  0.00946043],\n",
       "         [ 0.00047928,  0.02316320,  0.03352047, ...,  0.00080685,\n",
       "          -0.03456743, -0.01328012],\n",
       "         [ 0.03248323, -0.03780395, -0.00064561, ...,  0.00530206,\n",
       "          -0.00955564,  0.06567828],\n",
       "         ...,\n",
       "         [-0.00630769,  0.01780460,  0.00466285, ..., -0.03277393,\n",
       "          -0.02644830, -0.00526384],\n",
       "         [ 0.01885011,  0.02148437, -0.01662028, ..., -0.00708767,\n",
       "          -0.00565544,  0.02053009],\n",
       "         [ 0.02477874,  0.01506358,  0.01116655, ..., -0.00708454,\n",
       "           0.00903334, -0.05275095]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.06804319,  0.00458962, -0.02376591, ..., -0.06011189,\n",
       "         -0.06606505,  0.02801540]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.85125744, 0.83661556, 0.87781388, ..., 0.87725216, 0.95085537,\n",
       "         0.81941146]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.05317911, -0.03591057,  0.20516017, ...,  0.13731937,\n",
       "         -0.12709275, -0.08215416]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.83814621, 0.87267637, 0.84304523, ..., 0.86259049, 0.88411707,\n",
       "         0.81235564]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02163494, -0.00694682, -0.05896046, ..., -0.06261682,\n",
       "          0.03949421,  0.04043249]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03501302,  0.03018858,  0.03661941, ...,  0.00978265,\n",
       "           0.03156612, -0.05476935],\n",
       "         [-0.00991837, -0.01240232, -0.01831995, ..., -0.07278183,\n",
       "          -0.04727258,  0.00756496],\n",
       "         [ 0.04968473, -0.01692480,  0.03120444, ..., -0.00158221,\n",
       "          -0.00065053,  0.01177268],\n",
       "         ...,\n",
       "         [-0.00429989,  0.08016504, -0.00157381, ...,  0.07861188,\n",
       "           0.00161727, -0.08953319],\n",
       "         [ 0.01631587, -0.01743088, -0.01715460, ...,  0.00338537,\n",
       "           0.03959005,  0.04060884],\n",
       "         [ 0.01759223, -0.06978279,  0.01469684, ..., -0.04216471,\n",
       "           0.03592831,  0.05522601]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06405069, -0.02417626, -0.05481341, ..., -0.09836054,\n",
       "          0.17045116, -0.01261259]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02682483, -0.02102753, -0.02122916, ...,  0.08531135,\n",
       "          -0.00486700, -0.02029982],\n",
       "         [-0.05505390,  0.01445113, -0.04614696, ..., -0.01527161,\n",
       "          -0.02722833, -0.06723098],\n",
       "         [ 0.04575438,  0.04732095, -0.03016899, ...,  0.05616719,\n",
       "          -0.00869686, -0.00728364],\n",
       "         ...,\n",
       "         [-0.02608656,  0.00967433, -0.01983025, ...,  0.04830708,\n",
       "           0.04546465, -0.12036934],\n",
       "         [ 0.04962548, -0.00230622,  0.04710546, ...,  0.01732818,\n",
       "          -0.00672474,  0.01740935],\n",
       "         [-0.03407332,  0.00805629, -0.03464381, ..., -0.04751915,\n",
       "           0.03246695, -0.07769530]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03388688, -0.04051855, -0.04556179, ..., -0.02194118,\n",
       "          0.50741053, -0.04417201]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04074572,  0.02452112, -0.02356214, ...,  0.00678051,\n",
       "           0.00833152,  0.00132719],\n",
       "         [ 0.02182884,  0.01177052, -0.02985753, ..., -0.01239609,\n",
       "          -0.01703457,  0.02303630],\n",
       "         [-0.01797504,  0.01877809,  0.04157995, ..., -0.01086351,\n",
       "          -0.00929779,  0.02847199],\n",
       "         ...,\n",
       "         [-0.00378595,  0.01563191,  0.03524701, ..., -0.01426530,\n",
       "          -0.02716791,  0.01697749],\n",
       "         [ 0.00440138,  0.04618808, -0.03069574, ...,  0.00842788,\n",
       "          -0.01815901,  0.00045163],\n",
       "         [-0.02795562,  0.02384343,  0.00522414, ...,  0.04911107,\n",
       "           0.03808799,  0.01670834]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01440641,  0.01882312,  0.01136947, ..., -0.01003689,\n",
       "         -0.02269474,  0.04307024]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02655586, -0.00419396, -0.00366827, ...,  0.01998603,\n",
       "           0.00128623, -0.00327743],\n",
       "         [-0.02765294, -0.01796063, -0.00071650, ..., -0.01154523,\n",
       "           0.03113903, -0.02873746],\n",
       "         [ 0.01832886,  0.02185817, -0.00231846, ...,  0.01587060,\n",
       "           0.02344335, -0.01574544],\n",
       "         ...,\n",
       "         [ 0.01015431,  0.01476849, -0.01995412, ...,  0.04166604,\n",
       "           0.02991275,  0.01794981],\n",
       "         [-0.04011801,  0.02862328,  0.03609057, ..., -0.01671811,\n",
       "           0.02445957,  0.03262664],\n",
       "         [ 0.00232651, -0.00397825, -0.02807488, ..., -0.03579476,\n",
       "          -0.02871077,  0.04463149]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00184202,  0.01740104, -0.02379120, ..., -0.04877727,\n",
       "         -0.01149200,  0.00486433]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01560514, -0.07074734,  0.00401732, ...,  0.03151118,\n",
       "          -0.04281141,  0.02095548],\n",
       "         [ 0.02900624,  0.01761520, -0.01271771, ...,  0.02165873,\n",
       "          -0.01454263, -0.02130512],\n",
       "         [-0.02874614, -0.01421616,  0.01998836, ..., -0.01432651,\n",
       "          -0.01426523, -0.06459422],\n",
       "         ...,\n",
       "         [ 0.01386392,  0.00470283,  0.05304631, ..., -0.00718123,\n",
       "          -0.00259860, -0.00562586],\n",
       "         [ 0.06367473, -0.00040412,  0.03144833, ...,  0.02592428,\n",
       "          -0.01065795,  0.01653275],\n",
       "         [-0.00051811,  0.03394159, -0.02675230, ..., -0.02314733,\n",
       "          -0.04600877,  0.04055053]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07166687, -0.06705162, -0.09168223, ..., -0.09513054,\n",
       "         -0.07075720, -0.02514962]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01737836, -0.03061024, -0.01810622, ...,  0.06711366,\n",
       "          -0.01013427,  0.04229106],\n",
       "         [-0.00097479,  0.05226351, -0.01040202, ..., -0.03365973,\n",
       "          -0.02798437, -0.02046109],\n",
       "         [ 0.00110942, -0.00398437,  0.02171407, ..., -0.03010242,\n",
       "          -0.00430890,  0.00398239],\n",
       "         ...,\n",
       "         [ 0.00684173, -0.02755071,  0.03107509, ...,  0.06758308,\n",
       "           0.03382513, -0.02514008],\n",
       "         [ 0.00908181, -0.00839121, -0.00202709, ..., -0.02983308,\n",
       "          -0.02324181,  0.02519940],\n",
       "         [-0.09471492, -0.01741084,  0.04127817, ..., -0.01897779,\n",
       "          -0.00321677, -0.04545220]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.06382248,  0.01359472,  0.06035831, ..., -0.04611046,\n",
       "         -0.03787510, -0.05942323]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.83227295, 0.78566849, 0.85186601, ..., 0.86272609, 0.90548235,\n",
       "         0.79008025]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04127667,  0.02449795,  0.08855628, ...,  0.16701108,\n",
       "         -0.06242691,  0.01168709]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.81552345, 0.82877934, 0.83005619, ..., 0.82822800, 0.86718851,\n",
       "         0.80979079]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00154104, -0.04134180, -0.01487346, ..., -0.07775601,\n",
       "          0.04180989, -0.00536759]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04423125, -0.00151888, -0.01126574, ...,  0.07257059,\n",
       "          -0.02731586, -0.02456619],\n",
       "         [-0.02418322,  0.05469523,  0.01023780, ...,  0.02766413,\n",
       "          -0.00464458, -0.00848151],\n",
       "         [ 0.00336447, -0.04425853,  0.01857498, ...,  0.03001507,\n",
       "          -0.10236237,  0.03463997],\n",
       "         ...,\n",
       "         [-0.00534850,  0.02664109, -0.00428324, ...,  0.08452880,\n",
       "          -0.02359630, -0.00000180],\n",
       "         [-0.01861485,  0.03166460, -0.04066400, ..., -0.02769537,\n",
       "           0.03144030,  0.02708971],\n",
       "         [ 0.00774314, -0.00251167, -0.02750039, ..., -0.01392423,\n",
       "          -0.02825489,  0.05495920]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.33438760, -0.08886781, -0.03985358, ..., -0.01868708,\n",
       "         -0.05548369, -0.05405370]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00182123,  0.01236733, -0.02858185, ..., -0.03517187,\n",
       "          -0.01965582, -0.03676076],\n",
       "         [-0.01077216, -0.00428648,  0.04745959, ..., -0.04770785,\n",
       "          -0.00210348,  0.01893924],\n",
       "         [-0.01836362, -0.00017704, -0.00198370, ..., -0.02253495,\n",
       "          -0.01137373, -0.03524133],\n",
       "         ...,\n",
       "         [-0.01733949, -0.05274817,  0.02939005, ..., -0.01916321,\n",
       "          -0.06586710,  0.02827992],\n",
       "         [ 0.02039657, -0.01061583,  0.03341808, ..., -0.01608117,\n",
       "          -0.04614154,  0.00198659],\n",
       "         [ 0.02724009,  0.00071526, -0.02531865, ..., -0.00126453,\n",
       "           0.00511679, -0.06094822]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.79127318, -0.24246405, -0.20169002, ...,  0.18240429,\n",
       "          0.35526103,  0.03698255]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00491615, -0.03080594, -0.02981225, ..., -0.02225260,\n",
       "           0.03037158,  0.03702299],\n",
       "         [ 0.00105535, -0.03788039, -0.03354237, ..., -0.06982581,\n",
       "          -0.00383314,  0.02625431],\n",
       "         [ 0.01029072, -0.02709830,  0.04471479, ...,  0.01364813,\n",
       "          -0.02132356,  0.00661882],\n",
       "         ...,\n",
       "         [ 0.04620373,  0.02750327,  0.03408290, ..., -0.01570438,\n",
       "           0.01136414,  0.01734974],\n",
       "         [-0.03133423, -0.03124071,  0.01998067, ..., -0.01298530,\n",
       "          -0.02539698,  0.01852605],\n",
       "         [-0.02767282,  0.00463605,  0.05343375, ...,  0.00698981,\n",
       "           0.03723275, -0.02948592]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00670949, -0.01044359, -0.01503056, ..., -0.00626838,\n",
       "          0.03070596,  0.00348521]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01082670, -0.01357937,  0.02926615, ..., -0.01806737,\n",
       "          -0.00684620,  0.01188189],\n",
       "         [ 0.05158196, -0.00309677, -0.02115460, ..., -0.00958940,\n",
       "          -0.03988238,  0.00488225],\n",
       "         [ 0.00142899, -0.03253089,  0.02257462, ...,  0.05963032,\n",
       "           0.00598024,  0.00139834],\n",
       "         ...,\n",
       "         [ 0.04573987,  0.06314626,  0.01091660, ...,  0.04094835,\n",
       "          -0.02678842,  0.00489575],\n",
       "         [-0.03794288,  0.03032201, -0.08366483, ..., -0.01775566,\n",
       "          -0.00268001,  0.00408508],\n",
       "         [-0.03037945, -0.02338426, -0.00836416, ...,  0.01118356,\n",
       "           0.00980688, -0.04226194]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01916768, -0.08479441, -0.01693613, ...,  0.00697711,\n",
       "          0.02763889,  0.04489803]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00493278,  0.00860743,  0.02146619, ...,  0.00755138,\n",
       "          -0.01114970, -0.00265486],\n",
       "         [-0.04707518,  0.01199722,  0.04373101, ...,  0.03851110,\n",
       "          -0.03277592, -0.05548808],\n",
       "         [-0.03550646,  0.01633752,  0.02633511, ...,  0.02536692,\n",
       "          -0.01626068, -0.00571390],\n",
       "         ...,\n",
       "         [-0.04670866, -0.03311056,  0.01754504, ..., -0.05454967,\n",
       "          -0.02990490,  0.04575456],\n",
       "         [-0.00476316,  0.06778333,  0.04692407, ..., -0.02667100,\n",
       "           0.01604428,  0.01045597],\n",
       "         [ 0.03792063,  0.00996544, -0.00563364, ..., -0.01489129,\n",
       "          -0.04790431, -0.00894779]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07646449, -0.04381498, -0.04581287, ..., -0.12114132,\n",
       "          0.04343056, -0.10187629]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01051717, -0.05248954, -0.01774766, ...,  0.03623617,\n",
       "           0.03551636, -0.04645526],\n",
       "         [-0.02314715,  0.02585163, -0.00046362, ...,  0.01071808,\n",
       "          -0.02663158,  0.01973964],\n",
       "         [ 0.04338614, -0.01422875, -0.00673010, ...,  0.01002315,\n",
       "          -0.01185504, -0.00862137],\n",
       "         ...,\n",
       "         [ 0.01370729,  0.00488407,  0.01317002, ..., -0.03905154,\n",
       "          -0.02418946,  0.03249823],\n",
       "         [-0.02773938,  0.04134684,  0.03159573, ...,  0.00983085,\n",
       "          -0.00291599,  0.07620097],\n",
       "         [ 0.00663495,  0.02995758, -0.00889535, ...,  0.01658533,\n",
       "           0.04972849, -0.02813218]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.07007521, -0.03559033,  0.04560965, ..., -0.01948885,\n",
       "         -0.02543823, -0.13664231]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.82434022, 0.78544354, 0.83526903, ..., 0.83437425, 0.87350929,\n",
       "         0.78547579]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04456886,  0.09612303,  0.12638158, ...,  0.15422824,\n",
       "         -0.06749882, -0.06645528]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.84761584, 0.81187952, 0.82797247, ..., 0.85667443, 0.87375271,\n",
       "         0.82506472]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00013303, -0.06655721, -0.06395419, ..., -0.10870118,\n",
       "          0.00681414, -0.01448914]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01643239, -0.04568006,  0.09076791, ..., -0.07201532,\n",
       "          -0.02555205, -0.01328370],\n",
       "         [ 0.03331817,  0.00737782, -0.04723993, ..., -0.02115668,\n",
       "           0.02761779,  0.02804940],\n",
       "         [-0.05783859,  0.03732198, -0.03245348, ...,  0.00610055,\n",
       "          -0.01598749,  0.00885971],\n",
       "         ...,\n",
       "         [-0.06791214, -0.00375145,  0.00578814, ...,  0.00092242,\n",
       "          -0.01720461, -0.01710955],\n",
       "         [ 0.01469791,  0.03140292,  0.03787631, ...,  0.04080474,\n",
       "          -0.04659537,  0.03443894],\n",
       "         [ 0.02304429,  0.00141112, -0.03521570, ...,  0.00944849,\n",
       "           0.00661875,  0.03195567]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11108135, -0.06332392,  0.18540806, ..., -0.07900699,\n",
       "         -0.04841046,  0.04822268]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00417305,  0.04214438,  0.03303008, ...,  0.06174722,\n",
       "           0.01772683,  0.04633475],\n",
       "         [-0.07954489,  0.01360427, -0.03725577, ...,  0.01377076,\n",
       "           0.00227653, -0.03514709],\n",
       "         [-0.04606032,  0.02169878, -0.06516036, ..., -0.02992056,\n",
       "           0.01206220,  0.00464405],\n",
       "         ...,\n",
       "         [-0.00272200,  0.01102498, -0.01917917, ..., -0.03564269,\n",
       "          -0.01614091,  0.04872894],\n",
       "         [-0.01543225, -0.06765483,  0.02609084, ..., -0.05143869,\n",
       "          -0.02422854, -0.00184570],\n",
       "         [ 0.01952955,  0.00828632,  0.00610266, ...,  0.01213272,\n",
       "          -0.08911029,  0.00749498]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.14743587, -0.12633891,  0.51450408, ..., -0.41184372,\n",
       "         -0.08938358,  0.06626793]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02205023,  0.01300056,  0.04066550, ..., -0.00390868,\n",
       "          -0.03436257, -0.03429956],\n",
       "         [-0.00203048,  0.03860179, -0.01513875, ..., -0.01027184,\n",
       "          -0.00660428,  0.07416344],\n",
       "         [ 0.01060905,  0.00155545, -0.01677158, ...,  0.02380846,\n",
       "          -0.04321303,  0.03286563],\n",
       "         ...,\n",
       "         [-0.03757687,  0.01482994, -0.00924748, ...,  0.01094516,\n",
       "           0.01687897, -0.01046033],\n",
       "         [ 0.03766189, -0.02556957,  0.02909634, ...,  0.03510678,\n",
       "           0.02196427, -0.01253037],\n",
       "         [-0.00505929, -0.00930602, -0.02928211, ..., -0.04080055,\n",
       "          -0.05183009, -0.03719730]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00067070,  0.01160970,  0.01630268, ...,  0.04060462,\n",
       "         -0.01749575,  0.00217508]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04141348, -0.00150249, -0.01402644, ..., -0.03373633,\n",
       "          -0.00975989, -0.02843315],\n",
       "         [ 0.01158753,  0.03233829, -0.00033676, ..., -0.00120445,\n",
       "           0.00110371,  0.04556624],\n",
       "         [ 0.01622663,  0.01557537,  0.02117413, ..., -0.04822287,\n",
       "           0.03096032, -0.00954660],\n",
       "         ...,\n",
       "         [-0.00992788, -0.02424854, -0.00743503, ..., -0.00970814,\n",
       "          -0.02280663, -0.01213495],\n",
       "         [-0.02374438,  0.01329260,  0.04138668, ...,  0.02472509,\n",
       "          -0.01995627, -0.00512684],\n",
       "         [-0.01274339,  0.00615129,  0.02106905, ...,  0.00177409,\n",
       "           0.02043625,  0.02401215]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01282573, -0.00105385, -0.01895827, ...,  0.00134938,\n",
       "          0.00354252,  0.03761465]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02299511, -0.00959177, -0.01044346, ...,  0.00926082,\n",
       "           0.00115107,  0.00084745],\n",
       "         [-0.01572237, -0.00541600, -0.01393783, ...,  0.01589138,\n",
       "           0.00084803, -0.02401814],\n",
       "         [ 0.02292702,  0.02554971,  0.02368609, ..., -0.01994260,\n",
       "          -0.01642369,  0.01543709],\n",
       "         ...,\n",
       "         [-0.02221550,  0.00113614, -0.03976795, ...,  0.05339060,\n",
       "           0.00115124,  0.01831650],\n",
       "         [-0.00654601,  0.01486144, -0.01100273, ...,  0.01539254,\n",
       "           0.00301795, -0.01371702],\n",
       "         [ 0.01129487,  0.04303237,  0.02482114, ..., -0.02643904,\n",
       "          -0.01567727,  0.03836939]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11598071, -0.01203464, -0.03625809, ..., -0.07977565,\n",
       "         -0.03373020, -0.02871979]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02619605,  0.04859759, -0.00104828, ...,  0.00778068,\n",
       "           0.00899866,  0.02822085],\n",
       "         [ 0.00180804,  0.03683908,  0.01104179, ..., -0.01484974,\n",
       "          -0.00065796, -0.01258366],\n",
       "         [ 0.01265032,  0.01476661,  0.02736481, ...,  0.02537646,\n",
       "          -0.01384605,  0.01444030],\n",
       "         ...,\n",
       "         [-0.00900755,  0.00032269,  0.05340767, ..., -0.07005327,\n",
       "          -0.02307417,  0.00463121],\n",
       "         [ 0.01171643, -0.00178693,  0.05530255, ..., -0.01307523,\n",
       "           0.04708932,  0.08995398],\n",
       "         [ 0.02820562,  0.00236659,  0.00415020, ..., -0.02118464,\n",
       "           0.02319222, -0.00220980]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.09001704, -0.01546105,  0.00109951, ..., -0.00068576,\n",
       "         -0.02049053, -0.01210876]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.82053101, 0.80563450, 0.84372360, ..., 0.81352443, 0.87303174,\n",
       "         0.78407127]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01928568,  0.05674910,  0.08892796, ...,  0.15118930,\n",
       "         -0.10710350, -0.09421253]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.88185704, 0.86398649, 0.87851363, ..., 0.89672464, 0.92119604,\n",
       "         0.87213916]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02975761, -0.05561407, -0.09590593, ..., -0.10945600,\n",
       "         -0.00607674,  0.02157917]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.07096406,  0.02722012, -0.01940570, ...,  0.04578362,\n",
       "           0.00533522,  0.05505615],\n",
       "         [-0.05251753, -0.00896936, -0.02188550, ..., -0.00553780,\n",
       "           0.00548114, -0.02830553],\n",
       "         [-0.01353307, -0.02745790, -0.03141864, ...,  0.00358731,\n",
       "           0.00688631,  0.02101316],\n",
       "         ...,\n",
       "         [-0.01390900,  0.03064874, -0.03816224, ..., -0.00589400,\n",
       "           0.03262345,  0.00805149],\n",
       "         [-0.02203004,  0.05886613,  0.01423038, ..., -0.01161209,\n",
       "          -0.04603310, -0.02933666],\n",
       "         [-0.02562924,  0.02375583,  0.03726985, ...,  0.02003699,\n",
       "           0.02316686, -0.03739609]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.16055727,  0.14138530,  0.11975928, ..., -0.09063943,\n",
       "         -0.13044716,  0.09016567]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04879621, -0.03080657, -0.07315321, ..., -0.01523224,\n",
       "           0.01848659,  0.01512936],\n",
       "         [-0.00101769, -0.04091872, -0.03828941, ..., -0.01619315,\n",
       "          -0.02578322, -0.05582843],\n",
       "         [ 0.04788143, -0.04686113,  0.03866619, ...,  0.03036507,\n",
       "          -0.02772252, -0.00717499],\n",
       "         ...,\n",
       "         [ 0.02387415, -0.02942866,  0.03821105, ..., -0.03060200,\n",
       "           0.03895598,  0.03588142],\n",
       "         [-0.00887501, -0.00593338,  0.02079556, ...,  0.02346664,\n",
       "          -0.01389768, -0.02520107],\n",
       "         [-0.00222289, -0.00710976, -0.00413951, ..., -0.01288716,\n",
       "          -0.04109151,  0.00686601]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.54165041, -0.60405010,  0.25189367, ..., -0.41671813,\n",
       "         -0.04448418,  0.05013264]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02264360,  0.04046672,  0.01315875, ..., -0.01062294,\n",
       "           0.02215786, -0.04743329],\n",
       "         [ 0.01163459,  0.00250867,  0.03413664, ..., -0.01118305,\n",
       "          -0.01193346,  0.00018565],\n",
       "         [ 0.02022318,  0.00826251,  0.02163552, ...,  0.01079708,\n",
       "          -0.04501598,  0.03699998],\n",
       "         ...,\n",
       "         [-0.01955845,  0.00340671, -0.02390588, ..., -0.03151445,\n",
       "          -0.01870600, -0.01309579],\n",
       "         [-0.04533316, -0.04740889, -0.04351236, ..., -0.00640903,\n",
       "           0.00886867, -0.02657941],\n",
       "         [ 0.00559282, -0.03652686,  0.00374400, ...,  0.04448502,\n",
       "          -0.02825434, -0.01634162]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.05755761,  0.02426736, -0.02677301, ..., -0.01933841,\n",
       "         -0.01568994, -0.01464348]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01813933,  0.02742283,  0.05532995, ...,  0.02053887,\n",
       "          -0.02272437, -0.00344072],\n",
       "         [ 0.02510428, -0.02023484,  0.02058621, ...,  0.00290462,\n",
       "          -0.02554510,  0.04996771],\n",
       "         [ 0.02196320, -0.03671258, -0.03451934, ..., -0.02385935,\n",
       "          -0.00825255,  0.02641334],\n",
       "         ...,\n",
       "         [ 0.00746926,  0.02155666, -0.02357749, ...,  0.00120607,\n",
       "           0.00656168, -0.00787313],\n",
       "         [ 0.00641133,  0.02312932, -0.00331875, ...,  0.00285873,\n",
       "          -0.01838337, -0.01117692],\n",
       "         [-0.00096352, -0.00288116, -0.02297467, ..., -0.01344207,\n",
       "           0.01718361, -0.00241689]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02759953, -0.11220572, -0.02334527, ..., -0.01895914,\n",
       "          0.00472650,  0.06568823]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04341848, -0.02672322, -0.00135847, ..., -0.02131957,\n",
       "           0.03145845, -0.00957764],\n",
       "         [ 0.00875731, -0.06654152,  0.03088185, ..., -0.02786675,\n",
       "           0.02253983, -0.02396994],\n",
       "         [-0.00306437, -0.00879735, -0.04616856, ...,  0.02359225,\n",
       "           0.00222620, -0.04184236],\n",
       "         ...,\n",
       "         [ 0.00776420, -0.07896045, -0.00767570, ...,  0.01400738,\n",
       "           0.02316792, -0.04391278],\n",
       "         [ 0.02370606,  0.00588917, -0.03908227, ...,  0.00152654,\n",
       "          -0.02781506, -0.01772564],\n",
       "         [ 0.03059585, -0.00425736,  0.03159399, ...,  0.01051261,\n",
       "           0.03051092,  0.05389217]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06200086, -0.06936122, -0.09631998, ..., -0.06472751,\n",
       "         -0.04397390, -0.05674564]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00543784, -0.00768578, -0.00539137, ..., -0.01733594,\n",
       "           0.00936404,  0.02464062],\n",
       "         [-0.00403364, -0.05920605, -0.00628898, ..., -0.02486487,\n",
       "           0.03282728, -0.02571207],\n",
       "         [ 0.03358011, -0.02488020, -0.01118995, ...,  0.03047954,\n",
       "          -0.02628863,  0.00938242],\n",
       "         ...,\n",
       "         [ 0.03558131,  0.06716491,  0.00266783, ...,  0.00027961,\n",
       "          -0.06241891,  0.00331405],\n",
       "         [ 0.03924594, -0.00879915, -0.00586107, ...,  0.01118717,\n",
       "          -0.03178421,  0.04889722],\n",
       "         [ 0.01381763, -0.00498886,  0.00049443, ..., -0.05523103,\n",
       "          -0.01357242,  0.01552446]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.08341800, -0.03111418, -0.00200123, ..., -0.01913499,\n",
       "          0.02319259,  0.00447374]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.80409360, 0.78373110, 0.82912713, ..., 0.81423295, 0.86836976,\n",
       "         0.77070212]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00526527,  0.05455510,  0.04517696, ...,  0.07337583,\n",
       "         -0.09366862, -0.07038860]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.88412356, 0.86863285, 0.86603117, ..., 0.89490402, 0.88592833,\n",
       "         0.85318261]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02284453, -0.06419899, -0.07529220, ..., -0.06128797,\n",
       "         -0.03645021, -0.00353677]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01838314, -0.01085845,  0.01753395, ...,  0.02197471,\n",
       "          -0.04265789, -0.01465912],\n",
       "         [ 0.00334300,  0.12647508,  0.07571355, ..., -0.04951127,\n",
       "          -0.02034580, -0.05075400],\n",
       "         [ 0.01390969, -0.02368511, -0.00980714, ...,  0.00156988,\n",
       "          -0.01978925,  0.01209611],\n",
       "         ...,\n",
       "         [-0.00036532, -0.00935198, -0.05347853, ..., -0.02714564,\n",
       "           0.07707801,  0.02189277],\n",
       "         [-0.02570444, -0.01285727, -0.02763364, ..., -0.06527021,\n",
       "          -0.00832000, -0.01769448],\n",
       "         [-0.01793079,  0.05288590, -0.04907788, ..., -0.02036906,\n",
       "           0.00202356, -0.02896010]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07599435,  0.16911693,  0.03404111, ...,  0.09370137,\n",
       "         -0.00441652,  0.00559319]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01520677, -0.03351978,  0.04472135, ...,  0.00692617,\n",
       "          -0.01089556, -0.05962706],\n",
       "         [ 0.04652280,  0.01474855, -0.02791563, ...,  0.00142751,\n",
       "           0.04267006,  0.03782853],\n",
       "         [-0.08197371,  0.04237368,  0.01489611, ..., -0.01136054,\n",
       "          -0.02143388, -0.03031138],\n",
       "         ...,\n",
       "         [ 0.04894441, -0.05817173, -0.01304521, ..., -0.01373162,\n",
       "           0.04199870, -0.00319012],\n",
       "         [-0.05113457, -0.05571237, -0.03025313, ..., -0.00816631,\n",
       "          -0.00456885, -0.00950769],\n",
       "         [ 0.04883716,  0.08442573, -0.03306029, ...,  0.06590620,\n",
       "           0.00072969, -0.02769401]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00513325,  0.05592082,  0.69318664, ...,  0.85644394,\n",
       "         -0.19452928, -0.08180722]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01319527, -0.00946850,  0.00453275, ...,  0.02728230,\n",
       "          -0.00403567, -0.06304607],\n",
       "         [ 0.00851929,  0.01929439, -0.03696207, ...,  0.01085028,\n",
       "           0.00924319, -0.02435266],\n",
       "         [ 0.01143588, -0.00769038,  0.00214665, ..., -0.02850225,\n",
       "          -0.01181650,  0.00098352],\n",
       "         ...,\n",
       "         [-0.01541935, -0.03738782, -0.04572120, ..., -0.03158156,\n",
       "          -0.01043452,  0.04648917],\n",
       "         [-0.03537226, -0.01710613,  0.04114759, ...,  0.02778290,\n",
       "           0.02614198, -0.01628464],\n",
       "         [-0.00302924,  0.00104664, -0.00967991, ..., -0.02823652,\n",
       "          -0.03795766, -0.01889481]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02347608, -0.02108645,  0.08743146, ..., -0.01004080,\n",
       "          0.01407559, -0.00804778]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01901389,  0.03077764, -0.00511415, ...,  0.00710492,\n",
       "          -0.01254995, -0.00665091],\n",
       "         [ 0.01591153,  0.00786385, -0.01370056, ...,  0.01578846,\n",
       "          -0.00476976,  0.02656225],\n",
       "         [ 0.02730890, -0.00591416,  0.03585489, ..., -0.01698722,\n",
       "          -0.01123560, -0.02390921],\n",
       "         ...,\n",
       "         [ 0.00120695,  0.00972566, -0.00050467, ..., -0.00604030,\n",
       "           0.01325541, -0.04190155],\n",
       "         [-0.00843636,  0.00927280,  0.01365474, ...,  0.01569550,\n",
       "           0.01922211,  0.06506966],\n",
       "         [ 0.01788071, -0.00350994,  0.02270450, ...,  0.04456680,\n",
       "          -0.03107817,  0.03657080]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03426673,  0.04665212, -0.05971365, ..., -0.02106812,\n",
       "          0.01320385,  0.03131534]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04146699, -0.01459482, -0.00664123, ...,  0.06232709,\n",
       "          -0.03756649,  0.00082849],\n",
       "         [-0.02343252, -0.03398588,  0.04386530, ...,  0.00151815,\n",
       "           0.01973489,  0.05544226],\n",
       "         [ 0.09794421, -0.00540585,  0.01881156, ..., -0.01517049,\n",
       "           0.01306969, -0.03095267],\n",
       "         ...,\n",
       "         [-0.04316387,  0.01203251, -0.08114124, ..., -0.05130001,\n",
       "          -0.02776472, -0.00109383],\n",
       "         [-0.01556963,  0.04482371,  0.00422431, ..., -0.02113773,\n",
       "           0.00188038, -0.01384229],\n",
       "         [ 0.03619707,  0.02889311,  0.01391637, ...,  0.02674543,\n",
       "          -0.04562868,  0.05373535]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.09073801, -0.06678916, -0.07761860, ..., -0.08109409,\n",
       "         -0.11044587, -0.06136638]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05066092,  0.01068689,  0.00209889, ..., -0.03830676,\n",
       "          -0.00327091, -0.00134226],\n",
       "         [-0.01474226,  0.00685096, -0.04190193, ..., -0.03860686,\n",
       "           0.00500980,  0.01517310],\n",
       "         [-0.03247952,  0.00595023,  0.03989125, ..., -0.05278210,\n",
       "          -0.05500047, -0.04365244],\n",
       "         ...,\n",
       "         [ 0.02154514, -0.01469386, -0.02744979, ...,  0.00500758,\n",
       "           0.01059103,  0.00315812],\n",
       "         [-0.02519771, -0.06841030, -0.00573989, ..., -0.02367348,\n",
       "           0.00581075, -0.03966713],\n",
       "         [-0.00793746,  0.07401989, -0.01826358, ...,  0.00326044,\n",
       "          -0.03701102, -0.02710970]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03667320, -0.05328682, -0.02710221, ..., -0.01054526,\n",
       "         -0.01492322,  0.05880921]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.78755111, 0.74739236, 0.82052106, ..., 0.78678775, 0.84658664,\n",
       "         0.74066633]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01917819, -0.07626271,  0.07107167, ...,  0.05997226,\n",
       "         -0.00494414, -0.06640510]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.86611742, 0.88321429, 0.86007094, ..., 0.87344545, 0.86337709,\n",
       "         0.84806889]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02131290, -0.01950546, -0.05591732, ..., -0.06645759,\n",
       "         -0.01661105,  0.01009090]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02589074, -0.02596771, -0.01508026, ..., -0.02012471,\n",
       "          -0.03078021, -0.01714915],\n",
       "         [ 0.02250765, -0.01539443, -0.05658732, ..., -0.03479660,\n",
       "          -0.07493535,  0.03795735],\n",
       "         [-0.03220676,  0.02684108, -0.01390213, ...,  0.00821770,\n",
       "          -0.04019599, -0.06457604],\n",
       "         ...,\n",
       "         [-0.02473278, -0.00916992, -0.02835710, ...,  0.01304910,\n",
       "           0.02064553,  0.01939339],\n",
       "         [ 0.04550530,  0.04029979, -0.06641833, ...,  0.00545391,\n",
       "           0.06109666,  0.01132852],\n",
       "         [-0.00719760, -0.02454547, -0.03843178, ...,  0.00503056,\n",
       "           0.05766243,  0.04500033]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04370379, -0.12708180,  0.09901122, ..., -0.36043683,\n",
       "         -0.24303827,  0.06919101]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02099346, -0.03848011, -0.00503624, ..., -0.01155636,\n",
       "           0.01437353, -0.04235357],\n",
       "         [ 0.02451085,  0.03979734,  0.03911321, ..., -0.01307151,\n",
       "          -0.03302309, -0.01422682],\n",
       "         [ 0.00807752,  0.01825465, -0.03746862, ..., -0.01736550,\n",
       "          -0.03503136,  0.07067791],\n",
       "         ...,\n",
       "         [-0.01202302,  0.01064249,  0.06607401, ..., -0.00515832,\n",
       "          -0.04410101, -0.04422849],\n",
       "         [-0.01768879,  0.04984957,  0.04298213, ...,  0.00433199,\n",
       "           0.02722991,  0.08080701],\n",
       "         [ 0.07797424, -0.04686321, -0.08866926, ..., -0.01673182,\n",
       "          -0.00668827, -0.02959744]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.04446287,  0.20789328,  0.46345091, ..., -0.65606880,\n",
       "         -0.71612877,  0.45019263]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.08240642, -0.01482944,  0.02867026, ..., -0.04028129,\n",
       "           0.03004684,  0.03543157],\n",
       "         [-0.04775697,  0.02560890,  0.01929200, ..., -0.02376463,\n",
       "          -0.00088647,  0.01866565],\n",
       "         [ 0.00943891, -0.00010117,  0.02180449, ..., -0.01362994,\n",
       "           0.01363817,  0.02590755],\n",
       "         ...,\n",
       "         [ 0.00644269, -0.03953884, -0.05500319, ...,  0.02676107,\n",
       "          -0.00818423,  0.00444119],\n",
       "         [ 0.04860665,  0.01921073, -0.01461207, ...,  0.01475524,\n",
       "           0.01053226, -0.01047995],\n",
       "         [ 0.05142067,  0.08452414,  0.09419425, ...,  0.01527032,\n",
       "           0.00855672,  0.03805973]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01085144,  0.00609180,  0.00323522, ...,  0.01274506,\n",
       "          0.01297998, -0.02269399]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.05166185, -0.00515683,  0.01471738, ..., -0.06753398,\n",
       "          -0.05545996,  0.02843956],\n",
       "         [ 0.07547084, -0.02714180,  0.00924577, ...,  0.03107615,\n",
       "          -0.01337171, -0.02708754],\n",
       "         [ 0.01632723,  0.03902509, -0.00439483, ...,  0.02854893,\n",
       "           0.02966640,  0.03079667],\n",
       "         ...,\n",
       "         [ 0.00619060, -0.00706940, -0.07200591, ...,  0.00382110,\n",
       "          -0.01632083,  0.00025776],\n",
       "         [-0.00404428, -0.00559906,  0.01355121, ..., -0.02488862,\n",
       "           0.05770134,  0.02029199],\n",
       "         [ 0.03162804,  0.01911005,  0.01695803, ...,  0.03267058,\n",
       "           0.00419410, -0.00308315]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01379871, -0.05602975, -0.02137922, ..., -0.03712824,\n",
       "          0.00812127,  0.01521510]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02683536,  0.04052145,  0.00713441, ...,  0.00868117,\n",
       "           0.03772862, -0.02339846],\n",
       "         [-0.05598132, -0.02607626,  0.00314919, ..., -0.00946423,\n",
       "          -0.03146039, -0.02984332],\n",
       "         [-0.01314240,  0.01011352,  0.03336815, ..., -0.00205550,\n",
       "           0.01772505,  0.00913937],\n",
       "         ...,\n",
       "         [ 0.03118127, -0.01208196, -0.00018607, ..., -0.02350387,\n",
       "           0.00453610, -0.05006566],\n",
       "         [ 0.02916264, -0.01885523, -0.00110239, ..., -0.00886058,\n",
       "           0.02542669,  0.01350858],\n",
       "         [-0.01472474, -0.01451244, -0.02108336, ..., -0.01455327,\n",
       "          -0.00665334,  0.01419994]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06921770, -0.08341968, -0.04506689, ..., -0.09157335,\n",
       "         -0.08899314, -0.09139345]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04008959,  0.01993022,  0.05547764, ...,  0.05062301,\n",
       "           0.04756409,  0.01008281],\n",
       "         [ 0.01807333, -0.04522945,  0.00316323, ...,  0.02856520,\n",
       "          -0.02637284,  0.01700115],\n",
       "         [ 0.01687213,  0.01289924,  0.02178286, ..., -0.02572392,\n",
       "           0.00130287, -0.00491244],\n",
       "         ...,\n",
       "         [ 0.04095593,  0.02158283, -0.01535724, ...,  0.01995021,\n",
       "           0.01680066, -0.04830395],\n",
       "         [ 0.05056974,  0.04470460, -0.01167457, ...,  0.04894965,\n",
       "          -0.02594011, -0.04591954],\n",
       "         [-0.05895415, -0.00333515,  0.04893823, ..., -0.02943304,\n",
       "          -0.01528088,  0.00578829]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02320844, -0.06701141, -0.01662475, ...,  0.03266943,\n",
       "         -0.00881389, -0.01224991]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.77068251, 0.72176051, 0.79330462, ..., 0.75076342, 0.80769056,\n",
       "         0.73550546]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00673570, -0.04589262,  0.09753098, ...,  0.02866540,\n",
       "         -0.00472624, -0.01918724]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.84245431, 0.84338802, 0.84457439, ..., 0.86223525, 0.86488193,\n",
       "         0.83150905]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01875274, -0.00304561, -0.02575257, ..., -0.00950388,\n",
       "         -0.00966454, -0.02790637]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00368388, -0.01813353,  0.04195108, ..., -0.07122599,\n",
       "          -0.03504130, -0.01604483],\n",
       "         [ 0.03426934,  0.07859924, -0.00821702, ..., -0.01743614,\n",
       "          -0.02083490, -0.01921595],\n",
       "         [-0.00724751, -0.02074067, -0.06136423, ...,  0.01029405,\n",
       "           0.03533452,  0.00014326],\n",
       "         ...,\n",
       "         [-0.04495851,  0.00591622, -0.00754176, ..., -0.05873709,\n",
       "           0.00676173, -0.01064443],\n",
       "         [ 0.00612243,  0.01843722,  0.03004295, ..., -0.05621925,\n",
       "          -0.01199017, -0.04069093],\n",
       "         [ 0.03136507, -0.02244191,  0.01900747, ..., -0.06775961,\n",
       "           0.01150992,  0.00550103]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.09924686, -0.09713112,  0.02401996, ..., -0.00499722,\n",
       "         -0.12842491, -0.10444874]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02806530, -0.03124637,  0.03089304, ..., -0.04868706,\n",
       "          -0.02738833, -0.02749245],\n",
       "         [ 0.04489422,  0.02659286,  0.01388513, ..., -0.01757283,\n",
       "           0.03108081, -0.00968533],\n",
       "         [-0.04892358, -0.01254169, -0.00907381, ..., -0.01034672,\n",
       "          -0.03491110,  0.01039347],\n",
       "         ...,\n",
       "         [ 0.05147850,  0.01890388, -0.04483833, ..., -0.00632643,\n",
       "          -0.00251233, -0.03670190],\n",
       "         [-0.02732626, -0.01978318,  0.00256586, ...,  0.01986711,\n",
       "          -0.00590419, -0.02567006],\n",
       "         [ 0.02124384,  0.02062881, -0.01530757, ...,  0.03028633,\n",
       "          -0.00675373,  0.00010762]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.13946678,  0.71852756, -1.24150181, ..., -0.22072424,\n",
       "         -0.22528218, -0.45027936]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04212339, -0.03978303,  0.03615203, ..., -0.00956141,\n",
       "           0.00521542, -0.00767622],\n",
       "         [ 0.05439448,  0.00303884, -0.01571013, ..., -0.02491644,\n",
       "           0.03385667, -0.01961501],\n",
       "         [-0.01443850, -0.02616306, -0.00119446, ..., -0.04977832,\n",
       "          -0.02134308,  0.02019730],\n",
       "         ...,\n",
       "         [-0.02381574, -0.05958957,  0.00553120, ...,  0.05718578,\n",
       "          -0.02798552, -0.02707705],\n",
       "         [ 0.02894848,  0.03294937,  0.06357907, ..., -0.02746173,\n",
       "           0.01823195,  0.01206899],\n",
       "         [ 0.05882817, -0.03561416,  0.05479337, ...,  0.01810338,\n",
       "          -0.08013592, -0.00587942]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00607084,  0.02192001, -0.00192293, ...,  0.01653749,\n",
       "         -0.02127903,  0.00501299]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01142726,  0.03034769,  0.00721620, ..., -0.02879481,\n",
       "           0.00518014,  0.02712531],\n",
       "         [ 0.06214610,  0.01054164,  0.01865938, ..., -0.01239604,\n",
       "           0.02365587,  0.01121287],\n",
       "         [ 0.03881936,  0.01559640, -0.02023931, ...,  0.02354164,\n",
       "           0.03707667, -0.01217102],\n",
       "         ...,\n",
       "         [ 0.02563716, -0.04081278, -0.04011049, ..., -0.03235035,\n",
       "          -0.01931189, -0.02357684],\n",
       "         [ 0.02830765, -0.00989191,  0.02229771, ..., -0.02693478,\n",
       "          -0.02573456,  0.04567314],\n",
       "         [ 0.00578254,  0.01352440,  0.01831764, ..., -0.02830077,\n",
       "          -0.02310587, -0.02834650]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06097567,  0.01661795,  0.00030498, ..., -0.09668063,\n",
       "         -0.04365218,  0.01423980]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03063517, -0.00289621,  0.01129498, ...,  0.01566678,\n",
       "           0.01693849,  0.02733167],\n",
       "         [-0.00690751,  0.03947671,  0.05178257, ..., -0.02734528,\n",
       "           0.00206850,  0.04397124],\n",
       "         [-0.01734012, -0.03539509,  0.02073445, ..., -0.04389086,\n",
       "           0.02498374, -0.01599032],\n",
       "         ...,\n",
       "         [ 0.03883291,  0.02946376, -0.01730409, ...,  0.02545278,\n",
       "           0.07026967,  0.01986746],\n",
       "         [ 0.01993186,  0.01271523, -0.00564454, ...,  0.00068744,\n",
       "           0.01067781,  0.02422431],\n",
       "         [-0.01453362, -0.01765963, -0.00332596, ..., -0.00815516,\n",
       "          -0.00563939,  0.00766264]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00104922, -0.07030009, -0.06541006, ..., -0.08173747,\n",
       "         -0.08358615, -0.08097226]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03028653, -0.01051833,  0.01613138, ..., -0.02017745,\n",
       "          -0.00996672,  0.01752908],\n",
       "         [-0.01078485,  0.01226046, -0.06689949, ...,  0.01823781,\n",
       "           0.00901031, -0.03504695],\n",
       "         [ 0.01020091, -0.01298742,  0.01853217, ...,  0.00413693,\n",
       "           0.02273881, -0.06431067],\n",
       "         ...,\n",
       "         [-0.01518913, -0.00117039, -0.01493940, ..., -0.03360864,\n",
       "          -0.00098995,  0.04038444],\n",
       "         [-0.03400796, -0.00275021,  0.01327515, ..., -0.02280488,\n",
       "           0.03118988, -0.04724449],\n",
       "         [ 0.05619489,  0.03747953, -0.01455608, ..., -0.00595908,\n",
       "          -0.01647327, -0.00017366]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03981424, -0.07236140, -0.02394317, ...,  0.01602086,\n",
       "         -0.02507488,  0.06503391]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.76961195, 0.74477649, 0.77960074, ..., 0.74256653, 0.78422213,\n",
       "         0.74006402]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04248535, -0.08528386,  0.05214341, ...,  0.03288436,\n",
       "          0.00585082,  0.01384634]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90071571, 0.89516437, 0.90145695, ..., 0.92378521, 0.95160770,\n",
       "         0.90528023]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02202253,  0.02792052,  0.06066481, ..., -0.02721542,\n",
       "         -0.00634257, -0.04301886]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00191332, -0.04187622, -0.00326114, ..., -0.06803750,\n",
       "          -0.06168402,  0.00527372],\n",
       "         [ 0.00513645,  0.00217764, -0.00453816, ...,  0.00198908,\n",
       "           0.04245238,  0.00747822],\n",
       "         [-0.08842308,  0.04891618, -0.05254653, ...,  0.01774919,\n",
       "          -0.00001317,  0.00186885],\n",
       "         ...,\n",
       "         [ 0.02336360, -0.00802481, -0.00264251, ..., -0.00197927,\n",
       "           0.02598120,  0.01467833],\n",
       "         [ 0.01140706, -0.02409915,  0.00011126, ..., -0.02580843,\n",
       "          -0.07488635, -0.03624465],\n",
       "         [ 0.03618271,  0.01735357,  0.06402121, ..., -0.00957442,\n",
       "          -0.04080018,  0.00016510]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.12523216,  0.13259327, -0.01571945, ..., -0.01856571,\n",
       "          0.10351302, -0.18499866]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.10114269,  0.01399003, -0.01065752, ..., -0.05516052,\n",
       "          -0.06885610, -0.04889421],\n",
       "         [ 0.01313734, -0.01494786, -0.03833135, ..., -0.05081732,\n",
       "           0.02522722, -0.06199707],\n",
       "         [-0.04531201,  0.05109547, -0.00711014, ...,  0.03951384,\n",
       "          -0.04488112,  0.04142499],\n",
       "         ...,\n",
       "         [-0.05565071, -0.01168553, -0.02017102, ...,  0.04272538,\n",
       "           0.01389601,  0.00334733],\n",
       "         [-0.02533772, -0.03068689,  0.01490068, ...,  0.01875979,\n",
       "           0.00874509,  0.00756295],\n",
       "         [ 0.00009861, -0.03343005,  0.02427329, ..., -0.05306480,\n",
       "          -0.01116598, -0.05704200]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-1.13744867,  0.18442546, -0.10277516, ..., -0.90945113,\n",
       "          0.15467216,  0.64318126]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.05408011,  0.00431752, -0.00695071, ...,  0.02689116,\n",
       "          -0.04161447,  0.07591664],\n",
       "         [-0.06381927,  0.02432473,  0.02277985, ..., -0.06540360,\n",
       "           0.03225779, -0.02923017],\n",
       "         [-0.02337402,  0.02580905, -0.03632941, ..., -0.03266250,\n",
       "          -0.00431148, -0.01570085],\n",
       "         ...,\n",
       "         [ 0.10540436,  0.00233257, -0.01429207, ...,  0.00052624,\n",
       "           0.00252085, -0.05108113],\n",
       "         [ 0.04012473,  0.00982108, -0.03828787, ..., -0.00458003,\n",
       "          -0.05958925, -0.04765163],\n",
       "         [ 0.04313813, -0.04586849, -0.02287292, ...,  0.00519600,\n",
       "          -0.00204240, -0.01772070]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00765134,  0.01907802,  0.00462251, ..., -0.00697307,\n",
       "         -0.00204896,  0.00850016]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00854744,  0.04729215,  0.02646789, ...,  0.02780948,\n",
       "          -0.02522887, -0.04315673],\n",
       "         [-0.00885985, -0.02888988, -0.00147223, ...,  0.05457263,\n",
       "          -0.00800781,  0.01947640],\n",
       "         [ 0.00268508, -0.02626196,  0.00145065, ..., -0.03211806,\n",
       "           0.01463374,  0.04270155],\n",
       "         ...,\n",
       "         [ 0.00038499, -0.04101534, -0.03425192, ..., -0.00073716,\n",
       "          -0.00791129, -0.01003574],\n",
       "         [-0.02181146,  0.01160739,  0.02879332, ..., -0.03645229,\n",
       "          -0.00645653, -0.01841089],\n",
       "         [-0.03006281, -0.05196014, -0.00819790, ...,  0.02449100,\n",
       "          -0.01905537,  0.04394415]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01776673, -0.11767037, -0.04406783, ..., -0.04914298,\n",
       "          0.02312443,  0.04445110]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05322657,  0.01932541, -0.04025273, ...,  0.00976699,\n",
       "           0.03835808,  0.01231505],\n",
       "         [ 0.00104606,  0.00765530,  0.03979145, ...,  0.01752016,\n",
       "           0.01414074, -0.02979173],\n",
       "         [-0.02639088,  0.02178580, -0.00075935, ...,  0.01175206,\n",
       "           0.02909493,  0.03893232],\n",
       "         ...,\n",
       "         [ 0.04605819, -0.00527191, -0.00349680, ..., -0.00306411,\n",
       "          -0.00382188,  0.04357640],\n",
       "         [-0.01140471,  0.00888015, -0.00110476, ...,  0.01429311,\n",
       "          -0.04041576, -0.01160869],\n",
       "         [ 0.00377966, -0.00933230,  0.00582618, ...,  0.02354797,\n",
       "          -0.00798872,  0.00764799]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08133257, -0.09483589, -0.08970526, ..., -0.06382982,\n",
       "         -0.02230562, -0.06195077]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00456873,  0.01615437, -0.01066531, ...,  0.02564277,\n",
       "          -0.02414715,  0.03021802],\n",
       "         [-0.02551531,  0.01001091,  0.00681867, ..., -0.01363352,\n",
       "           0.05902440, -0.02366403],\n",
       "         [-0.01203813,  0.00359759,  0.01635535, ..., -0.01723167,\n",
       "          -0.05275695,  0.01115033],\n",
       "         ...,\n",
       "         [-0.00988611,  0.04652832,  0.01861833, ...,  0.01794791,\n",
       "           0.02235143, -0.01384160],\n",
       "         [-0.03835924,  0.03580575, -0.03731155, ...,  0.00294312,\n",
       "          -0.06161875,  0.01395170],\n",
       "         [-0.00574428, -0.08148260,  0.02627438, ..., -0.01773571,\n",
       "          -0.01776761,  0.03701729]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04064992, -0.05677281, -0.03595695, ...,  0.04819211,\n",
       "          0.01124411,  0.02797621]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.82126683, 0.80068332, 0.80579001, ..., 0.77373105, 0.81550574,\n",
       "         0.77450407]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03567071, -0.01893387, -0.00025195, ...,  0.04174772,\n",
       "          0.00933674,  0.06295587]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90089744, 0.91764265, 0.93456119, ..., 0.91035503, 0.92279774,\n",
       "         0.89370084]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.04818531,  0.07141299,  0.04749471, ..., -0.00947989,\n",
       "          0.03809004,  0.01517907]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04889330,  0.00533321, -0.02114698, ..., -0.02209738,\n",
       "           0.00755872, -0.02550680],\n",
       "         [-0.03246756, -0.01156666,  0.03930664, ...,  0.00263116,\n",
       "           0.04829899, -0.01862105],\n",
       "         [ 0.04952311,  0.00204894, -0.03227454, ..., -0.05853071,\n",
       "           0.03846289, -0.03388622],\n",
       "         ...,\n",
       "         [ 0.01616536, -0.04758287, -0.04150431, ...,  0.03939244,\n",
       "          -0.05743868, -0.06979914],\n",
       "         [-0.00187632,  0.00421790,  0.03044131, ..., -0.06316489,\n",
       "          -0.03061646, -0.03232678],\n",
       "         [-0.03563999, -0.01578635, -0.04484239, ...,  0.02663618,\n",
       "           0.00392189, -0.05123199]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.18103723, -0.09466570,  0.06379892, ..., -0.02122802,\n",
       "          0.12967266, -0.19290175]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01012673,  0.05436501, -0.00916613, ...,  0.02450540,\n",
       "          -0.00793565, -0.03389913],\n",
       "         [-0.02991581, -0.03132427,  0.02269576, ..., -0.03020807,\n",
       "           0.06449187,  0.00263612],\n",
       "         [-0.00033644,  0.04786411,  0.01271856, ...,  0.00655842,\n",
       "          -0.03008614, -0.00738289],\n",
       "         ...,\n",
       "         [ 0.01821156,  0.01538001, -0.00235010, ...,  0.04907823,\n",
       "          -0.03552124,  0.02474494],\n",
       "         [-0.05269456,  0.02787133,  0.02069156, ..., -0.00436556,\n",
       "          -0.02464737, -0.00260677],\n",
       "         [ 0.01378100, -0.02819749, -0.05371435, ..., -0.00451597,\n",
       "          -0.10599641, -0.03926290]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.39911148, -0.17402951, -1.06600046, ..., -0.89928621,\n",
       "          3.59075022,  0.68623114]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00193062, -0.01310596,  0.05263612, ..., -0.03490351,\n",
       "           0.00740158, -0.02772276],\n",
       "         [-0.05774023, -0.04833568, -0.02698833, ..., -0.06532957,\n",
       "           0.00453990, -0.00546517],\n",
       "         [-0.01910562, -0.04507819,  0.03103908, ...,  0.02370557,\n",
       "          -0.00246884,  0.00460647],\n",
       "         ...,\n",
       "         [-0.00800307,  0.04841613, -0.02479443, ...,  0.01195866,\n",
       "          -0.02708280,  0.01477809],\n",
       "         [ 0.08747353, -0.03755109,  0.04255898, ..., -0.07796308,\n",
       "           0.02122374, -0.03715724],\n",
       "         [-0.02437014,  0.00729149,  0.00836841, ..., -0.01264117,\n",
       "           0.01656661,  0.02097038]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00019659,  0.00858239,  0.00621987, ..., -0.01851103,\n",
       "         -0.03385237,  0.00413954]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01156540,  0.02766666,  0.00001330, ...,  0.00503166,\n",
       "          -0.03669026, -0.05433455],\n",
       "         [ 0.00350003, -0.01235734, -0.04341484, ...,  0.02126865,\n",
       "          -0.04916800,  0.02864446],\n",
       "         [ 0.00585900,  0.00441982, -0.00676176, ..., -0.00301300,\n",
       "          -0.01514014, -0.01358146],\n",
       "         ...,\n",
       "         [-0.03048439, -0.00394941,  0.01701021, ..., -0.02457967,\n",
       "          -0.05148224,  0.03259883],\n",
       "         [-0.02139176,  0.05843858, -0.00552989, ..., -0.00383503,\n",
       "           0.00591398,  0.05590708],\n",
       "         [ 0.00657459, -0.00831923,  0.01265434, ...,  0.00495747,\n",
       "           0.03871887,  0.00024045]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03021190,  0.00986714, -0.00391936, ..., -0.03466891,\n",
       "          0.03288059,  0.00090965]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00153298, -0.00830656,  0.00998949, ..., -0.00288672,\n",
       "           0.01863294, -0.03118649],\n",
       "         [-0.05413993, -0.04186415,  0.03155186, ...,  0.00907265,\n",
       "           0.01373257,  0.05672105],\n",
       "         [-0.04740092,  0.01872756, -0.03086713, ...,  0.00731078,\n",
       "          -0.02629871,  0.01442200],\n",
       "         ...,\n",
       "         [-0.00581520,  0.04831327,  0.01292040, ..., -0.00030050,\n",
       "          -0.04147946, -0.03354282],\n",
       "         [ 0.02265842, -0.00817670,  0.03447328, ...,  0.01484689,\n",
       "           0.00517339, -0.03608582],\n",
       "         [ 0.03733547, -0.04500068,  0.03875645, ...,  0.05767288,\n",
       "          -0.00287733,  0.03973411]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01640156, -0.08412332, -0.05394999, ..., -0.07120500,\n",
       "         -0.06475040, -0.06862959]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02090471, -0.00955646,  0.02855353, ..., -0.00772110,\n",
       "          -0.01798017,  0.02095107],\n",
       "         [-0.00173152,  0.05455944,  0.01132361, ...,  0.00827486,\n",
       "          -0.00941101,  0.02044690],\n",
       "         [-0.04604273,  0.00742994, -0.02166879, ..., -0.01275883,\n",
       "          -0.04580557, -0.01922577],\n",
       "         ...,\n",
       "         [-0.02290771, -0.00896259, -0.02183724, ..., -0.00110643,\n",
       "          -0.05799834, -0.03228886],\n",
       "         [ 0.02295280,  0.05516006, -0.01410295, ...,  0.00652650,\n",
       "           0.00818904,  0.02488092],\n",
       "         [ 0.02337046,  0.04769132,  0.01802455, ...,  0.02629641,\n",
       "           0.00452243,  0.03084501]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04658263, -0.04798800, -0.03586705, ...,  0.03009331,\n",
       "         -0.01332994,  0.01255456]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.83013463, 0.82473290, 0.83160442, ..., 0.78884298, 0.81694931,\n",
       "         0.81035036]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03110039,  0.01926077,  0.03558438, ...,  0.09841435,\n",
       "          0.05154670,  0.09798097]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.93321657, 0.95343918, 0.96100622, ..., 0.94698203, 0.95486373,\n",
       "         0.93451250]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01717645,  0.06147451,  0.01369375, ...,  0.01959276,\n",
       "          0.02912151, -0.00288273]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02492173,  0.04345034,  0.01377784, ...,  0.05114717,\n",
       "          -0.06443392,  0.01857411],\n",
       "         [ 0.00165716, -0.02389581, -0.02493926, ...,  0.02040860,\n",
       "          -0.02015713, -0.06027965],\n",
       "         [-0.01140467, -0.00963516,  0.00723813, ..., -0.02286366,\n",
       "           0.04394301,  0.00758239],\n",
       "         ...,\n",
       "         [ 0.02812671, -0.03552850, -0.04400702, ...,  0.07030799,\n",
       "           0.05284226, -0.01698628],\n",
       "         [-0.00115404,  0.00137297,  0.02415342, ...,  0.01053919,\n",
       "           0.01932038, -0.00717869],\n",
       "         [-0.00558907, -0.01213312, -0.00969005, ...,  0.05733300,\n",
       "           0.04805603, -0.00932599]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.12300807,  0.02240640,  0.02911280, ...,  0.14147827,\n",
       "         -0.12648070, -0.34446698]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.11337850, -0.01650257,  0.01894720, ..., -0.01170836,\n",
       "           0.02276016, -0.04308455],\n",
       "         [ 0.00747795,  0.01970559, -0.05935812, ..., -0.00906609,\n",
       "           0.02017381, -0.05336827],\n",
       "         [-0.03039628,  0.01683751,  0.02005253, ...,  0.01398276,\n",
       "           0.00630944, -0.06665531],\n",
       "         ...,\n",
       "         [-0.02886933, -0.03290362, -0.00634992, ...,  0.05279604,\n",
       "          -0.00085992,  0.02590885],\n",
       "         [ 0.04752360, -0.00114044,  0.05343920, ...,  0.02073353,\n",
       "           0.02334196,  0.01627050],\n",
       "         [ 0.02593083, -0.02916354,  0.03425177, ...,  0.00623205,\n",
       "          -0.01837134, -0.03471095]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.69677359, -0.08626849, -0.83884370, ..., -2.17025065,\n",
       "          0.56765717,  0.66954863]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01668728,  0.02858159,  0.03263478, ...,  0.03335546,\n",
       "          -0.01498143, -0.02223559],\n",
       "         [ 0.01066695,  0.04602562, -0.01107821, ...,  0.03700482,\n",
       "           0.01750256,  0.01109517],\n",
       "         [-0.01012320,  0.04001834,  0.02208383, ...,  0.02838183,\n",
       "          -0.07062399, -0.01262004],\n",
       "         ...,\n",
       "         [ 0.04256488,  0.00701911, -0.03833181, ..., -0.00318445,\n",
       "           0.01355277,  0.00979437],\n",
       "         [ 0.01691964,  0.05937792,  0.00316192, ...,  0.03536360,\n",
       "          -0.00598292,  0.02893113],\n",
       "         [-0.04495103, -0.04760366,  0.00394607, ..., -0.00679824,\n",
       "          -0.06019837, -0.04354174]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01101227,  0.01596928,  0.00682606, ..., -0.00151943,\n",
       "          0.01807886, -0.01223897]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02206074,  0.05088568, -0.02909322, ...,  0.03544123,\n",
       "           0.02612386, -0.00378744],\n",
       "         [ 0.02074947,  0.02044781, -0.01473253, ...,  0.00603725,\n",
       "           0.02321959, -0.01535660],\n",
       "         [ 0.00162725, -0.00073175,  0.02755783, ...,  0.00175825,\n",
       "          -0.00742319, -0.02811505],\n",
       "         ...,\n",
       "         [ 0.00770491, -0.03800195,  0.01536835, ..., -0.00647518,\n",
       "           0.01325225,  0.01737556],\n",
       "         [ 0.00519731,  0.03463152,  0.01938819, ..., -0.02703173,\n",
       "           0.03844651,  0.02883409],\n",
       "         [-0.04136768,  0.00774862, -0.04009037, ...,  0.02075408,\n",
       "          -0.00275456, -0.00415768]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08632933, -0.04362383,  0.09155405, ..., -0.04730501,\n",
       "          0.01540985,  0.03318964]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03053672,  0.00183112,  0.00912349, ..., -0.01898424,\n",
       "          -0.02379100,  0.09715752],\n",
       "         [ 0.00045310,  0.00976360, -0.05339252, ..., -0.04276333,\n",
       "           0.02792139,  0.02616123],\n",
       "         [-0.03667651, -0.00837845, -0.02391919, ...,  0.00105555,\n",
       "           0.00332484,  0.02343400],\n",
       "         ...,\n",
       "         [-0.00855943,  0.00529196, -0.02739612, ..., -0.01248878,\n",
       "          -0.00579460,  0.00229298],\n",
       "         [ 0.01647430,  0.02259985, -0.00100917, ..., -0.01901933,\n",
       "           0.00072410,  0.02588671],\n",
       "         [-0.03758239,  0.03443753, -0.01450838, ...,  0.01880875,\n",
       "          -0.04079519,  0.02663976]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06171277, -0.05900928, -0.09246824, ..., -0.01796244,\n",
       "         -0.12147632, -0.00322875]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01984054,  0.02287731, -0.02371440, ...,  0.00719668,\n",
       "           0.00955612,  0.01497765],\n",
       "         [-0.01982844,  0.00122757,  0.00870002, ..., -0.02213197,\n",
       "           0.04153570,  0.00797239],\n",
       "         [ 0.00552956,  0.07702807,  0.00668265, ...,  0.02788737,\n",
       "           0.00590417, -0.02864116],\n",
       "         ...,\n",
       "         [-0.04597281, -0.01369810, -0.01784400, ..., -0.00116561,\n",
       "           0.03498674,  0.03995312],\n",
       "         [ 0.02803085, -0.02313063, -0.03089742, ..., -0.00260282,\n",
       "          -0.01575124,  0.02388274],\n",
       "         [-0.04411380,  0.00514745,  0.00246420, ..., -0.01572957,\n",
       "           0.00024806, -0.00240821]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08541369, -0.13589755,  0.05716511, ..., -0.10249817,\n",
       "         -0.05167746,  0.11156197]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.85065246, 0.84205484, 0.85158831, ..., 0.82024562, 0.83747846,\n",
       "         0.83672190]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00036446,  0.01408722,  0.03802958, ...,  0.00656782,\n",
       "          0.00315072,  0.01273488]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.69577509, 0.73109460, 0.71899909, ..., 0.69161892, 0.69434923,\n",
       "         0.68268967]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02208978,  0.08926818,  0.05598526, ..., -0.00378850,\n",
       "         -0.01984994, -0.05638348]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04889631, -0.03953245, -0.04676077, ..., -0.00331457,\n",
       "          -0.04023956, -0.01677985],\n",
       "         [ 0.01944217,  0.04047803,  0.02205214, ...,  0.01468804,\n",
       "           0.01991374,  0.02325337],\n",
       "         [ 0.02258326, -0.03002027,  0.01482055, ...,  0.02296144,\n",
       "           0.00299030, -0.01849073],\n",
       "         ...,\n",
       "         [ 0.01505023,  0.01398209, -0.01521906, ...,  0.04968491,\n",
       "          -0.02096811,  0.02058058],\n",
       "         [ 0.02617332,  0.05145920,  0.01893478, ..., -0.04310032,\n",
       "          -0.02803920, -0.01105369],\n",
       "         [ 0.01987676,  0.02506975, -0.02003281, ..., -0.00674021,\n",
       "          -0.00266603, -0.00825870]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03466135, -0.03154757, -0.00266340, ..., -0.01167620,\n",
       "          0.01056642, -0.00496358]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[20, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.07260302,  0.00893798, -0.08115109, ..., -0.05861866,\n",
       "           0.02569943, -0.04830024],\n",
       "         [ 0.01771795, -0.03503437, -0.07568398, ...,  0.02236696,\n",
       "          -0.05688940, -0.09488992],\n",
       "         [-0.02510455,  0.07148174, -0.10158768, ...,  0.03863415,\n",
       "           0.01024576, -0.05338159],\n",
       "         ...,\n",
       "         [ 0.04096690, -0.03987848,  0.06959851, ...,  0.05565497,\n",
       "           0.03460664, -0.03564390],\n",
       "         [ 0.03216706, -0.07165346, -0.08885850, ..., -0.00237678,\n",
       "          -0.01215382, -0.07989253],\n",
       "         [-0.03810192,  0.00562082,  0.03281913, ..., -0.00032227,\n",
       "          -0.03861212, -0.08927232]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[20], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00671427,  0.00613561, -0.01602340, -0.03486771, -0.00079528,\n",
       "         -0.01652144, -0.02389209, -0.01194240,  0.00953578, -0.00186717,\n",
       "         -0.01929429, -0.00810205, -0.03000672, -0.02270882,  0.00962486,\n",
       "         -0.00838549, -0.00485422, -0.02795862, -0.00330600,  0.00116837]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00360417,  0.00553989,  0.00549994, ...,  0.03164842,\n",
       "           0.01151032,  0.01481300],\n",
       "         [-0.00411693,  0.00020544, -0.00574021, ..., -0.03103723,\n",
       "           0.00080197, -0.01190123],\n",
       "         [ 0.02673236,  0.00864224,  0.01981293, ..., -0.02391209,\n",
       "           0.02137185, -0.00817722],\n",
       "         ...,\n",
       "         [ 0.02359774,  0.00084564, -0.01197014, ..., -0.01030002,\n",
       "          -0.00334228,  0.02496037],\n",
       "         [-0.01860187, -0.01838612, -0.00071753, ..., -0.02279318,\n",
       "           0.02172718,  0.00557131],\n",
       "         [ 0.01934800,  0.00278352, -0.03000656, ..., -0.00392480,\n",
       "          -0.03824690, -0.03961597]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00044825, -0.00129102,  0.00302879, ..., -0.00072800,\n",
       "          0.00095159,  0.00117169]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [1.00038505, 1.00395548, 1.00212753, ..., 1.00243676, 1.00760233,\n",
       "         1.01096737]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.00265833, 0.00365360, 0.00819926, ..., 0.00071323, 0.00510949,\n",
       "         0.00890807])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814e9c02-6e35-40d4-94f8-e4e99bc11082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T03:31:32.871039Z",
     "iopub.status.busy": "2023-01-10T03:31:32.870365Z",
     "iopub.status.idle": "2023-01-10T03:31:33.598442Z",
     "shell.execute_reply": "2023-01-10T03:31:33.597326Z",
     "shell.execute_reply.started": "2023-01-10T03:31:32.870987Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " Tensor(shape=[30522, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00546739, -0.07279876, -0.00485531, ..., -0.05335438,\n",
       "           0.13600905, -0.20567332],\n",
       "         [-0.03285649, -0.04737137, -0.00188808, ...,  0.01321391,\n",
       "          -0.06982858, -0.06631948],\n",
       "         [-0.02384438, -0.01789385, -0.02179209, ..., -0.04086783,\n",
       "          -0.03336208, -0.08547164],\n",
       "         ...,\n",
       "         [ 0.00767266, -0.01697906, -0.01206527, ..., -0.00926016,\n",
       "           0.02441780, -0.08461355],\n",
       "         [-0.04005636, -0.01736297, -0.01372629, ..., -0.01628069,\n",
       "          -0.04072044, -0.11731133],\n",
       "         [ 0.01058857, -0.04614783, -0.01974028, ..., -0.03609759,\n",
       "          -0.06223337, -0.11604351]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[512, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00507997,  0.00187391, -0.01345916, ...,  0.00126663,\n",
       "          -0.00574510,  0.02086964],\n",
       "         [ 0.00292164,  0.00058186, -0.01195123, ...,  0.00351804,\n",
       "           0.01124866,  0.00287333],\n",
       "         [ 0.01181076, -0.01656369,  0.00427157, ...,  0.00434542,\n",
       "           0.02468900,  0.00723502],\n",
       "         ...,\n",
       "         [ 0.00702994, -0.00715088,  0.01145341, ..., -0.00003174,\n",
       "           0.00102580,  0.03143644],\n",
       "         [ 0.01968670,  0.00619306,  0.02487305, ..., -0.00513413,\n",
       "           0.00908471,  0.02814749],\n",
       "         [ 0.04055700,  0.01582482,  0.03196988, ...,  0.01533185,\n",
       "           0.01130116,  0.04628271]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00562339, -0.00902005,  0.00335708, ...,  0.00125806,\n",
       "           0.01050304,  0.02132046],\n",
       "         [-0.00033866, -0.00611977, -0.00980567, ...,  0.00252657,\n",
       "           0.00462465,  0.02257314],\n",
       "         [-0.01214475, -0.01347071,  0.00336370, ...,  0.01444779,\n",
       "           0.00906863,  0.01946940],\n",
       "         [-0.00529713, -0.00649051, -0.00009847, ...,  0.01121292,\n",
       "           0.00404791,  0.00556499]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[3, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00556043,  0.01207466, -0.05974247, ..., -0.00220376,\n",
       "           0.00053524,  0.01290023],\n",
       "         [-0.01766550, -0.02588688,  0.00750925, ...,  0.00620871,\n",
       "          -0.01174253, -0.00087369],\n",
       "         [ 0.00711616,  0.00082270, -0.01791317, ..., -0.01124782,\n",
       "          -0.01423857, -0.02957504]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.86570227, 0.87068999, 0.83374381, ..., 0.91927922, 0.89081973,\n",
       "         0.78663528]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02061026,  0.01057680,  0.02097345, ...,  0.01197484,\n",
       "          0.02429084,  0.08365896]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02165245,  0.01962121,  0.01430346, ..., -0.00230435,\n",
       "           0.04210546,  0.01765760],\n",
       "         [-0.03425077,  0.01871881, -0.01664569, ..., -0.01189850,\n",
       "          -0.00521408, -0.01579156],\n",
       "         [-0.05979552, -0.02007616, -0.03779425, ..., -0.01165872,\n",
       "           0.05649451, -0.00527014],\n",
       "         ...,\n",
       "         [ 0.01942109, -0.03110511,  0.03265965, ...,  0.03688818,\n",
       "          -0.01226761,  0.00433018],\n",
       "         [-0.01016609, -0.03582525,  0.00147209, ...,  0.03677451,\n",
       "          -0.01827369,  0.02352894],\n",
       "         [ 0.01772570, -0.01415499, -0.05572314, ...,  0.05526742,\n",
       "          -0.02089711,  0.02663185]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02542322,  0.20874120, -0.07034953, ..., -0.30008370,\n",
       "         -0.16278210,  0.13531761]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04844436, -0.02803303,  0.02447791, ...,  0.02649010,\n",
       "          -0.00308817,  0.00897467],\n",
       "         [ 0.04895176,  0.01249367, -0.00054956, ...,  0.01216429,\n",
       "           0.03598249, -0.00718619],\n",
       "         [-0.03661693,  0.00599952,  0.04517999, ...,  0.00405003,\n",
       "           0.00084686, -0.01294104],\n",
       "         ...,\n",
       "         [-0.03337665, -0.08218561,  0.02016096, ..., -0.02105017,\n",
       "           0.00806285,  0.00366512],\n",
       "         [ 0.06537340, -0.00860789,  0.04969020, ...,  0.06219239,\n",
       "          -0.04595096,  0.00966856],\n",
       "         [ 0.06969538,  0.01430999, -0.00746905, ...,  0.04257790,\n",
       "          -0.01162383,  0.00517727]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01875185, -0.03835705,  0.00663958, ...,  0.00386064,\n",
       "          0.02953196, -0.02359953]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01033662, -0.02179039, -0.00497147, ...,  0.02598202,\n",
       "          -0.01167515,  0.00564915],\n",
       "         [-0.00116191, -0.00146257, -0.00511527, ..., -0.00847754,\n",
       "           0.00729379, -0.00060772],\n",
       "         [-0.02963600,  0.00898237, -0.04023365, ...,  0.00477325,\n",
       "           0.02129426,  0.01641809],\n",
       "         ...,\n",
       "         [-0.00338870,  0.02051764, -0.03789696, ...,  0.00195613,\n",
       "          -0.00938758,  0.02400527],\n",
       "         [-0.06393202,  0.04914527,  0.02262706, ..., -0.00873399,\n",
       "          -0.00468901,  0.02234690],\n",
       "         [ 0.01461754,  0.02201836,  0.01110306, ..., -0.02330946,\n",
       "           0.01060808,  0.01422826]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00400644,  0.01754071, -0.01900113, ...,  0.00633497,\n",
       "          0.00191918, -0.03156042]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02621873,  0.00368805,  0.02841258, ..., -0.01556996,\n",
       "          -0.01134442, -0.03829392],\n",
       "         [-0.00777048,  0.00848474, -0.02965884, ..., -0.01691525,\n",
       "           0.02665857, -0.02585075],\n",
       "         [ 0.01652857,  0.05344447, -0.05279056, ..., -0.01853471,\n",
       "          -0.01565380,  0.00302158],\n",
       "         ...,\n",
       "         [ 0.00364930, -0.01000880,  0.02233331, ...,  0.02690089,\n",
       "           0.00325710, -0.02475746],\n",
       "         [-0.00095461, -0.02056030, -0.02109055, ..., -0.01350672,\n",
       "           0.01083132,  0.00907709],\n",
       "         [ 0.00524134,  0.00242417, -0.00171739, ..., -0.00413641,\n",
       "           0.01871274, -0.00721771]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03243011,  0.01921139,  0.00529409, ...,  0.00687134,\n",
       "          0.01170489,  0.01273240]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.09551344,  0.02521930, -0.01784329, ..., -0.00129528,\n",
       "           0.05789843, -0.01346657],\n",
       "         [-0.01448985,  0.03915878,  0.02124251, ..., -0.03387569,\n",
       "           0.02482050, -0.01462728],\n",
       "         [ 0.04040029,  0.02384592, -0.00888610, ..., -0.00302552,\n",
       "          -0.01827061,  0.00611765],\n",
       "         ...,\n",
       "         [ 0.05597835,  0.01895947,  0.04660091, ...,  0.01373478,\n",
       "          -0.00613690, -0.00124358],\n",
       "         [ 0.01932138, -0.00144440, -0.05377527, ..., -0.03028912,\n",
       "           0.08129494, -0.00171711],\n",
       "         [ 0.01906828,  0.00938510, -0.00710095, ..., -0.00337167,\n",
       "           0.05463964, -0.02433835]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.17491718, -0.07536733, -0.11202170, ..., -0.08807229,\n",
       "         -0.08983501, -0.05355591]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.06103866,  0.02414988,  0.02062188, ...,  0.03309232,\n",
       "          -0.01618136,  0.03889030],\n",
       "         [ 0.06439631,  0.01331663, -0.04194381, ..., -0.01601036,\n",
       "           0.02189787, -0.01762216],\n",
       "         [ 0.00159075, -0.00493440,  0.02056648, ...,  0.02668635,\n",
       "          -0.05351550, -0.01802632],\n",
       "         ...,\n",
       "         [-0.02118632, -0.03084333, -0.00357996, ...,  0.00452367,\n",
       "          -0.04288596, -0.00936652],\n",
       "         [ 0.03585682, -0.03002897, -0.02926642, ..., -0.04680423,\n",
       "           0.03261744, -0.04046116],\n",
       "         [ 0.03927838,  0.00310966,  0.00667719, ..., -0.00598648,\n",
       "           0.00330476,  0.00238648]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03800587, -0.00374643, -0.02657506, ...,  0.02238671,\n",
       "         -0.00462150,  0.01956801]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.99798673, 0.99116522, 0.99790424, ..., 1.03521132, 1.02945662,\n",
       "         1.00259316]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07245085,  0.07100190,  0.24703194, ..., -0.37113339,\n",
       "          0.31827593, -0.09715804]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90282136, 0.90011883, 0.87407351, ..., 0.88658857, 0.92085463,\n",
       "         0.86814106]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01253934,  0.01949977, -0.02989252, ...,  0.12062980,\n",
       "         -0.04499102,  0.06897105]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02154309,  0.03190599, -0.08757252, ..., -0.00134260,\n",
       "           0.00618432,  0.00707078],\n",
       "         [ 0.02182343, -0.03194952,  0.01743666, ...,  0.02420074,\n",
       "          -0.00206225, -0.03453589],\n",
       "         [-0.04914932, -0.01346543, -0.00552094, ...,  0.02001883,\n",
       "          -0.01056975, -0.02700518],\n",
       "         ...,\n",
       "         [ 0.03695894, -0.00901623,  0.00716919, ...,  0.04646511,\n",
       "          -0.01470129, -0.08644851],\n",
       "         [ 0.01755749, -0.04666661, -0.03593117, ..., -0.00303438,\n",
       "           0.01302075,  0.01753821],\n",
       "         [-0.02612897, -0.00387278,  0.06455828, ..., -0.03401105,\n",
       "           0.01652087, -0.03235384]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03384410, -0.02156361,  0.03866598, ..., -0.01099471,\n",
       "          0.07206319,  0.03021944]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00941576, -0.07384894,  0.00616098, ..., -0.00536570,\n",
       "           0.00444870, -0.02830235],\n",
       "         [ 0.00362398, -0.00350955,  0.00513141, ..., -0.04629123,\n",
       "          -0.00732370,  0.04995700],\n",
       "         [ 0.04416887, -0.00692058,  0.03782831, ...,  0.02833038,\n",
       "           0.00598005, -0.01226150],\n",
       "         ...,\n",
       "         [-0.01155730, -0.02872580, -0.03814134, ...,  0.01128108,\n",
       "          -0.04602158,  0.06626476],\n",
       "         [ 0.01047505, -0.01564571, -0.00693010, ..., -0.00622827,\n",
       "           0.01436899,  0.02368557],\n",
       "         [ 0.02521737, -0.01206553,  0.04228716, ...,  0.03169850,\n",
       "          -0.03626365,  0.04271752]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11305520,  0.02457824,  0.13670282, ...,  0.01204466,\n",
       "          0.02290571,  0.02541137]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02718382,  0.01082707, -0.01253162, ..., -0.02618417,\n",
       "          -0.02578423, -0.02676863],\n",
       "         [ 0.01534780, -0.02756925, -0.00300965, ...,  0.00271410,\n",
       "           0.00006806,  0.04656863],\n",
       "         [ 0.00499224, -0.04073225,  0.00086020, ...,  0.01447308,\n",
       "          -0.03157840, -0.00523639],\n",
       "         ...,\n",
       "         [ 0.03660113, -0.02194548,  0.02412545, ...,  0.01616369,\n",
       "           0.01634970,  0.00487118],\n",
       "         [-0.01420516, -0.04323233,  0.03074152, ..., -0.04000682,\n",
       "          -0.00857711,  0.01077608],\n",
       "         [ 0.06545540,  0.01408258,  0.02558282, ...,  0.00856049,\n",
       "          -0.00725661, -0.02173029]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00456013, -0.01741426, -0.01252179, ..., -0.01094165,\n",
       "         -0.00270965,  0.00184975]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00058088,  0.00973884,  0.03355338, ...,  0.02225498,\n",
       "          -0.00621057,  0.01763900],\n",
       "         [-0.00948755, -0.01129056,  0.03735543, ..., -0.00936331,\n",
       "          -0.01940664,  0.03551307],\n",
       "         [ 0.05118655, -0.03641982,  0.02014386, ..., -0.00973406,\n",
       "          -0.00700663,  0.02455928],\n",
       "         ...,\n",
       "         [ 0.05703275,  0.01904500,  0.00771489, ...,  0.00563726,\n",
       "           0.05299850, -0.00692609],\n",
       "         [ 0.01914904, -0.01172930,  0.00929820, ...,  0.00848367,\n",
       "           0.00066756, -0.01513171],\n",
       "         [-0.01188048, -0.03232439,  0.00781176, ..., -0.00068546,\n",
       "          -0.02298286, -0.00414053]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03031881, -0.00535547, -0.00167732, ...,  0.00315669,\n",
       "          0.02229424,  0.04434390]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01077013,  0.02916615, -0.07644665, ...,  0.08704734,\n",
       "          -0.04035007,  0.02655316],\n",
       "         [ 0.03327730,  0.00596931, -0.05741483, ..., -0.05065294,\n",
       "          -0.04293575, -0.03549986],\n",
       "         [-0.02018435, -0.06968486, -0.01512017, ..., -0.02514503,\n",
       "           0.04013383, -0.03291339],\n",
       "         ...,\n",
       "         [ 0.01527223,  0.02122314,  0.03708855, ..., -0.00555952,\n",
       "          -0.05866667, -0.01176534],\n",
       "         [-0.00294262, -0.07811566, -0.00358336, ...,  0.02932653,\n",
       "          -0.00567969, -0.02645823],\n",
       "         [ 0.01155640, -0.00353146, -0.04803866, ..., -0.02351953,\n",
       "           0.01430042, -0.00217569]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07261106, -0.08898391, -0.05689410, ..., -0.06246220,\n",
       "         -0.07401095, -0.07229283]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04780799, -0.01762321, -0.00699412, ...,  0.02068176,\n",
       "           0.02211725,  0.00943086],\n",
       "         [-0.02567902, -0.02564304, -0.00266114, ...,  0.02305603,\n",
       "          -0.00437081,  0.04152414],\n",
       "         [-0.02864391, -0.00578361, -0.01885343, ..., -0.03112473,\n",
       "          -0.00933424, -0.01714028],\n",
       "         ...,\n",
       "         [-0.01464074, -0.04180218, -0.00957387, ...,  0.02452425,\n",
       "           0.00530743,  0.03045905],\n",
       "         [-0.02847682,  0.02620400,  0.01142524, ...,  0.00097001,\n",
       "           0.02351801,  0.02545865],\n",
       "         [ 0.00504775, -0.03037585,  0.06141156, ...,  0.01618577,\n",
       "          -0.00094245,  0.01539848]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01372548,  0.01298664, -0.06168745, ...,  0.05964814,\n",
       "         -0.01751787, -0.00429494]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.99401480, 0.96494097, 0.98234493, ..., 1.00187516, 1.00430441,\n",
       "         0.98268753]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.12272438,  0.12252688,  0.09972298, ..., -0.21528834,\n",
       "          0.23244694, -0.00734201]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.93493503, 0.94117892, 0.93905395, ..., 0.92537439, 0.95446283,\n",
       "         0.92375511]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.08949640, -0.03592343,  0.00649307, ...,  0.11906743,\n",
       "         -0.08476302,  0.01887068]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00187264,  0.03664690, -0.07480329, ...,  0.00853819,\n",
       "           0.01785471,  0.03004906],\n",
       "         [-0.03120578,  0.04112335, -0.04363067, ..., -0.00244692,\n",
       "          -0.01342712,  0.02926392],\n",
       "         [-0.03969974, -0.01911366,  0.03674633, ..., -0.00063313,\n",
       "           0.02253249,  0.01838413],\n",
       "         ...,\n",
       "         [ 0.03319034,  0.01970395, -0.00325449, ...,  0.00408467,\n",
       "          -0.05736190, -0.03466770],\n",
       "         [ 0.02899564, -0.00671087,  0.01334862, ...,  0.02368167,\n",
       "          -0.04502670, -0.05679351],\n",
       "         [ 0.03549600, -0.01527241, -0.03217169, ..., -0.10398378,\n",
       "          -0.00355348,  0.02888017]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01107056,  0.07019701,  0.00223872, ..., -0.04540491,\n",
       "         -0.02341057, -0.01720056]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03010446, -0.03934263, -0.02948866, ...,  0.03090297,\n",
       "           0.03577599, -0.03602628],\n",
       "         [ 0.02586341,  0.01812079,  0.03825855, ...,  0.06579248,\n",
       "          -0.00825371,  0.01732639],\n",
       "         [-0.02337473,  0.00736421, -0.03712850, ...,  0.01651330,\n",
       "           0.00196081,  0.00831748],\n",
       "         ...,\n",
       "         [ 0.00029857, -0.05367414,  0.02828052, ..., -0.00679220,\n",
       "           0.02612982,  0.03743557],\n",
       "         [-0.01828360,  0.02882275, -0.07718309, ..., -0.03667499,\n",
       "           0.00525916, -0.04131386],\n",
       "         [-0.00268564, -0.00920135, -0.05722724, ...,  0.02526876,\n",
       "          -0.03519429,  0.07673659]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00083275,  0.07093410,  0.03901595, ..., -0.02240705,\n",
       "         -0.00767333, -0.06235615]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01523952, -0.00668102,  0.01625089, ..., -0.02025274,\n",
       "          -0.00861877,  0.00398694],\n",
       "         [ 0.01555767,  0.00056461, -0.02073646, ..., -0.00369188,\n",
       "          -0.03241087, -0.00664653],\n",
       "         [-0.00556967, -0.01767230, -0.01998700, ..., -0.00189256,\n",
       "           0.01083030,  0.02962894],\n",
       "         ...,\n",
       "         [ 0.00577600, -0.00091703, -0.04174646, ...,  0.03438747,\n",
       "           0.02222401,  0.00833589],\n",
       "         [-0.00471703, -0.00233638, -0.01592196, ...,  0.01168905,\n",
       "          -0.06525059,  0.02456177],\n",
       "         [-0.05034782,  0.00899318,  0.00329698, ..., -0.01281319,\n",
       "           0.00655066, -0.01299746]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00903887, -0.09171849, -0.01007821, ...,  0.02145014,\n",
       "          0.00223950,  0.00464470]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03380707, -0.02585695, -0.00164727, ..., -0.03032255,\n",
       "           0.02247412, -0.02902056],\n",
       "         [ 0.04501200, -0.01216291,  0.02577172, ..., -0.00168877,\n",
       "           0.00649749,  0.01537591],\n",
       "         [-0.01815041,  0.03196091, -0.06142617, ...,  0.02431093,\n",
       "          -0.01008292, -0.02308192],\n",
       "         ...,\n",
       "         [ 0.01441480, -0.00569054,  0.03525589, ..., -0.01252164,\n",
       "           0.00119713, -0.01213438],\n",
       "         [ 0.00702174, -0.01719729,  0.00019624, ..., -0.01220347,\n",
       "           0.05371847,  0.01703353],\n",
       "         [-0.01532890, -0.00562424, -0.00955719, ...,  0.00330495,\n",
       "          -0.01040510,  0.00341298]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02859519, -0.02938941, -0.00034968, ...,  0.01019300,\n",
       "         -0.02082036,  0.04858099]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00679939, -0.01256576, -0.00687045, ..., -0.00623931,\n",
       "           0.01218855, -0.01246139],\n",
       "         [ 0.05805406, -0.00307528,  0.00146839, ...,  0.05998588,\n",
       "          -0.01963969,  0.05309044],\n",
       "         [-0.09028150, -0.03650155, -0.01992772, ..., -0.02507983,\n",
       "           0.00012071, -0.01250919],\n",
       "         ...,\n",
       "         [ 0.01258776, -0.05904996,  0.02692041, ..., -0.00712835,\n",
       "           0.01661376,  0.02992825],\n",
       "         [ 0.02550282, -0.02386601,  0.03473059, ...,  0.02110808,\n",
       "           0.04082729,  0.06493478],\n",
       "         [ 0.00265130, -0.01601810,  0.04657507, ...,  0.03768580,\n",
       "          -0.06328547,  0.02608122]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06845414, -0.07368025, -0.04708447, ..., -0.03683836,\n",
       "         -0.07963219, -0.06683056]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.05431368,  0.02822990, -0.07565643, ...,  0.01565950,\n",
       "           0.04072224,  0.00865093],\n",
       "         [ 0.02540101, -0.02250307,  0.06017384, ..., -0.05258779,\n",
       "           0.02049353, -0.01783587],\n",
       "         [-0.00529703,  0.01758843,  0.04587194, ..., -0.00393205,\n",
       "           0.04465622,  0.03558236],\n",
       "         ...,\n",
       "         [-0.03817849,  0.02453324, -0.03119223, ...,  0.00151211,\n",
       "           0.04095440,  0.03231252],\n",
       "         [ 0.01465193, -0.04145223,  0.03117827, ..., -0.02160681,\n",
       "           0.02820252, -0.05742065],\n",
       "         [ 0.03285373,  0.01132218, -0.00171476, ...,  0.02001699,\n",
       "          -0.02100491,  0.03745595]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02098511,  0.00174295, -0.06190158, ...,  0.06962232,\n",
       "         -0.03900337, -0.00557880]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.96750849, 0.96198136, 0.99594635, ..., 0.97195476, 0.97673094,\n",
       "         0.93950188]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.10059139,  0.05345498,  0.20486343, ..., -0.13092649,\n",
       "          0.12834695, -0.02823232]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.93530500, 0.94601852, 0.91840184, ..., 0.92090803, 0.95994431,\n",
       "         0.89796305]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.08219226, -0.01976293, -0.07364026, ...,  0.11643357,\n",
       "         -0.05698409,  0.05195755]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.06997801,  0.03403695,  0.00801056, ..., -0.02036118,\n",
       "          -0.06785335, -0.02775296],\n",
       "         [ 0.02833418, -0.07958113,  0.00475356, ...,  0.01299560,\n",
       "          -0.01935024, -0.09614071],\n",
       "         [-0.00780280,  0.04042844, -0.00223793, ...,  0.03651365,\n",
       "           0.02833192,  0.02024033],\n",
       "         ...,\n",
       "         [-0.00209291, -0.00778890,  0.01572090, ...,  0.02165994,\n",
       "           0.05858569,  0.06132914],\n",
       "         [ 0.02443486, -0.04433451,  0.02128468, ..., -0.02124860,\n",
       "           0.05574485,  0.01170642],\n",
       "         [-0.07583261,  0.02089794,  0.03768731, ..., -0.02214307,\n",
       "           0.01177406, -0.01868921]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03499555,  0.01317501, -0.01954166, ..., -0.08677704,\n",
       "          0.02696713, -0.03937043]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.08577783, -0.03691950, -0.00576206, ...,  0.01532165,\n",
       "          -0.00048969, -0.03629885],\n",
       "         [-0.03039857,  0.05517736, -0.04979338, ...,  0.02226881,\n",
       "          -0.02124177, -0.00883540],\n",
       "         [ 0.05136275,  0.01417528, -0.00405279, ...,  0.00373357,\n",
       "          -0.00638491,  0.00085403],\n",
       "         ...,\n",
       "         [ 0.01661459,  0.02054391, -0.04933106, ..., -0.04079137,\n",
       "          -0.01123635, -0.02121757],\n",
       "         [-0.04180251,  0.02900794,  0.03635546, ...,  0.07041787,\n",
       "          -0.06371767, -0.05400907],\n",
       "         [-0.01798524,  0.04321076,  0.03616852, ...,  0.01083319,\n",
       "          -0.02116370, -0.04840666]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08373445, -0.00674625, -0.03055264, ..., -0.04085879,\n",
       "          0.00467196,  0.05222342]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00860242,  0.00299433, -0.00706796, ..., -0.01752977,\n",
       "          -0.02995522,  0.01674199],\n",
       "         [ 0.01701836, -0.02070845,  0.01477405, ...,  0.00805709,\n",
       "          -0.01092794,  0.00291236],\n",
       "         [-0.00363786, -0.00790362,  0.00909607, ..., -0.00439328,\n",
       "          -0.01526376, -0.02811198],\n",
       "         ...,\n",
       "         [ 0.06688646,  0.01193139,  0.04387220, ...,  0.02017850,\n",
       "           0.00646342, -0.02445910],\n",
       "         [-0.01343123, -0.03595743, -0.05103635, ..., -0.02585508,\n",
       "          -0.02041663,  0.00611049],\n",
       "         [-0.07655270,  0.00498827, -0.02575369, ..., -0.00418888,\n",
       "           0.03366595,  0.04145950]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00323314, -0.01217277, -0.01824006, ...,  0.01489943,\n",
       "         -0.01382563, -0.01431349]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02481145, -0.00204798, -0.00142929, ..., -0.03199236,\n",
       "          -0.00750615,  0.03314051],\n",
       "         [ 0.02667348,  0.00785610,  0.01867200, ..., -0.01153093,\n",
       "          -0.01400335, -0.00270230],\n",
       "         [ 0.00676689, -0.00546261, -0.04497155, ..., -0.01621365,\n",
       "           0.00660690,  0.01392223],\n",
       "         ...,\n",
       "         [-0.00013623, -0.02386822,  0.00430103, ..., -0.01840207,\n",
       "          -0.00975583, -0.02659154],\n",
       "         [ 0.00455912,  0.01981742,  0.00468709, ...,  0.00045966,\n",
       "           0.04549692, -0.00874993],\n",
       "         [ 0.01300030, -0.01487291, -0.02228289, ..., -0.00466248,\n",
       "           0.00946354, -0.01044399]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01113462,  0.07466472, -0.04647900, ...,  0.07520027,\n",
       "         -0.01815445,  0.02151146]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04626199,  0.02776363,  0.00199827, ...,  0.06784222,\n",
       "           0.00284590,  0.04270079],\n",
       "         [ 0.07302646, -0.05109327, -0.02547820, ...,  0.05750188,\n",
       "           0.02391753, -0.02378814],\n",
       "         [-0.01706478, -0.01367129, -0.07364381, ...,  0.02295348,\n",
       "          -0.04835924, -0.03520579],\n",
       "         ...,\n",
       "         [-0.00519177,  0.02273732, -0.00511212, ..., -0.00120540,\n",
       "          -0.00152330,  0.03417980],\n",
       "         [-0.06002333,  0.02506504, -0.01521083, ..., -0.00523602,\n",
       "           0.01008906, -0.01268393],\n",
       "         [-0.00987081,  0.07563142,  0.05039502, ...,  0.03034586,\n",
       "           0.01644229,  0.05555295]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07262418, -0.08076896, -0.07034615, ..., -0.07157809,\n",
       "         -0.06958293, -0.06831679]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03513527, -0.01159589,  0.01723501, ...,  0.00817777,\n",
       "          -0.00846626, -0.03822545],\n",
       "         [ 0.04117040, -0.03057771,  0.01741926, ..., -0.03891749,\n",
       "           0.01293027,  0.01624038],\n",
       "         [ 0.00273368, -0.01850114, -0.05195282, ...,  0.00437952,\n",
       "          -0.00481177, -0.03284320],\n",
       "         ...,\n",
       "         [ 0.02136684,  0.01275694,  0.00518470, ...,  0.02138918,\n",
       "          -0.04577834, -0.02127735],\n",
       "         [ 0.00761283, -0.01051725, -0.02619000, ..., -0.03392064,\n",
       "          -0.01217809,  0.01324927],\n",
       "         [-0.01311408,  0.06564178,  0.01153758, ...,  0.03449515,\n",
       "          -0.01438150, -0.06021000]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00146070,  0.01736160, -0.08845048, ...,  0.08512256,\n",
       "         -0.02943513, -0.02852380]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.97375715, 0.95534366, 0.99075872, ..., 0.96978706, 0.97134066,\n",
       "         0.93294019]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.15137358, -0.00185832,  0.22996755, ..., -0.06628359,\n",
       "          0.07091097,  0.02100921]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91615254, 0.93026501, 0.88591069, ..., 0.92984647, 0.95838410,\n",
       "         0.91024971]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.11008775,  0.01852817, -0.08447688, ...,  0.10112366,\n",
       "         -0.04002447,  0.01738966]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03399576,  0.02031573, -0.02786278, ..., -0.06836528,\n",
       "          -0.00591919,  0.01927357],\n",
       "         [-0.00593707, -0.04995826,  0.01392644, ...,  0.01490348,\n",
       "           0.00457600, -0.03664094],\n",
       "         [-0.04786201,  0.03231987,  0.00176772, ...,  0.06850375,\n",
       "           0.04279979, -0.00562250],\n",
       "         ...,\n",
       "         [ 0.00333498,  0.00163899, -0.02413108, ...,  0.00001026,\n",
       "           0.02035522, -0.04706169],\n",
       "         [-0.00387916,  0.00540464,  0.00191450, ...,  0.00479433,\n",
       "          -0.01436276, -0.02318076],\n",
       "         [-0.00591922, -0.00231971, -0.02099684, ..., -0.04298626,\n",
       "           0.03773485,  0.00231735]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01398670, -0.07123644,  0.07056879, ..., -0.01165437,\n",
       "         -0.00990477, -0.03876054]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.07808722, -0.04582607,  0.02169892, ...,  0.00510287,\n",
       "           0.00518550,  0.04320298],\n",
       "         [-0.02191243,  0.00421963,  0.03616475, ..., -0.02048114,\n",
       "           0.01053840, -0.00270772],\n",
       "         [ 0.02650898,  0.02639083, -0.04454264, ..., -0.04748500,\n",
       "          -0.03878909,  0.01734771],\n",
       "         ...,\n",
       "         [-0.02798215,  0.03657450, -0.04368250, ..., -0.01626463,\n",
       "           0.05824459,  0.04391992],\n",
       "         [ 0.01663339,  0.02996370, -0.00047135, ...,  0.02375348,\n",
       "           0.01040109,  0.00699306],\n",
       "         [-0.01814311, -0.05210248,  0.00367074, ...,  0.00615942,\n",
       "          -0.05360638, -0.05220679]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02196125, -0.25898373,  0.05722695, ...,  0.03923904,\n",
       "          0.01339656, -0.07149100]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01271745,  0.00932912, -0.00615469, ..., -0.00646952,\n",
       "           0.03720864,  0.05690637],\n",
       "         [ 0.00101497,  0.02227123, -0.04033122, ..., -0.01666568,\n",
       "          -0.02169786,  0.03382464],\n",
       "         [-0.02899723, -0.03611388, -0.01335074, ...,  0.00435250,\n",
       "          -0.03514659, -0.02195653],\n",
       "         ...,\n",
       "         [ 0.01083036, -0.01976180,  0.02129534, ..., -0.07126440,\n",
       "           0.01925775, -0.00844972],\n",
       "         [ 0.02286791, -0.01578311,  0.03902663, ...,  0.03612215,\n",
       "           0.01647159,  0.05462509],\n",
       "         [ 0.04522009, -0.01536091,  0.02590648, ...,  0.00809051,\n",
       "           0.01112818, -0.01647949]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01778710,  0.00416464, -0.00879775, ...,  0.00846842,\n",
       "          0.02127063,  0.00743342]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02183276,  0.03952023,  0.02365866, ..., -0.00951446,\n",
       "           0.01460638, -0.02132472],\n",
       "         [ 0.02341023, -0.05352094, -0.03196145, ...,  0.00172341,\n",
       "           0.00827760,  0.01806271],\n",
       "         [-0.00804600,  0.01007959, -0.04418446, ...,  0.00539618,\n",
       "          -0.01504476,  0.02132842],\n",
       "         ...,\n",
       "         [ 0.01624353, -0.01906842, -0.00886712, ..., -0.01457822,\n",
       "          -0.00217499, -0.01645518],\n",
       "         [-0.01582659, -0.00218876, -0.03744259, ..., -0.02248649,\n",
       "          -0.02424905,  0.03065636],\n",
       "         [ 0.00576605, -0.01345295,  0.02023068, ..., -0.00536284,\n",
       "          -0.00263893, -0.00827601]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03605250, -0.00289547, -0.00867259, ...,  0.02189634,\n",
       "          0.01296984,  0.03481429]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01562904,  0.02145915, -0.01037889, ..., -0.02132313,\n",
       "          -0.00687824,  0.04524128],\n",
       "         [-0.01257884,  0.00875120,  0.01045327, ..., -0.02285296,\n",
       "          -0.03066341, -0.02895666],\n",
       "         [ 0.03857575,  0.04216749,  0.00175718, ...,  0.04982113,\n",
       "          -0.00719159,  0.02707681],\n",
       "         ...,\n",
       "         [ 0.05156654, -0.03927720,  0.00137980, ..., -0.00655430,\n",
       "           0.02536841, -0.02673415],\n",
       "         [ 0.02349286, -0.01141057,  0.01382044, ...,  0.07115067,\n",
       "          -0.07281448, -0.00436265],\n",
       "         [ 0.06701785, -0.05514511, -0.01476882, ...,  0.00715050,\n",
       "           0.00359965,  0.03703189]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06330173, -0.08061309, -0.04132523, ..., -0.06171605,\n",
       "         -0.05903632, -0.03813280]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04038624, -0.03153719, -0.04486884, ...,  0.06937268,\n",
       "           0.00238660,  0.00462633],\n",
       "         [ 0.02697231, -0.07810778, -0.00530461, ...,  0.04892191,\n",
       "           0.01588615, -0.02809144],\n",
       "         [ 0.00620475, -0.02849613, -0.00488872, ..., -0.02944085,\n",
       "          -0.00421954, -0.00485915],\n",
       "         ...,\n",
       "         [-0.00222333, -0.03824960,  0.01656340, ..., -0.01359879,\n",
       "          -0.00316814,  0.04244627],\n",
       "         [ 0.01576062,  0.00117676,  0.03465547, ...,  0.00534002,\n",
       "          -0.00957956, -0.03543746],\n",
       "         [-0.03922075,  0.03528069,  0.04698691, ..., -0.02224552,\n",
       "          -0.01909704, -0.04533674]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02582171,  0.02858391, -0.02822003, ...,  0.08706655,\n",
       "         -0.01310323, -0.03085333]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.94602960, 0.93560201, 0.96940273, ..., 0.94384950, 0.95495099,\n",
       "         0.93721116]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.13666452,  0.06740961,  0.24714744, ...,  0.05493936,\n",
       "         -0.02943347,  0.05127873]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90467948, 0.93292862, 0.89632362, ..., 0.93428445, 0.96053994,\n",
       "         0.90887111]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.12613788, -0.02219705, -0.08584443, ...,  0.03465523,\n",
       "          0.00280716,  0.03019924]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02525022,  0.00997348,  0.02523055, ...,  0.01821265,\n",
       "           0.01927893, -0.02804378],\n",
       "         [ 0.00934064, -0.04756892,  0.01212151, ...,  0.05868220,\n",
       "           0.01743174, -0.04522275],\n",
       "         [-0.05335831,  0.02909278, -0.06018190, ..., -0.03175811,\n",
       "          -0.03409074,  0.02075919],\n",
       "         ...,\n",
       "         [-0.03246259,  0.03841541, -0.01159173, ..., -0.02544440,\n",
       "           0.02857324, -0.01477203],\n",
       "         [ 0.00069601, -0.00401515, -0.03121210, ...,  0.02699045,\n",
       "          -0.02644004, -0.03625650],\n",
       "         [ 0.01160645, -0.03046928,  0.04724977, ..., -0.01449508,\n",
       "           0.00447905, -0.03618418]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02486702,  0.00483830, -0.06196487, ..., -0.04950723,\n",
       "          0.00318141, -0.04628885]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01416538, -0.03613395,  0.02513991, ..., -0.02550254,\n",
       "           0.01536174,  0.01046561],\n",
       "         [ 0.00128976, -0.05321799, -0.00094758, ..., -0.02073003,\n",
       "           0.00385165,  0.01623077],\n",
       "         [-0.02344026,  0.06371332, -0.06331708, ...,  0.04763788,\n",
       "           0.00674263, -0.02445254],\n",
       "         ...,\n",
       "         [ 0.00379134, -0.02320586,  0.04097822, ...,  0.01700498,\n",
       "           0.00540856,  0.02748981],\n",
       "         [ 0.03022332,  0.00477480, -0.00118433, ...,  0.00658933,\n",
       "           0.02425473,  0.03914327],\n",
       "         [ 0.03268294,  0.03934529,  0.03580631, ..., -0.01468153,\n",
       "          -0.01619741,  0.02285166]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04470081,  0.07882296, -0.03312239, ..., -0.10481687,\n",
       "          0.17904553, -0.04678589]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02653860, -0.03695584,  0.02951830, ..., -0.05569368,\n",
       "          -0.05203701, -0.03448588],\n",
       "         [-0.02997836, -0.00208910, -0.01807279, ...,  0.02056126,\n",
       "          -0.00092571,  0.03345111],\n",
       "         [ 0.01940504, -0.01829948,  0.01312496, ..., -0.02723535,\n",
       "           0.00999050, -0.04778604],\n",
       "         ...,\n",
       "         [ 0.01868661, -0.01043159,  0.00705879, ..., -0.02021288,\n",
       "           0.00527732,  0.00475293],\n",
       "         [ 0.03974094, -0.02216908,  0.02411203, ..., -0.00396745,\n",
       "          -0.01381885,  0.00722956],\n",
       "         [ 0.04243631,  0.05131752,  0.01866504, ...,  0.02894462,\n",
       "          -0.00974737, -0.02251608]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00682494,  0.00718065,  0.00943569, ...,  0.00033061,\n",
       "          0.00380077, -0.01242587]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02560347,  0.04603404,  0.01466966, ..., -0.00779442,\n",
       "           0.03974799, -0.02575745],\n",
       "         [ 0.01130180,  0.01611723, -0.01469338, ...,  0.01351758,\n",
       "          -0.00127165,  0.01787735],\n",
       "         [-0.01964834,  0.05565464,  0.00488812, ...,  0.00077507,\n",
       "           0.02594108,  0.00857124],\n",
       "         ...,\n",
       "         [-0.02171527,  0.01764359, -0.01899547, ..., -0.00528950,\n",
       "           0.00270175,  0.04352304],\n",
       "         [-0.03526631,  0.03889945,  0.02359073, ...,  0.00800707,\n",
       "          -0.00693048,  0.03869750],\n",
       "         [ 0.00830131,  0.01082669, -0.01485202, ..., -0.04391113,\n",
       "           0.01789385,  0.00428850]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00321774,  0.01726199, -0.01119922, ...,  0.01594228,\n",
       "         -0.01356950,  0.02232339]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03664876,  0.08299423, -0.06810175, ...,  0.07155086,\n",
       "          -0.09021421, -0.02725267],\n",
       "         [ 0.00262020,  0.00953993, -0.01420933, ...,  0.01448051,\n",
       "          -0.00942457,  0.03747421],\n",
       "         [-0.01820736, -0.01777867, -0.02203698, ..., -0.05482380,\n",
       "          -0.02306272,  0.02269444],\n",
       "         ...,\n",
       "         [-0.01073818, -0.03439542, -0.03698038, ...,  0.03860046,\n",
       "           0.05953967,  0.00223158],\n",
       "         [-0.00494312, -0.02413690, -0.02241136, ...,  0.02070382,\n",
       "          -0.03459295,  0.02698510],\n",
       "         [-0.04337554, -0.00535397,  0.00926846, ..., -0.02016128,\n",
       "          -0.03217474,  0.05075156]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06642429, -0.07170234, -0.06812643, ..., -0.06019281,\n",
       "         -0.06323732, -0.08247820]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00773696, -0.00268321,  0.00632421, ...,  0.02429743,\n",
       "          -0.03457936,  0.04395073],\n",
       "         [ 0.03000369,  0.07178819, -0.00085886, ...,  0.02108173,\n",
       "           0.00012996, -0.04602132],\n",
       "         [-0.02257089, -0.01024841,  0.00287991, ..., -0.05408838,\n",
       "          -0.01149133,  0.01250494],\n",
       "         ...,\n",
       "         [-0.01869779,  0.01188279,  0.03368482, ..., -0.01765426,\n",
       "          -0.01429471, -0.00004435],\n",
       "         [-0.06735814, -0.00319236,  0.01050527, ...,  0.02841277,\n",
       "          -0.00733645, -0.00004277],\n",
       "         [-0.00074823, -0.03630643, -0.03597883, ...,  0.01190000,\n",
       "          -0.00577988,  0.01168995]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01862134, -0.00123157, -0.04569997, ...,  0.08507542,\n",
       "         -0.03216169,  0.00412705]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91890645, 0.90861154, 0.96628189, ..., 0.90526855, 0.94455820,\n",
       "         0.90617388]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.14411294,  0.06834798,  0.32178283, ...,  0.06243030,\n",
       "         -0.13738292,  0.14233761]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.85965973, 0.87435591, 0.82767040, ..., 0.89870644, 0.92101437,\n",
       "         0.86852270]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.12108129, -0.01575522, -0.09179127, ...,  0.04193841,\n",
       "          0.06296698, -0.02184233]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03380688,  0.04807649,  0.04148862, ...,  0.05621969,\n",
       "           0.01171872,  0.03739688],\n",
       "         [ 0.07536146,  0.00653215, -0.02172311, ...,  0.02080826,\n",
       "          -0.01734737,  0.04328398],\n",
       "         [-0.05615536, -0.00042504, -0.01416247, ..., -0.03495732,\n",
       "          -0.02041923,  0.03040441],\n",
       "         ...,\n",
       "         [-0.02851023,  0.00765766,  0.01112484, ...,  0.03089748,\n",
       "          -0.06270738,  0.03116149],\n",
       "         [ 0.01518233, -0.06055611, -0.08245116, ..., -0.06616655,\n",
       "          -0.01163218,  0.04284002],\n",
       "         [ 0.02861210,  0.06570279,  0.04717163, ...,  0.00120340,\n",
       "           0.01602398,  0.02459500]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02102922, -0.01445383, -0.03973243, ..., -0.05126784,\n",
       "         -0.03156053,  0.12396812]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02074802,  0.03802306, -0.00619604, ...,  0.06308566,\n",
       "          -0.00179902, -0.00632568],\n",
       "         [ 0.08615767,  0.01834288,  0.09253167, ...,  0.01334955,\n",
       "          -0.02464014, -0.00754465],\n",
       "         [ 0.00678109, -0.00632559, -0.03880756, ..., -0.07309668,\n",
       "           0.01825923, -0.02109207],\n",
       "         ...,\n",
       "         [-0.02538165,  0.03672335,  0.02449776, ..., -0.01942535,\n",
       "          -0.00113297, -0.02699711],\n",
       "         [ 0.07481990, -0.06120639, -0.07407296, ..., -0.13676056,\n",
       "          -0.02633959,  0.02001500],\n",
       "         [-0.03734317,  0.04944125,  0.02821858, ...,  0.01803591,\n",
       "           0.01387187, -0.00678328]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02535092,  0.00548275, -0.15597941, ..., -0.12344711,\n",
       "          0.04813453,  0.27004531]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00220596, -0.01619888,  0.00891397, ..., -0.01591601,\n",
       "          -0.03957880,  0.00046248],\n",
       "         [ 0.00317477,  0.02434142, -0.01682072, ..., -0.02396681,\n",
       "           0.02878522, -0.00931409],\n",
       "         [-0.01929663, -0.00972308, -0.02580839, ..., -0.02033661,\n",
       "          -0.03743759, -0.01160448],\n",
       "         ...,\n",
       "         [-0.02119110,  0.02721196,  0.03750570, ..., -0.05701033,\n",
       "           0.00604475, -0.04325784],\n",
       "         [ 0.02502355, -0.01110600,  0.00858043, ...,  0.02455712,\n",
       "           0.01548600,  0.02395849],\n",
       "         [ 0.01977784,  0.00230351,  0.00692518, ...,  0.00814558,\n",
       "           0.04576024,  0.00600056]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00145850, -0.00712285, -0.00073849, ...,  0.00663410,\n",
       "         -0.01109444, -0.01883978]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02222846, -0.00798066,  0.00630193, ...,  0.00146071,\n",
       "           0.01792075, -0.01550902],\n",
       "         [-0.00102717,  0.03915637,  0.00784601, ..., -0.00188191,\n",
       "           0.02245667,  0.05441244],\n",
       "         [ 0.01516188, -0.02673530, -0.06162628, ...,  0.02227389,\n",
       "           0.02187549, -0.02095728],\n",
       "         ...,\n",
       "         [-0.02286393,  0.05479193,  0.00865503, ...,  0.01455222,\n",
       "          -0.00759577,  0.02493307],\n",
       "         [ 0.01192001,  0.02076586, -0.03559021, ...,  0.01484361,\n",
       "          -0.00735056, -0.00929084],\n",
       "         [-0.01330237, -0.00333852,  0.01253251, ..., -0.00818697,\n",
       "           0.00905386, -0.03564806]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01331706, -0.01806567,  0.04605639, ...,  0.03244816,\n",
       "          0.00688528,  0.02974099]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00351270,  0.06981730,  0.00840263, ...,  0.02688709,\n",
       "           0.03053258,  0.08022568],\n",
       "         [-0.01497860, -0.01637135,  0.00722808, ..., -0.01411810,\n",
       "           0.00841993,  0.02292982],\n",
       "         [ 0.02392921, -0.06798774,  0.02454544, ..., -0.05106210,\n",
       "          -0.01425696,  0.03684787],\n",
       "         ...,\n",
       "         [ 0.03891969,  0.02768730,  0.04378244, ..., -0.00315902,\n",
       "           0.03664970,  0.01162622],\n",
       "         [-0.03390056, -0.06430257, -0.05577923, ..., -0.02697617,\n",
       "           0.02932780, -0.00053024],\n",
       "         [-0.04626441, -0.06141810, -0.04065566, ...,  0.00679405,\n",
       "           0.05760367,  0.01822959]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04625672, -0.09395215, -0.08552275, ...,  0.04141880,\n",
       "         -0.06599099, -0.08756623]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02121027,  0.00564026, -0.02963905, ...,  0.03943757,\n",
       "          -0.02763688, -0.00351428],\n",
       "         [ 0.00060014, -0.05157558,  0.03829021, ...,  0.00472567,\n",
       "           0.00383415, -0.00779823],\n",
       "         [-0.02437482, -0.02154900, -0.01676604, ...,  0.00017879,\n",
       "           0.01883107,  0.01978232],\n",
       "         ...,\n",
       "         [ 0.00364480,  0.04354706,  0.03758147, ...,  0.05241120,\n",
       "           0.03699256,  0.03405575],\n",
       "         [-0.03659790,  0.00801808,  0.00856293, ..., -0.03715747,\n",
       "           0.01856254, -0.00424565],\n",
       "         [ 0.04506321,  0.01111323,  0.03985028, ...,  0.01545806,\n",
       "           0.01365146, -0.02114736]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01423036,  0.04239644, -0.08600166, ...,  0.04143820,\n",
       "         -0.02112536, -0.00802210]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90010315, 0.91333568, 0.96468753, ..., 0.93274367, 0.94403005,\n",
       "         0.88995260]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00299480, -0.07702731,  0.30153364, ...,  0.13064542,\n",
       "         -0.14004233,  0.08640503]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.86856043, 0.86847001, 0.83318448, ..., 0.87944847, 0.88818556,\n",
       "         0.85346061]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.05180473,  0.02044404, -0.08346247, ..., -0.00960106,\n",
       "          0.08872372, -0.02259345]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01620971, -0.04560905,  0.03098615, ..., -0.00316686,\n",
       "          -0.01452449,  0.02478106],\n",
       "         [-0.04655116,  0.03137535, -0.03469355, ...,  0.00143017,\n",
       "          -0.00126999,  0.03925989],\n",
       "         [ 0.02541699,  0.00557904,  0.03699346, ...,  0.00542887,\n",
       "           0.01671376,  0.01225940],\n",
       "         ...,\n",
       "         [ 0.02343452, -0.03034202,  0.01583553, ...,  0.03642708,\n",
       "          -0.01698065, -0.04479694],\n",
       "         [-0.01259650,  0.05086679,  0.00403232, ...,  0.01624980,\n",
       "          -0.02007879,  0.00388376],\n",
       "         [-0.04312905, -0.03940958, -0.01197221, ...,  0.05321453,\n",
       "          -0.07952879,  0.05440563]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11712433,  0.06164765, -0.06698811, ...,  0.07491819,\n",
       "          0.07970842,  0.02759364]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01552467, -0.04890681,  0.05097117, ..., -0.01452721,\n",
       "          -0.02148134,  0.01617034],\n",
       "         [-0.00151417,  0.03504990, -0.03182294, ..., -0.06408381,\n",
       "           0.03554454, -0.02170342],\n",
       "         [-0.03568732,  0.01647079,  0.02755890, ..., -0.00720741,\n",
       "          -0.00100646,  0.00420907],\n",
       "         ...,\n",
       "         [-0.00313648, -0.00401388,  0.02978494, ...,  0.02710993,\n",
       "           0.00356990, -0.01775824],\n",
       "         [ 0.08011670,  0.04924062,  0.02638360, ..., -0.05846804,\n",
       "           0.03310552, -0.02365278],\n",
       "         [ 0.02099767,  0.05622954, -0.04962448, ...,  0.03714712,\n",
       "           0.04623958, -0.01611714]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02970341, -0.03920527, -0.02026020, ...,  0.02826411,\n",
       "         -0.01053408, -0.02425720]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00368040, -0.01163165, -0.05885848, ..., -0.00316089,\n",
       "          -0.04646534, -0.06630393],\n",
       "         [-0.02675333, -0.01044844,  0.01629238, ..., -0.02259798,\n",
       "          -0.00790832, -0.05486739],\n",
       "         [ 0.01214706,  0.02954725,  0.02558301, ...,  0.02377497,\n",
       "           0.00849482,  0.01912230],\n",
       "         ...,\n",
       "         [-0.02115771,  0.02560355,  0.01364876, ..., -0.01437963,\n",
       "           0.01070235, -0.02626784],\n",
       "         [-0.03823279, -0.01658314, -0.03770531, ..., -0.00202341,\n",
       "          -0.01240054,  0.01952831],\n",
       "         [-0.05002473, -0.02236416, -0.00600924, ...,  0.04451240,\n",
       "          -0.00663294, -0.03250650]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02776493, -0.01159485,  0.01236673, ...,  0.01444550,\n",
       "         -0.00486983,  0.00622440]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01846154, -0.00933932, -0.00018446, ...,  0.00239128,\n",
       "          -0.01921554, -0.02111529],\n",
       "         [ 0.02620279, -0.05159651, -0.00737029, ..., -0.04215209,\n",
       "           0.00029756,  0.02641732],\n",
       "         [ 0.04876318, -0.03095562,  0.01008690, ..., -0.00549633,\n",
       "          -0.03008938,  0.00908185],\n",
       "         ...,\n",
       "         [-0.03375439,  0.03316411, -0.01192684, ..., -0.00072493,\n",
       "          -0.01412632,  0.00021574],\n",
       "         [ 0.00228417,  0.03305425,  0.00174955, ..., -0.02817081,\n",
       "          -0.00398868,  0.01020736],\n",
       "         [ 0.02662574,  0.05463562, -0.00532984, ...,  0.01511543,\n",
       "          -0.00239537, -0.00018984]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.00540265, 0.00797991, 0.01923662, ..., 0.00891241, 0.00023567,\n",
       "         0.01341840]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.06274951,  0.07945332,  0.01841965, ...,  0.00071781,\n",
       "          -0.01624047,  0.01519056],\n",
       "         [ 0.01946210,  0.04991865,  0.01342262, ..., -0.00150899,\n",
       "          -0.01514412, -0.05370376],\n",
       "         [-0.08389179, -0.00409128,  0.02583046, ..., -0.00630115,\n",
       "           0.01170153, -0.04897782],\n",
       "         ...,\n",
       "         [-0.01145833, -0.03542885, -0.02991717, ..., -0.06116323,\n",
       "          -0.00308339, -0.00709347],\n",
       "         [ 0.06712300, -0.01133221, -0.00466776, ...,  0.01848467,\n",
       "          -0.02978520,  0.04790524],\n",
       "         [-0.01879886,  0.00273317, -0.00546179, ..., -0.02453848,\n",
       "           0.03832638, -0.00988463]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07938340, -0.06882890, -0.07691643, ..., -0.08104044,\n",
       "         -0.08440261, -0.08572096]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03470201, -0.05260455, -0.04447336, ..., -0.03178011,\n",
       "           0.03011216, -0.03662116],\n",
       "         [-0.05368047, -0.03558556,  0.03997234, ..., -0.00015956,\n",
       "          -0.02064098, -0.02471938],\n",
       "         [ 0.02492116,  0.02381684,  0.00684353, ...,  0.02712832,\n",
       "          -0.01779800, -0.02172330],\n",
       "         ...,\n",
       "         [ 0.05024826,  0.04659495,  0.06002700, ...,  0.00340735,\n",
       "           0.06516857,  0.01262121],\n",
       "         [-0.02835732, -0.02864577, -0.03120079, ...,  0.00182518,\n",
       "          -0.00962498,  0.03676590],\n",
       "         [ 0.01314224, -0.04077450,  0.03353657, ...,  0.01628619,\n",
       "           0.06126010,  0.03370872]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01547550,  0.05088839, -0.09637531, ...,  0.02647132,\n",
       "          0.02451104,  0.00769149]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91191322, 0.93411732, 0.99803013, ..., 0.94340795, 0.97544813,\n",
       "         0.90677744]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01603062, -0.16368960,  0.30049410, ...,  0.19713347,\n",
       "         -0.11984175,  0.08528440]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.88125497, 0.87915331, 0.85574061, ..., 0.88464046, 0.93392831,\n",
       "         0.86438161]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01618820,  0.05847332, -0.15155785, ..., -0.08062353,\n",
       "          0.08913953, -0.07354490]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00157293, -0.00919670,  0.02316195, ..., -0.02586107,\n",
       "           0.00221984, -0.02844881],\n",
       "         [ 0.07217497,  0.00399537,  0.00198101, ...,  0.01955234,\n",
       "          -0.02509576,  0.01195180],\n",
       "         [-0.04352979, -0.03020961, -0.04771511, ...,  0.00941115,\n",
       "           0.03678621,  0.02204640],\n",
       "         ...,\n",
       "         [-0.02108434,  0.03036138, -0.08341632, ...,  0.00337365,\n",
       "          -0.02927054,  0.00612737],\n",
       "         [-0.03147095, -0.01484789, -0.00764524, ...,  0.00569905,\n",
       "           0.03656472,  0.03373765],\n",
       "         [ 0.01699593,  0.05646973,  0.02555868, ..., -0.01874749,\n",
       "          -0.04172605, -0.00816155]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.15114419,  0.02228342,  0.38863695, ..., -0.02933374,\n",
       "          0.02248969, -0.07453002]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03970274,  0.03941768, -0.04736079, ...,  0.01707669,\n",
       "           0.02941790, -0.02698554],\n",
       "         [-0.03640243,  0.02217175,  0.00356769, ...,  0.03189336,\n",
       "          -0.00551184,  0.01844998],\n",
       "         [-0.00642844,  0.05800490,  0.00376029, ...,  0.00035130,\n",
       "           0.01985555,  0.04970741],\n",
       "         ...,\n",
       "         [-0.03453929, -0.01418229,  0.02443701, ..., -0.01154108,\n",
       "           0.04819652, -0.00380773],\n",
       "         [-0.03035449,  0.03613230, -0.03852251, ...,  0.00947247,\n",
       "           0.04085252,  0.03174260],\n",
       "         [-0.02383949, -0.01903046,  0.00943120, ...,  0.00541140,\n",
       "          -0.03444140,  0.01285043]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03306497, -0.04503963, -0.14246160, ...,  0.08947761,\n",
       "         -0.24728721,  0.06221331]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00273741,  0.01057714, -0.00033084, ...,  0.01444882,\n",
       "           0.01278752, -0.05431376],\n",
       "         [-0.06865352, -0.00734325,  0.01103945, ...,  0.01643217,\n",
       "          -0.07316630,  0.01969923],\n",
       "         [-0.00029593, -0.02500195, -0.01467490, ..., -0.02106159,\n",
       "           0.03492881, -0.00821112],\n",
       "         ...,\n",
       "         [-0.01294938,  0.02351945, -0.04695211, ...,  0.00275432,\n",
       "           0.02176201, -0.01409444],\n",
       "         [-0.02640696,  0.02415003, -0.00350878, ..., -0.01196201,\n",
       "           0.03261710, -0.00854834],\n",
       "         [ 0.00806285,  0.05429538,  0.02819853, ...,  0.01115885,\n",
       "           0.00243138,  0.03154756]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00671151,  0.00962553, -0.01803264, ...,  0.00024183,\n",
       "          0.01726011, -0.00309892]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03057409,  0.00288410,  0.05503271, ..., -0.05259801,\n",
       "           0.00897779,  0.04371420],\n",
       "         [ 0.02426711, -0.03052107,  0.03813267, ...,  0.03410167,\n",
       "          -0.03283604,  0.02833686],\n",
       "         [ 0.00581202, -0.03689761,  0.00679113, ...,  0.05074934,\n",
       "           0.02037095, -0.01019448],\n",
       "         ...,\n",
       "         [-0.01529931, -0.01230513, -0.02368005, ..., -0.00295667,\n",
       "           0.01251606, -0.02217311],\n",
       "         [ 0.02589613,  0.05019986, -0.02822282, ..., -0.01683327,\n",
       "          -0.02610164, -0.02757811],\n",
       "         [ 0.03259980, -0.01032188, -0.01849872, ...,  0.04238397,\n",
       "          -0.02228330,  0.00832932]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02026185,  0.02259838, -0.03171751, ...,  0.00101787,\n",
       "          0.00326002, -0.00759901]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01967999, -0.01924593,  0.02115881, ..., -0.06213649,\n",
       "          -0.01357924, -0.01102766],\n",
       "         [ 0.03137554,  0.00847778, -0.00023171, ...,  0.05535764,\n",
       "          -0.01340695,  0.10149105],\n",
       "         [ 0.05144629,  0.03077440, -0.01189708, ..., -0.01683447,\n",
       "           0.00008508, -0.00787574],\n",
       "         ...,\n",
       "         [-0.00706644, -0.03313646, -0.00958033, ...,  0.05701672,\n",
       "           0.01072607, -0.08097999],\n",
       "         [-0.00315071, -0.05312120,  0.02053762, ..., -0.01838971,\n",
       "           0.03492430,  0.09252689],\n",
       "         [-0.00336040, -0.01974069, -0.05228163, ..., -0.03990323,\n",
       "          -0.00152468, -0.00931251]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07401050, -0.07944326, -0.07633644, ..., -0.07434979,\n",
       "         -0.07115524, -0.07251805]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01071096, -0.02416724,  0.05032096, ..., -0.02705188,\n",
       "           0.01821935, -0.00250545],\n",
       "         [ 0.02228972,  0.00260459, -0.00322227, ...,  0.02111405,\n",
       "           0.04377576,  0.03020870],\n",
       "         [-0.01003814, -0.03121179,  0.00379972, ..., -0.07297442,\n",
       "          -0.04597769, -0.01309117],\n",
       "         ...,\n",
       "         [-0.00739180,  0.00699421, -0.00305540, ...,  0.09038488,\n",
       "           0.00807337,  0.03056293],\n",
       "         [ 0.01126506, -0.02593007, -0.03024018, ...,  0.01886912,\n",
       "          -0.02564907, -0.10041679],\n",
       "         [ 0.06130797,  0.10068315,  0.00156788, ..., -0.03887399,\n",
       "           0.00685058,  0.03200207]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00600650,  0.02959985, -0.07967660, ..., -0.00303168,\n",
       "         -0.00271580,  0.01661421]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90274310, 0.91616261, 0.96558905, ..., 0.92534983, 0.96804565,\n",
       "         0.88593072]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.07622778, -0.08663688,  0.27097580, ...,  0.16289634,\n",
       "         -0.04972670,  0.04509988]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.92892021, 0.94467449, 0.90503240, ..., 0.94718474, 1.00924659,\n",
       "         0.89064205]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06803160,  0.01651326, -0.16759479, ..., -0.12379067,\n",
       "          0.03936218, -0.06018992]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01645944, -0.00110132,  0.05721267, ...,  0.05670338,\n",
       "          -0.06143757,  0.02116298],\n",
       "         [ 0.05318939, -0.03424661,  0.09107473, ...,  0.00643509,\n",
       "           0.00739091, -0.03052291],\n",
       "         [ 0.00468693, -0.00649137,  0.01642319, ..., -0.03139646,\n",
       "           0.00863562,  0.03216072],\n",
       "         ...,\n",
       "         [-0.01039603,  0.06248394, -0.04222773, ...,  0.03824140,\n",
       "          -0.05030216,  0.00569024],\n",
       "         [-0.03975552, -0.07758250, -0.07925245, ..., -0.01805571,\n",
       "          -0.00660537, -0.01689503],\n",
       "         [-0.01594931,  0.02639727, -0.02701537, ..., -0.01993499,\n",
       "           0.03915585,  0.03943383]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04268955,  0.05650680,  0.05244983, ..., -0.19362609,\n",
       "          0.17445718, -0.35739923]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02392326,  0.03431656, -0.02542036, ..., -0.02779382,\n",
       "          -0.00686012,  0.00940440],\n",
       "         [-0.01772851, -0.04785739,  0.03712868, ..., -0.06415392,\n",
       "           0.00061310,  0.03076429],\n",
       "         [-0.00747574, -0.01553644, -0.07458159, ...,  0.04315230,\n",
       "          -0.05826787, -0.03647881],\n",
       "         ...,\n",
       "         [ 0.01411521,  0.02083189, -0.00797381, ...,  0.03179837,\n",
       "          -0.04297044, -0.00930720],\n",
       "         [-0.01045043, -0.04763203, -0.03988822, ...,  0.04822677,\n",
       "          -0.00701360,  0.00809740],\n",
       "         [-0.07130782,  0.01839141, -0.01913642, ..., -0.01396398,\n",
       "           0.02308682,  0.00611761]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.16321389, 0.18277295, 0.13306667, ..., 0.08990461, 0.00612404,\n",
       "         0.12486146]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02887514, -0.02687941,  0.04084717, ..., -0.01557303,\n",
       "           0.00383468,  0.00120676],\n",
       "         [-0.04774381, -0.01658677,  0.03232097, ...,  0.01392105,\n",
       "          -0.00183351,  0.01508192],\n",
       "         [-0.00093641,  0.00916918,  0.01638475, ..., -0.01464381,\n",
       "           0.02555167, -0.00514208],\n",
       "         ...,\n",
       "         [-0.00363764, -0.00256591,  0.04734938, ..., -0.00079785,\n",
       "           0.01646860,  0.02638915],\n",
       "         [-0.02575078,  0.00965003, -0.00521169, ...,  0.00611917,\n",
       "          -0.01035122, -0.00398822],\n",
       "         [-0.00520922,  0.00845477, -0.02362891, ..., -0.00916659,\n",
       "           0.03502503,  0.02816184]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.04719294,  0.02256671, -0.04648663, ..., -0.02889640,\n",
       "          0.01894476, -0.03040775]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00036346,  0.03867693, -0.00994973, ..., -0.00533597,\n",
       "           0.00503491, -0.00064666],\n",
       "         [ 0.01210742,  0.00440368, -0.04292953, ..., -0.02012360,\n",
       "          -0.03123745, -0.00246394],\n",
       "         [-0.01813881,  0.01176577, -0.03717897, ..., -0.03100852,\n",
       "           0.01185451,  0.00062346],\n",
       "         ...,\n",
       "         [ 0.01335914, -0.00541817,  0.02331955, ...,  0.00249005,\n",
       "           0.01920649, -0.00121260],\n",
       "         [ 0.01771336,  0.02870254, -0.03662108, ..., -0.02125874,\n",
       "          -0.00322677, -0.03666488],\n",
       "         [-0.01439105, -0.02305350,  0.00505187, ..., -0.03951306,\n",
       "          -0.00405833,  0.00889138]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00538653,  0.06317894, -0.03332582, ...,  0.07348315,\n",
       "         -0.04315170,  0.01434789]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01178819, -0.00858479, -0.00073724, ...,  0.00652279,\n",
       "           0.01677707, -0.07026646],\n",
       "         [ 0.04999716, -0.00432978, -0.00130038, ...,  0.03508716,\n",
       "           0.06152343, -0.04349520],\n",
       "         [-0.04266846,  0.01090301, -0.01094845, ..., -0.08525597,\n",
       "          -0.01653429, -0.05135628],\n",
       "         ...,\n",
       "         [ 0.04347723, -0.00037765, -0.01453897, ..., -0.02203736,\n",
       "          -0.01500141, -0.03166359],\n",
       "         [ 0.07192465,  0.00518894,  0.02059537, ...,  0.05330819,\n",
       "          -0.03862457, -0.02257478],\n",
       "         [-0.10213202, -0.03999119, -0.02616260, ...,  0.03343614,\n",
       "          -0.01168538, -0.00089295]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06283313, -0.02014690, -0.06207281, ..., -0.08467185,\n",
       "         -0.03116783, -0.07859302]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02341543, -0.00959854,  0.03718600, ..., -0.03377881,\n",
       "           0.00430652,  0.01227375],\n",
       "         [-0.02028036,  0.00512765,  0.04090320, ..., -0.00941237,\n",
       "          -0.01393618, -0.04612345],\n",
       "         [ 0.01890693,  0.00277378, -0.01164173, ..., -0.00900125,\n",
       "          -0.00750561, -0.03741794],\n",
       "         ...,\n",
       "         [-0.02670656,  0.01047785,  0.00077236, ...,  0.02052538,\n",
       "          -0.03162083, -0.05138053],\n",
       "         [-0.04544141, -0.03254434, -0.01646158, ...,  0.04742010,\n",
       "           0.01332909, -0.00703640],\n",
       "         [ 0.05472232, -0.00991647, -0.06255425, ...,  0.03295298,\n",
       "          -0.01430349,  0.06298971]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00768524, -0.00194863, -0.08029662, ..., -0.02544526,\n",
       "         -0.02473851,  0.05475409]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91041684, 0.92900145, 0.97243261, ..., 0.93199694, 0.95929790,\n",
       "         0.89136618]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03303102, -0.11742736,  0.23878746, ...,  0.11082016,\n",
       "          0.01158008, -0.01431019]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.94030493, 0.92569721, 0.88540763, ..., 0.93776667, 1.01090598,\n",
       "         0.88787633]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01157150,  0.03227582, -0.15525828, ..., -0.09141754,\n",
       "          0.02257527, -0.04913119]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04914455,  0.02481384, -0.04185954, ..., -0.01431483,\n",
       "           0.00240387, -0.02987926],\n",
       "         [ 0.00895251,  0.02411813, -0.00380282, ..., -0.01308491,\n",
       "          -0.00476777,  0.03696501],\n",
       "         [-0.03081588,  0.00990691, -0.00067603, ...,  0.00895613,\n",
       "           0.02553022, -0.00123565],\n",
       "         ...,\n",
       "         [-0.03426886, -0.02877931, -0.02318949, ...,  0.01261354,\n",
       "          -0.04045613,  0.02592612],\n",
       "         [ 0.02864576,  0.00667046,  0.03126473, ..., -0.00059500,\n",
       "           0.02955478,  0.02852032],\n",
       "         [ 0.02361967, -0.01802609,  0.00233899, ...,  0.05236093,\n",
       "           0.00091933,  0.00729866]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00427256,  0.01770321,  0.02901169, ..., -0.00696510,\n",
       "         -0.06042413, -0.05172079]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03230345, -0.04086738, -0.00520857, ..., -0.01386861,\n",
       "           0.00085905, -0.01966209],\n",
       "         [ 0.01500539, -0.00582238, -0.02343191, ..., -0.02277756,\n",
       "          -0.01935237, -0.02127424],\n",
       "         [-0.02275254,  0.01338232,  0.00258984, ...,  0.00481220,\n",
       "           0.04196810, -0.04703217],\n",
       "         ...,\n",
       "         [ 0.06220374,  0.04789198,  0.00203325, ...,  0.03317720,\n",
       "           0.05502317, -0.02984311],\n",
       "         [ 0.00805228, -0.01488882,  0.01130398, ..., -0.01035870,\n",
       "           0.05179714,  0.01815714],\n",
       "         [ 0.05637969, -0.01174146, -0.02351759, ..., -0.03319816,\n",
       "          -0.00134980,  0.02490211]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.10861035,  0.24191169,  0.34863511, ..., -0.07710074,\n",
       "         -0.06742996, -0.49149805]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01764765,  0.05311744,  0.01238860, ...,  0.00053928,\n",
       "           0.00791885, -0.00777203],\n",
       "         [ 0.01126399,  0.00358806, -0.01449637, ...,  0.06234708,\n",
       "           0.06112702,  0.03390437],\n",
       "         [ 0.00884905,  0.00032051, -0.01748706, ..., -0.04366452,\n",
       "           0.02947392,  0.01879255],\n",
       "         ...,\n",
       "         [-0.01807507,  0.00551250, -0.02997680, ..., -0.01501716,\n",
       "           0.00036944, -0.01395639],\n",
       "         [ 0.00267371,  0.01363740,  0.02186996, ...,  0.01158929,\n",
       "          -0.00226137, -0.00498831],\n",
       "         [ 0.01768754, -0.00601523,  0.02679238, ...,  0.04205087,\n",
       "          -0.01140830,  0.01933147]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00694902, -0.01260735,  0.03413962, ...,  0.01206533,\n",
       "          0.00436168, -0.01765770]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00891095,  0.00343766, -0.01430287, ..., -0.00437912,\n",
       "           0.02044433,  0.02046243],\n",
       "         [-0.01300011,  0.03379876,  0.01729446, ..., -0.03567056,\n",
       "           0.01702907,  0.00110346],\n",
       "         [ 0.02335511, -0.03785004,  0.03499012, ..., -0.00932552,\n",
       "           0.01169709, -0.01187002],\n",
       "         ...,\n",
       "         [-0.03080001,  0.00407373,  0.00275953, ...,  0.00471949,\n",
       "          -0.01792369,  0.01248472],\n",
       "         [ 0.00991338, -0.01064032,  0.00841515, ...,  0.02605110,\n",
       "          -0.02267374,  0.03234264],\n",
       "         [-0.00398178, -0.04027536, -0.00800358, ..., -0.05718777,\n",
       "           0.01945242,  0.00638092]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00466047, -0.00325754,  0.01552474, ..., -0.00622418,\n",
       "          0.00892059,  0.10920756]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05477000, -0.02088392, -0.05706711, ...,  0.01369629,\n",
       "          -0.00624509, -0.06516023],\n",
       "         [-0.00585976,  0.04927057, -0.00126941, ...,  0.01173862,\n",
       "           0.01623367,  0.03284916],\n",
       "         [-0.03101115,  0.01946129,  0.02731403, ...,  0.00911041,\n",
       "          -0.04180754,  0.02981427],\n",
       "         ...,\n",
       "         [ 0.02838359,  0.01379003, -0.07243607, ...,  0.04156595,\n",
       "          -0.02366978,  0.01026506],\n",
       "         [-0.02429375,  0.01146780, -0.02320224, ...,  0.04603010,\n",
       "           0.01249264, -0.05262753],\n",
       "         [-0.01341172, -0.00363162,  0.04133292, ...,  0.03193299,\n",
       "          -0.01942892, -0.04265017]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.09110897, -0.08223435, -0.07207403, ...,  0.00938086,\n",
       "          0.03468283, -0.02931571]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05986182,  0.02804859, -0.04116379, ...,  0.01490304,\n",
       "           0.00311553, -0.04326749],\n",
       "         [-0.01836013,  0.05751385,  0.02399960, ...,  0.01852573,\n",
       "          -0.02068319,  0.03313210],\n",
       "         [ 0.00957355,  0.02570712,  0.00239368, ...,  0.00440887,\n",
       "           0.03556174,  0.01934461],\n",
       "         ...,\n",
       "         [-0.03976499,  0.07409966,  0.01713257, ...,  0.02165014,\n",
       "           0.03369028,  0.06084331],\n",
       "         [-0.04402779,  0.00643101,  0.01413611, ...,  0.03178599,\n",
       "           0.02190585,  0.04666542],\n",
       "         [ 0.00986791, -0.06544518,  0.02017365, ...,  0.00849102,\n",
       "          -0.00582980,  0.03534719]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02279478,  0.03358344, -0.03583237, ...,  0.02508860,\n",
       "         -0.07104435,  0.06592368]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.91363966, 0.90465671, 0.92790288, ..., 0.94004893, 0.94849735,\n",
       "         0.88802880]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02926966, -0.10560635,  0.17815672, ...,  0.15558781,\n",
       "          0.06121523, -0.06644358]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90946883, 0.91726625, 0.90760428, ..., 0.92126721, 0.98054278,\n",
       "         0.89457297]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00406428,  0.03929247, -0.06246166, ..., -0.05230488,\n",
       "          0.00197186,  0.01944300]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03538308,  0.01018057, -0.01251241, ...,  0.01073656,\n",
       "          -0.08388323, -0.01430826],\n",
       "         [ 0.01896496, -0.01782219, -0.02333739, ..., -0.00073895,\n",
       "           0.05531346,  0.03633278],\n",
       "         [-0.03783100, -0.01645574, -0.03033436, ...,  0.02219100,\n",
       "           0.01046022, -0.01295591],\n",
       "         ...,\n",
       "         [-0.00950601,  0.00143231, -0.03729945, ...,  0.01433766,\n",
       "          -0.02161212,  0.00798458],\n",
       "         [ 0.02040522, -0.00803297, -0.00770934, ...,  0.02340165,\n",
       "          -0.01210863, -0.01093119],\n",
       "         [-0.01261359, -0.01729089,  0.01467079, ..., -0.00609337,\n",
       "          -0.00367250,  0.04830111]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02688649, -0.14536770,  0.18096966, ...,  0.11206455,\n",
       "         -0.03406007,  0.02992524]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03197132, -0.04858785, -0.00798439, ...,  0.06775092,\n",
       "          -0.03077757, -0.01798019],\n",
       "         [ 0.02210682,  0.03439195,  0.03176307, ...,  0.00560363,\n",
       "           0.01271306, -0.01674884],\n",
       "         [-0.01796863,  0.02465871,  0.02027617, ..., -0.01325801,\n",
       "          -0.03810804,  0.04478473],\n",
       "         ...,\n",
       "         [ 0.04419782,  0.02703919,  0.03916579, ...,  0.00621506,\n",
       "          -0.01454278, -0.07832742],\n",
       "         [-0.03818258, -0.00868636,  0.03360559, ..., -0.04451760,\n",
       "          -0.07124975, -0.00262361],\n",
       "         [ 0.02086318,  0.02943123, -0.03169481, ..., -0.01251203,\n",
       "          -0.01960608,  0.04419363]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08861177,  0.02036802,  0.15411504, ...,  0.09790452,\n",
       "         -0.29928333,  0.00132499]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04805978,  0.01980548,  0.07689622, ...,  0.05275806,\n",
       "           0.01207626, -0.02179280],\n",
       "         [-0.00125577, -0.07469635, -0.06302358, ..., -0.05653621,\n",
       "           0.02765130,  0.02694579],\n",
       "         [ 0.00725264,  0.00693710,  0.00598896, ...,  0.00213343,\n",
       "           0.03544633,  0.01788708],\n",
       "         ...,\n",
       "         [ 0.00571834, -0.02812434,  0.01447497, ...,  0.04494910,\n",
       "          -0.02982744, -0.08320878],\n",
       "         [-0.02461279,  0.01824461,  0.02250403, ...,  0.02345819,\n",
       "           0.07024187,  0.04168170],\n",
       "         [ 0.02222569,  0.00048392, -0.01645726, ...,  0.02760743,\n",
       "          -0.03289435, -0.03795275]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00771586,  0.00304864, -0.01058285, ..., -0.00071838,\n",
       "          0.01253403,  0.00010490]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01362179, -0.01228201,  0.02945867, ...,  0.03951726,\n",
       "           0.06178520,  0.01086211],\n",
       "         [ 0.01601996,  0.00176369,  0.03269286, ..., -0.00513804,\n",
       "          -0.02994656,  0.00323572],\n",
       "         [-0.05944305,  0.05366262,  0.00678045, ...,  0.02546630,\n",
       "           0.01577497,  0.01398287],\n",
       "         ...,\n",
       "         [-0.00437649, -0.00169571, -0.06423540, ...,  0.01780980,\n",
       "           0.03987381, -0.02634483],\n",
       "         [ 0.01727470, -0.04313487,  0.04264866, ...,  0.01469304,\n",
       "          -0.01814170, -0.02711133],\n",
       "         [-0.02389555,  0.00805750,  0.02149708, ..., -0.00676353,\n",
       "           0.00285572,  0.06383098]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02662213, -0.08740468, -0.00331191, ...,  0.08682272,\n",
       "         -0.01374793,  0.03058601]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01915744, -0.00411907, -0.01125680, ...,  0.00833294,\n",
       "          -0.07426554, -0.02673411],\n",
       "         [ 0.02079125, -0.00414610,  0.03645442, ..., -0.00069318,\n",
       "          -0.00318838,  0.02645848],\n",
       "         [ 0.03058129, -0.03576641,  0.01357151, ...,  0.02692423,\n",
       "           0.05012881, -0.02250883],\n",
       "         ...,\n",
       "         [-0.01137183, -0.03744521,  0.04163112, ..., -0.00817413,\n",
       "          -0.00710329, -0.00221190],\n",
       "         [ 0.03925821,  0.02364125, -0.03110881, ...,  0.02774203,\n",
       "          -0.02100562,  0.00539468],\n",
       "         [-0.01228705, -0.02692647,  0.02303310, ...,  0.04659699,\n",
       "          -0.00763856, -0.02319642]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07777014, -0.02577599, -0.05460755, ..., -0.08819459,\n",
       "         -0.07305256, -0.09653366]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01427169,  0.01315905,  0.02187943, ...,  0.02795485,\n",
       "          -0.02512600,  0.00469289],\n",
       "         [ 0.04137782,  0.02893962,  0.04644689, ..., -0.02909283,\n",
       "          -0.01957322,  0.01237540],\n",
       "         [-0.00958222,  0.01093161, -0.02297383, ...,  0.00152503,\n",
       "          -0.02026521, -0.01345396],\n",
       "         ...,\n",
       "         [-0.01778005,  0.05638054, -0.01815024, ...,  0.00076212,\n",
       "           0.00094645,  0.01440251],\n",
       "         [ 0.01670219,  0.02210589, -0.02048748, ..., -0.00623645,\n",
       "          -0.01684329, -0.06787483],\n",
       "         [-0.05446017, -0.05345682,  0.00473014, ..., -0.02658066,\n",
       "           0.01558983,  0.07064301]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02312165,  0.00322920, -0.00645101, ...,  0.03040004,\n",
       "         -0.05707321,  0.04406023]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90788680, 0.90355569, 0.91523618, ..., 0.92875504, 0.95141250,\n",
       "         0.87363231]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02602037, -0.07180270,  0.09320769, ...,  0.08954467,\n",
       "          0.06064738,  0.01407709]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.89134812, 0.89967889, 0.89376909, ..., 0.91330904, 0.96290195,\n",
       "         0.85717756]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01046764, -0.00377135, -0.02940233, ..., -0.04233900,\n",
       "         -0.02097282, -0.01970338]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00386459,  0.01617385, -0.02247608, ...,  0.01372136,\n",
       "          -0.08997398,  0.06247601],\n",
       "         [-0.01904178, -0.03591531,  0.03665331, ...,  0.00892878,\n",
       "           0.08186270,  0.10515185],\n",
       "         [ 0.00059213,  0.00878551, -0.08889096, ...,  0.07396272,\n",
       "          -0.09052765, -0.00277337],\n",
       "         ...,\n",
       "         [-0.00792000, -0.00528079,  0.00151087, ..., -0.05280887,\n",
       "           0.10651544, -0.03912970],\n",
       "         [-0.05079252, -0.04313026, -0.07054727, ..., -0.01825853,\n",
       "          -0.04112098,  0.02779458],\n",
       "         [ 0.02814453, -0.00452590,  0.07116905, ..., -0.02289633,\n",
       "           0.06878462, -0.01122809]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11378269,  0.03080056,  0.11700400, ..., -0.02067091,\n",
       "         -0.04918093,  0.00466941]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05513529, -0.01902248,  0.03439472, ..., -0.08734810,\n",
       "           0.01004401, -0.02954047],\n",
       "         [-0.04421583,  0.07797311, -0.02319006, ...,  0.00114298,\n",
       "          -0.00192046, -0.01077057],\n",
       "         [-0.00755303, -0.04602458,  0.02093693, ...,  0.00051806,\n",
       "          -0.02092226,  0.08345028],\n",
       "         ...,\n",
       "         [-0.03515130,  0.00670630, -0.04985934, ..., -0.02868390,\n",
       "           0.01072811,  0.03132531],\n",
       "         [-0.01074285,  0.08735020,  0.03146072, ..., -0.04457564,\n",
       "          -0.01583859,  0.02869688],\n",
       "         [-0.01723269, -0.00706636,  0.03469196, ...,  0.01455405,\n",
       "          -0.01904934, -0.00848046]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00032046, -0.01594060,  0.03150896, ...,  0.04255866,\n",
       "          0.07266828,  0.17110194]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02524042, -0.01156613, -0.03102603, ...,  0.00633657,\n",
       "          -0.00710327,  0.00088418],\n",
       "         [ 0.01891261, -0.02133663,  0.03108322, ...,  0.02220915,\n",
       "           0.01325203, -0.01371997],\n",
       "         [-0.05520946,  0.06507695,  0.00684695, ...,  0.00432709,\n",
       "           0.00943187,  0.03131051],\n",
       "         ...,\n",
       "         [ 0.01063357, -0.01432649, -0.04701619, ...,  0.00882386,\n",
       "          -0.02744542, -0.00031725],\n",
       "         [-0.01568667,  0.00701148, -0.00544578, ..., -0.02983680,\n",
       "           0.00541605,  0.00833206],\n",
       "         [-0.00256457,  0.00458861,  0.03443707, ..., -0.00973082,\n",
       "           0.04205228, -0.01484039]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01232762,  0.01992843,  0.00329195, ...,  0.00420778,\n",
       "         -0.00574968,  0.08667539]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04615640,  0.01281291, -0.03866822, ..., -0.06109206,\n",
       "           0.02434283, -0.07182746],\n",
       "         [ 0.04398469,  0.03055700, -0.00874852, ...,  0.00003953,\n",
       "           0.00802639,  0.01216986],\n",
       "         [ 0.05045652, -0.00559819, -0.00347532, ...,  0.00644745,\n",
       "          -0.00214704,  0.03320580],\n",
       "         ...,\n",
       "         [-0.00288285, -0.00761148, -0.00951443, ..., -0.00649285,\n",
       "          -0.02826624,  0.00905112],\n",
       "         [-0.03540911,  0.02118564,  0.01698185, ..., -0.02052954,\n",
       "           0.00487551, -0.00077992],\n",
       "         [-0.00681161,  0.00237399, -0.01225946, ...,  0.01300215,\n",
       "           0.00087761, -0.01145677]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01715026, -0.04203990,  0.00139860, ..., -0.05901207,\n",
       "         -0.02252339,  0.10716650]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02396782,  0.01451411, -0.05181728, ...,  0.04699504,\n",
       "          -0.02610783, -0.02769667],\n",
       "         [ 0.01398061,  0.03564427,  0.00419557, ..., -0.02287082,\n",
       "           0.01658864, -0.02360392],\n",
       "         [-0.05237678,  0.05923977, -0.06549666, ..., -0.00959357,\n",
       "          -0.12796871,  0.00248267],\n",
       "         ...,\n",
       "         [-0.01182477, -0.02209351,  0.05464987, ..., -0.02026761,\n",
       "           0.04737367,  0.02360628],\n",
       "         [ 0.01203627,  0.01551853,  0.01651492, ..., -0.01516623,\n",
       "           0.02038913, -0.06470333],\n",
       "         [ 0.04425601,  0.02097624,  0.02647918, ..., -0.01142650,\n",
       "           0.00844620,  0.02416505]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07613230, -0.05756746, -0.08893313, ..., -0.04608973,\n",
       "         -0.10790805, -0.04605167]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04900569,  0.00422795, -0.03068528, ..., -0.02181638,\n",
       "           0.01244559, -0.02348805],\n",
       "         [ 0.02022150,  0.03219492,  0.00608654, ..., -0.01228870,\n",
       "           0.01271608,  0.00065512],\n",
       "         [ 0.01565040, -0.04344282,  0.07864422, ..., -0.03911450,\n",
       "           0.04770081, -0.00248255],\n",
       "         ...,\n",
       "         [ 0.00340492,  0.01309512, -0.03801236, ..., -0.02992273,\n",
       "           0.00534698,  0.05892901],\n",
       "         [ 0.01059243,  0.00601713, -0.07151075, ...,  0.01695063,\n",
       "          -0.00467405,  0.05191450],\n",
       "         [ 0.01024429, -0.03597855,  0.02645372, ...,  0.03255892,\n",
       "          -0.04917452, -0.02181352]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03326367, -0.00964120, -0.00633800, ..., -0.04283603,\n",
       "         -0.11842811,  0.03111336]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.89756298, 0.89123082, 0.90314639, ..., 0.92543739, 0.97821075,\n",
       "         0.85351938]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00936892, -0.04785558,  0.09253957, ...,  0.20781167,\n",
       "         -0.04065345, -0.08334860]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.85630471, 0.88069838, 0.86673933, ..., 0.87348843, 0.92974913,\n",
       "         0.84571487]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00975297,  0.00476136, -0.02483401, ..., -0.10593291,\n",
       "          0.00928201,  0.01711968]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00965272, -0.04250776,  0.04286716, ..., -0.07035988,\n",
       "          -0.01544900,  0.01090079],\n",
       "         [ 0.03248251, -0.01258503, -0.00399783, ..., -0.00329400,\n",
       "           0.01618955,  0.00706371],\n",
       "         [-0.01602150, -0.08455168, -0.02101744, ..., -0.01097917,\n",
       "           0.01932612,  0.02802197],\n",
       "         ...,\n",
       "         [ 0.05307091, -0.05537638, -0.05845071, ...,  0.00446768,\n",
       "          -0.03727963, -0.02543362],\n",
       "         [ 0.01574416,  0.02872995,  0.01970221, ...,  0.04533172,\n",
       "           0.01399978, -0.01854716],\n",
       "         [-0.00702682,  0.06231867, -0.01865251, ..., -0.01434674,\n",
       "           0.09243033,  0.04206719]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.08696913,  0.05382522, -0.02537982, ...,  0.10459639,\n",
       "         -0.06339618, -0.00632953]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01257013, -0.01818248, -0.02468867, ..., -0.06160270,\n",
       "          -0.00039322,  0.04248675],\n",
       "         [ 0.04628785, -0.02676297,  0.00525550, ...,  0.03481279,\n",
       "           0.02233996,  0.01365132],\n",
       "         [-0.04735937, -0.00301722, -0.03536402, ..., -0.01636937,\n",
       "          -0.04443841, -0.03044484],\n",
       "         ...,\n",
       "         [-0.02960213,  0.03438141,  0.01024313, ...,  0.00830206,\n",
       "          -0.01563803, -0.00427836],\n",
       "         [ 0.01943152,  0.01222918, -0.00084774, ..., -0.01270372,\n",
       "          -0.01114109,  0.05384707],\n",
       "         [-0.00329314,  0.02841735,  0.01400429, ...,  0.01747740,\n",
       "          -0.06720136,  0.03999337]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.37845913, -0.26668978, -0.32822454, ...,  0.12004040,\n",
       "         -0.25263330,  0.00465063]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01152014,  0.05623285, -0.01599250, ...,  0.00000309,\n",
       "           0.01970500,  0.00738411],\n",
       "         [-0.00700328,  0.04575947,  0.01232667, ...,  0.05671566,\n",
       "          -0.02119248,  0.03244673],\n",
       "         [-0.01957578,  0.03281967,  0.03176875, ..., -0.00143266,\n",
       "          -0.01153245, -0.00737897],\n",
       "         ...,\n",
       "         [-0.02126837, -0.04057017, -0.03724524, ...,  0.03581547,\n",
       "           0.03658266, -0.00566942],\n",
       "         [-0.01508931, -0.03457372, -0.04755278, ...,  0.00773972,\n",
       "          -0.01030966,  0.02231431],\n",
       "         [-0.03183440,  0.01739812,  0.05626680, ...,  0.02733516,\n",
       "          -0.00018490,  0.02853000]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01104302,  0.02621641, -0.00137250, ..., -0.00036582,\n",
       "         -0.03519859, -0.08571228]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00603982, -0.03404764, -0.01310442, ..., -0.00299937,\n",
       "          -0.02052747,  0.01527405],\n",
       "         [ 0.01142874, -0.02904579,  0.02788821, ...,  0.02271727,\n",
       "          -0.01006074, -0.02793089],\n",
       "         [-0.04719558, -0.01797715,  0.06327135, ..., -0.03996994,\n",
       "          -0.04400016, -0.00539443],\n",
       "         ...,\n",
       "         [ 0.00740639,  0.03507692,  0.02254636, ..., -0.00246577,\n",
       "          -0.02470388,  0.05933399],\n",
       "         [ 0.03067776,  0.01469063, -0.00469437, ..., -0.02019646,\n",
       "          -0.01299332, -0.01346829],\n",
       "         [ 0.02048670,  0.03073333, -0.01075032, ...,  0.02551979,\n",
       "           0.00201940,  0.03929907]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04351561, -0.01120257, -0.00835043, ..., -0.01812008,\n",
       "         -0.00430295,  0.05558858]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00371333, -0.03507373, -0.02270810, ..., -0.01407082,\n",
       "           0.00471978,  0.01042539],\n",
       "         [-0.02431703, -0.02915119,  0.01552758, ...,  0.00817508,\n",
       "          -0.01193655,  0.02075509],\n",
       "         [-0.02207215,  0.02721941, -0.00363961, ...,  0.00712708,\n",
       "           0.03197444, -0.00978914],\n",
       "         ...,\n",
       "         [ 0.00985953, -0.02873943, -0.04195756, ..., -0.03799156,\n",
       "          -0.02831369, -0.04502012],\n",
       "         [-0.00140197,  0.01405528, -0.00758565, ...,  0.00203092,\n",
       "           0.02715702,  0.04274823],\n",
       "         [ 0.00588775, -0.01352227,  0.01854353, ...,  0.07924407,\n",
       "           0.00873893, -0.04269660]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08765444, -0.03520038, -0.09954143, ..., -0.09838357,\n",
       "         -0.03140571, -0.04797393]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01135853, -0.01125981, -0.02049443, ..., -0.02044005,\n",
       "          -0.02259785,  0.00946043],\n",
       "         [ 0.00047928,  0.02316320,  0.03352047, ...,  0.00080685,\n",
       "          -0.03456743, -0.01328012],\n",
       "         [ 0.03248323, -0.03780395, -0.00064561, ...,  0.00530206,\n",
       "          -0.00955564,  0.06567828],\n",
       "         ...,\n",
       "         [-0.00630769,  0.01780460,  0.00466285, ..., -0.03277393,\n",
       "          -0.02644830, -0.00526384],\n",
       "         [ 0.01885011,  0.02148437, -0.01662028, ..., -0.00708767,\n",
       "          -0.00565544,  0.02053009],\n",
       "         [ 0.02477874,  0.01506358,  0.01116655, ..., -0.00708454,\n",
       "           0.00903334, -0.05275095]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.06804319,  0.00458962, -0.02376591, ..., -0.06011189,\n",
       "         -0.06606505,  0.02801540]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.85125744, 0.83661556, 0.87781388, ..., 0.87725216, 0.95085537,\n",
       "         0.81941146]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.05317911, -0.03591057,  0.20516017, ...,  0.13731937,\n",
       "         -0.12709275, -0.08215416]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.83814621, 0.87267637, 0.84304523, ..., 0.86259049, 0.88411707,\n",
       "         0.81235564]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02163494, -0.00694682, -0.05896046, ..., -0.06261682,\n",
       "          0.03949421,  0.04043249]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03501302,  0.03018858,  0.03661941, ...,  0.00978265,\n",
       "           0.03156612, -0.05476935],\n",
       "         [-0.00991837, -0.01240232, -0.01831995, ..., -0.07278183,\n",
       "          -0.04727258,  0.00756496],\n",
       "         [ 0.04968473, -0.01692480,  0.03120444, ..., -0.00158221,\n",
       "          -0.00065053,  0.01177268],\n",
       "         ...,\n",
       "         [-0.00429989,  0.08016504, -0.00157381, ...,  0.07861188,\n",
       "           0.00161727, -0.08953319],\n",
       "         [ 0.01631587, -0.01743088, -0.01715460, ...,  0.00338537,\n",
       "           0.03959005,  0.04060884],\n",
       "         [ 0.01759223, -0.06978279,  0.01469684, ..., -0.04216471,\n",
       "           0.03592831,  0.05522601]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06405069, -0.02417626, -0.05481341, ..., -0.09836054,\n",
       "          0.17045116, -0.01261259]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02682483, -0.02102753, -0.02122916, ...,  0.08531135,\n",
       "          -0.00486700, -0.02029982],\n",
       "         [-0.05505390,  0.01445113, -0.04614696, ..., -0.01527161,\n",
       "          -0.02722833, -0.06723098],\n",
       "         [ 0.04575438,  0.04732095, -0.03016899, ...,  0.05616719,\n",
       "          -0.00869686, -0.00728364],\n",
       "         ...,\n",
       "         [-0.02608656,  0.00967433, -0.01983025, ...,  0.04830708,\n",
       "           0.04546465, -0.12036934],\n",
       "         [ 0.04962548, -0.00230622,  0.04710546, ...,  0.01732818,\n",
       "          -0.00672474,  0.01740935],\n",
       "         [-0.03407332,  0.00805629, -0.03464381, ..., -0.04751915,\n",
       "           0.03246695, -0.07769530]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03388688, -0.04051855, -0.04556179, ..., -0.02194118,\n",
       "          0.50741053, -0.04417201]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04074572,  0.02452112, -0.02356214, ...,  0.00678051,\n",
       "           0.00833152,  0.00132719],\n",
       "         [ 0.02182884,  0.01177052, -0.02985753, ..., -0.01239609,\n",
       "          -0.01703457,  0.02303630],\n",
       "         [-0.01797504,  0.01877809,  0.04157995, ..., -0.01086351,\n",
       "          -0.00929779,  0.02847199],\n",
       "         ...,\n",
       "         [-0.00378595,  0.01563191,  0.03524701, ..., -0.01426530,\n",
       "          -0.02716791,  0.01697749],\n",
       "         [ 0.00440138,  0.04618808, -0.03069574, ...,  0.00842788,\n",
       "          -0.01815901,  0.00045163],\n",
       "         [-0.02795562,  0.02384343,  0.00522414, ...,  0.04911107,\n",
       "           0.03808799,  0.01670834]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01440641,  0.01882312,  0.01136947, ..., -0.01003689,\n",
       "         -0.02269474,  0.04307024]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02655586, -0.00419396, -0.00366827, ...,  0.01998603,\n",
       "           0.00128623, -0.00327743],\n",
       "         [-0.02765294, -0.01796063, -0.00071650, ..., -0.01154523,\n",
       "           0.03113903, -0.02873746],\n",
       "         [ 0.01832886,  0.02185817, -0.00231846, ...,  0.01587060,\n",
       "           0.02344335, -0.01574544],\n",
       "         ...,\n",
       "         [ 0.01015431,  0.01476849, -0.01995412, ...,  0.04166604,\n",
       "           0.02991275,  0.01794981],\n",
       "         [-0.04011801,  0.02862328,  0.03609057, ..., -0.01671811,\n",
       "           0.02445957,  0.03262664],\n",
       "         [ 0.00232651, -0.00397825, -0.02807488, ..., -0.03579476,\n",
       "          -0.02871077,  0.04463149]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00184202,  0.01740104, -0.02379120, ..., -0.04877727,\n",
       "         -0.01149200,  0.00486433]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01560514, -0.07074734,  0.00401732, ...,  0.03151118,\n",
       "          -0.04281141,  0.02095548],\n",
       "         [ 0.02900624,  0.01761520, -0.01271771, ...,  0.02165873,\n",
       "          -0.01454263, -0.02130512],\n",
       "         [-0.02874614, -0.01421616,  0.01998836, ..., -0.01432651,\n",
       "          -0.01426523, -0.06459422],\n",
       "         ...,\n",
       "         [ 0.01386392,  0.00470283,  0.05304631, ..., -0.00718123,\n",
       "          -0.00259860, -0.00562586],\n",
       "         [ 0.06367473, -0.00040412,  0.03144833, ...,  0.02592428,\n",
       "          -0.01065795,  0.01653275],\n",
       "         [-0.00051811,  0.03394159, -0.02675230, ..., -0.02314733,\n",
       "          -0.04600877,  0.04055053]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07166687, -0.06705162, -0.09168223, ..., -0.09513054,\n",
       "         -0.07075720, -0.02514962]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01737836, -0.03061024, -0.01810622, ...,  0.06711366,\n",
       "          -0.01013427,  0.04229106],\n",
       "         [-0.00097479,  0.05226351, -0.01040202, ..., -0.03365973,\n",
       "          -0.02798437, -0.02046109],\n",
       "         [ 0.00110942, -0.00398437,  0.02171407, ..., -0.03010242,\n",
       "          -0.00430890,  0.00398239],\n",
       "         ...,\n",
       "         [ 0.00684173, -0.02755071,  0.03107509, ...,  0.06758308,\n",
       "           0.03382513, -0.02514008],\n",
       "         [ 0.00908181, -0.00839121, -0.00202709, ..., -0.02983308,\n",
       "          -0.02324181,  0.02519940],\n",
       "         [-0.09471492, -0.01741084,  0.04127817, ..., -0.01897779,\n",
       "          -0.00321677, -0.04545220]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.06382248,  0.01359472,  0.06035831, ..., -0.04611046,\n",
       "         -0.03787510, -0.05942323]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.83227295, 0.78566849, 0.85186601, ..., 0.86272609, 0.90548235,\n",
       "         0.79008025]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04127667,  0.02449795,  0.08855628, ...,  0.16701108,\n",
       "         -0.06242691,  0.01168709]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.81552345, 0.82877934, 0.83005619, ..., 0.82822800, 0.86718851,\n",
       "         0.80979079]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00154104, -0.04134180, -0.01487346, ..., -0.07775601,\n",
       "          0.04180989, -0.00536759]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04423125, -0.00151888, -0.01126574, ...,  0.07257059,\n",
       "          -0.02731586, -0.02456619],\n",
       "         [-0.02418322,  0.05469523,  0.01023780, ...,  0.02766413,\n",
       "          -0.00464458, -0.00848151],\n",
       "         [ 0.00336447, -0.04425853,  0.01857498, ...,  0.03001507,\n",
       "          -0.10236237,  0.03463997],\n",
       "         ...,\n",
       "         [-0.00534850,  0.02664109, -0.00428324, ...,  0.08452880,\n",
       "          -0.02359630, -0.00000180],\n",
       "         [-0.01861485,  0.03166460, -0.04066400, ..., -0.02769537,\n",
       "           0.03144030,  0.02708971],\n",
       "         [ 0.00774314, -0.00251167, -0.02750039, ..., -0.01392423,\n",
       "          -0.02825489,  0.05495920]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.33438760, -0.08886781, -0.03985358, ..., -0.01868708,\n",
       "         -0.05548369, -0.05405370]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00182123,  0.01236733, -0.02858185, ..., -0.03517187,\n",
       "          -0.01965582, -0.03676076],\n",
       "         [-0.01077216, -0.00428648,  0.04745959, ..., -0.04770785,\n",
       "          -0.00210348,  0.01893924],\n",
       "         [-0.01836362, -0.00017704, -0.00198370, ..., -0.02253495,\n",
       "          -0.01137373, -0.03524133],\n",
       "         ...,\n",
       "         [-0.01733949, -0.05274817,  0.02939005, ..., -0.01916321,\n",
       "          -0.06586710,  0.02827992],\n",
       "         [ 0.02039657, -0.01061583,  0.03341808, ..., -0.01608117,\n",
       "          -0.04614154,  0.00198659],\n",
       "         [ 0.02724009,  0.00071526, -0.02531865, ..., -0.00126453,\n",
       "           0.00511679, -0.06094822]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.79127318, -0.24246405, -0.20169002, ...,  0.18240429,\n",
       "          0.35526103,  0.03698255]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00491615, -0.03080594, -0.02981225, ..., -0.02225260,\n",
       "           0.03037158,  0.03702299],\n",
       "         [ 0.00105535, -0.03788039, -0.03354237, ..., -0.06982581,\n",
       "          -0.00383314,  0.02625431],\n",
       "         [ 0.01029072, -0.02709830,  0.04471479, ...,  0.01364813,\n",
       "          -0.02132356,  0.00661882],\n",
       "         ...,\n",
       "         [ 0.04620373,  0.02750327,  0.03408290, ..., -0.01570438,\n",
       "           0.01136414,  0.01734974],\n",
       "         [-0.03133423, -0.03124071,  0.01998067, ..., -0.01298530,\n",
       "          -0.02539698,  0.01852605],\n",
       "         [-0.02767282,  0.00463605,  0.05343375, ...,  0.00698981,\n",
       "           0.03723275, -0.02948592]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00670949, -0.01044359, -0.01503056, ..., -0.00626838,\n",
       "          0.03070596,  0.00348521]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01082670, -0.01357937,  0.02926615, ..., -0.01806737,\n",
       "          -0.00684620,  0.01188189],\n",
       "         [ 0.05158196, -0.00309677, -0.02115460, ..., -0.00958940,\n",
       "          -0.03988238,  0.00488225],\n",
       "         [ 0.00142899, -0.03253089,  0.02257462, ...,  0.05963032,\n",
       "           0.00598024,  0.00139834],\n",
       "         ...,\n",
       "         [ 0.04573987,  0.06314626,  0.01091660, ...,  0.04094835,\n",
       "          -0.02678842,  0.00489575],\n",
       "         [-0.03794288,  0.03032201, -0.08366483, ..., -0.01775566,\n",
       "          -0.00268001,  0.00408508],\n",
       "         [-0.03037945, -0.02338426, -0.00836416, ...,  0.01118356,\n",
       "           0.00980688, -0.04226194]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01916768, -0.08479441, -0.01693613, ...,  0.00697711,\n",
       "          0.02763889,  0.04489803]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00493278,  0.00860743,  0.02146619, ...,  0.00755138,\n",
       "          -0.01114970, -0.00265486],\n",
       "         [-0.04707518,  0.01199722,  0.04373101, ...,  0.03851110,\n",
       "          -0.03277592, -0.05548808],\n",
       "         [-0.03550646,  0.01633752,  0.02633511, ...,  0.02536692,\n",
       "          -0.01626068, -0.00571390],\n",
       "         ...,\n",
       "         [-0.04670866, -0.03311056,  0.01754504, ..., -0.05454967,\n",
       "          -0.02990490,  0.04575456],\n",
       "         [-0.00476316,  0.06778333,  0.04692407, ..., -0.02667100,\n",
       "           0.01604428,  0.01045597],\n",
       "         [ 0.03792063,  0.00996544, -0.00563364, ..., -0.01489129,\n",
       "          -0.04790431, -0.00894779]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07646449, -0.04381498, -0.04581287, ..., -0.12114132,\n",
       "          0.04343056, -0.10187629]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01051717, -0.05248954, -0.01774766, ...,  0.03623617,\n",
       "           0.03551636, -0.04645526],\n",
       "         [-0.02314715,  0.02585163, -0.00046362, ...,  0.01071808,\n",
       "          -0.02663158,  0.01973964],\n",
       "         [ 0.04338614, -0.01422875, -0.00673010, ...,  0.01002315,\n",
       "          -0.01185504, -0.00862137],\n",
       "         ...,\n",
       "         [ 0.01370729,  0.00488407,  0.01317002, ..., -0.03905154,\n",
       "          -0.02418946,  0.03249823],\n",
       "         [-0.02773938,  0.04134684,  0.03159573, ...,  0.00983085,\n",
       "          -0.00291599,  0.07620097],\n",
       "         [ 0.00663495,  0.02995758, -0.00889535, ...,  0.01658533,\n",
       "           0.04972849, -0.02813218]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.07007521, -0.03559033,  0.04560965, ..., -0.01948885,\n",
       "         -0.02543823, -0.13664231]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.82434022, 0.78544354, 0.83526903, ..., 0.83437425, 0.87350929,\n",
       "         0.78547579]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04456886,  0.09612303,  0.12638158, ...,  0.15422824,\n",
       "         -0.06749882, -0.06645528]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.84761584, 0.81187952, 0.82797247, ..., 0.85667443, 0.87375271,\n",
       "         0.82506472]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00013303, -0.06655721, -0.06395419, ..., -0.10870118,\n",
       "          0.00681414, -0.01448914]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01643239, -0.04568006,  0.09076791, ..., -0.07201532,\n",
       "          -0.02555205, -0.01328370],\n",
       "         [ 0.03331817,  0.00737782, -0.04723993, ..., -0.02115668,\n",
       "           0.02761779,  0.02804940],\n",
       "         [-0.05783859,  0.03732198, -0.03245348, ...,  0.00610055,\n",
       "          -0.01598749,  0.00885971],\n",
       "         ...,\n",
       "         [-0.06791214, -0.00375145,  0.00578814, ...,  0.00092242,\n",
       "          -0.01720461, -0.01710955],\n",
       "         [ 0.01469791,  0.03140292,  0.03787631, ...,  0.04080474,\n",
       "          -0.04659537,  0.03443894],\n",
       "         [ 0.02304429,  0.00141112, -0.03521570, ...,  0.00944849,\n",
       "           0.00661875,  0.03195567]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11108135, -0.06332392,  0.18540806, ..., -0.07900699,\n",
       "         -0.04841046,  0.04822268]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00417305,  0.04214438,  0.03303008, ...,  0.06174722,\n",
       "           0.01772683,  0.04633475],\n",
       "         [-0.07954489,  0.01360427, -0.03725577, ...,  0.01377076,\n",
       "           0.00227653, -0.03514709],\n",
       "         [-0.04606032,  0.02169878, -0.06516036, ..., -0.02992056,\n",
       "           0.01206220,  0.00464405],\n",
       "         ...,\n",
       "         [-0.00272200,  0.01102498, -0.01917917, ..., -0.03564269,\n",
       "          -0.01614091,  0.04872894],\n",
       "         [-0.01543225, -0.06765483,  0.02609084, ..., -0.05143869,\n",
       "          -0.02422854, -0.00184570],\n",
       "         [ 0.01952955,  0.00828632,  0.00610266, ...,  0.01213272,\n",
       "          -0.08911029,  0.00749498]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.14743587, -0.12633891,  0.51450408, ..., -0.41184372,\n",
       "         -0.08938358,  0.06626793]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02205023,  0.01300056,  0.04066550, ..., -0.00390868,\n",
       "          -0.03436257, -0.03429956],\n",
       "         [-0.00203048,  0.03860179, -0.01513875, ..., -0.01027184,\n",
       "          -0.00660428,  0.07416344],\n",
       "         [ 0.01060905,  0.00155545, -0.01677158, ...,  0.02380846,\n",
       "          -0.04321303,  0.03286563],\n",
       "         ...,\n",
       "         [-0.03757687,  0.01482994, -0.00924748, ...,  0.01094516,\n",
       "           0.01687897, -0.01046033],\n",
       "         [ 0.03766189, -0.02556957,  0.02909634, ...,  0.03510678,\n",
       "           0.02196427, -0.01253037],\n",
       "         [-0.00505929, -0.00930602, -0.02928211, ..., -0.04080055,\n",
       "          -0.05183009, -0.03719730]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00067070,  0.01160970,  0.01630268, ...,  0.04060462,\n",
       "         -0.01749575,  0.00217508]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04141348, -0.00150249, -0.01402644, ..., -0.03373633,\n",
       "          -0.00975989, -0.02843315],\n",
       "         [ 0.01158753,  0.03233829, -0.00033676, ..., -0.00120445,\n",
       "           0.00110371,  0.04556624],\n",
       "         [ 0.01622663,  0.01557537,  0.02117413, ..., -0.04822287,\n",
       "           0.03096032, -0.00954660],\n",
       "         ...,\n",
       "         [-0.00992788, -0.02424854, -0.00743503, ..., -0.00970814,\n",
       "          -0.02280663, -0.01213495],\n",
       "         [-0.02374438,  0.01329260,  0.04138668, ...,  0.02472509,\n",
       "          -0.01995627, -0.00512684],\n",
       "         [-0.01274339,  0.00615129,  0.02106905, ...,  0.00177409,\n",
       "           0.02043625,  0.02401215]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01282573, -0.00105385, -0.01895827, ...,  0.00134938,\n",
       "          0.00354252,  0.03761465]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02299511, -0.00959177, -0.01044346, ...,  0.00926082,\n",
       "           0.00115107,  0.00084745],\n",
       "         [-0.01572237, -0.00541600, -0.01393783, ...,  0.01589138,\n",
       "           0.00084803, -0.02401814],\n",
       "         [ 0.02292702,  0.02554971,  0.02368609, ..., -0.01994260,\n",
       "          -0.01642369,  0.01543709],\n",
       "         ...,\n",
       "         [-0.02221550,  0.00113614, -0.03976795, ...,  0.05339060,\n",
       "           0.00115124,  0.01831650],\n",
       "         [-0.00654601,  0.01486144, -0.01100273, ...,  0.01539254,\n",
       "           0.00301795, -0.01371702],\n",
       "         [ 0.01129487,  0.04303237,  0.02482114, ..., -0.02643904,\n",
       "          -0.01567727,  0.03836939]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.11598071, -0.01203464, -0.03625809, ..., -0.07977565,\n",
       "         -0.03373020, -0.02871979]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02619605,  0.04859759, -0.00104828, ...,  0.00778068,\n",
       "           0.00899866,  0.02822085],\n",
       "         [ 0.00180804,  0.03683908,  0.01104179, ..., -0.01484974,\n",
       "          -0.00065796, -0.01258366],\n",
       "         [ 0.01265032,  0.01476661,  0.02736481, ...,  0.02537646,\n",
       "          -0.01384605,  0.01444030],\n",
       "         ...,\n",
       "         [-0.00900755,  0.00032269,  0.05340767, ..., -0.07005327,\n",
       "          -0.02307417,  0.00463121],\n",
       "         [ 0.01171643, -0.00178693,  0.05530255, ..., -0.01307523,\n",
       "           0.04708932,  0.08995398],\n",
       "         [ 0.02820562,  0.00236659,  0.00415020, ..., -0.02118464,\n",
       "           0.02319222, -0.00220980]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.09001704, -0.01546105,  0.00109951, ..., -0.00068576,\n",
       "         -0.02049053, -0.01210876]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.82053101, 0.80563450, 0.84372360, ..., 0.81352443, 0.87303174,\n",
       "         0.78407127]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01928568,  0.05674910,  0.08892796, ...,  0.15118930,\n",
       "         -0.10710350, -0.09421253]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.88185704, 0.86398649, 0.87851363, ..., 0.89672464, 0.92119604,\n",
       "         0.87213916]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02975761, -0.05561407, -0.09590593, ..., -0.10945600,\n",
       "         -0.00607674,  0.02157917]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.07096406,  0.02722012, -0.01940570, ...,  0.04578362,\n",
       "           0.00533522,  0.05505615],\n",
       "         [-0.05251753, -0.00896936, -0.02188550, ..., -0.00553780,\n",
       "           0.00548114, -0.02830553],\n",
       "         [-0.01353307, -0.02745790, -0.03141864, ...,  0.00358731,\n",
       "           0.00688631,  0.02101316],\n",
       "         ...,\n",
       "         [-0.01390900,  0.03064874, -0.03816224, ..., -0.00589400,\n",
       "           0.03262345,  0.00805149],\n",
       "         [-0.02203004,  0.05886613,  0.01423038, ..., -0.01161209,\n",
       "          -0.04603310, -0.02933666],\n",
       "         [-0.02562924,  0.02375583,  0.03726985, ...,  0.02003699,\n",
       "           0.02316686, -0.03739609]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.16055727,  0.14138530,  0.11975928, ..., -0.09063943,\n",
       "         -0.13044716,  0.09016567]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04879621, -0.03080657, -0.07315321, ..., -0.01523224,\n",
       "           0.01848659,  0.01512936],\n",
       "         [-0.00101769, -0.04091872, -0.03828941, ..., -0.01619315,\n",
       "          -0.02578322, -0.05582843],\n",
       "         [ 0.04788143, -0.04686113,  0.03866619, ...,  0.03036507,\n",
       "          -0.02772252, -0.00717499],\n",
       "         ...,\n",
       "         [ 0.02387415, -0.02942866,  0.03821105, ..., -0.03060200,\n",
       "           0.03895598,  0.03588142],\n",
       "         [-0.00887501, -0.00593338,  0.02079556, ...,  0.02346664,\n",
       "          -0.01389768, -0.02520107],\n",
       "         [-0.00222289, -0.00710976, -0.00413951, ..., -0.01288716,\n",
       "          -0.04109151,  0.00686601]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.54165041, -0.60405010,  0.25189367, ..., -0.41671813,\n",
       "         -0.04448418,  0.05013264]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02264360,  0.04046672,  0.01315875, ..., -0.01062294,\n",
       "           0.02215786, -0.04743329],\n",
       "         [ 0.01163459,  0.00250867,  0.03413664, ..., -0.01118305,\n",
       "          -0.01193346,  0.00018565],\n",
       "         [ 0.02022318,  0.00826251,  0.02163552, ...,  0.01079708,\n",
       "          -0.04501598,  0.03699998],\n",
       "         ...,\n",
       "         [-0.01955845,  0.00340671, -0.02390588, ..., -0.03151445,\n",
       "          -0.01870600, -0.01309579],\n",
       "         [-0.04533316, -0.04740889, -0.04351236, ..., -0.00640903,\n",
       "           0.00886867, -0.02657941],\n",
       "         [ 0.00559282, -0.03652686,  0.00374400, ...,  0.04448502,\n",
       "          -0.02825434, -0.01634162]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.05755761,  0.02426736, -0.02677301, ..., -0.01933841,\n",
       "         -0.01568994, -0.01464348]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01813933,  0.02742283,  0.05532995, ...,  0.02053887,\n",
       "          -0.02272437, -0.00344072],\n",
       "         [ 0.02510428, -0.02023484,  0.02058621, ...,  0.00290462,\n",
       "          -0.02554510,  0.04996771],\n",
       "         [ 0.02196320, -0.03671258, -0.03451934, ..., -0.02385935,\n",
       "          -0.00825255,  0.02641334],\n",
       "         ...,\n",
       "         [ 0.00746926,  0.02155666, -0.02357749, ...,  0.00120607,\n",
       "           0.00656168, -0.00787313],\n",
       "         [ 0.00641133,  0.02312932, -0.00331875, ...,  0.00285873,\n",
       "          -0.01838337, -0.01117692],\n",
       "         [-0.00096352, -0.00288116, -0.02297467, ..., -0.01344207,\n",
       "           0.01718361, -0.00241689]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02759953, -0.11220572, -0.02334527, ..., -0.01895914,\n",
       "          0.00472650,  0.06568823]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04341848, -0.02672322, -0.00135847, ..., -0.02131957,\n",
       "           0.03145845, -0.00957764],\n",
       "         [ 0.00875731, -0.06654152,  0.03088185, ..., -0.02786675,\n",
       "           0.02253983, -0.02396994],\n",
       "         [-0.00306437, -0.00879735, -0.04616856, ...,  0.02359225,\n",
       "           0.00222620, -0.04184236],\n",
       "         ...,\n",
       "         [ 0.00776420, -0.07896045, -0.00767570, ...,  0.01400738,\n",
       "           0.02316792, -0.04391278],\n",
       "         [ 0.02370606,  0.00588917, -0.03908227, ...,  0.00152654,\n",
       "          -0.02781506, -0.01772564],\n",
       "         [ 0.03059585, -0.00425736,  0.03159399, ...,  0.01051261,\n",
       "           0.03051092,  0.05389217]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06200086, -0.06936122, -0.09631998, ..., -0.06472751,\n",
       "         -0.04397390, -0.05674564]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00543784, -0.00768578, -0.00539137, ..., -0.01733594,\n",
       "           0.00936404,  0.02464062],\n",
       "         [-0.00403364, -0.05920605, -0.00628898, ..., -0.02486487,\n",
       "           0.03282728, -0.02571207],\n",
       "         [ 0.03358011, -0.02488020, -0.01118995, ...,  0.03047954,\n",
       "          -0.02628863,  0.00938242],\n",
       "         ...,\n",
       "         [ 0.03558131,  0.06716491,  0.00266783, ...,  0.00027961,\n",
       "          -0.06241891,  0.00331405],\n",
       "         [ 0.03924594, -0.00879915, -0.00586107, ...,  0.01118717,\n",
       "          -0.03178421,  0.04889722],\n",
       "         [ 0.01381763, -0.00498886,  0.00049443, ..., -0.05523103,\n",
       "          -0.01357242,  0.01552446]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.08341800, -0.03111418, -0.00200123, ..., -0.01913499,\n",
       "          0.02319259,  0.00447374]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.80409360, 0.78373110, 0.82912713, ..., 0.81423295, 0.86836976,\n",
       "         0.77070212]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00526527,  0.05455510,  0.04517696, ...,  0.07337583,\n",
       "         -0.09366862, -0.07038860]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.88412356, 0.86863285, 0.86603117, ..., 0.89490402, 0.88592833,\n",
       "         0.85318261]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02284453, -0.06419899, -0.07529220, ..., -0.06128797,\n",
       "         -0.03645021, -0.00353677]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01838314, -0.01085845,  0.01753395, ...,  0.02197471,\n",
       "          -0.04265789, -0.01465912],\n",
       "         [ 0.00334300,  0.12647508,  0.07571355, ..., -0.04951127,\n",
       "          -0.02034580, -0.05075400],\n",
       "         [ 0.01390969, -0.02368511, -0.00980714, ...,  0.00156988,\n",
       "          -0.01978925,  0.01209611],\n",
       "         ...,\n",
       "         [-0.00036532, -0.00935198, -0.05347853, ..., -0.02714564,\n",
       "           0.07707801,  0.02189277],\n",
       "         [-0.02570444, -0.01285727, -0.02763364, ..., -0.06527021,\n",
       "          -0.00832000, -0.01769448],\n",
       "         [-0.01793079,  0.05288590, -0.04907788, ..., -0.02036906,\n",
       "           0.00202356, -0.02896010]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.07599435,  0.16911693,  0.03404111, ...,  0.09370137,\n",
       "         -0.00441652,  0.00559319]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01520677, -0.03351978,  0.04472135, ...,  0.00692617,\n",
       "          -0.01089556, -0.05962706],\n",
       "         [ 0.04652280,  0.01474855, -0.02791563, ...,  0.00142751,\n",
       "           0.04267006,  0.03782853],\n",
       "         [-0.08197371,  0.04237368,  0.01489611, ..., -0.01136054,\n",
       "          -0.02143388, -0.03031138],\n",
       "         ...,\n",
       "         [ 0.04894441, -0.05817173, -0.01304521, ..., -0.01373162,\n",
       "           0.04199870, -0.00319012],\n",
       "         [-0.05113457, -0.05571237, -0.03025313, ..., -0.00816631,\n",
       "          -0.00456885, -0.00950769],\n",
       "         [ 0.04883716,  0.08442573, -0.03306029, ...,  0.06590620,\n",
       "           0.00072969, -0.02769401]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00513325,  0.05592082,  0.69318664, ...,  0.85644394,\n",
       "         -0.19452928, -0.08180722]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01319527, -0.00946850,  0.00453275, ...,  0.02728230,\n",
       "          -0.00403567, -0.06304607],\n",
       "         [ 0.00851929,  0.01929439, -0.03696207, ...,  0.01085028,\n",
       "           0.00924319, -0.02435266],\n",
       "         [ 0.01143588, -0.00769038,  0.00214665, ..., -0.02850225,\n",
       "          -0.01181650,  0.00098352],\n",
       "         ...,\n",
       "         [-0.01541935, -0.03738782, -0.04572120, ..., -0.03158156,\n",
       "          -0.01043452,  0.04648917],\n",
       "         [-0.03537226, -0.01710613,  0.04114759, ...,  0.02778290,\n",
       "           0.02614198, -0.01628464],\n",
       "         [-0.00302924,  0.00104664, -0.00967991, ..., -0.02823652,\n",
       "          -0.03795766, -0.01889481]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02347608, -0.02108645,  0.08743146, ..., -0.01004080,\n",
       "          0.01407559, -0.00804778]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01901389,  0.03077764, -0.00511415, ...,  0.00710492,\n",
       "          -0.01254995, -0.00665091],\n",
       "         [ 0.01591153,  0.00786385, -0.01370056, ...,  0.01578846,\n",
       "          -0.00476976,  0.02656225],\n",
       "         [ 0.02730890, -0.00591416,  0.03585489, ..., -0.01698722,\n",
       "          -0.01123560, -0.02390921],\n",
       "         ...,\n",
       "         [ 0.00120695,  0.00972566, -0.00050467, ..., -0.00604030,\n",
       "           0.01325541, -0.04190155],\n",
       "         [-0.00843636,  0.00927280,  0.01365474, ...,  0.01569550,\n",
       "           0.01922211,  0.06506966],\n",
       "         [ 0.01788071, -0.00350994,  0.02270450, ...,  0.04456680,\n",
       "          -0.03107817,  0.03657080]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03426673,  0.04665212, -0.05971365, ..., -0.02106812,\n",
       "          0.01320385,  0.03131534]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.04146699, -0.01459482, -0.00664123, ...,  0.06232709,\n",
       "          -0.03756649,  0.00082849],\n",
       "         [-0.02343252, -0.03398588,  0.04386530, ...,  0.00151815,\n",
       "           0.01973489,  0.05544226],\n",
       "         [ 0.09794421, -0.00540585,  0.01881156, ..., -0.01517049,\n",
       "           0.01306969, -0.03095267],\n",
       "         ...,\n",
       "         [-0.04316387,  0.01203251, -0.08114124, ..., -0.05130001,\n",
       "          -0.02776472, -0.00109383],\n",
       "         [-0.01556963,  0.04482371,  0.00422431, ..., -0.02113773,\n",
       "           0.00188038, -0.01384229],\n",
       "         [ 0.03619707,  0.02889311,  0.01391637, ...,  0.02674543,\n",
       "          -0.04562868,  0.05373535]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.09073801, -0.06678916, -0.07761860, ..., -0.08109409,\n",
       "         -0.11044587, -0.06136638]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05066092,  0.01068689,  0.00209889, ..., -0.03830676,\n",
       "          -0.00327091, -0.00134226],\n",
       "         [-0.01474226,  0.00685096, -0.04190193, ..., -0.03860686,\n",
       "           0.00500980,  0.01517310],\n",
       "         [-0.03247952,  0.00595023,  0.03989125, ..., -0.05278210,\n",
       "          -0.05500047, -0.04365244],\n",
       "         ...,\n",
       "         [ 0.02154514, -0.01469386, -0.02744979, ...,  0.00500758,\n",
       "           0.01059103,  0.00315812],\n",
       "         [-0.02519771, -0.06841030, -0.00573989, ..., -0.02367348,\n",
       "           0.00581075, -0.03966713],\n",
       "         [-0.00793746,  0.07401989, -0.01826358, ...,  0.00326044,\n",
       "          -0.03701102, -0.02710970]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03667320, -0.05328682, -0.02710221, ..., -0.01054526,\n",
       "         -0.01492322,  0.05880921]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.78755111, 0.74739236, 0.82052106, ..., 0.78678775, 0.84658664,\n",
       "         0.74066633]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01917819, -0.07626271,  0.07107167, ...,  0.05997226,\n",
       "         -0.00494414, -0.06640510]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.86611742, 0.88321429, 0.86007094, ..., 0.87344545, 0.86337709,\n",
       "         0.84806889]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02131290, -0.01950546, -0.05591732, ..., -0.06645759,\n",
       "         -0.01661105,  0.01009090]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02589074, -0.02596771, -0.01508026, ..., -0.02012471,\n",
       "          -0.03078021, -0.01714915],\n",
       "         [ 0.02250765, -0.01539443, -0.05658732, ..., -0.03479660,\n",
       "          -0.07493535,  0.03795735],\n",
       "         [-0.03220676,  0.02684108, -0.01390213, ...,  0.00821770,\n",
       "          -0.04019599, -0.06457604],\n",
       "         ...,\n",
       "         [-0.02473278, -0.00916992, -0.02835710, ...,  0.01304910,\n",
       "           0.02064553,  0.01939339],\n",
       "         [ 0.04550530,  0.04029979, -0.06641833, ...,  0.00545391,\n",
       "           0.06109666,  0.01132852],\n",
       "         [-0.00719760, -0.02454547, -0.03843178, ...,  0.00503056,\n",
       "           0.05766243,  0.04500033]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04370379, -0.12708180,  0.09901122, ..., -0.36043683,\n",
       "         -0.24303827,  0.06919101]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02099346, -0.03848011, -0.00503624, ..., -0.01155636,\n",
       "           0.01437353, -0.04235357],\n",
       "         [ 0.02451085,  0.03979734,  0.03911321, ..., -0.01307151,\n",
       "          -0.03302309, -0.01422682],\n",
       "         [ 0.00807752,  0.01825465, -0.03746862, ..., -0.01736550,\n",
       "          -0.03503136,  0.07067791],\n",
       "         ...,\n",
       "         [-0.01202302,  0.01064249,  0.06607401, ..., -0.00515832,\n",
       "          -0.04410101, -0.04422849],\n",
       "         [-0.01768879,  0.04984957,  0.04298213, ...,  0.00433199,\n",
       "           0.02722991,  0.08080701],\n",
       "         [ 0.07797424, -0.04686321, -0.08866926, ..., -0.01673182,\n",
       "          -0.00668827, -0.02959744]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.04446287,  0.20789328,  0.46345091, ..., -0.65606880,\n",
       "         -0.71612877,  0.45019263]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.08240642, -0.01482944,  0.02867026, ..., -0.04028129,\n",
       "           0.03004684,  0.03543157],\n",
       "         [-0.04775697,  0.02560890,  0.01929200, ..., -0.02376463,\n",
       "          -0.00088647,  0.01866565],\n",
       "         [ 0.00943891, -0.00010117,  0.02180449, ..., -0.01362994,\n",
       "           0.01363817,  0.02590755],\n",
       "         ...,\n",
       "         [ 0.00644269, -0.03953884, -0.05500319, ...,  0.02676107,\n",
       "          -0.00818423,  0.00444119],\n",
       "         [ 0.04860665,  0.01921073, -0.01461207, ...,  0.01475524,\n",
       "           0.01053226, -0.01047995],\n",
       "         [ 0.05142067,  0.08452414,  0.09419425, ...,  0.01527032,\n",
       "           0.00855672,  0.03805973]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01085144,  0.00609180,  0.00323522, ...,  0.01274506,\n",
       "          0.01297998, -0.02269399]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.05166185, -0.00515683,  0.01471738, ..., -0.06753398,\n",
       "          -0.05545996,  0.02843956],\n",
       "         [ 0.07547084, -0.02714180,  0.00924577, ...,  0.03107615,\n",
       "          -0.01337171, -0.02708754],\n",
       "         [ 0.01632723,  0.03902509, -0.00439483, ...,  0.02854893,\n",
       "           0.02966640,  0.03079667],\n",
       "         ...,\n",
       "         [ 0.00619060, -0.00706940, -0.07200591, ...,  0.00382110,\n",
       "          -0.01632083,  0.00025776],\n",
       "         [-0.00404428, -0.00559906,  0.01355121, ..., -0.02488862,\n",
       "           0.05770134,  0.02029199],\n",
       "         [ 0.03162804,  0.01911005,  0.01695803, ...,  0.03267058,\n",
       "           0.00419410, -0.00308315]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01379871, -0.05602975, -0.02137922, ..., -0.03712824,\n",
       "          0.00812127,  0.01521510]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02683536,  0.04052145,  0.00713441, ...,  0.00868117,\n",
       "           0.03772862, -0.02339846],\n",
       "         [-0.05598132, -0.02607626,  0.00314919, ..., -0.00946423,\n",
       "          -0.03146039, -0.02984332],\n",
       "         [-0.01314240,  0.01011352,  0.03336815, ..., -0.00205550,\n",
       "           0.01772505,  0.00913937],\n",
       "         ...,\n",
       "         [ 0.03118127, -0.01208196, -0.00018607, ..., -0.02350387,\n",
       "           0.00453610, -0.05006566],\n",
       "         [ 0.02916264, -0.01885523, -0.00110239, ..., -0.00886058,\n",
       "           0.02542669,  0.01350858],\n",
       "         [-0.01472474, -0.01451244, -0.02108336, ..., -0.01455327,\n",
       "          -0.00665334,  0.01419994]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06921770, -0.08341968, -0.04506689, ..., -0.09157335,\n",
       "         -0.08899314, -0.09139345]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04008959,  0.01993022,  0.05547764, ...,  0.05062301,\n",
       "           0.04756409,  0.01008281],\n",
       "         [ 0.01807333, -0.04522945,  0.00316323, ...,  0.02856520,\n",
       "          -0.02637284,  0.01700115],\n",
       "         [ 0.01687213,  0.01289924,  0.02178286, ..., -0.02572392,\n",
       "           0.00130287, -0.00491244],\n",
       "         ...,\n",
       "         [ 0.04095593,  0.02158283, -0.01535724, ...,  0.01995021,\n",
       "           0.01680066, -0.04830395],\n",
       "         [ 0.05056974,  0.04470460, -0.01167457, ...,  0.04894965,\n",
       "          -0.02594011, -0.04591954],\n",
       "         [-0.05895415, -0.00333515,  0.04893823, ..., -0.02943304,\n",
       "          -0.01528088,  0.00578829]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.02320844, -0.06701141, -0.01662475, ...,  0.03266943,\n",
       "         -0.00881389, -0.01224991]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.77068251, 0.72176051, 0.79330462, ..., 0.75076342, 0.80769056,\n",
       "         0.73550546]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00673570, -0.04589262,  0.09753098, ...,  0.02866540,\n",
       "         -0.00472624, -0.01918724]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.84245431, 0.84338802, 0.84457439, ..., 0.86223525, 0.86488193,\n",
       "         0.83150905]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01875274, -0.00304561, -0.02575257, ..., -0.00950388,\n",
       "         -0.00966454, -0.02790637]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00368388, -0.01813353,  0.04195108, ..., -0.07122599,\n",
       "          -0.03504130, -0.01604483],\n",
       "         [ 0.03426934,  0.07859924, -0.00821702, ..., -0.01743614,\n",
       "          -0.02083490, -0.01921595],\n",
       "         [-0.00724751, -0.02074067, -0.06136423, ...,  0.01029405,\n",
       "           0.03533452,  0.00014326],\n",
       "         ...,\n",
       "         [-0.04495851,  0.00591622, -0.00754176, ..., -0.05873709,\n",
       "           0.00676173, -0.01064443],\n",
       "         [ 0.00612243,  0.01843722,  0.03004295, ..., -0.05621925,\n",
       "          -0.01199017, -0.04069093],\n",
       "         [ 0.03136507, -0.02244191,  0.01900747, ..., -0.06775961,\n",
       "           0.01150992,  0.00550103]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.09924686, -0.09713112,  0.02401996, ..., -0.00499722,\n",
       "         -0.12842491, -0.10444874]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02806530, -0.03124637,  0.03089304, ..., -0.04868706,\n",
       "          -0.02738833, -0.02749245],\n",
       "         [ 0.04489422,  0.02659286,  0.01388513, ..., -0.01757283,\n",
       "           0.03108081, -0.00968533],\n",
       "         [-0.04892358, -0.01254169, -0.00907381, ..., -0.01034672,\n",
       "          -0.03491110,  0.01039347],\n",
       "         ...,\n",
       "         [ 0.05147850,  0.01890388, -0.04483833, ..., -0.00632643,\n",
       "          -0.00251233, -0.03670190],\n",
       "         [-0.02732626, -0.01978318,  0.00256586, ...,  0.01986711,\n",
       "          -0.00590419, -0.02567006],\n",
       "         [ 0.02124384,  0.02062881, -0.01530757, ...,  0.03028633,\n",
       "          -0.00675373,  0.00010762]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.13946678,  0.71852756, -1.24150181, ..., -0.22072424,\n",
       "         -0.22528218, -0.45027936]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04212339, -0.03978303,  0.03615203, ..., -0.00956141,\n",
       "           0.00521542, -0.00767622],\n",
       "         [ 0.05439448,  0.00303884, -0.01571013, ..., -0.02491644,\n",
       "           0.03385667, -0.01961501],\n",
       "         [-0.01443850, -0.02616306, -0.00119446, ..., -0.04977832,\n",
       "          -0.02134308,  0.02019730],\n",
       "         ...,\n",
       "         [-0.02381574, -0.05958957,  0.00553120, ...,  0.05718578,\n",
       "          -0.02798552, -0.02707705],\n",
       "         [ 0.02894848,  0.03294937,  0.06357907, ..., -0.02746173,\n",
       "           0.01823195,  0.01206899],\n",
       "         [ 0.05882817, -0.03561416,  0.05479337, ...,  0.01810338,\n",
       "          -0.08013592, -0.00587942]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00607084,  0.02192001, -0.00192293, ...,  0.01653749,\n",
       "         -0.02127903,  0.00501299]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01142726,  0.03034769,  0.00721620, ..., -0.02879481,\n",
       "           0.00518014,  0.02712531],\n",
       "         [ 0.06214610,  0.01054164,  0.01865938, ..., -0.01239604,\n",
       "           0.02365587,  0.01121287],\n",
       "         [ 0.03881936,  0.01559640, -0.02023931, ...,  0.02354164,\n",
       "           0.03707667, -0.01217102],\n",
       "         ...,\n",
       "         [ 0.02563716, -0.04081278, -0.04011049, ..., -0.03235035,\n",
       "          -0.01931189, -0.02357684],\n",
       "         [ 0.02830765, -0.00989191,  0.02229771, ..., -0.02693478,\n",
       "          -0.02573456,  0.04567314],\n",
       "         [ 0.00578254,  0.01352440,  0.01831764, ..., -0.02830077,\n",
       "          -0.02310587, -0.02834650]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06097567,  0.01661795,  0.00030498, ..., -0.09668063,\n",
       "         -0.04365218,  0.01423980]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03063517, -0.00289621,  0.01129498, ...,  0.01566678,\n",
       "           0.01693849,  0.02733167],\n",
       "         [-0.00690751,  0.03947671,  0.05178257, ..., -0.02734528,\n",
       "           0.00206850,  0.04397124],\n",
       "         [-0.01734012, -0.03539509,  0.02073445, ..., -0.04389086,\n",
       "           0.02498374, -0.01599032],\n",
       "         ...,\n",
       "         [ 0.03883291,  0.02946376, -0.01730409, ...,  0.02545278,\n",
       "           0.07026967,  0.01986746],\n",
       "         [ 0.01993186,  0.01271523, -0.00564454, ...,  0.00068744,\n",
       "           0.01067781,  0.02422431],\n",
       "         [-0.01453362, -0.01765963, -0.00332596, ..., -0.00815516,\n",
       "          -0.00563939,  0.00766264]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00104922, -0.07030009, -0.06541006, ..., -0.08173747,\n",
       "         -0.08358615, -0.08097226]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.03028653, -0.01051833,  0.01613138, ..., -0.02017745,\n",
       "          -0.00996672,  0.01752908],\n",
       "         [-0.01078485,  0.01226046, -0.06689949, ...,  0.01823781,\n",
       "           0.00901031, -0.03504695],\n",
       "         [ 0.01020091, -0.01298742,  0.01853217, ...,  0.00413693,\n",
       "           0.02273881, -0.06431067],\n",
       "         ...,\n",
       "         [-0.01518913, -0.00117039, -0.01493940, ..., -0.03360864,\n",
       "          -0.00098995,  0.04038444],\n",
       "         [-0.03400796, -0.00275021,  0.01327515, ..., -0.02280488,\n",
       "           0.03118988, -0.04724449],\n",
       "         [ 0.05619489,  0.03747953, -0.01455608, ..., -0.00595908,\n",
       "          -0.01647327, -0.00017366]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03981424, -0.07236140, -0.02394317, ...,  0.01602086,\n",
       "         -0.02507488,  0.06503391]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.76961195, 0.74477649, 0.77960074, ..., 0.74256653, 0.78422213,\n",
       "         0.74006402]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04248535, -0.08528386,  0.05214341, ...,  0.03288436,\n",
       "          0.00585082,  0.01384634]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90071571, 0.89516437, 0.90145695, ..., 0.92378521, 0.95160770,\n",
       "         0.90528023]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02202253,  0.02792052,  0.06066481, ..., -0.02721542,\n",
       "         -0.00634257, -0.04301886]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00191332, -0.04187622, -0.00326114, ..., -0.06803750,\n",
       "          -0.06168402,  0.00527372],\n",
       "         [ 0.00513645,  0.00217764, -0.00453816, ...,  0.00198908,\n",
       "           0.04245238,  0.00747822],\n",
       "         [-0.08842308,  0.04891618, -0.05254653, ...,  0.01774919,\n",
       "          -0.00001317,  0.00186885],\n",
       "         ...,\n",
       "         [ 0.02336360, -0.00802481, -0.00264251, ..., -0.00197927,\n",
       "           0.02598120,  0.01467833],\n",
       "         [ 0.01140706, -0.02409915,  0.00011126, ..., -0.02580843,\n",
       "          -0.07488635, -0.03624465],\n",
       "         [ 0.03618271,  0.01735357,  0.06402121, ..., -0.00957442,\n",
       "          -0.04080018,  0.00016510]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.12523216,  0.13259327, -0.01571945, ..., -0.01856571,\n",
       "          0.10351302, -0.18499866]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.10114269,  0.01399003, -0.01065752, ..., -0.05516052,\n",
       "          -0.06885610, -0.04889421],\n",
       "         [ 0.01313734, -0.01494786, -0.03833135, ..., -0.05081732,\n",
       "           0.02522722, -0.06199707],\n",
       "         [-0.04531201,  0.05109547, -0.00711014, ...,  0.03951384,\n",
       "          -0.04488112,  0.04142499],\n",
       "         ...,\n",
       "         [-0.05565071, -0.01168553, -0.02017102, ...,  0.04272538,\n",
       "           0.01389601,  0.00334733],\n",
       "         [-0.02533772, -0.03068689,  0.01490068, ...,  0.01875979,\n",
       "           0.00874509,  0.00756295],\n",
       "         [ 0.00009861, -0.03343005,  0.02427329, ..., -0.05306480,\n",
       "          -0.01116598, -0.05704200]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-1.13744867,  0.18442546, -0.10277516, ..., -0.90945113,\n",
       "          0.15467216,  0.64318126]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.05408011,  0.00431752, -0.00695071, ...,  0.02689116,\n",
       "          -0.04161447,  0.07591664],\n",
       "         [-0.06381927,  0.02432473,  0.02277985, ..., -0.06540360,\n",
       "           0.03225779, -0.02923017],\n",
       "         [-0.02337402,  0.02580905, -0.03632941, ..., -0.03266250,\n",
       "          -0.00431148, -0.01570085],\n",
       "         ...,\n",
       "         [ 0.10540436,  0.00233257, -0.01429207, ...,  0.00052624,\n",
       "           0.00252085, -0.05108113],\n",
       "         [ 0.04012473,  0.00982108, -0.03828787, ..., -0.00458003,\n",
       "          -0.05958925, -0.04765163],\n",
       "         [ 0.04313813, -0.04586849, -0.02287292, ...,  0.00519600,\n",
       "          -0.00204240, -0.01772070]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00765134,  0.01907802,  0.00462251, ..., -0.00697307,\n",
       "         -0.00204896,  0.00850016]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00854744,  0.04729215,  0.02646789, ...,  0.02780948,\n",
       "          -0.02522887, -0.04315673],\n",
       "         [-0.00885985, -0.02888988, -0.00147223, ...,  0.05457263,\n",
       "          -0.00800781,  0.01947640],\n",
       "         [ 0.00268508, -0.02626196,  0.00145065, ..., -0.03211806,\n",
       "           0.01463374,  0.04270155],\n",
       "         ...,\n",
       "         [ 0.00038499, -0.04101534, -0.03425192, ..., -0.00073716,\n",
       "          -0.00791129, -0.01003574],\n",
       "         [-0.02181146,  0.01160739,  0.02879332, ..., -0.03645229,\n",
       "          -0.00645653, -0.01841089],\n",
       "         [-0.03006281, -0.05196014, -0.00819790, ...,  0.02449100,\n",
       "          -0.01905537,  0.04394415]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01776673, -0.11767037, -0.04406783, ..., -0.04914298,\n",
       "          0.02312443,  0.04445110]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.05322657,  0.01932541, -0.04025273, ...,  0.00976699,\n",
       "           0.03835808,  0.01231505],\n",
       "         [ 0.00104606,  0.00765530,  0.03979145, ...,  0.01752016,\n",
       "           0.01414074, -0.02979173],\n",
       "         [-0.02639088,  0.02178580, -0.00075935, ...,  0.01175206,\n",
       "           0.02909493,  0.03893232],\n",
       "         ...,\n",
       "         [ 0.04605819, -0.00527191, -0.00349680, ..., -0.00306411,\n",
       "          -0.00382188,  0.04357640],\n",
       "         [-0.01140471,  0.00888015, -0.00110476, ...,  0.01429311,\n",
       "          -0.04041576, -0.01160869],\n",
       "         [ 0.00377966, -0.00933230,  0.00582618, ...,  0.02354797,\n",
       "          -0.00798872,  0.00764799]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08133257, -0.09483589, -0.08970526, ..., -0.06382982,\n",
       "         -0.02230562, -0.06195077]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00456873,  0.01615437, -0.01066531, ...,  0.02564277,\n",
       "          -0.02414715,  0.03021802],\n",
       "         [-0.02551531,  0.01001091,  0.00681867, ..., -0.01363352,\n",
       "           0.05902440, -0.02366403],\n",
       "         [-0.01203813,  0.00359759,  0.01635535, ..., -0.01723167,\n",
       "          -0.05275695,  0.01115033],\n",
       "         ...,\n",
       "         [-0.00988611,  0.04652832,  0.01861833, ...,  0.01794791,\n",
       "           0.02235143, -0.01384160],\n",
       "         [-0.03835924,  0.03580575, -0.03731155, ...,  0.00294312,\n",
       "          -0.06161875,  0.01395170],\n",
       "         [-0.00574428, -0.08148260,  0.02627438, ..., -0.01773571,\n",
       "          -0.01776761,  0.03701729]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04064992, -0.05677281, -0.03595695, ...,  0.04819211,\n",
       "          0.01124411,  0.02797621]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.82126683, 0.80068332, 0.80579001, ..., 0.77373105, 0.81550574,\n",
       "         0.77450407]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03567071, -0.01893387, -0.00025195, ...,  0.04174772,\n",
       "          0.00933674,  0.06295587]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.90089744, 0.91764265, 0.93456119, ..., 0.91035503, 0.92279774,\n",
       "         0.89370084]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.04818531,  0.07141299,  0.04749471, ..., -0.00947989,\n",
       "          0.03809004,  0.01517907]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04889330,  0.00533321, -0.02114698, ..., -0.02209738,\n",
       "           0.00755872, -0.02550680],\n",
       "         [-0.03246756, -0.01156666,  0.03930664, ...,  0.00263116,\n",
       "           0.04829899, -0.01862105],\n",
       "         [ 0.04952311,  0.00204894, -0.03227454, ..., -0.05853071,\n",
       "           0.03846289, -0.03388622],\n",
       "         ...,\n",
       "         [ 0.01616536, -0.04758287, -0.04150431, ...,  0.03939244,\n",
       "          -0.05743868, -0.06979914],\n",
       "         [-0.00187632,  0.00421790,  0.03044131, ..., -0.06316489,\n",
       "          -0.03061646, -0.03232678],\n",
       "         [-0.03563999, -0.01578635, -0.04484239, ...,  0.02663618,\n",
       "           0.00392189, -0.05123199]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.18103723, -0.09466570,  0.06379892, ..., -0.02122802,\n",
       "          0.12967266, -0.19290175]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01012673,  0.05436501, -0.00916613, ...,  0.02450540,\n",
       "          -0.00793565, -0.03389913],\n",
       "         [-0.02991581, -0.03132427,  0.02269576, ..., -0.03020807,\n",
       "           0.06449187,  0.00263612],\n",
       "         [-0.00033644,  0.04786411,  0.01271856, ...,  0.00655842,\n",
       "          -0.03008614, -0.00738289],\n",
       "         ...,\n",
       "         [ 0.01821156,  0.01538001, -0.00235010, ...,  0.04907823,\n",
       "          -0.03552124,  0.02474494],\n",
       "         [-0.05269456,  0.02787133,  0.02069156, ..., -0.00436556,\n",
       "          -0.02464737, -0.00260677],\n",
       "         [ 0.01378100, -0.02819749, -0.05371435, ..., -0.00451597,\n",
       "          -0.10599641, -0.03926290]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.39911148, -0.17402951, -1.06600046, ..., -0.89928621,\n",
       "          3.59075022,  0.68623114]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00193062, -0.01310596,  0.05263612, ..., -0.03490351,\n",
       "           0.00740158, -0.02772276],\n",
       "         [-0.05774023, -0.04833568, -0.02698833, ..., -0.06532957,\n",
       "           0.00453990, -0.00546517],\n",
       "         [-0.01910562, -0.04507819,  0.03103908, ...,  0.02370557,\n",
       "          -0.00246884,  0.00460647],\n",
       "         ...,\n",
       "         [-0.00800307,  0.04841613, -0.02479443, ...,  0.01195866,\n",
       "          -0.02708280,  0.01477809],\n",
       "         [ 0.08747353, -0.03755109,  0.04255898, ..., -0.07796308,\n",
       "           0.02122374, -0.03715724],\n",
       "         [-0.02437014,  0.00729149,  0.00836841, ..., -0.01264117,\n",
       "           0.01656661,  0.02097038]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.00019659,  0.00858239,  0.00621987, ..., -0.01851103,\n",
       "         -0.03385237,  0.00413954]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01156540,  0.02766666,  0.00001330, ...,  0.00503166,\n",
       "          -0.03669026, -0.05433455],\n",
       "         [ 0.00350003, -0.01235734, -0.04341484, ...,  0.02126865,\n",
       "          -0.04916800,  0.02864446],\n",
       "         [ 0.00585900,  0.00441982, -0.00676176, ..., -0.00301300,\n",
       "          -0.01514014, -0.01358146],\n",
       "         ...,\n",
       "         [-0.03048439, -0.00394941,  0.01701021, ..., -0.02457967,\n",
       "          -0.05148224,  0.03259883],\n",
       "         [-0.02139176,  0.05843858, -0.00552989, ..., -0.00383503,\n",
       "           0.00591398,  0.05590708],\n",
       "         [ 0.00657459, -0.00831923,  0.01265434, ...,  0.00495747,\n",
       "           0.03871887,  0.00024045]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.03021190,  0.00986714, -0.00391936, ..., -0.03466891,\n",
       "          0.03288059,  0.00090965]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.00153298, -0.00830656,  0.00998949, ..., -0.00288672,\n",
       "           0.01863294, -0.03118649],\n",
       "         [-0.05413993, -0.04186415,  0.03155186, ...,  0.00907265,\n",
       "           0.01373257,  0.05672105],\n",
       "         [-0.04740092,  0.01872756, -0.03086713, ...,  0.00731078,\n",
       "          -0.02629871,  0.01442200],\n",
       "         ...,\n",
       "         [-0.00581520,  0.04831327,  0.01292040, ..., -0.00030050,\n",
       "          -0.04147946, -0.03354282],\n",
       "         [ 0.02265842, -0.00817670,  0.03447328, ...,  0.01484689,\n",
       "           0.00517339, -0.03608582],\n",
       "         [ 0.03733547, -0.04500068,  0.03875645, ...,  0.05767288,\n",
       "          -0.00287733,  0.03973411]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01640156, -0.08412332, -0.05394999, ..., -0.07120500,\n",
       "         -0.06475040, -0.06862959]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02090471, -0.00955646,  0.02855353, ..., -0.00772110,\n",
       "          -0.01798017,  0.02095107],\n",
       "         [-0.00173152,  0.05455944,  0.01132361, ...,  0.00827486,\n",
       "          -0.00941101,  0.02044690],\n",
       "         [-0.04604273,  0.00742994, -0.02166879, ..., -0.01275883,\n",
       "          -0.04580557, -0.01922577],\n",
       "         ...,\n",
       "         [-0.02290771, -0.00896259, -0.02183724, ..., -0.00110643,\n",
       "          -0.05799834, -0.03228886],\n",
       "         [ 0.02295280,  0.05516006, -0.01410295, ...,  0.00652650,\n",
       "           0.00818904,  0.02488092],\n",
       "         [ 0.02337046,  0.04769132,  0.01802455, ...,  0.02629641,\n",
       "           0.00452243,  0.03084501]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.04658263, -0.04798800, -0.03586705, ...,  0.03009331,\n",
       "         -0.01332994,  0.01255456]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.83013463, 0.82473290, 0.83160442, ..., 0.78884298, 0.81694931,\n",
       "         0.81035036]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03110039,  0.01926077,  0.03558438, ...,  0.09841435,\n",
       "          0.05154670,  0.09798097]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.93321657, 0.95343918, 0.96100622, ..., 0.94698203, 0.95486373,\n",
       "         0.93451250]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.01717645,  0.06147451,  0.01369375, ...,  0.01959276,\n",
       "          0.02912151, -0.00288273]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.02492173,  0.04345034,  0.01377784, ...,  0.05114717,\n",
       "          -0.06443392,  0.01857411],\n",
       "         [ 0.00165716, -0.02389581, -0.02493926, ...,  0.02040860,\n",
       "          -0.02015713, -0.06027965],\n",
       "         [-0.01140467, -0.00963516,  0.00723813, ..., -0.02286366,\n",
       "           0.04394301,  0.00758239],\n",
       "         ...,\n",
       "         [ 0.02812671, -0.03552850, -0.04400702, ...,  0.07030799,\n",
       "           0.05284226, -0.01698628],\n",
       "         [-0.00115404,  0.00137297,  0.02415342, ...,  0.01053919,\n",
       "           0.01932038, -0.00717869],\n",
       "         [-0.00558907, -0.01213312, -0.00969005, ...,  0.05733300,\n",
       "           0.04805603, -0.00932599]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.12300807,  0.02240640,  0.02911280, ...,  0.14147827,\n",
       "         -0.12648070, -0.34446698]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.11337850, -0.01650257,  0.01894720, ..., -0.01170836,\n",
       "           0.02276016, -0.04308455],\n",
       "         [ 0.00747795,  0.01970559, -0.05935812, ..., -0.00906609,\n",
       "           0.02017381, -0.05336827],\n",
       "         [-0.03039628,  0.01683751,  0.02005253, ...,  0.01398276,\n",
       "           0.00630944, -0.06665531],\n",
       "         ...,\n",
       "         [-0.02886933, -0.03290362, -0.00634992, ...,  0.05279604,\n",
       "          -0.00085992,  0.02590885],\n",
       "         [ 0.04752360, -0.00114044,  0.05343920, ...,  0.02073353,\n",
       "           0.02334196,  0.01627050],\n",
       "         [ 0.02593083, -0.02916354,  0.03425177, ...,  0.00623205,\n",
       "          -0.01837134, -0.03471095]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.69677359, -0.08626849, -0.83884370, ..., -2.17025065,\n",
       "          0.56765717,  0.66954863]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.01668728,  0.02858159,  0.03263478, ...,  0.03335546,\n",
       "          -0.01498143, -0.02223559],\n",
       "         [ 0.01066695,  0.04602562, -0.01107821, ...,  0.03700482,\n",
       "           0.01750256,  0.01109517],\n",
       "         [-0.01012320,  0.04001834,  0.02208383, ...,  0.02838183,\n",
       "          -0.07062399, -0.01262004],\n",
       "         ...,\n",
       "         [ 0.04256488,  0.00701911, -0.03833181, ..., -0.00318445,\n",
       "           0.01355277,  0.00979437],\n",
       "         [ 0.01691964,  0.05937792,  0.00316192, ...,  0.03536360,\n",
       "          -0.00598292,  0.02893113],\n",
       "         [-0.04495103, -0.04760366,  0.00394607, ..., -0.00679824,\n",
       "          -0.06019837, -0.04354174]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.01101227,  0.01596928,  0.00682606, ..., -0.00151943,\n",
       "          0.01807886, -0.01223897]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.02206074,  0.05088568, -0.02909322, ...,  0.03544123,\n",
       "           0.02612386, -0.00378744],\n",
       "         [ 0.02074947,  0.02044781, -0.01473253, ...,  0.00603725,\n",
       "           0.02321959, -0.01535660],\n",
       "         [ 0.00162725, -0.00073175,  0.02755783, ...,  0.00175825,\n",
       "          -0.00742319, -0.02811505],\n",
       "         ...,\n",
       "         [ 0.00770491, -0.03800195,  0.01536835, ..., -0.00647518,\n",
       "           0.01325225,  0.01737556],\n",
       "         [ 0.00519731,  0.03463152,  0.01938819, ..., -0.02703173,\n",
       "           0.03844651,  0.02883409],\n",
       "         [-0.04136768,  0.00774862, -0.04009037, ...,  0.02075408,\n",
       "          -0.00275456, -0.00415768]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08632933, -0.04362383,  0.09155405, ..., -0.04730501,\n",
       "          0.01540985,  0.03318964]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[ 0.03053672,  0.00183112,  0.00912349, ..., -0.01898424,\n",
       "          -0.02379100,  0.09715752],\n",
       "         [ 0.00045310,  0.00976360, -0.05339252, ..., -0.04276333,\n",
       "           0.02792139,  0.02616123],\n",
       "         [-0.03667651, -0.00837845, -0.02391919, ...,  0.00105555,\n",
       "           0.00332484,  0.02343400],\n",
       "         ...,\n",
       "         [-0.00855943,  0.00529196, -0.02739612, ..., -0.01248878,\n",
       "          -0.00579460,  0.00229298],\n",
       "         [ 0.01647430,  0.02259985, -0.00100917, ..., -0.01901933,\n",
       "           0.00072410,  0.02588671],\n",
       "         [-0.03758239,  0.03443753, -0.01450838, ...,  0.01880875,\n",
       "          -0.04079519,  0.02663976]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.06171277, -0.05900928, -0.09246824, ..., -0.01796244,\n",
       "         -0.12147632, -0.00322875]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[4096, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.01984054,  0.02287731, -0.02371440, ...,  0.00719668,\n",
       "           0.00955612,  0.01497765],\n",
       "         [-0.01982844,  0.00122757,  0.00870002, ..., -0.02213197,\n",
       "           0.04153570,  0.00797239],\n",
       "         [ 0.00552956,  0.07702807,  0.00668265, ...,  0.02788737,\n",
       "           0.00590417, -0.02864116],\n",
       "         ...,\n",
       "         [-0.04597281, -0.01369810, -0.01784400, ..., -0.00116561,\n",
       "           0.03498674,  0.03995312],\n",
       "         [ 0.02803085, -0.02313063, -0.03089742, ..., -0.00260282,\n",
       "          -0.01575124,  0.02388274],\n",
       "         [-0.04411380,  0.00514745,  0.00246420, ..., -0.01572957,\n",
       "           0.00024806, -0.00240821]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.08541369, -0.13589755,  0.05716511, ..., -0.10249817,\n",
       "         -0.05167746,  0.11156197]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.85065246, 0.84205484, 0.85158831, ..., 0.82024562, 0.83747846,\n",
       "         0.83672190]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00036446,  0.01408722,  0.03802958, ...,  0.00656782,\n",
       "          0.00315072,  0.01273488]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.69577509, 0.73109460, 0.71899909, ..., 0.69161892, 0.69434923,\n",
       "         0.68268967]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [ 0.02208978,  0.08926818,  0.05598526, ..., -0.00378850,\n",
       "         -0.01984994, -0.05638348]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.04889631, -0.03953245, -0.04676077, ..., -0.00331457,\n",
       "          -0.04023956, -0.01677985],\n",
       "         [ 0.01944217,  0.04047803,  0.02205214, ...,  0.01468804,\n",
       "           0.01991374,  0.02325337],\n",
       "         [ 0.02258326, -0.03002027,  0.01482055, ...,  0.02296144,\n",
       "           0.00299030, -0.01849073],\n",
       "         ...,\n",
       "         [ 0.01505023,  0.01398209, -0.01521906, ...,  0.04968491,\n",
       "          -0.02096811,  0.02058058],\n",
       "         [ 0.02617332,  0.05145920,  0.01893478, ..., -0.04310032,\n",
       "          -0.02803920, -0.01105369],\n",
       "         [ 0.01987676,  0.02506975, -0.02003281, ..., -0.00674021,\n",
       "          -0.00266603, -0.00825870]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.03466135, -0.03154757, -0.00266340, ..., -0.01167620,\n",
       "          0.01056642, -0.00496358]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[20, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.07260302,  0.00893798, -0.08115109, ..., -0.05861866,\n",
       "           0.02569943, -0.04830024],\n",
       "         [ 0.01771795, -0.03503437, -0.07568398, ...,  0.02236696,\n",
       "          -0.05688940, -0.09488992],\n",
       "         [-0.02510455,  0.07148174, -0.10158768, ...,  0.03863415,\n",
       "           0.01024576, -0.05338159],\n",
       "         ...,\n",
       "         [ 0.04096690, -0.03987848,  0.06959851, ...,  0.05565497,\n",
       "           0.03460664, -0.03564390],\n",
       "         [ 0.03216706, -0.07165346, -0.08885850, ..., -0.00237678,\n",
       "          -0.01215382, -0.07989253],\n",
       "         [-0.03810192,  0.00562082,  0.03281913, ..., -0.00032227,\n",
       "          -0.03861212, -0.08927232]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[20], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00671427,  0.00613561, -0.01602340, -0.03486771, -0.00079528,\n",
       "         -0.01652144, -0.02389209, -0.01194240,  0.00953578, -0.00186717,\n",
       "         -0.01929429, -0.00810205, -0.03000672, -0.02270882,  0.00962486,\n",
       "         -0.00838549, -0.00485422, -0.02795862, -0.00330600,  0.00116837]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024, 1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [[-0.00360417,  0.00553989,  0.00549994, ...,  0.03164842,\n",
       "           0.01151032,  0.01481300],\n",
       "         [-0.00411693,  0.00020544, -0.00574021, ..., -0.03103723,\n",
       "           0.00080197, -0.01190123],\n",
       "         [ 0.02673236,  0.00864224,  0.01981293, ..., -0.02391209,\n",
       "           0.02137185, -0.00817722],\n",
       "         ...,\n",
       "         [ 0.02359774,  0.00084564, -0.01197014, ..., -0.01030002,\n",
       "          -0.00334228,  0.02496037],\n",
       "         [-0.01860187, -0.01838612, -0.00071753, ..., -0.02279318,\n",
       "           0.02172718,  0.00557131],\n",
       "         [ 0.01934800,  0.00278352, -0.03000656, ..., -0.00392480,\n",
       "          -0.03824690, -0.03961597]]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [-0.00044825, -0.00129102,  0.00302879, ..., -0.00072800,\n",
       "          0.00095159,  0.00117169]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [1.00038505, 1.00395548, 1.00212753, ..., 1.00243676, 1.00760233,\n",
       "         1.01096737]),\n",
       " Parameter containing:\n",
       " Tensor(shape=[1024], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
       "        [0.00265833, 0.00365360, 0.00819926, ..., 0.00071323, 0.00510949,\n",
       "         0.00890807])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e85e93f0-61e0-41e8-9f1c-b774969419e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T03:32:00.765656Z",
     "iopub.status.busy": "2023-01-10T03:32:00.764919Z",
     "iopub.status.idle": "2023-01-10T03:32:00.770163Z",
     "shell.execute_reply": "2023-01-10T03:32:00.769239Z",
     "shell.execute_reply.started": "2023-01-10T03:32:00.765604Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 此时modelpredict参数不变\n",
    "modelpredict = prompt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b56bd2b-88fe-432f-b3c5-69da2f8abbe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:57:54.611215Z",
     "iopub.status.busy": "2023-01-10T04:57:54.610464Z",
     "iopub.status.idle": "2023-01-10T04:57:54.616340Z",
     "shell.execute_reply": "2023-01-10T04:57:54.615508Z",
     "shell.execute_reply.started": "2023-01-10T04:57:54.611169Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_vocab = [\"Self-direction: thought\",\"Self-direction: action\",\"Stimulation\",\"Hedonism\",\"Achievement\",\"Power: dominance\",\"Power: resources\",\"Face\",\"Security: personal\",\"Security: societal\",\"Tradition\",\"Conformity: rules\",\"Conformity: interpersonal\",\"Humility\",\"Benevolence: caring\",\"Benevolence: dependability\",\"Universalism: concern\",\"Universalism: nature\",\"Universalism: tolerance\",\"Universalism: objectivity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a79b6f00-9e6f-4c3b-b15e-7179d525548a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T04:39:22.137906Z",
     "iopub.status.busy": "2023-01-10T04:39:22.136504Z",
     "iopub.status.idle": "2023-01-10T04:39:38.055464Z",
     "shell.execute_reply": "2023-01-10T04:39:38.054492Z",
     "shell.execute_reply.started": "2023-01-10T04:39:22.137861Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 12:39:22,139] [    INFO] - ***** Running Prediction *****\r\n",
      "[2023-01-10 12:39:22,143] [    INFO] -   Num examples = 1576\r\n",
      "[2023-01-10 12:39:22,145] [    INFO] -   Total prediction steps = 197\r\n",
      "[2023-01-10 12:39:22,147] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 12:39:22,150] [    INFO] -   Total Batch size = 8\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95a5e2ddf5e495c8583d7c524f5d0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction.\n",
    "test_ret = trainer.predict(test_ds)\n",
    "#trainer.log_metrics(\"dev\", dev_ret.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8762dd1a-6cdd-47b2-b5d6-d34bf0df96bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T05:43:15.103267Z",
     "iopub.status.busy": "2023-01-10T05:43:15.102617Z",
     "iopub.status.idle": "2023-01-10T05:43:20.622700Z",
     "shell.execute_reply": "2023-01-10T05:43:20.621761Z",
     "shell.execute_reply.started": "2023-01-10T05:43:15.103220Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logits = test_ret[0][0]\n",
    "# probs = F.sigmoid(paddle.to_tensor(logits))\n",
    "# results = []\n",
    "# for prob in probs:\n",
    "#         result = []\n",
    "#         for c, pred in enumerate(prob):\n",
    "#             if pred > 0.5:\n",
    "#                 result.append(label_vocab[c])\n",
    "#                 # result.append(str(c))\n",
    "#                 # # result.append(str(c))\n",
    "#         results.append(','.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "11b22737-a1dd-41f0-9c04-53e6c41b2113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T05:59:13.882620Z",
     "iopub.status.busy": "2023-01-10T05:59:13.881223Z",
     "iopub.status.idle": "2023-01-10T05:59:16.239229Z",
     "shell.execute_reply": "2023-01-10T05:59:16.238070Z",
     "shell.execute_reply.started": "2023-01-10T05:59:13.882569Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-10 13:59:13,884] [    INFO] - ***** Running Prediction *****\r\n",
      "[2023-01-10 13:59:13,887] [    INFO] -   Num examples = 279\r\n",
      "[2023-01-10 13:59:13,890] [    INFO] -   Total prediction steps = 35\r\n",
      "[2023-01-10 13:59:13,891] [    INFO] -   Pre device batch size = 8\r\n",
      "[2023-01-10 13:59:13,893] [    INFO] -   Total Batch size = 8\r\n"
     ]
    }
   ],
   "source": [
    "test2_ret = trainer.predict(test2_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e0161338-9180-4c23-b351-ea7a146b52b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T06:00:58.992650Z",
     "iopub.status.busy": "2023-01-10T06:00:58.991927Z",
     "iopub.status.idle": "2023-01-10T06:00:58.998766Z",
     "shell.execute_reply": "2023-01-10T06:00:58.997851Z",
     "shell.execute_reply.started": "2023-01-10T06:00:58.992606Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def computeResult(test_ret):\n",
    "    logits = test_ret[0][0]\n",
    "    probs = F.sigmoid(paddle.to_tensor(logits))\n",
    "    results = []\n",
    "    for prob in probs:\n",
    "            result = []\n",
    "            for c, pred in enumerate(prob):\n",
    "                if pred > 0.5:\n",
    "                    result.append(label_vocab[c])\n",
    "            results.append(','.join(result))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ee259-e555-4d51-bb69-8c13eacdc676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = computeResult(test_ret)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fcb005ea-9805-4e7f-af03-65dc9edabcc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T06:01:33.805096Z",
     "iopub.status.busy": "2023-01-10T06:01:33.804434Z",
     "iopub.status.idle": "2023-01-10T06:01:34.776388Z",
     "shell.execute_reply": "2023-01-10T06:01:34.775549Z",
     "shell.execute_reply.started": "2023-01-10T06:01:33.805049Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self-direction: thought',\n",
       " 'Conformity: rules,Humility,Benevolence: caring,Universalism: concern',\n",
       " 'Self-direction: action',\n",
       " 'Security: societal,Universalism: concern',\n",
       " 'Security: societal,Benevolence: dependability',\n",
       " 'Self-direction: action,Security: personal,Conformity: interpersonal,Universalism: concern',\n",
       " 'Face,Benevolence: caring',\n",
       " 'Face,Benevolence: caring',\n",
       " 'Achievement,Face,Security: personal,Benevolence: caring,Universalism: tolerance',\n",
       " 'Universalism: objectivity',\n",
       " '',\n",
       " 'Conformity: rules',\n",
       " 'Conformity: rules',\n",
       " 'Conformity: rules,Benevolence: dependability,Universalism: concern',\n",
       " 'Achievement,Security: personal,Conformity: rules,Benevolence: dependability',\n",
       " 'Conformity: rules,Benevolence: caring,Benevolence: dependability',\n",
       " 'Conformity: rules,Humility',\n",
       " 'Face,Security: societal,Benevolence: caring,Benevolence: dependability,Universalism: tolerance',\n",
       " 'Achievement,Conformity: rules,Benevolence: caring,Benevolence: dependability',\n",
       " 'Security: personal,Security: societal,Universalism: concern',\n",
       " 'Power: dominance,Benevolence: caring,Benevolence: dependability,Universalism: concern',\n",
       " 'Benevolence: dependability',\n",
       " 'Self-direction: action,Achievement,Benevolence: dependability',\n",
       " 'Self-direction: action,Achievement',\n",
       " '',\n",
       " 'Conformity: rules,Benevolence: caring,Benevolence: dependability,Universalism: concern,Universalism: objectivity',\n",
       " 'Achievement',\n",
       " 'Benevolence: dependability,Universalism: objectivity',\n",
       " 'Achievement,Face',\n",
       " 'Tradition,Conformity: rules',\n",
       " 'Security: societal',\n",
       " 'Face,Security: personal,Conformity: rules,Universalism: concern',\n",
       " 'Benevolence: dependability,Universalism: objectivity',\n",
       " 'Conformity: rules,Conformity: interpersonal',\n",
       " 'Universalism: objectivity',\n",
       " 'Self-direction: thought,Achievement,Universalism: objectivity',\n",
       " 'Self-direction: thought,Self-direction: action,Achievement',\n",
       " 'Hedonism,Security: personal',\n",
       " 'Hedonism,Security: personal',\n",
       " 'Hedonism,Security: personal',\n",
       " 'Self-direction: thought,Self-direction: action,Security: personal',\n",
       " 'Self-direction: action,Achievement,Security: personal,Universalism: concern',\n",
       " 'Achievement,Security: personal',\n",
       " 'Conformity: rules,Universalism: concern',\n",
       " 'Benevolence: caring,Universalism: concern',\n",
       " 'Tradition,Benevolence: caring,Benevolence: dependability,Universalism: concern,Universalism: objectivity',\n",
       " 'Universalism: concern',\n",
       " 'Achievement,Face',\n",
       " 'Self-direction: action,Tradition,Universalism: concern,Universalism: objectivity',\n",
       " 'Security: personal,Universalism: nature',\n",
       " 'Security: personal',\n",
       " 'Benevolence: caring',\n",
       " 'Self-direction: action,Achievement,Security: personal',\n",
       " 'Security: societal,Humility',\n",
       " 'Achievement,Universalism: concern',\n",
       " 'Achievement,Universalism: concern,Universalism: objectivity',\n",
       " 'Conformity: rules,Humility,Universalism: concern',\n",
       " 'Self-direction: thought,Self-direction: action,Security: societal,Universalism: concern',\n",
       " 'Face,Security: personal,Humility,Universalism: concern',\n",
       " 'Self-direction: action,Security: societal,Conformity: rules,Humility,Universalism: concern,Universalism: tolerance',\n",
       " 'Self-direction: action,Achievement,Security: personal',\n",
       " 'Conformity: rules,Universalism: concern',\n",
       " 'Benevolence: caring,Universalism: concern',\n",
       " 'Security: societal,Conformity: rules,Benevolence: caring,Benevolence: dependability,Universalism: concern',\n",
       " 'Tradition,Conformity: rules,Universalism: tolerance',\n",
       " 'Tradition,Benevolence: caring,Universalism: tolerance',\n",
       " 'Conformity: rules',\n",
       " 'Conformity: rules,Benevolence: caring,Benevolence: dependability',\n",
       " '',\n",
       " 'Self-direction: thought,Self-direction: action,Face,Conformity: rules',\n",
       " 'Universalism: concern',\n",
       " 'Security: personal,Conformity: rules',\n",
       " 'Universalism: concern',\n",
       " 'Stimulation,Benevolence: caring,Benevolence: dependability',\n",
       " 'Security: societal,Universalism: concern,Universalism: objectivity',\n",
       " 'Humility,Benevolence: caring,Universalism: objectivity',\n",
       " 'Security: societal,Benevolence: dependability',\n",
       " 'Self-direction: action,Tradition,Benevolence: caring,Universalism: concern',\n",
       " 'Power: dominance,Benevolence: dependability',\n",
       " 'Self-direction: thought,Self-direction: action,Benevolence: caring',\n",
       " 'Security: personal',\n",
       " '',\n",
       " 'Hedonism,Security: personal,Tradition,Universalism: concern',\n",
       " 'Achievement,Security: personal,Universalism: concern',\n",
       " 'Achievement,Power: resources,Security: personal',\n",
       " 'Achievement,Security: personal,Benevolence: dependability',\n",
       " 'Security: personal,Security: societal,Benevolence: caring',\n",
       " 'Achievement',\n",
       " 'Achievement,Face',\n",
       " 'Self-direction: thought,Achievement,Benevolence: caring,Benevolence: dependability,Universalism: objectivity',\n",
       " 'Achievement,Benevolence: caring',\n",
       " 'Achievement,Benevolence: dependability,Universalism: objectivity',\n",
       " 'Self-direction: thought,Security: societal,Benevolence: dependability,Universalism: tolerance,Universalism: objectivity',\n",
       " 'Tradition',\n",
       " 'Universalism: concern,Universalism: objectivity',\n",
       " 'Self-direction: thought,Self-direction: action,Achievement,Universalism: objectivity',\n",
       " 'Benevolence: caring,Benevolence: dependability',\n",
       " 'Self-direction: action,Security: societal,Benevolence: caring,Benevolence: dependability',\n",
       " 'Conformity: rules,Humility',\n",
       " 'Self-direction: action',\n",
       " 'Face,Conformity: rules,Benevolence: caring',\n",
       " 'Security: societal,Benevolence: caring,Universalism: concern',\n",
       " 'Conformity: interpersonal,Universalism: objectivity',\n",
       " 'Face,Security: personal',\n",
       " 'Security: societal,Conformity: rules',\n",
       " 'Tradition,Benevolence: dependability,Universalism: concern',\n",
       " 'Face,Conformity: rules,Benevolence: dependability',\n",
       " 'Security: personal,Benevolence: caring,Universalism: concern',\n",
       " 'Achievement,Security: personal,Benevolence: caring',\n",
       " 'Security: personal,Benevolence: caring,Universalism: concern',\n",
       " 'Conformity: rules,Universalism: concern,Universalism: objectivity',\n",
       " 'Self-direction: action,Benevolence: caring,Universalism: concern',\n",
       " 'Tradition,Benevolence: caring,Universalism: concern',\n",
       " 'Tradition,Universalism: concern',\n",
       " 'Face,Security: personal,Universalism: concern',\n",
       " 'Self-direction: action,Achievement,Power: dominance',\n",
       " 'Benevolence: caring,Benevolence: dependability,Universalism: concern,Universalism: objectivity',\n",
       " 'Achievement,Conformity: rules,Benevolence: dependability',\n",
       " '',\n",
       " 'Security: societal,Benevolence: caring,Benevolence: dependability',\n",
       " 'Power: dominance,Tradition,Benevolence: caring,Universalism: tolerance',\n",
       " 'Self-direction: thought',\n",
       " 'Self-direction: action,Security: personal,Conformity: interpersonal,Benevolence: caring',\n",
       " 'Benevolence: caring,Benevolence: dependability',\n",
       " 'Security: societal,Benevolence: caring',\n",
       " 'Conformity: rules,Benevolence: caring,Universalism: concern',\n",
       " 'Security: personal,Security: societal,Universalism: concern,Universalism: tolerance',\n",
       " 'Self-direction: action,Security: societal',\n",
       " 'Security: societal,Conformity: rules,Universalism: concern',\n",
       " 'Self-direction: action,Benevolence: caring',\n",
       " 'Security: societal,Benevolence: caring,Benevolence: dependability,Universalism: concern',\n",
       " 'Benevolence: caring,Universalism: objectivity',\n",
       " 'Self-direction: action,Universalism: concern',\n",
       " 'Benevolence: caring',\n",
       " 'Security: personal,Conformity: interpersonal,Benevolence: caring,Universalism: tolerance',\n",
       " 'Tradition,Benevolence: caring,Universalism: concern,Universalism: tolerance',\n",
       " 'Security: personal,Benevolence: caring',\n",
       " 'Security: personal,Humility,Benevolence: caring,Benevolence: dependability,Universalism: tolerance',\n",
       " 'Benevolence: dependability,Universalism: concern,Universalism: tolerance,Universalism: objectivity',\n",
       " 'Tradition,Universalism: concern',\n",
       " 'Security: personal,Security: societal,Benevolence: caring,Benevolence: dependability',\n",
       " 'Tradition,Humility,Benevolence: dependability,Universalism: concern,Universalism: objectivity',\n",
       " 'Humility,Benevolence: caring,Benevolence: dependability',\n",
       " 'Conformity: interpersonal,Benevolence: caring,Universalism: concern',\n",
       " 'Self-direction: action,Security: personal,Conformity: interpersonal,Benevolence: caring',\n",
       " 'Achievement,Face',\n",
       " 'Achievement,Universalism: concern,Universalism: objectivity',\n",
       " 'Tradition,Conformity: rules,Benevolence: dependability',\n",
       " 'Tradition,Conformity: rules,Universalism: concern',\n",
       " 'Tradition',\n",
       " 'Achievement,Benevolence: caring',\n",
       " 'Tradition,Universalism: concern',\n",
       " 'Security: societal,Universalism: concern,Universalism: objectivity',\n",
       " 'Face,Security: societal,Conformity: rules,Universalism: concern',\n",
       " 'Self-direction: action,Security: personal',\n",
       " 'Security: personal,Benevolence: dependability',\n",
       " '',\n",
       " 'Self-direction: action,Humility,Universalism: tolerance,Universalism: objectivity',\n",
       " 'Self-direction: action,Conformity: rules,Conformity: interpersonal,Universalism: objectivity',\n",
       " 'Achievement,Conformity: rules,Benevolence: caring',\n",
       " 'Self-direction: thought,Universalism: objectivity',\n",
       " 'Security: societal,Benevolence: caring,Benevolence: dependability,Universalism: concern',\n",
       " 'Self-direction: action,Security: societal,Conformity: rules,Benevolence: dependability',\n",
       " 'Conformity: rules,Benevolence: dependability,Universalism: tolerance,Universalism: objectivity',\n",
       " 'Security: societal,Conformity: rules,Universalism: objectivity',\n",
       " 'Stimulation,Conformity: rules',\n",
       " 'Self-direction: thought,Security: societal,Universalism: concern,Universalism: objectivity',\n",
       " 'Achievement,Universalism: concern,Universalism: objectivity',\n",
       " 'Security: societal,Universalism: concern',\n",
       " 'Achievement,Security: personal,Benevolence: dependability',\n",
       " 'Power: resources,Security: personal,Security: societal',\n",
       " 'Self-direction: action,Conformity: rules',\n",
       " 'Conformity: interpersonal',\n",
       " 'Self-direction: thought,Achievement,Universalism: objectivity',\n",
       " 'Face,Benevolence: dependability,Universalism: concern',\n",
       " 'Benevolence: caring',\n",
       " 'Achievement,Benevolence: caring',\n",
       " 'Security: societal,Conformity: rules',\n",
       " 'Security: personal,Security: societal',\n",
       " 'Achievement,Benevolence: caring,Universalism: objectivity',\n",
       " 'Security: personal,Benevolence: caring',\n",
       " 'Self-direction: action,Humility,Universalism: tolerance,Universalism: objectivity',\n",
       " 'Self-direction: action,Universalism: concern',\n",
       " 'Universalism: concern,Universalism: tolerance,Universalism: objectivity',\n",
       " 'Self-direction: action,Achievement,Benevolence: dependability,Universalism: objectivity',\n",
       " 'Self-direction: thought,Achievement,Face,Benevolence: dependability',\n",
       " 'Self-direction: thought,Achievement,Conformity: rules,Benevolence: caring,Universalism: concern,Universalism: objectivity',\n",
       " 'Self-direction: thought,Achievement,Universalism: objectivity',\n",
       " 'Self-direction: thought,Achievement,Tradition,Universalism: tolerance',\n",
       " 'Hedonism,Security: personal,Benevolence: caring',\n",
       " 'Self-direction: thought,Achievement',\n",
       " 'Self-direction: thought,Power: resources,Benevolence: caring,Universalism: concern',\n",
       " 'Achievement,Power: dominance,Security: personal,Tradition,Benevolence: caring,Universalism: concern',\n",
       " 'Achievement,Universalism: concern,Universalism: objectivity',\n",
       " 'Power: resources',\n",
       " 'Self-direction: thought,Conformity: rules,Benevolence: caring,Benevolence: dependability,Universalism: tolerance,Universalism: objectivity',\n",
       " '',\n",
       " 'Achievement,Universalism: tolerance',\n",
       " 'Universalism: concern,Universalism: tolerance',\n",
       " '',\n",
       " 'Security: societal,Benevolence: caring',\n",
       " 'Security: personal,Benevolence: caring',\n",
       " 'Tradition,Benevolence: caring',\n",
       " 'Face,Conformity: rules,Universalism: objectivity',\n",
       " 'Self-direction: thought,Achievement,Universalism: objectivity',\n",
       " 'Security: societal,Benevolence: caring',\n",
       " 'Self-direction: action,Achievement,Power: dominance,Universalism: objectivity',\n",
       " 'Achievement,Universalism: objectivity',\n",
       " 'Self-direction: action,Achievement,Power: dominance,Universalism: objectivity',\n",
       " 'Face,Benevolence: caring,Universalism: concern',\n",
       " 'Achievement,Power: dominance,Universalism: objectivity',\n",
       " 'Self-direction: thought,Achievement,Benevolence: dependability,Universalism: objectivity',\n",
       " 'Self-direction: action,Power: dominance,Humility',\n",
       " 'Self-direction: thought,Self-direction: action,Conformity: rules,Benevolence: dependability',\n",
       " 'Achievement',\n",
       " 'Self-direction: action,Security: societal,Tradition,Conformity: rules',\n",
       " 'Self-direction: action,Stimulation,Achievement',\n",
       " 'Self-direction: action,Face,Security: personal,Conformity: rules',\n",
       " 'Self-direction: thought,Achievement,Universalism: objectivity',\n",
       " 'Security: societal',\n",
       " 'Benevolence: dependability',\n",
       " 'Security: societal,Universalism: concern',\n",
       " 'Self-direction: thought,Achievement,Universalism: tolerance',\n",
       " 'Achievement',\n",
       " 'Tradition,Benevolence: caring,Universalism: tolerance',\n",
       " 'Face,Conformity: rules',\n",
       " 'Face,Conformity: rules,Humility,Benevolence: caring,Benevolence: dependability,Universalism: concern',\n",
       " 'Security: personal,Conformity: interpersonal,Benevolence: caring,Universalism: concern',\n",
       " 'Self-direction: action,Power: resources',\n",
       " 'Self-direction: action,Conformity: rules,Benevolence: dependability,Universalism: objectivity',\n",
       " 'Face,Tradition,Universalism: concern',\n",
       " 'Security: personal,Humility,Universalism: concern',\n",
       " 'Power: resources,Tradition,Universalism: concern',\n",
       " 'Achievement',\n",
       " 'Self-direction: thought,Achievement,Universalism: objectivity',\n",
       " 'Power: dominance,Security: societal,Benevolence: dependability',\n",
       " 'Security: societal,Benevolence: caring',\n",
       " 'Self-direction: action,Security: societal,Benevolence: dependability',\n",
       " 'Achievement,Security: personal,Conformity: rules',\n",
       " 'Security: personal,Conformity: rules',\n",
       " 'Hedonism,Security: personal,Conformity: rules',\n",
       " 'Hedonism,Security: personal',\n",
       " 'Benevolence: caring',\n",
       " 'Security: personal,Tradition,Benevolence: caring',\n",
       " 'Security: personal,Benevolence: caring',\n",
       " 'Security: personal,Conformity: rules,Benevolence: dependability',\n",
       " 'Face,Security: personal,Universalism: concern',\n",
       " 'Achievement,Security: personal,Benevolence: caring,Universalism: concern,Universalism: tolerance',\n",
       " 'Achievement,Security: societal,Benevolence: dependability',\n",
       " 'Conformity: rules,Benevolence: caring,Benevolence: dependability',\n",
       " 'Self-direction: action,Benevolence: dependability',\n",
       " 'Achievement,Benevolence: caring,Universalism: tolerance,Universalism: objectivity',\n",
       " 'Achievement,Benevolence: caring,Benevolence: dependability',\n",
       " 'Self-direction: thought,Achievement,Benevolence: dependability',\n",
       " 'Achievement,Benevolence: dependability,Universalism: objectivity',\n",
       " 'Benevolence: dependability,Universalism: objectivity',\n",
       " 'Self-direction: thought,Self-direction: action,Achievement,Power: resources,Face,Benevolence: caring',\n",
       " 'Face,Security: personal,Benevolence: caring',\n",
       " 'Security: personal,Benevolence: caring,Benevolence: dependability',\n",
       " 'Self-direction: thought,Benevolence: caring',\n",
       " 'Benevolence: caring',\n",
       " 'Security: personal,Benevolence: caring',\n",
       " 'Face,Conformity: rules,Conformity: interpersonal,Universalism: tolerance',\n",
       " 'Hedonism,Security: personal,Benevolence: caring',\n",
       " 'Achievement,Face,Security: societal,Conformity: rules,Benevolence: dependability',\n",
       " 'Benevolence: caring',\n",
       " 'Achievement,Benevolence: caring,Benevolence: dependability',\n",
       " 'Self-direction: action,Security: personal,Conformity: rules,Benevolence: caring',\n",
       " 'Hedonism,Security: personal',\n",
       " 'Self-direction: action',\n",
       " 'Security: personal,Benevolence: caring,Universalism: concern',\n",
       " 'Achievement,Power: resources,Benevolence: dependability',\n",
       " 'Self-direction: thought,Power: dominance,Security: personal,Conformity: rules',\n",
       " 'Power: dominance,Security: societal',\n",
       " 'Achievement,Face',\n",
       " 'Security: societal',\n",
       " 'Conformity: rules,Benevolence: dependability,Universalism: concern',\n",
       " 'Self-direction: action,Universalism: concern',\n",
       " 'Self-direction: thought,Achievement,Universalism: tolerance']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = computeResult(test2_ret)\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b04046ca-8afc-49e0-9c22-ae13100a37f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T05:41:51.275634Z",
     "iopub.status.busy": "2023-01-10T05:41:51.274881Z",
     "iopub.status.idle": "2023-01-10T05:41:51.284179Z",
     "shell.execute_reply": "2023-01-10T05:41:51.283130Z",
     "shell.execute_reply.started": "2023-01-10T05:41:51.275586Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def result2tsv(result1,filepath):\n",
    "    validData = pd.read_csv(filepath,sep='\\t')\n",
    "    dictvalidT =validData.to_dict(\"list\")\n",
    "\n",
    "    validPred = {}\n",
    "    validPred[\"Argument ID\"] = dictvalidT[\"Argument ID\"]\n",
    "    validPred[\"sentence\"] = dictvalidT[\"sentence\"]\n",
    "\n",
    "    for x in label_vocab:\n",
    "        validPred[x] = []\n",
    "    \n",
    "    for x in range(len(result1)):\n",
    "        types = result1[x].split(\",\")\n",
    "        if types == ['']:\n",
    "            for y in label_vocab:\n",
    "                validPred[y].append(0)\n",
    "        else:  \n",
    "            for z in label_vocab:\n",
    "                if z in types:\n",
    "                    validPred[z].append(1)\n",
    "                else:\n",
    "                    validPred[z].append(0)\n",
    "    validData = pd.read_csv(filepath,sep='\\t')\n",
    "    for x in label_vocab:\n",
    "        for y in range(len(validData[x])):\n",
    "            validData[x].iloc[y] = validPred[x][y]\n",
    "    \n",
    "    validData.drop(columns=[\"sentence\"],inplace=True)\n",
    "    return validData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "08f3b7d4-0d6a-4d73-a2ab-b22a24927f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T06:03:17.318729Z",
     "iopub.status.busy": "2023-01-10T06:03:17.318015Z",
     "iopub.status.idle": "2023-01-10T06:03:17.328152Z",
     "shell.execute_reply": "2023-01-10T06:03:17.327082Z",
     "shell.execute_reply.started": "2023-01-10T06:03:17.318670Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data\r\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c457d62-cbf7-4c7a-be9d-17d6be6357a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T05:41:53.079126Z",
     "iopub.status.busy": "2023-01-10T05:41:53.078385Z",
     "iopub.status.idle": "2023-01-10T05:41:56.955941Z",
     "shell.execute_reply": "2023-01-10T05:41:56.954867Z",
     "shell.execute_reply.started": "2023-01-10T05:41:53.079081Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "valid = result2tsv(resultsdev,\"validation.tsv\")\n",
    "valid.to_csv('validERNIE2.0Prompt.tsv',columns=valid.columns.tolist(),\n",
    "            sep='\\t',\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "46e928a4-532f-4651-991f-8e1c434ff8ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T06:04:30.616289Z",
     "iopub.status.busy": "2023-01-10T06:04:30.615562Z",
     "iopub.status.idle": "2023-01-10T06:04:30.623579Z",
     "shell.execute_reply": "2023-01-10T06:04:30.622777Z",
     "shell.execute_reply.started": "2023-01-10T06:04:30.616233Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testOutput(results2,filepath):\n",
    "    testData = pd.read_csv(filepath,sep='\\t')\n",
    "    dicttestT =testData.to_dict(\"list\")\n",
    "\n",
    "    testPred = {}\n",
    "    testPred[\"Argument ID\"] = dicttestT[\"Argument ID\"]\n",
    "    testPred[\"sentence\"] = dicttestT[\"sentence\"]\n",
    "\n",
    "    for x in label_vocab:\n",
    "        testPred[x] = []\n",
    "\n",
    "    for x in range(len(results2)):\n",
    "        types = results2[x].split(\",\")\n",
    "        if types == ['']:\n",
    "            for y in label_vocab:\n",
    "                testPred[y].append(0)\n",
    "        else:  \n",
    "            for z in label_vocab:\n",
    "                if z in types:\n",
    "                    testPred[z].append(1)\n",
    "                else:\n",
    "                    testPred[z].append(0)\n",
    "    testPredD = pd.DataFrame.from_dict(testPred)\n",
    "    testPredD.drop(columns=[\"sentence\"],inplace=True)\n",
    "\n",
    "    return testPredD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89e68c67-3af6-41da-942e-a0918f3a9b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T05:43:46.385771Z",
     "iopub.status.busy": "2023-01-10T05:43:46.385082Z",
     "iopub.status.idle": "2023-01-10T05:43:46.419529Z",
     "shell.execute_reply": "2023-01-10T05:43:46.418385Z",
     "shell.execute_reply.started": "2023-01-10T05:43:46.385723Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = testOutput(results,\"test.tsv\")\n",
    "test.to_csv('testErnie2.0Prompt.tsv',columns=test.columns.tolist(),\n",
    "            sep='\\t',\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2701777a-bd1b-43a2-896c-288ca1dd46a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T06:04:35.463525Z",
     "iopub.status.busy": "2023-01-10T06:04:35.462016Z",
     "iopub.status.idle": "2023-01-10T06:04:35.482404Z",
     "shell.execute_reply": "2023-01-10T06:04:35.481326Z",
     "shell.execute_reply.started": "2023-01-10T06:04:35.463461Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test2 = testOutput(results2,\"test2.tsv\")\n",
    "test2.to_csv('test222Ernie2.0Prompt.tsv',columns=test2.columns.tolist(),\n",
    "            sep='\\t',\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d212086-ae9d-4179-8766-16d1a14ec901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
